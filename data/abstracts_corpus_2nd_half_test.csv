cs,en
"Prezentujeme úvod do strojového učení prostřednictvím úlohy počítačového zpracování přirozeného jazyka, a sice přiřazení správného významu slov ve větách. Zaměřujeme se hlavně na praktické aspekty v systému R. Článek je urče studentům a mladým vědcům, kteří nemají znalosti  strojového učení a chtějí začít.","We present a gentle introduction to machine learning  and we explain it on its application in the field of natural language processing. Namely, we address the task of word sense disambiguation practically in the R software system. We focus on readers who approach some task and want to use machine learning, and who do not know how to start."
"Tento funkční vzorek slouží pro vícejazyčné (české a anglické) vyhledávání relevantních slov či krátkých frází v archivu přeživších Holocaustu, spravovaném USC (University of Southern California) Shoah Foundation Institute (http://dornsife.usc.edu/vhi/). Tento archiv obsahuje více než 110 tisíc hodin záznamů v 32 jazycích, přičemž přibližně polovina těchto rozhovorů je vedena v angličtině. Česká část archivu obnáší zhruba jeden tisíc hodin. Funkční vzorek se skládá ze serverového počítače, softwarových modulů MCLASS (http://www.kky.zcu.cz/cs/sw/MCLAAS), WFBAS (http://www.kky.zcu.cz/cs/sw/WFBAS), pracovní databáze sestavené softwary SEASR-CZE (http://www.kky.zcu.cz/cs/sw/SEASR-CZE) a SEASR-ENG (http://www.kky.zcu.cz/cs/sw/SEASR-ENG) a tenkého klienta s obvyklým webovým prohlížečem. Serverový počítač je počítač s konfigurací odpovídající náročnosti vykonávané úlohy s připojením k internetu. Počítač použitý pro funkční vzorek má 2 procesory Intel(R) Xeon(R) CPU E5-2620 v2 @ 2.10GHz. Pro účely vyhledávání v systému jsou česká a anglická řečová data nejprve zpracována příslušným modulem rozpoznávání řeči (SEASR-CZE, resp. SEASR-ENG).. Každý ze systémů v současnosti hledá výskyty slov či frází zhruba v 1000 hodin videozáznamů. V případě češtiny jde o veškerá dostupná data; v angličtině je k dispozici více než 50 tisíc hodin, ale rozpoznání a zaindexování celého tohoto objemu bude vyžadovat paralelizaci jednotlivých procesů. Pro křížové vyhledávání (dotaz v češtině, data/rozhovory v angličtině a češtině) v softwaru byl použit systém překladu dotazu. Implementace byla provedena jako zvláštní verze systému MTMonkey (http://ufal.mff.cuni.cz/mtmonkey)","This functional prototype is used for multi-lingual (Czech and English) search for relevant words or short phrases in the archive of Holocaust survivors, managed by USC (University of Southern California) Shoah Foundation Institute (http://dornsife.usc.edu/vhi/), which contains more than 110,000 hours of records in 32 languages, with approximately half of these interviews is conducted in English. Czech part of the archive accounts for approximately one thousand hours. For the purposes of searching in the system MCLAAS are Czech and English speech data first processed with the appropriate speech recognition module (SEASR-CZE - see http://www.kky.zcu.cz/en/sw/SEASR-CZE or SEASR-ENG - see http://www.kky.zcu.cz/en/sw/SEASR-ENG) and then a so-called index is created, which is a machine representation of recognized utterances, which speeds up the search for a desired word or phrase. Those are all data available in the case of Czech; in English there are more than 50,000 hours, but the recognition and indexing of all this volume will require parallelization of individual processes. Cross-searching (query in English, data / interviews in English and Czech) in the system is facilitated by automatic query translation. Implementation was carried out as a special version of MTMonkey (http://ufal.mff.cuni.cz/mtmonkey)."
"Článek popisuje probíhající experiment soustřeďující se na kvantifikaci slovosledných vlastností tří indoevropských jazyků, češtiny, angličtiny a němčiny. Statistiky jsou získávány ze syntakticky anotovaných korpusů za pomoci dotazovacího jazyka PML-TQ.
tato studie slouží jako motivace pro formální modelování metod NLP.","The paper describes an ongoing experiment
consisting in the attempt to quantify word-order properties of three Indo-European languages (Czech, English and German). The statistics are collected from the syntactically annotated treebanks available for all three languages.
The treebanks are searched by means of a universal query tool PML-TQ. The search concentrates on the mutual order of a verb and its complements (subject, object(s)) and the statistics are calculated for all permutations of the three elements. The results for all three languages are compared and a measure expressing the degree of word order freedom is suggested in the final section of the paper.
This study constitutes a motivation for formal modeling of natural language processing methods."
"Článek popisuje experiment soustřeďující se na zkoumání a kvantifikaci slovosledných vlastností na základě dat dostupných díky projektu HamleDT.
Tato studie usiluje o objektivní porovnání přirozených jazyků, a to kombinováním jak hledisek čistě lingvistických, tak hledisek kvantitativních, která jsou založena na velkém souboru dostupných dat. 
Tato studie slouží jako motivace pro formální modelování metod NLP; zároveň si klade za cíl představit výzkumný potenciál jazykových zdrojů se standardizovanou anotací.","The paper describes an experiment consisting in the attempt to quantify word-order properties of three Indo-European languages (Czech, English and Farsi). The investigation is driven by the
endeavor to find an objective way how to compare natural languages from the point of view of the degree of their word-order freedom. Unlike
similar studies which concentrate either on purely linguistic or purely statistical approach, our experiment tries to combine both - the observations are verified against large samples of sentences from available treebanks, and, at the same time, we exploit the ability of our tools to analyze selected important phenomena (as, e.g., the differences of the word order of a main and a subordinate clause) more deeply.
The quantitative results of our research are collected from the syntactically annotated treebanks available for all three languages. Thanks to the HamleDT project, it is possible to search all treebanks in a uniform way by means of a universal query tool PML-TQ. This is also a secondary goal of this paper - to demonstrate the research potential provided by language resources which are to a certain extent unified."
Tento článek shrnuje experimenty týkající se automatické analýzy koordinačních a apozičních konstrukcí v Pražském závislostním korpuse na základě metody redukční analýzy.,"This  paper  summarizes  results  of  automatic  analysis of  coordinating  constructions  and  appositions  in  the Prague Dependency Treebank using a method of analysis by reduction. Experiments are performed on a large subset of the treebank. This subset is obtained as a result
of a query providing a set of more than 4,300 suitable sentences and their tree structures containing coordinations and appositions. The automatic procedure is complemented by a manual analysis of reasons why certain sentences (trees) were not fully reduced. This analysis helps to gain a better insight into the phenomena of co-
ordination and apposition and their formal properties."
"Spolu se vznikem stále dalších jazykových zdrojů – slovníků, lexikálních databází, korpusů, treebanků – roste i potřeba jejich účinného propojování, které by umožnilo snadné využití veškerých shromážděných vlastností a informací. V tomto ohledu je také aktuální téma univerzálních lexikografických formátů.

Tato práce zkoumá metody automatického propojování jazykových dat. Představíme zde systém na propojování slovníků, jakými jsou například VALLEX, PDT-Vallex, FrameNet, nebo SemLex, které poskytují syntaktickou informaci o svých heslech. Systém je automatický, umožňuje tudíž opakovanou aplikaci na novější verze vyvíjejících se jazykových zdrojů. Na základě syntaktické informace obsažené ve slovníku víceslovných výrazů SemLex navrhujeme metodu vyhledávající tyto výrazy v automaticky anotovaném textu.

Praktickým výstupem potvrzujícím úspěšnost použitých metod je mj. propojení slovníků VALLEX a PDT-Vallex vedoucí k doplnění desítek tisíc anotovaných vět z treebanků PDT a PCEDT do VALLEXu.","Along with the increasing development of language resources – i.e., new lexicons, lexical databases, corpora, treebanks – the need for their efficient interlinking is growing. With such a linking, one can easily benefit from all their properties and information. Considering the convergence of resources, universal lexicographic formats are frequently discussed.

In the present thesis, we investigate and analyse methods of interlinking language resources automatically. We introduce a system for interlinking lexicons (such as VALLEX, PDT-Vallex, FrameNet or SemLex) that offer information on syntactic properties of their entries. The system is automated and can be used repeatedly with newer versions of lexicons under development. We also design a method for identification of multiword expressions in a parsed text based on syntactic information from the SemLex lexicon.

An output that verifies feasibility of the used methods is, among others, the mapping between the VALLEX and the PDT-Vallex lexicons, resulting in tens of thousands of annotated treebank sentences from the PDT and the PCEDT treebanks added into VALLEX."
"Spojení slovníků na úrovni hesel či jejich částí přináší zpravidla rozšíření informací pro obě strany. Spojení českých valenčních slovníků VALLEX a PDT-Vallex přinese VALLEXu napojení na data PDT a tudíž desítky tisíc příkladových vět; PDT-Vallexu pak další syntakticko-sémantické informace (jako je reciprocita, kontrola, sémantická třída, ad.). Referát představí datový formát a postup použitý při propojování lexikálních jednotek a dosažené a zveřejněné výsledky.",Linking Czech valency lexicons VALLEX and PDT-Vallex will connect VALLEX with tens of thousands of example sentences in corpus data of PDT. The presentation will introduce the data format and the approach used to automatick linking and the published results.
"Sestavili jsme slovník víceslovných entit BBN a následně jsme jej využili ke kontrolám anotací (anotace WSJ, BBN, PCEDT).","We compiled a lexicon of multiword BBN entities and used it for consistency checking of annotations (WSJ, BBN and PDT annotations)."
"Po krátkém úvodu ilustrujícím bohatost české morfologie se v přednášce zaměřuji na způsob zachycení morfologických kategorií v Pražském závislostním korpusu. V druhé části přednášky se věnuji přehledu historie taggerů češtiny, rozpoznávání pojmenovaných entit v češtině a naší aktuální práci na budování lexikálního zdroje derivační morfologie češtiny.","After a brief introduction into the rich morphology of the Czech language, I focus on the multi-layered annotation scheme of the Prague Dependency Treebank. Morphological categories are described at a separate annotation layer. The meanings conveyed by this categories are involved in the deep-syntatic annotation layer as well. The semiautomatic annotation is illustrated by several examples in the talk. Development of Czech taggers, named entity recognition tools and our recent work on a resource of derivational morphology are outlined as a few topics based on Praguian morphology."
"Slovnědruhová kategorie a morfologické rysy tokenů jsou v Pražském závislostním korpusu zachyceny na zvláštní anotační rovině, významy vyjadřované morfologickými kategorie jsou ovšem také součástí hloubkově syntaktické roviny. V příspěvku podrobně představujeme zachycení morfologických kategorií v tomto korpusu a věnujeme se také aplikacím, pro které byla tato morfologicky anotovaná data použita.","Morphological annotation constitutes a separate layer in the multilayered annotation scenario of the Prague Dependency Treebank. At this layer, morphological categories expressed by a word form are captured in a positional part-of-speech tag. According to the Praguian approach based on the relation between form and function, functions (meanings) of morphological categories are represented as well, namely as grammateme attributes at the deep-syntactic (tectogrammatical) layer of the treebank. In the present paper, we first describe the role of morphology in the Prague Dependency Treebank, and then outline several recent topics based on Praguian morphology: named entity recognition in Czech, formemes attributes encoding morpho-syntactic information in the dependency-based machine translation system, and development of a lexical database of derivational relations based partially on information provided by the morphological analyser."
"Na přednášce bude představena lexikální síť DeriNet, která zachycuje derivační vztahy v morfologii češtiny.",The presentation will be focused on the lexical NetWork DeriNet that captures morphological derivations in Czech.
"Universal Dependencies je projekt, který vyvíjí mezijazykově konzistentní morfologicko-syntaktickou anotaci mnoha jazyků s cílem usnadnit vývoj jazykově nezávislých parserů, mezijazykové strojové učení a výzkum parsingu z perspektivy jazykové typologie. Anotační schéma je založeno na univerzálních Stanfordských závislostech (de Marneffe et al., 2006, 2008, 2014), univerzálních značkách Google (Petrov et al., 2012) a na Intersetu, tj. interlingvě pro sady morfologických značek (Zeman, 2008).","Universal Dependencies is a project that seeks to develop cross-linguistically consistent treebank annotation for many languages, with the goal of facilitating multilingual parser development, cross-lingual learning, and parsing research from a language typology perspective. The annotation scheme is based on (universal) Stanford dependencies (de Marneffe et al., 2006, 2008, 2014), Google universal part-of-speech tags (Petrov et al., 2012), and the Interset interlingua for morphosyntactic tagsets (Zeman, 2008)."
"Universal Dependencies je projekt, který vyvíjí mezijazykově konzistentní morfologicko-syntaktickou anotaci mnoha jazyků s cílem usnadnit vývoj jazykově nezávislých parserů, mezijazykové strojové učení a výzkum parsingu z perspektivy jazykové typologie. Anotační schéma je založeno na univerzálních Stanfordských závislostech (de Marneffe et al., 2006, 2008, 2014), univerzálních značkách Google (Petrov et al., 2012) a na Intersetu, tj. interlingvě pro sady morfologických značek (Zeman, 2008). Toto je třetí vydání treebanků UD, verze 1.2.","Universal Dependencies is a project that seeks to develop cross-linguistically consistent treebank annotation for many languages, with the goal of facilitating multilingual parser development, cross-lingual learning, and parsing research from a language typology perspective. The annotation scheme is based on (universal) Stanford dependencies (de Marneffe et al., 2006, 2008, 2014), Google universal part-of-speech tags (Petrov et al., 2012), and the Interset interlingua for morphosyntactic tagsets (Zeman, 2008). This is the third release of UD Treebanks, Version 1.2."
"V článku je navržen nový algoritmus pro závislostní syntaktickou analýzu, který umožňuje použít různé typy predikčních rysů a přitom zůstává výpočetně zvládnutelný. Základní myšlenka vychází z postupného upravování závislostního stromu opakovaným aplikovaním jednoduchých transformačních operací.","We propose a new dependency parsing algorithm, designed to allow
for any features while maintaining tractability. The main idea is to start with a
baseline parse tree rather than with no tree at all, and to transform that tree into
the correct one by repeated application of simple transformation operations. We
focus on inference, discussing anticipated issues and possible remedies. Suggestions
towards the training procedure and the feature set are also briefly presented."
"Depfix -- open-souce systém pro automatickou post-editaci výstupů frázového strojového překladu. Depfix zapojuje řadu nástrojů pro automatické zpracování přirozeného jazyka, pomocí nichž získává rozbor vstupních vět, a používá sadu pravidel pro opravu závažných chyb či chyb obvyklých ve výstupech strojových překladačů.","Depfix, an open-source system for automatic post-editing of phrase-based machine translation outputs. Depfix employs a range of natural language processing tools to obtain analyses of the input sentences, and uses a set of rules to correct common or serious errors in machine translation outputs."
Toto je sada konfiguračních souborů parseru MSTperl a skriptů pro přenos delexikalizovaného parseru. Byly použity v práci popsané v článku arXiv:1506.04897 (http://arxiv.org/abs/1506.04897) a v několika souvisejících článcích. Parser MSTperl je dostupný na adrese http://hdl.handle.net/11234/1-1480,"This is a set of MSTperl parser configuration files and scripts for delexicalized parser transfer. They were used in the work reported in arXiv:1506.04897 (http://arxiv.org/abs/1506.04897), as well as several related papers. The MSTperl parser is available at http://hdl.handle.net/11234/1-1480"
"MSTperl je Perlovou reimplementací MST parseru  Ryana McDonalda, s několika pokročilými funkcemi navíc, jako je podpora pro paralelní rysy.","MSTperl is a Perl reimplementation of the MST parser of Ryan McDonald, with several additional advanced functions, such as support for parallel features."
"Porovnáváme dva anotační styly, Pražské závislosti a univerzální
    Stanfordské závislosti, ve smyslu jejich vhodnosti pro parsing.
    Konkrétně se zaměřujeme na porovnání stylu zavěšení adpozic, použivaného v těchto dvou
    formalismech, na úloze vícezdrojového mezijazyčného přenosu delexikalizovaného parseru,
    používajíce MSTParser.
    Zjišťujeme, že v našem scénáři se stává zřetelnou výhoda Stanfordského stylu,
    neboť převod anotace adpozic v treebancích anotovaných v Pražském stylu do Stanfordského stylu vede k mírně lepšímu výsledku (+0.2%
    UAS).
    Dále ukazujeme, že nejlepších výsledků lze dosáhnout pomocí natrénování parserů
    na treebancích využívajících oba styly anotace adpozic, analýzy cílového
    treebanku pomocí všech těchto parserů a kombinace všech získaných stromů,
    po jejich převodu do stejného anotačního stylu (dalších +0.18% UAS).
    Rozdíly ve skóre jsou ještě vyšší, když se použije menší sada různorodých zdrojových
    treebanků (až 2.24% UAS oproti základní verzi).","We compare two annotation styles, Prague dependencies and Universal
Stanford Dependencies, in their adequacy for parsing.
We specifically focus on comparing the adposition attachment style, used in these two
formalisms, applied in multi-source cross-lingual delexicalized dependency
parser transfer performed by parse tree combination.
We show that in our setting, converting the adposition annotation to Stanford style in the
Prague style training treebanks leads to promising results.
We find that best results can be obtained by parsing the target sentences
with parsers trained on treebanks using both of the adposition annotation
styles in parallel,
and combining all the resulting parse trees together
after having converted them to the Stanford adposition style (+0.39% UAS over Prague
style baseline).
The score improvements are considerably more significant when using a smaller set of diverse source
treebanks (up to +2.24% UAS over the baseline)."
"Představujeme naši práci v oblasti částečně řízené syntaktické analýzy vět přirozeného jazyka, se zaměřením na mezijazyčný přenos delexicalizovaných závislostních parserů s více zdroji.
Nejprve vyhodnocujeme vliv anotačního stylu treebanku na úspěšnost parsingu,
se zaměřením na styl zavěšení adpozic. Poté představujeme KLcpos3, empirickou
míru podobnosti jazyků, navrženou a vyladěnou pro vážení zdrojových parserů 
při přenosu delexicalizovaných parserů s více zdroji. Nakonec představíme novou metodu kombinace zdrojů, založenou na interpolaci natrénovaných modelů parserů.","We present our work on semi-supervised
parsing of natural language sentences, focusing
on multi-source crosslingual transfer
of delexicalized dependency parsers.
We first evaluate the influence of treebank
annotation styles on parsing performance,
focusing on adposition attachment
style. Then, we present KLcpos3, an empirical
language similarity measure, designed
and tuned for source parser weighting
in multi-source delexicalized parser
transfer. And finally, we introduce a novel
resource combination method, based on
interpolation of trained parser models."
"Představujeme implementaci doménové adaptace pomocí  interpolace překladových modelů v TectoMT, překladovém systému s hloubkovým transferem. Vyhodnotili jsme tuto metodu na šesti jazykových párech s doménovým paralelním korpusem o 1000 větách, a získali jsme zlepšení až o 3 body BLEU. Váhy pro interpolaci jsou nastaveny uniformně, bez zapojení jakéhokoliv ladění.","We present an implementation of domain adaptation by translation model interpolation in the
TectoMT translation system with deep transfer. We evaluate the method on six language pairs
with a 1000-sentence in-domain parallel corpus, and obtain improvements of up to 3 BLEU
points. The interpolation weights are set uniformly, without employing any tuning."
"Představujeme KLcpos3, míru podobnosti jazyků založenou na Kullbackově-Leiblerově
divergenci rozložení trigramů hrubých značek slovních druhů v otagovaných korpusech. Tato míra byla navržena pro vícejazyčný delexicalizovaný parsing, a to jak pro výběr zdrojového treebanku při přenosu parseru s jedním zdrojem, tak pro vážení zdrojových treebanků při přenosu parseru s více zdroji. V úloze výběru zdroje rozpozná KLcpos3
nejlepší zdrojový treebank v 8 z 18 případů. V úloze vážení zdroje přínáší zvýšení UAS o +4.5 procentního bodu oproti nevážené kombinaci stromů.","We present KLcpos3, a language similarity measure based on Kullback-Leibler
divergence of coarse part-of-speech tag trigram distributions in tagged
corpora. It has been designed for multilingual delexicalized parsing, both for
source treebank selection in single-source parser transfer, and for source
treebank weighting in multi-source transfer. In the selection task, KLcpos3
identifies the best source treebank in 8 out of 18 cases. In the weighting
task, it brings +4.5% UAS absolute, compared to unweighted parse tree
combination."
"Představujeme interpolaci natrénovaných
modelů MSTParseru jako metodu kombinace zdrojů
pro vícezdrojový delexikalizovaný přenos parseru. Představujeme jak
neváženou metodu, tak variantu
ve které je každý zdrojový model vážen
podobností zdrojového a cílového jazyka. Vyhodnocení na sbírce treebanků
HamleDT ukazuje, že
vážená interpolace modelů má podobnou úspěšnost jako vážená kombinace stromů, přičemž je mnohem méně komputačně
náročná.","We introduce interpolation of trained MSTParser models as a resource combination method for multi-source delexicalized parser transfer. We present both an unweighted method, as well as a variant in which each source model is weighted by the similarity of the source language to the target language. Evaluation on the HamleDT treebank collection shows that theweightedmodelinterpolationperforms comparably to weighted parse tree combination method, while being computationally much less demanding."
"Článek je zaměřen na tři témate související s autorčiným prvním rokem doktorského studia. Zaprvé, zabývá se nástroji pro rozpoznávání koreference v češtině a angličtině. Zadruhé, popisuje metody extrakce číselných výrazů napojených na vybrané typy entit v prostředí GATE. Poslední část je věnovaná editoru Capek a získávání anotovaných větných diagramů","This paper is devoted to three topics concerning my first year
postgraduate studies at UFAL. First, I will present the current state-of-the-art of
coreference resolution in the Czech and English language. Next, I will describe a
method of extraction of numerical expressions linked to certain entities with the
GATE tool and the last part will be dedicated to the Capek sentence diagramming
editor and a method of getting more annotated data from sentence diagrams."
Tato práce porovnává několik systémů pro rozpoznávání koreference v angličtině v překladu přes hloubkovou syntax z angličtiny do češtiny a holandštiny.,"This work focuses on using anaphora for machine translation with deep-syntactic transfer. We compare multiple coreference resolvers for English in terms of how they affect the quality of pronoun translation in English-Czech and English-Dutch machine translation systems with deep transfer. We examine which pronouns in the target language depend on anaphoric information, and design rules that take advantage of this information. The resolvers’ performance measured by translation quality is contrasted with their
intrinsic evaluation results. In addition, a more detailed manual analysis of English-to-Czech translation was carried out."
"V teto prednasce predstavujeme srovnani koreferencnich vyrazu v cestine a anglictine na zaklade paralelnich dat Prazskeho anglicko-ceskeho zavislostniho korpusu. V centru naseho vyzkumu jsou osobni, privlastnovaci, reflexivni a vztazna zajmena. Zvlastni pozornost venujeme rovnez vynechani zajmen v anaforicke pozici.","In this talk, we present a comprehensive study on mappings between certain classes of coreferential expressions in English and Czech. We focused on central pronouns, relative pronouns and anaphoric zeros. For instance, the English sentence ""It switched to a caffeine-free formula using its new Coke in 1985"" has been in PCEDT translated to ""V roce 1985 přešla na bezkofeinovou recepturu, kterou používá pro svojí novou kolu"". This pair of sentences exhibits several types of changes in expressing coreference: English personal pronouns turns into a Czech zero, possessive pronoun into a possessive reflexive and finally, the -ing participle has been translated to a relative clause. In a similar manner, we have collected a statistics of mappings from a subsection of PCEDT, which we will support by multiple examples and contrast with the theoretical assumptions. For such a study, the quality of word alignment is crucial. Thus, we designed a rule-based refining algorithm for English personal and possessive pronouns and Czech relative pronouns, which served as an automatic alignment pre-annotation. Subsequently, this annotation has been manually corrected and completed, obtaining a basis for this empirical study."
"In this work, we present a comprehensive study on correspondences between certain classes of coreferential expressions in English and Czech. We focus on central pronouns, relative pronouns, and anaphoric zeros. We designed an alignment-refining algorithm for English personal and possessive pronouns and Czech relative pronouns that improves the quality of alignment links not only for the classes it aimed at but also in general. Moreover, the instances of anaphoric expressions we focus on were manually annotated with their alignment counterparts, which served as a basis for this empirical study. The collected statistics of correspondences are contrasted with theoretical assumptions regarding the use of anaphoric means in the languages under analysis, such as pro-drop properties, the use of finite and non-finite constructions, etc. Finally, we present the ways how the observed correspondences can be exploited in cross-lingual coreference resolution.","V této práci představujeme podrobný srovnávací výzkum některých typů koreferenčních vztahů v češtině a angličtině na paralelním česko-anglickém korpusu. Zaměřujeme se na centrální, vztažná a anaforická zájmena. Vypracovali jsme algoritmus vylepšení automatického vyrovnání několika typů českých a anglických zájmen, který vylepšuje kvalitu vyrovnání nejen pro tyto typy ale a pro všechny ostatní. Korespondence daných typů zájmen byly anatovány ručně a dále lingvisticky analyzovány."
"V této práci představujeme podrobný srovnávací výzkum některých typů koreferenčních vztahů v češtině a angličtině na paralelním česko-anglickém korpusu. Zaměřujeme se na centrální, vztažná a anaforická zájmena. Vypracovali jsme algoritmus vylepšení automatického vyrovnání několika typů českých a anglických zájmen, který vylepšuje kvalitu vyrovnání nejen pro tyto typy ale a pro všechny ostatní. Korespondence daných typů zájmen byly anatovány ručně a dále lingvisticky analyzovány.","In this work, we present a comprehensive study on correspondences between certain classes of coreferential expressions in English and Czech. We focus on central pronouns, relative pronouns, and anaphoric zeros. We designed an alignment-refining algorithm for English personal and possessive pronouns and Czech relative pronouns that improves the quality of alignment links not only for the classes it aimed at but also in general. Moreover, the instances of anaphoric expressions we focus on were manually annotated with their alignment counterparts, which served as a basis for this empirical study. The collected statistics of correspondences are contrasted with theoretical assumptions regarding the use of anaphoric means in the languages under analysis, such as pro-drop properties, the use of finite and non-finite constructions, etc. Finally, we present the ways how the observed correspondences can be exploited in cross-lingual coreference resolution."
"Nástroj MT-ComparEval byl navržen tak, aby umožnil vývojářům strojového překladu porovnávat a vyhodnocovat různé MT systémy a jejich verze.
MT-ComparEval obsahuje několik metrik pro vyhodnocení strojového překladu.","The tool described in this article has been designed to help MT developers by implementing
a web-based graphical user interface that allows to systematically compare and evaluate various
MT engines/experiments using comparative analysis via automatic measures and statistics.
The evaluation panel provides graphs, tests for statistical significance and n-gram statistics.
We also present a demo server http://wmt.ufal.cz with WMT14 and WMT15 translations."
"CloudASR je cloudová platforma pro automatické rozpoznávání řeči, která umožňuje dávkové i online zpracování nahrávek. Její hlavní přednosti jsou škálovatelnost, přizpůsobitelnost a snadný proces nasazaní.","CloudASR is a cloud platform for automatic speech recognition, which supports batch and online speech recognition mode. Its main features are scalability, customizability and easy deployment."
"CloudASR je softwarová platforma a veřejná služba pro rozpoznávání řeči. Její tři silné stránky jsou: kvalita rozpoznávání na úrovni stavu poznání, jednoduché nasazení, a škálovatelnost. Dále, obsahuje anotační rozhraní pro přidávání transkripcí. API platformy podporuje jak dávkovou tak online rozpoznávání. Dávková verze je kompatibilní s Google Speech API. Platforma umožňuje přidání nových rozpoznávačů, které potom můžou fungovat paralelně vedle sebe.","CloudASR is a software platform and a public ASR web-service. Its three strong features are state-of-the-art online speech recognition performance, easy deployment, and scalability. Furthermore, it contains an annotation interface for the addition of transcriptions for the recordings. The platform API supports both batch and online speech recognition. The batch version is compatible with Google Speech API. New ASR engines can be added onto the platform and can work simultaneously."
"MT-ComparEval je nástroj, který umožňuje vývojářům strojového překladu porovnávat a vyhodnocovat různé MT systémy a jejich verze. MT-ComparEval obsahuje několik metrik pro vyhodnocení strojového překladu.","MT-ComparEval is a tool for Machine Translation developers, which allows to compare and evaluate different MT systems (and their versions). MT-ComparEval includes several automatic MT evaluation metrics."
"Představujeme aktuální vývoj korektor, je
statistický systém kontroly pravopisu. Kromě lexikonu, Korektor používá jazyk modely najít chyby real-slovo, detekovatelná pouze v kontextu. Modely a chyba probanického, vyvozené z chyb korpusů, jsou také používány pro navrhovaly
GEST nejpravděpodobnější opravy. Korektor byl původně vyškolení na malé chyby korpusu a použité jazykové modely extrahuje z in-house corpus WebColl. Ukážeme dvě nedávná zlepšení:
• Postavili jsme nové jazykové modely z volne dostupný schopné (šoural) verze České národní korespondence hnis a ukazují, že tyto provádět trvale lepší na texty vyráběných jak rodilými mluvčími a non-nativní studenti češtiny.
• Trénovali jsme nové modely chyb na ručně s poznámkami žák korpus a ukázat, že lepší výkon než Standardní model chyba (detekce chyb) nejenom
pro texty studenty "", ale také pro naše standardní hodšpatne rozpoznaných zpráv data rodilého Čecha. Pro korekci chyb se
standardní model chyba překonaly non-nativní modulárně els ve 2 ze 3 testovaných datových sad.
Diskutujeme důvody pro tento ne zcela intuitivní zlepprostředí. Na základě těchto poznatků a na základě analýzy chyb základě
v obou domorodec a češtině frekventantů, navrhujeme směry pro další zlepšení korektor.","We present recent developments of Korektor, a
statistical spell checking system. In addition to lexicon, Korektor uses language models to find real-word errors, detectable only in context. The models and error probabilities, learned from error corpora, are also used to suggest the most likely corrections. Korektor was originally
trained on a small error corpus and used language models extracted from an in-house corpus WebColl. We show two recent improvements:
• We built new language models from freely avail-
able (shuffled) versions of the Czech National Corpus and show that these perform consistently better on texts produced both by native speakers and non-native learners of Czech.
• We trained new error models on a manually annotated learner corpus and show that they perform better than the standard error model (in error detection) not only for the learners’ texts, but also for our standard eval-
uation data of native Czech. For error correction, the standard error model outperformed non-native models in 2 out of 3 test datasets.
We discuss reasons for this not-quite-intuitive improvement. Based on these findings and on an analysis of errors in both native and learners’ Czech, we propose directions
for further improvements of Korektor."
Cílem práce je (i) srovnat přístupy k analýze a anotaci textových jevů v PDiT a GECCo a (ii) určit společné a rozdílné rysy mezi odpovídajícími vědeckymi paradigmaty.,"The aim of this work is (i) to compare two frameworks for the analysis and annotation
of discourse-structuring devices (DSDs) and further discourse phenomena in GECCo X PDiT and (ii) identify commonalities and/or differences between the two frameworks"
"Tento článek se zabývá použitím lingvistiké informace pro výběr dat pro trénování jazykových modelů. Navrhovaná metoda vychází ze známých a používaných postupů, které využívají povrchových tvarů slov, a obohacuje je o informace o lemmatech, pojmenovaných entitách a slovních druzích.","This paper explores the use of linguistic information for the selection of data to train language models. We depart from the state-of-the-art method in perplexity-based data selection and extend it in order to use word-level linguistic units (i.e. lemmas, named entity categories and part-of-speech tags) instead of surface forms. We then present two methods that combine the different types of linguistic knowledge as well as the surface forms (1, naıve selection of the top ranked sentences selected by each method; 2, linear interpolation of the datasets selected by the different methods). The paper presents detailed results and analysis for four languages with different levels of morphologic complexity (English, Spanish, Czech and Chinese). The interpolation-based combination outperforms the purely statistical baseline in all the scenarios, resulting in language models with lower perplexity. In relative terms the improvements are similar regardless of the language, with perplexity reductions achieved in the range 7.72% to 13.02%. In absolute terms the reduction is higher for languages with high type-token ratio (Chinese, 202.16) or rich morphology (Czech, 81.53) and lower for the remaining languages, Spanish (55.2) and English (34.43 on the same dataset as Czech and 61.90 on the same dataset as Spanish)."
"Článek představuje probíhající výzkum zaměřený na vyhledávání ilustrativních obrázků pro články ""soft news"", kde vhodnost ilustrativního obrázku není primárně určena jeho popisností. Popisujeme základní řešení a experimenty používající Denoising Autoencoders.","This work presents ongoing research on finding illustrative images to “soft
news” articles, magazine-style texts where the appropriateness of an illustrative image is
not judged primarily by its descriptiveness. We describe our baselines and experiments
using Denoising Autoencoders and present the web-pic multimodal dataset of Czech news
articles and their accompanying images. Finally, we briefly present the Safire library, a
Python framework for building and analyzing complex experimental pipelines suitable for
multimodal tasks."
Článek popisuje případovou studii automatického překladu mezi příbuznými jazyky. Porovnává systémy pracující tradičními metodami s překladačem firmy Google. Porovnání je založeno na lidském hodnocení 200 náhodně vybraných vět z novinových článků.,"This paper describes an experiment comparing results of machine translation between two pairs of related Slavic languages. Two language pairs on three different translation platforms were observed in the experiment. One pair represents really very close languages (Czech and Slovak), the other pair are slightly less similar languages (Slovenian and Croatian).
The comparison is performed by means of three MT systems, one for each pair representing rule-based approach, the other one representing statistical (same system for both language pairs) approach to the task. Both sets of results are manually evaluated by native speakers of the target language. The results are discussed both from the linguistic and quantitative points of view."
"Sledování dialogového stavu je důležitá komponenta moderních dialogových systémů. Ukazujeme inkrementální sledovač dialogového stavu založený na LSTM sítích. Ke sledování používá přímo výsledky rozpoznávání řeči. Ukazujeme klíčová nestandardní aspekty modelu, které pomáhají dostat úspěšnost sledovače k systémům v současném stavu poznání: zahrnutí skóre rozpoznávače, abstrakce málo viděných hodnot, použití transkripce pro trénování a průměrování modelu.","A dialog state tracker is an important component in modern
spoken dialog systems. We present an incremental dialog
state tracker, based on LSTM networks. It directly uses automatic
speech recognition hypotheses to track the state. We
also present the key non-standard aspects of the model that
bring its performance close to the state-of-the-art and experimentally
analyze their contribution: including the ASR confi-
dence scores, abstracting scarcely represented values, including
transcriptions in the training data, and model averaging"
"Sledování dialogového stavu je důležitou součástí moderních řečových dialogových systémů. Navrhujeme první inkrementální trénovatelný sledovač dialogového stavu, který používá přímo výstup z rozpoznávače řeči ke sledování stavu. Je založen na sítích s dlouhou krátkodobou pamětí a je plně trénovatelný z anotovaných dat. Dosahujeme slibných výsledků na sledování pod-úkolů Method a Requested v DSTC2.","A dialog state tracker is an important component in modern spoken dialog systems. We present the first trainable incremental dialog state tracker
that directly uses automatic speech recognition hypotheses to track the state. It is based on a long short-term memory recurrent neural network, and it is fully trainable from annotated data. The tracker achieves promissing performance on the Method and Requested tracking sub-tasks in DSTC2."
"Tento příspěvek pojednává o adaptaci modelu závislého typu Stanfordova typu (de Marneffe a Manning 2008) původně určeného pro angličtinu na požadavky typologicky odlišných jazyků z hlediska praktického rozboru. Argumentujeme pro rámec gramatiky funkční závislosti, který je založen na myšlence paralelnosti mezi syntaxí a sémantikou.","This paper discusses the adaptation of the Stanford typed dependency model (de Marneffe and Manning 2008), initially designed for English, to the requirements of typologically different languages from the viewpoint of practical parsing. We argue for a framework of functional dependency grammar that is based on the idea of parallelism between syntax and semantics.
There is a twofold challenge: (1) specifying the annotation scheme in order to deal with the morphological and syntactic peculiarities of each language and (2) maintaining crosslinguistically consistent annotations to ensure homogenous analysis for similar linguistic phenomena. We applied a number of modifications to the original Stanford scheme in an attempt to capture the language-specific grammatical features present in heterogeneous CoNLL-encoded data sets for German, Dutch, French, Spanish, Brazilian Portuguese, Russian, Polish, Indonesian, and Traditional Chinese. From a multilingual perspective, we discuss features such as subject and object verb complements, comparative phrases, expletives,
reduplication, copula elision, clitics and adpositions."
"RExtractor je systém pro extrakci informací. Vstupní dokumenty jsou zpracovány NLP nástroji. Extrakce následně probíhá pomocí dotazů nad závislostními stromy. Výsledkem je znalostní báze dokumentu, definována jako množina entit a vztahů mezi nima. Dotazy nad stromy jsou definovány manuálně. Architektura systému je navržena doménově a jazykově nezávisle. Systém demonstrujeme na českých a anglických právních dokumentech.",The RExtractor system is an information extractor that processes input documents by natural language processing tools and consequently queries the parsed sentences to extract a knowledge base of entities and their relations. The extraction queries are designed manually using a tool that enables natural graphical representation of queries over dependency trees. A workflow of the system is designed to be language and domain independent. We demonstrate RExtractor on Czech and English legal documents.
Prezentujeme výsledky experimentů na úloze identifikace mateřského jazyka. Vytvořili jsme systém pro automatickou identifikaci mateřského jazyka autora anglicky psaného textu. Systém je založen na jazykovém modelování a využíva rysy spočítané na základe křížové entropie.,"This paper reports on the task of Native Language Identification (NLI). We developed a machine learning system to identify the native language of authors of English texts written by non-native English speakers. Our system is based on the language modeling approach and employs cross-entropy scores as features for supervised learning, which leads to a significantly reduced feature space. Our method uses the SVM learner and achieves the accuracy of 82.4 % with only 55 features. We compare our results with the previous similar work by Tetreault et al. (2012) and analyze more details about the use of language modeling for NLI. We experiment with the TOEFL11 corpus (Blanchard et al., 2013) and provide an exact comparison with results achieved in the First Shared Task in NLI (Tetreault et al., 2013)."
"RExtractor je systém pro extrakci informací. Vstupní dokumenty jsou zpracovány NLP nástroji. Extrakce následně probíhá pomocí dotazů nad závislostními stromy. Výsledkem je znalostní báze dokumentu, definována jako množina entit a vztahů mezi nima. Dotazy nad stromy jsou definovány manuálně. Architektura systému je navržena doménově a jazykově nezávisle. Systém demonstrujeme na českých a anglických právních dokumentech.",The RExtractor system is an information extractor that processes input documents by natural  language  processing  tools  and  consequently  queries  the  parsed  sentences  to  extract a knowledge base of entities and their relations.   The  extraction  queries  are  designed manually  using  a  tool  that  enables  natural graphical  representation  of  queries  over  dependency trees.  A workflow of the system is designed to be language and domain independent.   We  demonstrate RExtractor  on  Czech and English legal documents.
Korpus Czech Legal Text Treebank (CLTT) je kolekcí 1 133 ručně syntakticky anotovaných vět. Věty pochází ze Zákona o účetnictví (563/1991 Sb.) a z Vyhlášky o účetnictví (500/2002 Sb.).,"The Czech Legal Text Treebank (CLTT) is a collection of 1133 manually annotated dependency trees. CLTT consists of two legal documents: The Accounting Act (563/1991 Coll., as amended) and Decree on Double-entry Accounting for undertakers (500/2002 Coll., as amended)."
"Prezentace představuje repozitář LINDAT/CLARIN a některé změny platformy DSpace, na které je repozitář založený.",The presentation introduces the LINDAT/CLARIN repository and some of the modifications to DSpace - the platform the repository is based on.
"Nekrolog obsahující zhodnocení vědeckého přínosu jedné ze zakladatelek počítačové lingvistiky, americké badatelky prof. J. J. Robinson.","Obituary article evaluating the scientific contribution of J.J.Robinson, an American computational linguist, one of the founders of the field."
"Představujeme CLARIN Concept Registry, nový registr sémantických konceptů, který je dostupný on-line a jeho smyslem je sloužit jako definice konceptů, na které se odkazují projekty CLARIN. Tento nový registr nahrazuje (pro účely CLARINu) ISOcat. Probíráme různé problémy, které komplikovaly používání ISOcatu, a navrhujeme řešení těchto problémů v CCR.","We introduce the CLARIN Concept Registry, a new on-line registry of semantic concepts that can be used in (and referenced from) CLARIN projects. This new registry replaces (for CLARIN purposes) ISOcat. We discuss various issues that made ISOcat less useful, and propose solutions to those issues in CCR."
"Studujeme metodu ručního hodnocení strojového překladu, v níž anotátoři uspořádávají podle kvality jen krátké úseky místo celých vět. Anotace je tak snazší a rychlejší.","We propose a manual evaluation method for machine translation (MT), in which annotators
rank only translations of short segments instead of whole sentences. This results in an easier
and more efficient annotation. We have conducted an annotation experiment and evaluated a
set of MT systems using this method. The obtained results are very close to the official WMT14
evaluation results. We also use the collected database of annotations to automatically evaluate
new, unseen systems and to tune parameters of a statistical machine translation system. The
evaluation of unseen systems, however, does not work and we analyze the reasons."
"Článek představuje výsledky soutěže v ladění systémů strojového překladu, WMT15 Tuning Shared Task. Účastníkům jsme poskytli úplný překladový systém a jejich úkolem bylo nastavit jeho interní váhy. Výsledné překlady byly porovnány v ručním hodnocení.","This paper presents the results of the WMT15 Tuning Shared Task. We provided the
participants of this task with a complete machine translation system and asked them to tune its
internal parameters (feature weights). The tuned systems were used to translate the test set and
the outputs were manually ranked for translation quality. We received 4 submissions in the
English-Czech and 6 in the Czech-English translation direction. In addition, we ran
3 baseline setups, tuning the
parameters with standard optimizers for BLEU score."
"Článek představuje výsledky soutěže v automatickém hodnocení kvality strojového překladu (WMT15 Metrics Shared Task). Úkolem účastníků bylo vyhodnotit kvalitu překladových systémů, které se zúčastnily překladové úlohy WMT15. Získaných 46 metrik od 11 týmů jsme pak společně se 7 základními metrikami (BLEU, SentBLEU, NIST, WER, PER, TER a CDER) porovnali z hlediska korelace s lidským hodnocením pro celý testset i pro jednotlivé věty.","This paper presents the results of the WMT15 Metrics Shared Task. We asked
participants of this task to score the outputs of the MT systems involved in
the WMT15 Shared Translation Task. We collected scores of 46 metrics from 11
research groups. In addition to that, we computed scores of 7 standard metrics
(BLEU, SentBLEU, NIST, WER, PER, TER and CDER) as baselines. The collected scores were
evaluated in terms of system level correlation (how well each metric's scores
correlate with WMT15 official manual ranking of systems) and in terms of segment
level correlation (how often a metric agrees with humans in comparing two
translations of a particular sentence)."
"Článek popisuje několik případů 
mezijazykových rozdílů závislosti na materiálu paralelního češko-anglického závislostního korpusu. Pozornost je soustředěna zejména na místa, kde dochází k neshodám v propojení slovesných argumentů. Článek se věnuje otázce, zda takové neshody pramení ze sémantických vlastností jednotlivých jazyků, nebo z charakteru použité lingvistické teorie. Autoři se zamýšlejí nad případným využitím získaných poznatků pro strojový překlad.","This paper analyses several points of interlingual dependency mismatch on the material of a parallel Czech-English dependency treebank. Particularly, the points of alignment mismatch between the valency frame arguments of the corresponding verbs are observed and described. The attention is drawn to the question whether such mismatches stem from the inherent semantic properties of the individual languages, or from the character of the used linguistic theory. Comments are made on the possible shifts in meaning. The authors use the findings to make predictions about possible machine translation implementation of the data."
"V monografii je představen výzkum vztahů působících společně ve výstavbě textu (syntaktická výstavba, aktuální členění, sémantické diskurzní vztahy v užším smyslu, koreference a asociativní anafora).",In this monograph we present the results of our research on the interplay of intra-sentential relations such as deep syntactic relations and information structure of the sentence and the inter-sentential relations such as discourse relations and coreferential and other associative links.
Seznámení s anotací diskurzních vztahů a koreference a asociační anafory v Pražském závislostním korpusu,"Information about annotation of discourse relations, coreference and bridging anaphora in the Prague Dependency Treebank"
"Článek popisuje metody a výsledky CLEF 2015 eHealth Evaluation Lab, Task 2, který se zaměřuje na efektivitu vyhledávání medicínských informací na webu.","This paper details methods, results and analysis of the CLEF 2015 eHealth Evaluation Lab, Task 2. This task investigates the effectiveness of web search engines in providing access to medical information with the aim of fostering advances in the development of these technologies"
"V práci se zabýváme popisem a analýzou diskurzních (tj. textových) konektorů v češtině v širším smyslu, tedy tím, jakými jazykovými prostředky je možné vyjadřovat v textu diskurzní vztahy. Výzkum přitom neomezujeme na předem stanovenou skupinu výrazů (danou například příslušností k určitým slovním druhům, jako jsou spojky či strukturující částice), ale snažíme se nalézt a obecně popsat všechny jazykové prostředky v češtině, které mají schopnost spojovat jednotlivé úseky textu v jeden koherentní celek. Zaměřujeme se především na méně probádané víceslovné konektivní struktury typu ""to je důvod, proč""; ""kvůli těmto skutečnostem""; ""z těchto důvodů"" atd., pro které užíváme označení sekundární konektory (za primární konektory považujeme především konektivní synsémantika typu ""však"", ""nebo"", ""a"", ""ale"", ""proto"" apod.).","The thesis focuses on description and analysis of discourse connectives in Czech in broader sense, i.e. by which language means it is possible to express sense relation within a text. The thesis is not limited to any parts of speech (like conjunctions or structuring particles) but it tries to find and describe all language means in Czech with the ability to connect two pieces or units of a text into one coherent complex. The thesis investigates discourse connectives in Czech with respect to the so called secondary connectives (i.e. mainly multiword phrases like ""to je důvod, proč"" – ""that is the reason why""; ""kvůli těmto skutečnostem"" – ""due to these facts"" etc., in opposition to primary connectives like ""však"" – ""however"", ""nebo"" – ""or"", ""a"" – ""and"", ""ale"" – ""but"", ""proto"" – ""therefore"" etc.)."
"Cílem posteru je přispět do diskuze o diskurzních konektorech, zejména o jejich definici a o kritériích, podle kterých je možné vymezit jejich hranice.","The aim of the poster is to contribute to the general discussion on discourse connectives, 
especially on their definition and principles we may hold as boundaries surrounding this class of
expressions."
"Článek představuje novou anotaci diskurzních vztahů v Pražském závislostním korpusu (PDT) – anotaci tzv. sekundárních konektorů (většinou víceslovných frází jako ""podmínkou je"", ""to je důvod, proč"", ""na závěr"", ""to znamená"" atd.). 
Nejprve se článek soustředí na na teoretické vymezení těchto výrazů (hlavně s ohledem na tzv. primární konektory jako ""a"", ""ale"", ""nebo"", ""také"" atd.) a pak se zaměřuje na popis a definici diskurzních konektorů jako takových (primárních i sekundárních).
Poté článek představuje možnosti anotací sekundárních konektorů ve velkých korpusech (jako je PDT). Příspěvek popisuje obecné anotační principy pro sekundární konektory použité v PDT pro češtinu a srovnává výsledky této anotace s výsledky anotací primárních konektorů v PDT. Hlavním cílem příspěvku je představit nový typ anotace diskurzu, která by mohla být využita i pro další jazyky.","The paper introduces a new annotation of
discourse relations in the Prague Dependency
Treebank (PDT), i.e. the annotation of the so
called secondary connectives (mainly
multiword phrases like ""the condition is"", ""that is the reason why"", ""to conclude"", ""this means"" etc.).
Firstly, the paper concentrates on theoretical
introduction of these expressions (mainly with
respect to primary connectives like ""and"", ""but"", ""or"", ""too"" etc.) and tries to contribute to the description and definition of discourse connectives in general (both primary and secondary). 
Secondly, the paper demonstrates possibilities of annotations of secondary connectives in large corpora (like PDT). The paper describes general annotation principles for secondary connectives used in PDT for Czech and compares the results of this annotation with annotation of primary connectives in PDT. In this respect, the main aim of the paper is to introduce a new type of discourse annotation that could be adopted also by other languages."
"V článku překládáme pilotní studii zaměřenou na anotaci významu slov získaných z několika informačních zdrojů. Studie je prvním krokem z zamýšlené anotací ""ukotvení"".","We present a pilot study in web-based annotation of words with senses coming
from several knowledge bases and sense inventories. The study is the first step in a
planned larger annotation of “grounding” and should allow us to select a subset of these
“dictionaries” that seem to cover any given text reasonably well and show an acceptable
level of inter-annotator agreement."
"Představujeme pilotní experimenty s anotací významů slov ve webovém anotačním prostředí. Významy přitom pocházejí z několika různých zdrojů. Experimenty jsou prvním krokem v plánované větší anotaci a měly by nám pomoci s výběrem podmnožiny studovaných zdrojů tak, aby pokrývaly veškerý text v co největším rozsahu a současně vykazovaly přijatelnou úroveň shody mezi anotátory.",We present a pilot study of a web-based annotation of words with senses. The annotated senses come from several knowledge bases and sense inventories. The study is the first step in a planned larger annotation of grounding and should allow us to select a subset of the sense sources that cover any given text reasonably well and show an acceptable level of inter-annotator agreement.
"V članku se popisuje system pro SemEval-
2015 Task 13: Multilingual All-Words Sense
Disambiguation and Entity Linking. My jsme se zameřili na monolingvalní disambiguaci a propojeni entit.","This paper describes our system for SemEval-
2015 Task 13: Multilingual All-Words Sense
Disambiguation and Entity Linking. We have
participated with our system in the sub-task
which aims at monolingual all-words disambiguation
and entity linking. Aside from system
description, we pay closer attention to the
evaluation of system outputs"
"Představujeme podrobnou analýzu kombinace systému založeného na transferu TectoMT se statistickým systémem Moses pro překlad mezi angličtinou a češtinou. Popisujeme možnosti zkoumání této kombinace systémů jak pomocí ruční, tak i automatické evaluace. Přesto, že výstupy TectoMT často obsahují chyby, Moses dokáže z jeho výstupů vybrat vhodné části. V mnoha případech pak TectoMT poskytne nové, užitečné překladové varianty, které jsou pro statistickou komponentu jinak nedosažitelné, navzdory velikosti trénovacích dat. Naše analýzy potvrzují, že TectoMT napomáhá dodržení gramatické shody a požadavků valence, ale zároveň zlepšuje překlad rozmanité škály jazykových jevů. Zahrnutí výstupů systému založeného na transferu do frázového překladu má také zřejmě pozitivní vliv na prohledávaný prostor hypotéz. Zjišťujeme, že jednotlivé komponenty této kombinace jsou komplementární a výsledný systém překládá signifikantně lépe než kterákoliv jednotlivá komponenta.","We present a thorough analysis of a combination of a statistical and a transfer-based system for English->Czech translation, Moses and TectoMT. We describe several techniques for inspecting such a system combination which are based both on automatic and manual evaluation. While TectoMT often produces bad translations, Moses is still able to select the good parts of them. In many cases, TectoMT provides useful novel translations which are otherwise simply unavailable to the statistical component, despite the very large training data. Our analyses confirm the expected behaviour that TectoMT helps with preserving grammatical agreements and valency requirements, but that it also improves a very diverse set of other phenomena. Interestingly, including the outputs of the
transfer-based system in the phrase-based search seems to have a positive effect on the search space. Overall, we find that the components of this combination are complementary and the final system produces significantly better translations than either component by itself."
"Představujeme diskriminativní model s bohatou sadou rysů pro strojový překlad, který využívá abstraktní sémantickou reprezentaci na zdrojové straně. Náš model využíváme jako nový rys ve frázovém překladači a dosahujeme mírných zlepšení BLEU skóre v experimentu n-best reranking.",We present a feature-rich discriminative model for machine translation which uses an abstract semantic representation on the source side. We include our model as an additional feature in a phrase-based decoder and we show modest gains in BLEU score in an n-best re-ranking experiment.
"V této práci se zaměřujeme na postojovou analýzu aspektů, což je relativně nová úloha z oblasti počítačového zpracování přirozených jazyků (NLP). Představujeme novou datovou sadu v češtině, která sestává z uživatelských hodnocení produktů z oblasti IT. Zároveň popisujeme průběh naší práce na automatické extrakci aspektů. Věříme, že tato oblast může účastníky workshopu zaujmout a že tento příspěvek podnítí diskuzi na toto téma s výzkumníky z příbuzných oborů.","This work focuses on aspect-based sentiment analysis, a relatively recent task in natural language processing. We present a new dataset for Czech aspect-based sentiment analysis which consists of segments from user reviews of IT products. We also describe our work in progress on the task of aspect term extraction. We believe that this area can be of interest to other workshop participants and that this paper can inspire a fruitful discussion on the topic with researchers from related fields."
"Parsito je rychlý závislostní parser napsaný v C++ vydaný jako open-source. Parsito je založené na transition-based parsingu, má vysokou úspěšnost a dosahuje rychlosti 30 tisíc slov za sekundu. Parsito lze natrénovat na libovolných vstupních datech, bez nutnosti navrhovat jazykově závislé rysy, protože používá klasifikátor založený na neuronových sítích. K dispozici jsou natrénované modely pro všechny treebanky z projektu Universal Dependencies (37 treebanků k prosinci 2015).","Parsito is a fast open-source dependency parser written in C++. Parsito is based on greedy transition-based parsing, it has very high accuracy and achieves a throughput of 30K words per second. Parsito can be trained on any input data without feature engineering, because it utilizes artificial neural network classifier. Trained models for all treebanks from Universal Dependencies project are available (37 treebanks as of Dec 2015)."
"MorphoDiTa (morfologický slovník a tagger) je open-source nástroj pro morfologickou analýzu textů v přirozených jazycích. Provádí morfologickou analýzu, morfologické generování, tagování a tokenizaci a je distribuován jako samostatný nástroj nebo jako knihovna spolu s natrénovanými lingvistickými modely. V českém jazyce dosahuje MorphoDiTa state-of-the-art výsledků s rychlostí 10-200 tisíc slov za sekundu. MorphoDiTa je svobodný software pod LGPL licencí a jazykové modely jsou zdarma pro nekomerční použití a jsou distribuovány pod CC BY-NC-SA licencí, i když u některých modelů mohou původní data použitá k vytvoření modelu implikovat další licenční podmínky.","MorphoDiTa: Morphological Dictionary and Tagger is an open-source tool for morphological analysis of natural language texts. It performs morphological analysis, morphological generation, tagging and tokenization and is distributed as a standalone tool or a library, along with trained linguistic models. In the Czech language, MorphoDiTa achieves state-of-the-art results with a throughput around 10-200K words per second. MorphoDiTa is a free software under LGPL license and the linguistic models are free for non-commercial use and distributed under CC BY-NC-SA license, although for some models the original data used to create the model may impose additional licensing conditions."
"NameTag je open-source nástroj pro rozpoznávání jmenných entity (Named Entity Recognition - NER). NameTag identifikuje vlastní jména v textu a zařazuje je do předem definovaných kategorií, jako jsou názvy osob, míst, organizací, atd. NameTag je distribuován jako samostatný nástroj nebo jako knihovna spolu s natrénovanými lingvistickými modely. V českém jazyce dosahuje NameTag state-of-the-art výkonu (Straková et al.,. 2013). NameTag je svobodný software pod LGPL licencí a jazykové modely jsou zdarma pro nekomerční použití a jsou distribuovány pod CC BY-NC-SA licencí, i když u některých modelů mohou původní data použítá k vytvoření modelu implikovat další licenční podmínky.","NameTag is an open-source tool for named entity recognition (NER). NameTag identifies proper names in text and classifies them into predefined categories, such as names of persons, locations, organizations, etc. NameTag is distributed as a standalone tool or a library, along with trained linguistic models. In the Czech language, NameTag achieves state-of-the-art performance (Straková et. al. 2013). NameTag is a free software under LGPL license and the linguistic models are free for non-commercial use and distributed under CC BY-NC-SA license, although for some models the original data used to create the model may impose additional licensing conditions."
"V článku popisujeme přechodový neprojektivní závislostní parser používající klasifikátor založený na neuronových sítích, který nevyžaduje tvorbu rysů. Dále představujeme nové přechodové orákulum, které zvyšuje úspěšnost parseru porovnatelně s dynamickým orákulem, ale je použitelné pro každý přechodový systém, jako například neprojektivní systém s operací swap. Parser je velmi rychlý, jeho modely kompaktní, přičemž dosahuje vysoké úspěšnosti bez potřeby dalších zdrojů jako například korpusů s čistým textem. Parser jsme otestovali na všech 19 korpusech z projektu Universal Dependencies. Implementaci parseru v jazyce C++ uvolňujeme jako open-source.","We describe a transition-based, non-projective dependency parser which uses a neural network classifier for prediction and requires no feature engineering.  We propose a new, search-based oracle, which improves parsing accuracy similarly to a dynamic oracle, but is applicable to any transition system, such as the fully non-projective swap system. The parser has excellent parsing speed, compact models, and achieves high accuracy without requiring any additional resources such as raw corpora. We tested it on all 19 treebanks of the Universal Dependencies project. The C++ implementation of the parser is being released as an open-source tool."
Vytvorili sme citačnú službu na protokole OAI-PMH pre digitálnu knižnicu DSpace.,"Citing submissions is important but citing data submissions has not an established format yet.

We have created a citation service based on DSpace OAI-PMH endpoint implementation which returns citations of resources specified by PID and in desired format like simple html styled text. We display the citation box in DSpace item view but also in external applications."
CLARIN centrum sa môže nazývať CLARIN-B centrum iba ak spĺňa špecifické kritériá. Digitálny repozitár LINDAT/CLARIN postavený na DSpace spĺňa väčšinu týchto požiadaviek.,This talk presents the steps required for becoming a CLARIN-B centre using LINDAT/CLARIN digital library based on DSpace.
"Identifikovali sme štyri základné vlastnosti, ktoré spravili zdieľanie dát v našom repozitári atraktívnejšie.",Our experience show that submitters of data to our repository request specific features in contrast to the established ones. We have identified four such features which we implemented into our repository based on DSpace. Three features are described in this paper in more detail. The last one is described in a separate paper.
"Zdieľanie dát sa stáva neoddeliteľnou súčasťou vedeckej práce. Pripraviť dáta na zdieľanie vyžaduje vybranie správnej licencie. Popisujeme framework, ktorý takéto zdieľanie umožňuje.","The necessity to share and preserve data and software is becoming more and more important. Without the data and the software, research cannot be reproduced and tested by the scientific community. Making data and software simply reusable and legally unequivocal requires choosing a license for data and software which is not a trivial task. We describe a legal/licensing framework which implements the complete support for licensing submissions."
"S přibývajícím množstvím dat a služeb dostupných v infrastruktuře LINDAT/CLARIN roste potřeba správně citovat, sdílet, odkazovat a získávat statistiky využití. Představení frameworku, který zajišťuje jednotný vzhled a zmíněnou funkcionalitu.","With an increasing amount of data and services available in the LINDAT/CLARIN infrastructure comes the need to properly cite, share, cross-reference and gather usage statistics. We introduce a framework that ensures a consistent look and the mentioned functionality."
"CsEnVi Pairwise Parallel Corpora je soubor dvou paralelních korpusů, anglicko-vietnamského a česko-vietnamského, sestavených z dostupných filmových titulků a titulků přednášek TED. Korpusy byly očištěny naší poloautomatickou filtrací a jsou zarovnány po větách.",CsEnVi Pairwise Parallel Corpora is a collection of two parallel corpora: an English-Vietnamese one and a Czech-Vietnamese one. The corpora contain translations of movie and TED subtitles that were already available. The corpora were cleaned using our semi-automatic filtering and are provided aligned at the sentence level.
"Představujeme nástroj pro spojování frázových tabulek prostřednictvím prostředního, pivotního, jazyka.","Over the past years, pivoting methods, i.e. machine translation via a third language, gained respectable attention. Various experiments with different approaches and datasets have been carried out but the lack of open-source tools makes it difficult to replicate the results of these experiments. This paper presents a new tool for pivoting for phrase-based statistical machine translation by so called phrase-table triangulation. Besides the tool description, this paper discusses the strong and weak points of various triangulation techniques implemented in the tool."
"Soubor obsahuje standardní test set WMT z roku 2013, ručně přeložený z angličtiny do vietnamštiny. Soubor tak představuje obohacení dosavadní multiparalelní kolekce (anglicky, česky, německy, francouzsky, španělsky a rusky) o nový jazyk.","The file contains the standard WMT 2013 test set, manually translated from English to Vietnamese, thus extending the WMT 2013 multi-parallel set of languages (English, Czech, German, French, Spanish, Russian)."
"Představujeme model a algoritmus pro sémantickou analýzu ve formalismu lambda-kalkulus, který je založen na přístupu Constrined Conditional Model.Dále představujeme metodu pro učení omezujících podmínek přímo ze znalostních grafů. V našem probíhajícím průzkumu optimalizujeme model pomocí lineárního programování.","We introduce a model and an algorithm for semantic parsing in λ-calculus formalism which is
based on Constrained Conditional Model framework (Roth and Yih, 2005). We also introduce an
approach for learning the constraints of our model directly from knowledge graph which scales up for
new domains easily. In this ongoing project we optimize our model on a dataset using integer linear
programming. Our project includes two parts and our results in the first part show a meaningful
improvement over previous models."
"Poruzumění mluvené řeči (Spoken language understanding, SLU) a konkrétněji sémantický parsing je zásadní komponentou každé řečové aplikace. Tento článek podává přehled současného výzkumu v oblasti SLU s důrazem na metody strojového učení používané k tomuto účelu. Sledujeme aktuální trendy v sémantickém parsingu a diskusi uzavíráme výhledem na nejslibnější směry výzkumu do budoucna.","Spoken Language Understanding (SLU) and more specifically, semantic parsing is an indispensable task in each speech-enabled application. In this survey, we review the current research on SLU and semantic parsing with emphasis on machine learning techniques used for these tasks. Observing the current trends in semantic parsing, we conclude our discussion by suggesting some of the most promising future research trends."
"Doktorská práce se zabývá lingvistickou analýzou diskurzních vztahů jakožto jednoho z aspektů textové koherence. Diskurzními vztahy rozumíme významové vztahy mezi jednotlivými propozicemi v textu, tzv. diskurzními argumenty. Cílem práce je ucelený popis diskurzních vztahů v češtině a jeho vtělení do anotačního schématu Pražského závislostního korpusu. Práce je rozdělena do tří částí: První z nich je zaměřena na teoretický popis diskurzních vztahů a rozbor vhodnosti různých metodologických postupů při korpusovém zpracování. Druhá část podrobně popisuje navržené schéma pro anotaci diskurzních vztahů a proces vzniku takto značeného korpusu včetně evaluace konzistence značených dat. V poslední části práce se pak věnujeme některým problematickým okruhům při užití navrženého schématu a jejich řešení.","This doctoral thesis is devoted to linguistic analysis of discourse relations as one of the aspects of discourse coherence. Discourse relations are semantic relations holding between propositions in a discourse (discourse arguments). The aim of the thesis is a complex description of discourse relations in Czech and its application in an annotation scheme in the Prague Dependency Treebank. The thesis is divided into three parts: The first one is focused on the theoretical description of discourse relations and on analysis of adequacy of various methodological concepts in corpus processing. The second part describes in detail the proposed scheme for the annotation of discourse relations and the process of the corpus build-up including the evaluation of consistency of the annotated data. Finally, in the last part of the thesis, we address some problematic issues arisen with the employment the proposed scheme and look for their possible solutions."
"Článek si klade za cíl nalézt v bohatě anotovaném korpusu příznaky přínosné pro automatickou anotaci/detekci atribuce – přiřazení obsahu textu zdrojům, které jej vyjadřují. Určení atribuce je významnou součástí reprezentace a modelování dirkurzních vztahů, ale je rovněž zásadní součástí např. analýzy sentimentu (identifikace zdrojů).","The paper aims at mining a richly annotated treebank for features relevant in automatic annotation/detection of attribution – ascription of texts contents to agents who expressed them. Resolving attribution is an important component
for representing and modeling discourse structure, but it is also an essential task in opinion mining and sentiment analysis (e.g. identification of sources)."
"Článek popisuje algoritmus na naučení se morfologických paradigmat a slovníku pro flektivní jazyky, který je nenáročný na zdroje.","This paper presents a resource-light acquisition
of morphological paradigms and lexicon for fusional languages. It builds upon Paramor [10], an unsupervised system, by extending it: (1) to accept a small seed of manually provided word inflections with marked morpheme boundary; (2) to handle basic allomorphic changes acquiring
the rules from the seed and/or from previously
acquired paradigms. The algorithm has been tested on Czech and Slovene tagged corpora and has shown increased F-measure in comparison with the Paramor baseline."
"Universal Dependencies je projekt, který vyvíjí mezijazykově konzistentní morfologicko-syntaktickou anotaci mnoha jazyků s cílem usnadnit vývoj jazykově nezávislých parserů, mezijazykové strojové učení a výzkum parsingu z perspektivy jazykové typologie. Anotační schéma je založeno na univerzálních Stanfordských závislostech (de Marneffe et al., 2006, 2008, 2014), univerzálních značkách Google (Petrov et al., 2012) a na Intersetu, tj. interlingvě pro sady morfologických značek (Zeman, 2008). Toto je druhé vydání treebanků UD, verze 1.1.","Universal Dependencies is a project that seeks to develop cross-linguistically consistent treebank annotation for many languages, with the goal of facilitating multilingual parser development, cross-lingual learning, and parsing research from a language typology perspective. The annotation scheme is based on (universal) Stanford dependencies (de Marneffe et al., 2006, 2008, 2014), Google universal part-of-speech tags (Petrov et al., 2012), and the Interset interlingua for morphosyntactic tagsets (Zeman, 2008). This is the second release of UD Treebanks, Version 1.1."
"Cílem Rozpoznávání textu z fotografií (STR) je právně lokalizovat a přespat text zachycený na fotografii z reálného prostředí. Rostoucí úspěšnost rozpoznávání zároveň dělá z těchto textů zajímavý zdroj dat pro zpracování přirozeného jazyka a zároveň přináší nové problémy, které jsou specifické právě pro texty, které se na fotografiích vyskytují.
V tomto článku představujeme učení dekódování textových řetězců v systému STR pomocí metod strukturní predikce, které se využívají při dekódování v rozpoznávání řeči a strojovém překladu. Model při učení využívá jazykové a typografické rysy. Navržená metoda je evaluována  na standardní datové sadě a zvyšuje úspěšnost rozpoznávání znaků i rozpoznávání celých slov.","Scene Text Recognition (STR) is a task of localizing and transcribing textual information captured in real-word images. With its increasing accuracy, it becomes a new source of textual data for standard Natural Language Processing tasks and poses new problems because of the specific nature of Scene Text.
In this paper, we learn a string hypotheses decoding procedure in an STR pipeline using structured prediction methods that proved to be useful in automatic Speech Recognition and Machine Translation. The model allow to employ
a wide range of typographical and language features into the decoding process. The proposed method is evaluated on a standard dataset and improves both character and word recognition performance over the baseline."
"V této disertační práci zkoumáme strojový překlad mezi češtinou a ruštinou z hlediska lingvisty. 
Hlavním cílem práce je lingvistický rozbor chyb ve výstupu čtyř systémů strojového překladu, dvou experimentálních - TectoMT, Moses - a dvou komerčních - PC Translator a Google Translate. Analyzujeme každý typ chyb a řešíme, zda daná chyba souvisí s rozdílem mezi češtinou a ruštinou nebo zda je zapříčiněná architecturou jednotlivých systémů. Ve zvláštní kapitole se zaměřujeme na chyby v povrchové valenci sloves.","In this thesis we analyze machine translation between Czech and Russian languages from the perspective of a linguist. We explore the output of our two experimental systems and two commercial systems: PC Translator and Google Translate. We make a linguistically-motivated classification of errors for the language pair and describe each type of error in detail, analyzing whether it occurred due to some difference between Czech and Russian or is it caused by the system architecture. In particular, we focus on one specific error type - surface valency."
Zkoumáme chyby ve VV v statistickém strojovém překladu pro několik jazyků. Poživáme několik metod pro integraci VV do překladového systému.,"In this paper, we analyse the usage of multiword expressions in Statistical Machine Translation. We exploit the  Moses SMT toolkit to train models for French-English and Czech-Russian language pairs. For each language pair, two models were built: a baseline model without additional MWE data and the model enhanced with information on MWE. For the French-English pair, we tried three methods of introducing the MWE data. For Czech-Russian pair, we used just one method - adding automatically extracted data as a parallel corpus."
Představujeme nový dialogový systém učící se z interakce s uživateli. Systém žádá uživatele o radu u neznámých otázek a zobecňuje je v souladu se svou znalostní bází. Dialogový systém je vyhodnocen prostředníctvím platformy CrowdFlower.,"We present a novel knowledge based dialog system that learns from
interactions with users. It asks users for advice about unknown questions and
generalizes them according to its knowledge base. The dialog system was evaluated
through the CrowdFlower crowdsourcing platform and it showed the ability to adapt
without any prior information except the knowledge base."
"Tento článek představuje hybridní dialog state tracker, který kombinuje přístup pravidlový s přístupem strojového učení pro trackování stavu dialogu. Strojové učení je v našem trackeru realizováno s využitím Long Short Term Memory (LSTM) sítě. Podle našich současných znalostí hybridní tracker dosahuje state-of-the-art výsledků v soutěži Dialog State Tracking Challenge (DSTC) 2, v kategorii systémů využívající pouze originální SLU jako svůj vstup.","This paper presents a hybrid dialog state tracker that combines a rule based and
a machine learning based approach to belief state tracking. Therefore, we call it
a hybrid tracker. The machine learning in our tracker is realized by a Long Short
Term Memory (LSTM) network. To our knowledge, our hybrid tracker sets a new
state-of-the-art result for the Dialog State Tracking Challenge (DSTC) 2 dataset
when the system uses only live SLU as its input."
"CLARA (Common Language Resources and Their Applications) je projekt v rámci Marie Curie Initial Training Network, který probíhal v letech 2009-2014 a jehož cílem bylo poskytnout vědeckou přípravu mladým vědcům v oblasti jazykových zdrojů a zpracování jazykových dat (např. návrhy jazykových infrastruktur, lexikální sémantické modelování, modelování domény, multimediální a multimodální komunikace, technologie automatického zpracování jazyka a jejich aplikace). Projekt vyústil v nový teoretický vhled do problematiky a jeho výstupem jsou nové jazykové zdroje a nástroje, především však připravil novou generaci výzkumníků, kteří jsou schopni dále obor rozvíjet.","CLARA (Common Language Resources and Their Applications) is a Marie Curie Initial Training Network which ran from 2009 until 2014 with the aim of providing researcher training in crucial areas related to language resources and infrastructure. The scope of the project was broad and included infrastructure design, lexical semantic modeling, domain modeling, multimedia and multimodal communication, applications, and parsing technologies and grammar models. An international consortium of 9 partners and 12 associate partners employed researchers in 19 new positions and organized a training program consisting of 10 thematic courses and summer/winter schools. The project has resulted in new theoretical insights as well as new resources and tools. Most importantly, the project
has trained a new generation of researchers who can perform advanced research and development in language resources and technologies."
"Přednáška prezentuje český žákovský korpus Czesl, jeho anotační schéma a způsob anotace.","Czesl is a corpus of texts produced by non‐native speakers of Czech. To  adequately  annotate the  deviations  in  Czech word‐order  and  a fairly complex inflectional morphology, the corpus uses two tiers of annotation,  each  tier  correcting  different  types  of  errors. Links between the tiers allow capturing errors in word order and complex discontinuous  expressions.  Errors  are  not  only  corrected,  but  also classified. We combine (1) a grammar-based taxonomy of errors in spelling,  morphology,  morphosyntax,  lexicon  and  style,  and  (2)  a formal  error  classification based on surface alternations. The annotation scheme  was  tested  on  a  data set  of  approx.  175,000 words  with  fair  inter‐annotator  agreement  results.  In  addition  to presenting  the  current state  of  the  corpus,  I  will  discuss  various decisions (design, workflow, technical) made during its creation and revisit them with the advantage of hindsight."
Cílem naší práce je prozkoumat možnost využití školních rozborů jako trénovací data pro automatickou syntaktickou analýzu. Implementujeme editor pro procvičování tvaroslovných a větných rozborů. Následně tyto rozbory shromažďujeme a transformujeme do tvaru potřebného pro trénování vybraného parseru. Pilotním jazykem je čeština a cílovým formátem jsou anotace ve stylu Pražského závislostního korpusu. Nyní se zaměřujeme na vyhodnocení větných rozborů a jejich kombinaci s cílem získat kvalitnější rozbory.,"The purpose of our work is to explore the possibility of using sentence diagrams produced by schoolchildren as training data for automatic syntactic analysis. We have implemented a sentence diagram editor that schoolchildren can use to practice morphology and syntax. We collect their diagrams, combine them into a single diagram for each sentence and transform them into a form suitable for training a particular syntactic parser. In this study, the object language is Czech, where sentence diagrams are part of elementary school curriculum, and the target format is the annotation scheme of the Prague Dependency Treebank. We mainly focus on the evaluation of individual diagrams and on their combination into a merged better version."
"Přednáška prezentuje český žákovský korpus Czesl, jeho anotační schéma a způsob anotace.","Czesl is a corpus of texts produced by non‐native speakers of Czech. To  adequately  annotate the  deviations  in  Czech word‐order  and  a fairly complex inflectional morphology, the corpus uses two tiers of annotation,  each  tier  correcting  different  types  of  errors. Links between the tiers allow capturing errors in word order and complex discontinuous  expressions.  Errors  are  not  only  corrected,  but  also classified. We combine (1) a grammar-based taxonomy of errors in spelling,  morphology,  morphosyntax,  lexicon  and  style,  and  (2)  a formal  error  classification based on surface alternations. The annotation scheme  was  tested  on  a  data set  of  approx.  175,000 words  with  fair  inter‐annotator  agreement  results."
"Potřeba dat o akvizici češtiny cizinci vedla k vytvoření prvního žákovského korpusu češtiny. Po představení jeho základního designu a parametrů, se zaměřujeme na technické aspekty: přepis ručně psaných textů, proces anotace a možnosti využití výsledků, spolu s nástroji používanými pro tyto úkoly.","The need for data about the acquisition of Czech by non-native learners prompted the compilation of the first learner corpus of Czech. After introducing its basic design and parameters, including a multi-tier manual annotation scheme and error taxonomy, we focus on the more technical aspects: transcription of hand-written source texts, process of annotation, and options for exploiting the result, together with tools used for these tasks and decisions behind the choices. To support or even substitute manual annotation we assign some error tags automatically and use automatic annotation tools (tagger, spell checker)."
"Práce se zabývá popisem českého slovosledu kontextově nezapojených participantů. Sleduje, zda v povrchovém slovosledu existuje jejich základní (frekvenčně výrazně převažující) pořadí (srov. narodit se v Brně v roce 1950 vs. narodit se v roce 1950 v Brně). Zároveň se věnuje sledování faktorů, které slovosled ovlivňují (např. formě participantu, způsobu jeho lexikálního vyjádření nebo vlivu slovesné valence). V závěru krátce srovnává slovosledné tendence v češtině a v němčině. Pro ověření stanovených cílů užívá zejména data Pražského závislostního korpusu. Práce teoreticky vychází ze zásad funkčního generativního popisu. Výsledky výzkumu ukazují, že v českém povrchovém slovosledu lze alespoň v některých případech vysledovat určité obecnější tendence k jednomu ze dvou možných slovosledných pořadí.","The presented thesis is focused on the Czech word order of contextually non-bound verbal modifications. It monitors whether there is a basic order in the contextually non-bound part of the sentence (significantly predominant in frequency) in the surface word order (cf. narodit se v Brně v roce 1950 vs. narodit se v roce 1950 v Brně; literally to be born in Brno in 1950 vs. to be born in 1950 in Brno). At the same time, we try to find out the factors influencing the word order (such as the form of modifications, their lexical expression or the effect of verbal valency). Finally, we briefly compare the word order tendencies in Czech and German. For the verification of the objectives, mainly the data from the Prague Dependency Treebank are used. The work is based on the theoretical principles of Functional Generative Description. Research results demonstrate that, at least in some cases, it is possible to detect certain general tendencies to use preferably one of two possible surface word order sequences in Czech."
"Práce se zabývá slovosledem aktantů (aktoru a patientu) v ohniskové části českých vět. Slovosledná analýza výskytů aktoru a patientu přináší popis faktorů, které mohou ovlivnit uspořádání větných participantů ve slovosledu jako takových.",The paper deals with word order of inner participants (Actor and Patient) in the focus-part of Czech sentences. The analysis of the sequence of Actor and Patient reveals the criteria that may influence the arrangement of sentence participants as such.
"Poster představil tabulku kontextové zapojenosti závislých vět v češtině a popisuje důvody, proč bývají některé typy závislých vět českými pisateli častěji prezentovány jako čtenáři známé.",The paper deals with the established scale of contextual boundness of subordinate clauses in Czech and describes the reasons why some types of categories are more often presented as known then others by the Czech writers.
Článek popisuje 40. ročník Olympiády v českém jazyce – přináší komentovaný přehled úkolů a hodnotí úspěšnost řešitelů.,The article describes the 40th year of the Olympics in the Czech language – it provides an commented list of tasks and evaluate the success of investigators.
"V příspěvku je testována hypotéza, že valenčně obligatorní volná slovesná doplnění v povrchovém slovosledu následují za neobligatorními (fakultativními). Užité metody hypotézu nepotvrdily,  ale výsledky výzkumu ukázaly, že slovosled kontextově nezapojených volných slovesných doplnění v češtině ovlivňují jiné faktory – pozice věty v textu, forma a délka slovesného doplnění a jeho syntakticko-sémantická role (funktor).","The paper tests a hypothesis that obligatory adverbials (in terms of the valency)
follow the non-obligatory (i.e. optional) ones in the surface word order. Neither of the used methods has proved the given hypothesis but according to the results, there are several other
features that influence word order of contextually non-bound free modifiers of a verb in Czech, namely position of the sentence in the
text, form and length of the verb modifiers (the whole subtrees), and the semantic dependency relation (functor) of the modifiers."
"Článek je aktualizovanou a rozšířenou verzí článku z konference DepLing 2011. Reprezentuje první krok v porovnání vlastností syntakticko-sémantických vztahů přítomných ve struktuře věty a jejich ekvivalentů ve struktuře diskurzu. Studie byla provedena na ručně anotovaných datech Pražského závislostního korpusu (PDT). Podle analýzy podkladové syntaktické struktury věty (tektogramatiky) v PDT rozlišujeme řadu typů vztahů, které mohou být vyjádřeny jak v jedné větě (tj. ve stromu), tak i v delším textu, napříč hranicemi vět (mezi stromy). Tvrdíme, že tyto vztahy na jednu stranu zachovávají své sémantické vlastnosti jak uvnitř věty, tak v delším textu (např. příčinný vztah zůstává příčinným vztahem), na druhou stranu ale v souladu se sémantickými vlastnostmi vztahů je jejich distribuce uvnitř vět či mezi větami velice rozličná. V této studii toto pozorování ověřujeme na třech případech (na podmínkovém, specifikačním a opozičním vztahu) a dokládáme podobným chováním anglických dat projektu Penn Discourse Treebank.","The present contribution is an updated and extended version of the paper from the conference DepLing 2011. It represents the first step in comparing the nature of syntactico-semantic relations present in the sentence structure to their equivalents in the discourse structure. The study is carried out on the basis of a Czech manually annotated material collected in the Prague Dependency Treebank (PDT). According to the analysis of the underlying syntactic structure of a sentence (tectogrammatics) in the PDT, we distinguish various types of relations that can be expressed both within a single sentence (i.e. in a tree) and in a larger text, beyond the sentence boundary (between trees). We suggest that, on the one hand, semantic nature of each type of these relations corresponds both within a sentence and in a larger text (i.e. a causal relation remains a causal relation) but, on the other hand, according to the semantic properties of the relations, their distribution in a sentence or between sentences is very diverse. In this study, this observation is analyzed in detail for three cases (relations of condition, specification and opposition) and further supported by similar behaviour of the English data from the Penn Discourse Treebank."
"Zpráva z 25. ročníku evropské letní školy logiky, jazyka a informace v Düsseldorfu.","A report from the 25th European Summer School in Logic, Language and Information in Düsseldorf."
"Příspěvek je věnován automatické detekci vulgarismů, tj. význačných indikátorů negativního hodnocení, v rámci postojové analýzy. Zaměříme se na význam a kategorizaci vulgarismů a především popíšeme základní strategie při vytváření nových vulgarismů v internetové komunikaci, od přidávání nepísmenných znaků přes záměnu písmen po užívání speciálních zkratek a výrazů na pomezí argotu. Dále navrhneme základní řešení pro automatické zpracování těchto slov.",This talk is focused on automatioc swear words detection in sentiment analysis. We outline swear words categorization and describe basic strategies when creating new vulgarisms within online communication.
"V článku představujeme Archiv vizuální historie MALACH jako multimodální zdroj dat pro postojovou analýzu v češtině, případně v dalších jazycích, které archiv obsahuje.","In this paper, we introduce the Visual History Archive of the USC Shoah Foundation as a multimodal data resource for sentiment analysis in Czech, but potentially all thirty three languages it contains. We take the opportunity of having both physical access to these unique data and the well-established research group on sentiment analysis at Charles University in Prague. Our aim is to provide methodology for sentiment annotation of these multimodal data combining subjectivity detection within a treebank with spoken term detection."
Tento výzkum rozvíjí myšlenku ekvikomplexity typologicky odlišných jazyků za pomocí konstrukční analýzy struktur obsahujících  adkolokační verbální idiomy.,"This survey serves as an illustration of equalization tendency in typologically different languages, using constructional analysis of structures containing adcollocational verbal idioms."
"Předběžný výzkum struktury evaluativního významu v češtině. Popisujeme způsoby, jakými je evaluativní význam modelován na různých úrovních popisu jazyka, především však na rovině morfologické. Při formalizaci využíváme konstrukčně-gramatického formalismu.","In this paper we present a preliminary research into the linguistic structure of evaluative meaning in Czech. We describe the ways the evaluative meaning is modelled in Czech using means from different layers of linguistic description, mainly morphology. Moreover, we use the construction grammar framework (see Fried and Östman 2004) to capture evaluative sentences and to depict the relationship between structure, meaning and use of evaluative expressions in language, joining the growing body of constructional research concerning the expressions of subjective judgement, broadly defined (e.g. Matsumoto 2008, Fried and Östman 2009, Terkourafi 2010)."
"V přednášce se zaměříme na problematiku postojové analýzy, tedy lingvistického zkoumání emocí, názorů a postojů vyjádřených v textu nebo v řeči. Shrneme dosavadní bádání v oboru a zaměříme se na jednotlivé aspekty vyjadřování emocí: na stránku lexikální (slovník hodnotících výrazů pro češtinu, evaluativní idiomy), gramatickou (význam jednotlivých slovních druhů, typické syntaktické vzorce hodnotících vět) a především sémantickou a pragmatickou. Dále představíme dostupné aplikace vycházející z postojové analýzy a nastíníme problémy a výzvy, které jsou v této disciplíně aktuální – např. automatická detekce cílů hodnocení či zapojení nadvětné syntaxe.","In this talk we focus on sentiment analysis, i.e. linguistic analysis of emotions and opinions expressed in speech or in text."
"Příspěvek byl věnován problematice neshodného genitivního přívlastku, konkrétně možnostem jeho pronikání do antepozice. V hlavní části jsme se věnovali kategorizaci neshodných genitivních přívlastků vyskytujících se v antepozici na datech z PDT.","The talk was dedicated to syntactic position of non-conguent attribute expressed by a noun in genitive, including categorization based on PDT data."
"Příspěvek popisuje možnosti vylepšení automatické detekce hodnocených entit v rámci postojové analýzy za využití metod kvantitativní lingvistiky, přesněji tematické koncentrace textu.","This contribution describes improvements of opinion target identification in sentiment analysis, employing methods from quantitative linguistics, namely thematic concentration of the text."
"Cílem tohoto článku je představit Czech subjectivity lexicon, nový lexikální zdroj pro analýzu sentimentu v češtině. Popisujeme jednotlivé fáze manuálních úprav slovníku a demonstrujeme jeho využití při klasifikaci polarity, respektive pro trénování Maximum Entrophy klasifikátoru. Úspěšnost klasifikátoru obohaceného o slovník testujeme na několika datasetech. Na základě výsledků navrhujeme vylepšení stávajícího systému.","The aim of this paper is to introduce the Czech subjectivity lexicon, a new lexical resource for sentiment analysis in Czech. We describe particular stages of the manual refinement of the lexicon and demonstrate its use in the state-of-the-art polarity classifiers, namely the Maximum Entrophy classifier. We test the success rate of the system enriched with the dictionary on different data sets, compare the results and suggest some further improvements of the lexicon-based classification system."
"Přestože je postojová analýza široce zkoumaným odvětvím, většina výzkumu probíhá na prostém textu. Tento poster ukazuje využití závislostních dat z PDT pro nejrůznější úlohy v rámci opinion miningu.","Although sentiment analysis has been gaining a booming interest recently, most experiments use only plain text corpora. This poster shows that an existing richly annotated Prague Dependency Treebank can be exploited as a source of valuable information important for various opinion mining subtasks."
V příspěvku popisujeme generalizované vzorce výskytu postojových cílů (opinion targets) v evaluativních konstrukcích.,"In this paper, we describe and generalize syntactic patterns of structures containing opinion targets, i.e. evaluated entities, taking into account their semantic properties."
"Článek popisuje systém pro automatickou extrakci hodnocených cílů, se kterým jsme se zúčastnili soutěže SemEval 2014. Systém je pravidlový, bez zapojení strojového učení, přesto však dosahuje relativně dobrých výsledků.","This paper describes our submission to SemEval
2014 Task 41 (aspect based sentiment analysis). The current work is based on the assumption that it could be advantageous to connect the subtasks into one workflow, not necessarily following their
given order. We took part in all four subtasks (aspect term extraction, aspect term polarity, aspect category detection, aspect category polarity), using polarity items detection via various subjectivity lexicons and employing a rule-based system applied on dependency data. To determine aspect categories, we simply look up their WordNet hypernyms. For such a basic method using no machine learning techniques, we consider the results rather satisfactory."
Používání funkčních slov v neřízeném závislostním parsingu. Používání funkčních slov v neřízeném závislostním parsingu.,"In this paper, we show some properties of function words in dependency trees. Function
words are grammatical words, such as articles, prepositions, pronouns, conjunctions, or auxiliary verbs. These words are often short and very frequent in texts and therefore many of them can be easily recognized. We formulate a hypothesis that function words tend to have a fixed number of dependents and we prove this hypothesis on treebanks. Using this hypothesis, we are able to improve unsupervised dependency parsing and outperform previously published state-of-the-art results for many languages."
"Při nasazování dialogového systému pro novou doménu je nutné se vypořádat s nedostatkem trénovacích dat pro doménově specifické statistické modely. V tomto článku popisujeme své zkušenosti s vytvářením dialogového systému pro informace o veřejné dopravě a počasí přímo za provozu s uživateli z řad veřejnosti. Postupovali jsme inkrementálně od minimálního systému, který byl nasazen na bezplatné telefonní číslo ke sběru řečových dat. Na získaných datech jsme byli schopni natrénovat statistické modely – doménové jazykové modely pro rozpoznávání řeči a model pro porozumění jazyku, který používá automaticky generovanou sémantickou anotaci. Náš postup ukazuje, že úspěšný systém lze postavit i s minimálním úsilím a bez předem dostupných trénovacích dat pro danou doménu.","When deploying a spoken dialogue system in a new domain, one faces a situation where little to no data is available to train domain-specific statistical models. We describe our experience with bootstrapping a dialogue system for public transit and weather information in real-word deployment under public use. We proceeded incrementally, starting from a minimal system put on a toll-free telephone number to collect speech data. We were able to incorporate statistical modules trained on collected data – in-domain speech recognition language models and spoken language understanding – while simultaneously extending the domain, making use of automatically generated semantic annotation. Our approach shows that a successful system can be built with minimal effort and no in-domain data at hand."
"Prezentujeme metodu strojového učení („s učitelem“) pro detekci a výběr slovesných valenčních rámců, tj. specifický druh desambiguace významu sloves založený na informacích o subkategorizaci; odpovídá to detekci zmínek o událostech v textu. Používáme bohaté závislostní informace z Pražských závislostních korpusů češtiny a angličtiny a několika dříve vyvinutých nástrojů (taggery, parsery).

Výběr rámce je založen na slovnících ručně sestavených pro tyto korpusy – PDT-Vallexu pro češtinu a EngVallexu pro angličtinu. Výsledky ukazují, že detekce predikátů je snažší v češtině, ale při výběr správného rámce jsme dosáhli lepších výsledků v angličtině.","We present a supervised learning method for verbal valency frame detection and selection, i.e., a specific kind of word sense disambiguation for verbs based on subcategorization information, which amounts to detecting mentions of events in text. We use the rich dependency annotation present in the Prague Dependency Treebanks for Czech and English, taking advantage of several analysis tools (taggers, parsers) developed on these datasets previously. 

The frame selection is based on manually created lexicons accompanying these treebanks, namely on PDT-Vallex for Czech and EngVallex for English. The results show that verbal predicate detection is easier for Czech, but in the subsequent frame selection task, better results have been achieved for English."
"Tento balíček obsahuje sady paralelních vět pro vývoj a testování strojového překladu souhrnů vědeckých článků z oboru medicíny mezi češtinou, angličtinou, francouzštinou a němčinou.","This package contains data sets for development and testing of machine translation of sentences from summaries of medical articles between Czech, English, French, and German."
"Lékařská překladová úloha na WMT 2014 představuje zajímavou výzvu pro strojový překlad (machine translation, MT). Ve standardní překladové úloze je koncovou aplikací překlad sám o sobě. Naproti tomu v této úloze je systém strojového překladu součástí většího systému pro mezijazykové vyhledávání informací (information retrieval, IR).","The WMT 2014 Medical Translation Task poses an interesting challenge for Machine Translation
(MT). In the standard translation task, the end application is the translation itself. In this task, the MT system is considered a part of a larger system for cross-lingual information retrieval (IR)."
"Prezentujeme sadu nahrávek telefonních hovorů v angličtině a češtině, vytvořenou pro trénování akustických modelů pro automatické rozpoznávání řeči v hlasových dialogových systémech. Data sestávají ze 45 hodin nahrávek v angličtině a více než 18 hodin v češtině. Všechna data a část transkripcí byla získána pomocí crowdsourcingu, zbytek byl přepsán profesionálně. Data zveřejňujeme společně se skripty pro preprocessing a sestavení akustických modelů v nástrojích HTK a Kaldi, včetně modelů natrénovaných na našich datech. Data jsou licencována pod CC-BY-SA 3.0, skripty pod licencí Apache 2.0. V článku popisujeme metodiku sběru dat, jejich velikost a vlastnosti, a trénovací skripty a jejich použití. Použitelnost dat a skriptů demostrujeme natrénováním a validací akustických modelů.","We present a dataset of telephone conversations in English and Czech, developed to train acoustic models for automatic speech recognition (ASR) in spoken dialogue systems (SDSs). The data comprise 45 hours of speech in English and over 18 hours in Czech. All audio data and a large part of transcriptions was collected using crowdsourcing; the rest was transcribed by hired transcribers. We release the data together with scripts for data re-processing and building acoustic models using the HTK and Kaldi ASR toolkits. We publish the trained models described in this paper as well. The data are released under the CC-BY-SA 3.0 license, the scripts are licensed under Apache 2.0. In the paper, we report on the methodology of collecting the data, on the size and properties of the data, and on the scripts and their use. We verify the  usability of the datasets by training and valuating acoustic models using the presented data and scripts."
Vystadial 2013 ASR trénovací skripty obsahují skripty pro HTK a KALDI vyvinuté pro trénování akustických modelů pro automatické rozpoznávání řeči v dialogových systémech.,Vystadial 2013 ASR training scripts  provides ASR training scripts for HTK or KALDI developed for training acoustic models for automatic speech recognition in spoken dialogue systems.
"Vystadial 2013 je databáze telefonních hovorů v češtině, vyvinuté pro trénování akustických modelů pro automatické rozpoznávání řeči v dialogových systémech. Data obsahují více než 15 hodin v českém jazyce.","Vystadial 2013 is a dataset of telephone conversations in Czech, developed for training acoustic models for automatic speech recognition in spoken dialogue systems. The data comprise over over 15 hours in Czech, plus orthographic transcriptions."
"Vystadial 2013 je databáze telefonních hovorů v anglickém jazyce, vyvinuté pro trénování akustických modelů pro automatické rozpoznávání řeči v dialogových systémech. Data obsahují více než 41 hodin v anglickém jazyce.","Vystadial 2013 is a dataset of telephone conversations in English, developed for training acoustic models for automatic speech recognition in spoken dialogue systems. The data comprise over over 41 hours in English, plus orthographic transcriptions."
"""Lehká"" slovesa představující určitý typ komplexních predikátů představují značný problém jak pro teoretickou, tak pro komputační lingvistiku. Syntaktické struktury, které daná slovesa zakládají, jsou dány nejen slovesem, ale i predikativním elementem, se kterým se daná slovesa kombinují. V uvedeném příspěvku jsou analyzovány ze syntaktického i sémantického hlediska česká ""lehká"" slovesa kombinovaná s predikativními jmény. Je navržena jejich teoreticky adekvátní a zároveň úsporná lexikografická reprezentace. Dále jsou probírány zejména dva aspekty: možnost sestavení inventáře českých ""lehkých"" sloves a kritéria pro jejich rozpoznání.","Light verbs – representing a type of complex predicates – pose a serious challenge for both theoretical and applied linguistics as their syntactic structures are determined not solely by verbs alone but also by predicative elements with which light verbs combine. In this contribution, syntactic and semantic properties of Czech light verbs combined with predicative nouns are discussed and an adequate and economical lexicographic representation of these phenomena are proposed. Moreover, two tasks are addressed: compiling an inventory of Czech light verbs entering into combination with predicative nouns and adopting criteria for distinguishing light verbs from main verbs."
"Práce předkládá návrh formalizovaného lexikografického modelu alternací,tedy změn v syntaktické struktuře sloves, a jejich lingvisticky adekvátního, přitom ekonomického popisu ve slovníku. Jádrem práce je podrobný rozbor dvou vybraných typů lexikalizovaných alternací. Na základě této analýzy je navržen systém popisu alternací pro češtinu sestávající z lexikálních jednotek propojených atributy určujícími typy možných alternací (datová komponenta slovníku) a z obecných pravidel popisujících korespondenci situačních participantů a valenčních doplnění (pravidlová komponenta slovníku).","In this work, a formal model of a lexicographic description of selected changes in valency structure of Czech verbs, alternations, is proposed. This model is based on a thorough analysis of two types of Czech alternations. The proposed lexicographic representation supposes separate lexical units of verbs linked by a special attribute in the data component of the lexicon and general rules determining the mapping between participants and valency complementations of verbs."
"Článek pojednává o českých reflexivních slovesech z lexikografického hlediska. Ukazujeme, že reflexivní morfémy se/si plní v češtině různé funkce: (i) jsou to buď prostředky slovotvorného procesu reflexivizace, nebo (ii) prostředky vlastní (syntaktické) reflexivity, reciprocity, příp. diatezí. Všechny uvedené jazykové procesy jsou spoojeny se změnami ve valenční struktuře sloves. V článku podáváme návrh na jejich zachycení ve valenčním slovníku VALLEX.","Thi paper deals with Czech reflexive verbs from the lexicographic point of view. We show that
the Czech reflexive morphemes se/si constitute different linguistic meanings: either they are formal means of the word formation process of the so called reflexivization, or they are associated with the syntactic phenomena of reflexivity, reciprocity, and diatheses.
All of these processes are associated with changes in the valency structure of verbs. We formulate a proposal for their lexicographic representation for the valency lexicon of Czech verbs, VALLEX."
Roland Wagner v článku zaměřeném na česká reflexivní slovesa publikovaném v PBML prezentuje kritické výhrady k Funkčnímu generativnímu popisu (FGP). Pro autory FGP představuje jeho článek výzvu k doplnění mezer v analýze daného jevu v rámci FGP a k vyjasnění některých teoretických předpokladů týkajících se valence sloves a jejich reflexivních protějšků.,"Roland Wagner’s contribution published in the last volume of the PBML journal – focusing
(among other ideas) on the role of Czech reflexives – presents several critical remarks concerning the Functional Generative Description. These remarks represent a good challenge for the
authors developing this model to fill empirical gaps and to make clear some theoretical presuppositions concerning valency frames of verbs and their respective reflexive counterparts that are primarily addressed by RW’s critical survey."
"Závislostní sémantickou analýzu se širokým pokrytím definujeme jako úlohu nalézt skladební dvojice mezi všemi autosémantickými slovy ve větě, tj. strukturu sémantických závislostí, která reprezentuje jádro významu věty.",We define broad-coverage semantic dependency parsing as the task of recovering sentence-internal predicate-argument relationships for all content words i.e. a semantic dependency structure that constitutes the core structure of sentence meaning.
"V této práci představujeme dva nedávno vydané open-source nástroje: NameTag je volně šiřitelný software pro rozpoznávání pojmenovaných entit, který dosahuje nejlepších známých výsledků na češtině; MorphoDiTa provádí morfologickou analýzu (s lematizací), morfologické generování, značkování a tokenizaci s nejlepšími známými výsledky pro češtinu a rychlostí zpracování kolem 10-200 tisíc slov za sekundu. Nástroje mohou být natrénovány pro libovolný jazyk, pro který jsou k dispozici anotovaná data, jsou však zvlášť navrženy tak, aby byly efektivní pro flexivní jazyky. Oba nástroje jsou volně šiřitelné pod licencí LGPL a jsou distribuovány spolu z předtrénovanými lingvistickými modely, které jsou zdarma pro nekomerční využití podle licence CC BY-NC-SA. Vydání zahrnují samostatné nástroje, knihovny v C++ s vazbami pro Javu, Python a Perl, a konečně webové služby.","We present two recently released open-source taggers: NameTag is a free software for named entity recognition (NER) which achieves state-of-the-art performance on Czech; MorphoDiTa (Morphological Dictionary and Tagger) performs morphological analysis (with lemmatization), morphological generation, tagging and tokenization with state-of-the-art results for Czech and a throughput around 10-200K words per second. The taggers can be trained for any language for which annotated data exist, but they are specifically designed to be efficient for inflective languages. Both tools are free software
under LGPL license and are distributed along with trained linguistic models which are free for non-commercial use under the CC BY-NC-SA license. The releases include standalone tools, C++ libraries with Java, Python and Perl bindings and web services."
"Votter Corpus je nový anotovaný soubor sociálních dotazů a odpovědí. Votter Corpus je nový ve svém použití formátu mobilních aplikací a románu v jeho pokrytí specifických demografických. S více než 26 000 hlasy a téměř 1 miliony hlasů pokrývá Votter Corpus každodenní otázky a odpovědi, a to především pro uživatele, kteří jsou ve věku od 13 do 24 let.","The Votter Corpus is a new annotated corpus of social polling questions and answers. The Votter Corpus is novel in its use of the mobile application format and novel in its coverage of specific demographics. With over 26,000 polls and close to 1 millions votes, the Votter Corpus covers everyday question and answer language, primarily for users who are female and between the ages of 13-24. The corpus is annotated by topic and by popularity of particular answers. The corpus contains many unique characteristics such as emoticons, common mobile misspellings, and images associated with many of the questions. The corpus is a collection of questions and answers from The Votter App on the Android operating system. Data is created solely on this mobile platform which differs from most social media corpora. The Votter Corpus is being made available online in XML format for research and non-commercial use. The Votter android app can be downloaded for free in most android app stores."
"Reprezentace AMR abstrahují od morfologicko- syntaktických jevů, protože mnohé z nich mohou být důvodem mezijazykových rozdílů. V článku se snažíme zjistit, zda by AMR mohly napomoci počítačovému překladu. Využíváme k tomu porovnání překladu a anotace anglických vět do češtiny a čínštiny.","Abstract Meaning Representations (AMRs) are rooted, directional and labeled graphs that abstract away from morpho-syntactic idiosyncrasies such as word category (verbs and nouns), word order, and function words (determiners, some prepositions). Because these syntactic idiosyncrasies account for many of the cross-lingual differences, it would be interesting to see if this representation can serve, e.g., as a useful, minimally divergent transfer layer in machine translation. To answer this question, we have translated 100 English sentences that have existing AMRs into Chinese and Czech to create AMRs for them. A cross-linguistic comparison of English to Chinese and Czech AMRs reveals both cases where the AMRs for the language pairs align well structurally and cases of linguistic divergence.
We found that the level of compatibility of AMR between English and Chinese is higher than between English and Czech. We believe this kind of comparison is beneficial to further refining the annotation standards for each of the three languages and will lead to more compatible annotation guidelines between the languages."
"Univerzální závislosti (Universal Dependencies) je projekt, jehož cílem je vytvořit mezijazykově konzistentní závislostní anotaci pro mnoho jazyků, s cílem zjednodušit vývoj jazykově nezávislých parserů, mezijazykové učení a výzkum parsingu z pohledu jazykové typologie. Anotační schéma je založeno na (univerzálních) Stanfordských závislostech (de Marneffe et al., 2006, 2008, 2014), univerzálních značkách Google (Petrov et al., 2012) a Intersetu, interlinguy pro sady morfologických značek (Zeman, 2008).","Universal Dependencies is a project that seeks to develop cross-linguistically consistent treebank annotation for many languages, with the goal of facilitating multilingual parser development, cross-lingual learning, and parsing research from a language typology perspective. The annotation scheme is based on (universal) Stanford dependencies (de Marneffe et al., 2006, 2008, 2014), Google universal part-of-speech tags (Petrov et al., 2012), and the Interset interlingua for morphosyntactic tagsets (Zeman, 2008). The general philosophy is to provide a universal inventory of categories and guidelines to facilitate consistent annotation of similar constructions across languages, while allowing language-specific extensions when necessary."
"V článku popisujeme našu účasť v úlohe Search v  Search and Hyperlinking Task vrácmi Benchmarku MediaEval 2014. Na základe našich experimentov porovnávame dva typy segmentácie: segmentácia na úseky rovnakej dĺžky a segmentácia, ktorá  využíva rozhodovacie stromy. Taktiež ukážeme užitočnosť využitia metadát a preskúmame odstraňovanie prekrývajucich sa relevantných segmentov.","In this paper, we describe our participation in the Search part of the Search and Hyperlinking Task in MediaEval Benchmark 2014. In our experiments, we compare two types of segmentation: fixed-length segmentation and segmentation employing Decision Trees on various features. We also show usefulness of exploiting metadata and explore removal of overlapping retrieved segments."
"Článok sa zaoberá vyhľadávaním informácií v audio-vizuálnych nahrávkach. Takéto nahrávky sú často dlhé a pre užívateľa môže byť preto dôležité vyhľadanie presného relevantného úseku. Pri vyhľadávaní relevantných segmentov sú nahrávky najprv rozdelené na menšie časti, na ktoré sú aplikované štandardné metódy vyhľadávania informácií. V článku porovnávame niekoľko metód, ktoré slúžia na segmentáciu nahrávok, zvlášť sa zameriavame na prístupy založené na strojovom učení.","This paper deals with Information Retrieval from audio-visual recordings. Such recordings are often quite long and users may want to find the exact starting points of relevant passages they search for. In Passage Retrieval, the recordings are automatically segmented into smaller parts, on which the standard retrieval techniques are  applied. In this paper, we discuss various techniques for segmentation of audio-visual recordings and focus on machine learning approaches which decide on segment boundaries based on various features combined in a decision-tree model. Our experiments are carried out on the data used for the Search and Hyperlinking Task and Similar Segments in Social Speech Task of the MediaEval Benchmark 2013."
"V článku prezentujeme naše experimenty vrámci úlohy Hyperlinking v Search and Hyperlinking Task na Benchmarku MediaEval 2014. Náš systém úspešne kombinuje príznaky rôznych modalít (textové, vizuálne, prozodické). V článku tiež ukážeme vhodnosť použitia nami navrhnutých segmentačných metód, ktoré využívajú rozhodovacie stromy.","In this report, we present our experiments performed for the Hyperlinking part of the Search and Hyperlinking Task in MediaEval Benchmark 2014. Our system successfully combines features from multiple modalities (textual, visual, and prosodic) and confirms the positive effect of our former method for segmentation based on Decision Trees."
"Podmnožina organizátorů Úlohy 8 na SemEvalu 2014 se pokusila použít k řešení úlohy parsery, které byly již dříve vyvinuty pro jednotlivé datové formáty využité v této úloze. Kombinace výstupů těchto parserů byla zařazena jako samostatné řešení otevřené části úlohy (open track). Použité systémy byly typicky vyvíjeny souběžně s anotací dat, konkrétně (a) pro formát DM jde o parser nad ručně sestavenou English Resource Grammar; (b) pro formát PAS jde o systém Enju s pravděpodobnostní HPSG, získanou lingvistickou projekcí PTB; a (c) pro formát PCEDT jde o scénář anglické tektogramatické analýzy v prostředí Treex, zahrnující statistický závislostní analyzátor a řadu cílených zpracovacích bloků, které převádějí stromy z analytické na tektogramatickou rovinu.","As a submission of its own to the open track of Task 8 at SemEval 2014, a subset of the organizers sought to connect the task to pre-existing, ‘in-house’ parsing systems that can output the same types of semantic dependency graphs as used in the task. For each of the three target formats, there is an existing parsing system, which typically was developed in parallel to the creation of the target dependency graphs, viz. (a) for the DM format, the parser using the hand-engineered English Resource Grammar; (b) for the PAS format, the Enju parsing system, with its probabilistic HPSG acquired through linguistic projection of the PTB; and (c) for the PCEDT format, the scenario for English tectogrammatical analysis within the Treex framework, comprising a pipeline of a syntactical data-driven dependency parser and a number of hand-engineered processing blocks that convert trees from the analytical to the tectogrammatical layer."
"V článku popisujeme vydání rozsáhlého jednojazyčného korpusu urdštiny s automatickým značkováním slovních druhů. Navazujeme na práci Jawaid a Bojar (2012), kde byly pro značkování použity tři taggery a finální výsledek určilo jejich hlasování. Používáme stejnou komplexní sestavu na velký jednojazyčný korpus a výsledek zpřístupňujeme veřejnosti. Kromě toho na tomto velkém korpusu trénujeme jeden samostatný tagger, což, doufáme, podstatě zjednoduší zpracování urdštiny. Tento samostatný tagger na nezávislých testovacích datech dosahuje přenosti 88,74 %.","In this paper, we describe a release of a sizeable monolingual Urdu corpus automatically tagged with part-of-speech tags.
We extend the work of Jawaid and Bojar (2012) who use three different taggers and then apply a voting scheme to
disambiguate among the different choices suggested by each tagger. We run this complex ensemble on a large monolingual
corpus and release the tagged corpus. Additionally, we use this data to train a single standalone tagger which will
hopefully significantly simplify Urdu processing. The standalone tagger obtains the accuracy of 88.74% on test data."
Článek představuje shrnutí existujících jazykových zdrojů pro překlad z angličtiny do urdštiny a demonstruje výsledky dosažené frázovým a hierarchickým statistickým překladem na třech oficiálních testovacích sadách vět. Ve všech případech hierarchický překlad dopadá lépe.,"The aim of this paper is to categorize and present the existence of resources for English-
to-Urdu machine translation (MT) and to establish an empirical baseline for this task.
By doing so, we hope to set up a common ground for MT research with Urdu to allow
for a congruent progress in this field. We build baseline phrase-based MT (PBMT) and
hierarchical MT systems and report the results on 3 official independent test sets. On all
test sets, hierarchial MT significantly outperformed PBMT. The highest single-reference
BLEU score is achieved by the hierarchical system and reaches 21.58% but this figure
depends on the randomly selected test set. Our manual evaluation of 175 sentences
suggests that in 45% of sentences, the hierarchical MT is ranked better than the PBMT
output compared to 21% of sentences where PBMT wins, the rest being equal."
"Článek navazuje na starší práce o dvoukrokovém překladu a rozšiřuje je ve dvou směrech. Jednak v prvním kroku nahrazujeme frázový překlad hierarchickým, a jednak na rozhraní mezi prvním a druhým krokem používáme svaz slov jako záměrně víceznačnou reprezetanci.","The idea of two-step machine translation was introduced to divide the complexity of the search space into two independent steps: (1)
lexical translation and reordering, and (2) conjugation and declination in the target language. In this paper, we extend the two-step
machine translation structure by replacing state-of-the-art phrase-based machine translation with the hierarchical machine translation in
the 1st step. We further extend the fixed string-based input format of the 2nd step with word lattices (Dyer et al., 2008); this provides
the 2nd step with the opportunity to choose among a sample of possible reorderings instead of relying on the single best one as produced
by the 1st step."
"Popisujeme metodu poloautomatické extrakce slovenských víceslovných výrazů ze závislostního korpusu. Proces používá automatickou konverzi ze závislostních syntaktických stromů do hloubkové syntaxe a automatické značkování slovesných doplnění na základě valenčního slovníku. Jak valenční slovník tak konverze syntaktického korpusu vznikla úpravou podobného nástroje pro češtinu; autmomaticky přeložený valenční slovník byl ručně zkontrolován a opraven. Přínos této práce je dvojí – valenční slovník slovenských víceslovných výrazů s přímými odkazy na odpovídající výrazy v českém slovníku PDT-Vallex a metoda pro extrakci víceslovných výrazů ze Slovenského závislostního korpusu. Práce na projektu stále probíhá, cílem je 1) vytvořit slovenský valenční slovník paralelní k českému a 2) použít extrahované slovesné rámce v kolokačním slovníku slovenských sloves.","We describe a method for semi-automatic extraction of Slovak multiword expressions (MWEs) from a dependency treebank. The process uses an automatic conversion from dependency syntactic trees to deep syntax and automatic tagging of verbal argument nodes based on a valency dictionary. Both the valency dictionary and the treebank conversion were adapted from the corresponding Czech versions; the automatically translated valency dictionary has been manually proofread and corrected. There are two main achievements – a valency dictionary of Slovak MWEs with direct links to corresponding expressions in the Czech dictionary, PDT-Vallex, and a method of extraction of MWEs from
the Slovak Dependency Treebank. The extraction reached very high precision but lower recall in a manual evaluation. This is a work in progress, the overall goal of which is twofold: to create a Slovak language valency dictionary paralleling the Czech one, with bilingual links; and to use the extracted verbal frames in a collocation dictionary of Slovak verbs."
"Poster představující souhrnné informace o Centru vizuální historie Malach, jeho aktivitách a dostupných archivních zdrojích.","Poster summarizing the basic information on Malach Center for Visual History, its activities and available archival resources."
"Různé pokusy o konceptualizaci často vágně užívaného pojmu kolektivní paměť dospívají k závěru, že kolektivní paměť je hluboce provázaná s jazykovými a narativními fenomény. V tomto příspěvku je mým cílem předložit přehled a diskusi souvislosti mezi jazykem a kolektivní pamětí v kontextu sociální teorie. V díle zakládajících teoretických postav M. Halbwachse a J. Assmanna je význam jazyka ve vztahu k otázkám kolektivní paměti chápán jako ústřední. Stejně tak v posledních dvou dekádách se ze specifické role narativu a konverzace stává významný předmět teoretického výzkumu kolektivní paměti. Na druhou stranu, v empirických šetřeních jako by byl vztah jazyka a kolektivní paměti spíše podceňován. Ukazuje se, že různé společenskovědní a humanitní disciplíny se s podobnými tématy vyrovnávají značně odlišně a rozdíly lze nalézt také v míře explicitní pozornosti věnované tématu kolektivní paměti.","Various attempts to conceptualize the often vaguely used term collective memory come to the conclusion that collective memory is deeply related to linguistic and narrative phenomena. In the present paper, I aim to provide an overview and discussion of the link between language and collective memory in the context of social theory. In the case of the founding theoretical figures, M. Halbwachs and J. Assmann, the importance of language in relation to the issues of collective memory is profound. In the past two decades, the specific role of narrative and conversation had become an important subject in researching collective memory. In empirical research, on the other hand, the relationship of language and collective memory seems to be rather underrepresented. Various fields and disciplines deal with similar topics quite differently, and they also differ in the degree of explicit scrutiny of the collective memory phenomena."
"Dialektika paměti a identity je ve společenských vědách často spojována s tématem narativity. Identita je artikulována (či dokonce utvářena) jazykovými prostředky jako smysluplný životní příběh na základě zapamatovaných prožitých zkušeností a biografické práce. Orální historie (konkrétně Archiv vizuální historie USC Shoah Foundation) poskytuje bohatý zdroj materiálu pro zkoumání osobní, sociální i kolektivní identifikace narátorů, ale zároveň klade výzkum identit před určitá úskalí.","The topics of memory, identity and narrative are deeply intertwined. Since John Locke (1632–1704), it is quite widely acknowledged that the very sense of one’s personal identity is based on (autobiographical) memory. During the 20th century, study of collective identity and collective memory emerged in the social sciences, along with questions about possible analogy between the mechanisms of individual identity/memory and collective identity/memory. The dialectics of memories and identities have also been connected by the notion of narrative. Therefore the identity is articulated (or even constructed) by linguistic means as a meaningful life story on the basis of past experiences and biographic work. In case of oral historical interviews, the triad of identity—memory—narrative takes on specific features. I will focus on the USC Shoah Foundation’s Visual History Archive as a data resource and try to provide answers to several questions, including: How are different social identities manifested in the audiovisual oral histories? Is there a narrative expression of plurality of identities, conflicts and tensions? Are these topics somehow present in the testimonies of the Holocaust survivors? How is the sociological point of view contributing to this kind of research? As we will see, oral history is indeed a rich data resource for researching the social aspects of collective and personal identities. However, because language is privileged in oral history, we might be missing another important means of identity expression (in non-verbal ways of individual or collective action). To a certain extent, this may be overcome due to the increasing number of videotaped oral history interviews."
Článek poskytuje základní informace o Centru vizuální historie Malach a dostupných archivních zdrojích v kontextu orální historie jako specifické metody zachycení minulosti.,The article provides readers with basic information on the Malach Center for Visual History and available archival resources in the context of oral history as a specific method of capturing the past.
"Orální historie – ať už jako kvalitativní výzkumná metoda nebo disciplína sui generis – se v posledních desetiletích bezpochyby stává předmětem rostoucího zájmu akademiků, badatelů, ale také různých organizací a veřejnosti jako takové. Přibývá orálně historických projektů, které jsou realizovány v odlišných kontextech a regionech, zaměřují se na rozmanitá témata a historická období moderních dějin, vzájemně se liší rozpočtem, výzkumnými otázkami i technologickým zázemím. V tomto příspěvku přistupuji k problematice orální historie ze sociologického hlediska a pokusím se nastínit možné sociologické přístupy ke zkoumání tohoto sociálního fenoménu, které by bylo možno souhrnně označit souslovím sociologie orální historie. Jelikož toto odvětví sociologie zatím není formálně utvořeno (natož institucionálně zakotveno), má můj příspěvek spíše charakter programový a ukazuje různé teoretické a epistemologické cesty, jimiž by zkoumání na tomto poli mohlo v budoucnu směřovat.","Oral history - whether as a qualitative method or 
discipline *sui generis* - is indeed receiving growing attention in the past decades, from scholars as well as NGO's and also the wide public. Many different oral historical projects are being conducted, in varying contexts and regions, focusing on a variety of historical events, issues and research questions, with different budgets and technological backgrounds. From a sociological point of view, it is possible to interpret the universal practice of oral history as a social phenomenon of its own kind. Sociology can approach oral history from two different points of view, which are also shaping the basic structure of my talk: oral history (1) *as a subject itself* - the sociological interpretation of oral history as a social practice; (2) *as a secondary data source* - the sociological interpretation of existing oral historical data. First, I will present some approaches to oral history as a subject of  sociological research, consisting of two distinctive but complementary dimensions: (1.1) *micro-social*, and (1.2) *macro-social*. The traditional (and tricky) antinomy of individual and society is also manifesting itself in oral history, but certainly with some specific features. I will elaborate on the possible facilitation of oral history in sociological research, and also on the limitations of it. The central argument is that sociological insight can generate new ideas and knowledge about the process of oral history, but also about the role and meaning of oral history in (post)modern society. Building upon this, the contemporary praxis of oral history (and its methodology and epistemology) could be enhanced in different ways, including the conscious reflection of contextual, situational, socio-historical and linguistic aspects of an oral historical interview."
"Jedním z důsledků ""digitálního obratu"" je narůstající objem jazykových narativních dat dostupných on-line. Ve svém příspěvku jsem se zaměřil na případovou studii z oblasti ""sociologie orální historie"", konkrétně na různé způsoby, jak může sociologie využívat orálně historická data. Naznačil jsem také klíčovou roli ICT v usnadňování tohoto využití na příkladu Archivu vizuální historie USC Shoah Foundation.","One of the consequences of the “digital turn” is a growing amount of linguistic narrative data available on-line. Large portion of this data is generated directly by the individual social actors. But there is also a second realm, which is a result – or sometimes a by-product – of qualitative research and oral history projects. In my talk, based on the case study of “sociology of oral history”, I intend to provide an insight into the ways of possible usage of oral history data in sociology, but also outline the crucial role of ICT in facilitating these efforts. Quite often, the results of process-oriented oral history projects (i.e. oral history projects without a specific research question) are published on-line in various digital environments. “Digital oral history” usually includes digital archives of interview collections with metadata, search tools, user work-space, Web 2.0 features etc. Due to this practice, large quantity of data is potentially available for reuse and secondary analysis by researchers, who did not participate in the initial data collection process. The analysis of this data could be supported by a wide variety of ICT tools. However, within the broad field of social sciences, different disciplines have very different requirements for exploitable data. I will use the data from USC Shoah Foundation’s Visual History Archive (http://vhaonline.usc.edu) in the context of my own research experience, in an attempt to illustrate this complexity."
"Valenční slovníky typicky obsahují informace o nepříznakovém užití sloves (aktivní formu); nicméně slovesa typicky vstupují do různých povrchových struktur. Zde se soustřeďujeme na popis změn ve valenční struktuře, a to změn spojených s diatezemi.","Valency lexicons typically describe only unmarked usages of verbs (the active form); however verbs prototypically enter different surface
structures. In this paper, we focus on the so-called diatheses, i.e., the relations between different surface syntactic manifestations of verbs
that are brought about by changes in the morphological category of voice, e.g., the passive diathesis. The change in voice of a verb is
prototypically associated with shifts of some of its valency complementations in the surface structure. These shifts are implied by changes
in morphemic forms of the involved valency complementations and are regular enough to be captured by syntactic rules. However, as
diatheses are lexically conditioned, their applicability to an individual lexical unit of a verb is not predictable from its valency frame
alone. In this work, we propose a representation of this linguistic phenomenon in a valency lexicon of Czech verbs, VALLEX, with the
aim to enhance this lexicon with the information on individual types of Czech diatheses. In order to reduce the amount of necessary
manual annotation, a semi-automatic method is developed. This method draws evidence from a large morphologically annotated corpus,
relying on grammatical constraints on the applicability of individual types of diatheses."
"Příspěvek popisuje návrh a první implementaci systému pro lidský a strojový překlad tweetů. V prvních experimentech se omezujeme na překlad vybraných zdrojů z Ukrajiny (zdrojovým jazykem je primárně ukrajinština a ruština, občas angličtina). Zdrojové tweety jsou distribuovány registrovaným 'překladatelům', překlady je možné na webu ručně hodnotit a dostatečně dobré překlady odesíláme jako tweety do světa. Výhledově všechny tyto kroky bude provádět i stroj, zatím máme zapojen jen strojový překlad.","The paper describes the design and implementation of a system for human and machine translation of tweets. In these early experiments, we limit the system to follow some selected sources from Ukraine (the source language is primarily Ukrainian and Russian, sometimes English)."
Tento článek prezentuje sadu morfologických nástrojů pro současnou arabštinu založenou na korpusu a konečných automatech a poskytovanou pod GPLv3 licencí.,"We develop an open-source large-scale ﬁnite-state morphological processing toolkit (AraComLex) for Modern StandardArabic (MSA) distributed under the GPLv3 license (http://aracomlex.sourceforge.net). The morphological transducer is based on a lexical database speciﬁcally constructed for this purpose. In contrast to previous resources, the database is tuned to MSA, eliminating lexical entries no longer attested in contemporary use. The database is built using a corpus of 1,089,111,204 word tokens, a pre-annotation tool, machine learning techniques and knowledge-based pattern matching to automatically acquire lexical knowledge. Our morphological transducer is evaluated and compared to LDC’s SAMA(StandardArabic Morphological Analyser). We also develop a ﬁnite-state morphological guesser as part of a methodology for extracting unknown word forms, lemmatizing them, and giving them a priority weight for inclusion in the lexicon."
Technická zprava shrnuje pravidla anotace koreference v Pražském česko-anglickém závislostním korpusu.,The technical report presents the guidelines for manual annotation of nominal coreference in the Prague Czech-English Treebank.
V článku se popisují principy evaluační soutěže na automatické rozřešení koreferenčních a anaforických vztahů pro ruštinu.,"The paper reports on the recent forum RU-EVAL—a new initiative for evaluation of Russian NLP resources, methods and toolkits. The first two events were devoted to morphological and syntactic parsing correspondingly. The third event was devoted to anaphora and coreference resolution. Seven participating IT companies and academic institutions submitted their results for the anaphora resolution task and three of them presented the results of the coreference resolution task as well. The event was organized in order to estimate the state of the art for this NLP task in Russian and to compare various methods and principles implemented for Russian. We discuss the evaluation procedure. The anaphora and coreference tasks are specified in the present work. The phenomena taken into consideration are described. We also give a brief outlook of similar evaluation events whose experience we lay upon. In our work we formulate the training and Gold Standard corpora construction guidelines and present the measures used in evaluation."
"Příspěvek uvádí sadu slovesných předpon, které spolu s reflexním morfémem mění význam slovesa, a to vždy stejným způsobem. Předpony tvoří posloupnost podle stupně intenzity, kterou pozměňují akci popisovanou daným slovesem. Představujeme proces intenzifikace slovesa, popisujeme sémantiku cirkumfixů, morfologické, syntaktické a sémantické omezení na jejich použití v ruštině.","The current paper addresses verbal circumfixal derivation patterns in modern Russian. The discussion is focused on a series of circumfixes which trigger the intensified usage of the basic verb (~'keep doingP too much'). Derivatives built up by adding a prefix and a reflexive -OR to an imper-fective verb are examined. Although each prefix adds specific shades of meaning to the verb, such patterns are, however, claimed to share common features at different levels of linguistic analysis, such as morphology, syntax, and semantics. Furthermore, such patterns are highly productive in modern language; once certain constraints are fulfilled, an intensified derivative can be formed from any imperfective verb. This fact, along with the patterns in question sharing certain common features, allow us to argue that they can be considered inflectional, rather than derivational."
"Tento článek popisuje Parmesan, náš příspěvěk na  Workshop on Statistical Machine Translation 2014.
Ukazuje, že parafrázovací tabulky Meteoru pro češtinu obsahují tolik šumu, že jejich použití ve skutečnosti může poškodit výkon metriky. Nicméně po důkladní filtraci mohou být velmi užitečné v cíleném parafrázovní referenčních vět předcházejícím evaluaci.
Parmesan nejprve provede cílené parafrázování referenčních vět a poté spočítá Meteor score s pouze přímou shodou na těchto nových referencích. Na datech z WMT12 a WMT13 ukazuje signifikantně vyšší shodu s lidským hodnocením než Meteor.","This paper describes Parmesan, our submission to the 2014 Workshop on Statistical
Machine Translation (WMT) metrics task for evaluation English-to-Czech translation. 
We show that the Czech Meteor Paraphrase tables are so noisy that they actually can harm 
the performance of the metric. However, they can be very useful after extensive filtering 
in targeted paraphrasing of Czech reference sentences prior to the evaluation.
Parmesan first performs targeted paraphrasing of reference sentences, then it computes 
the Meteor score using only the exact match on~these new reference sentences. It shows 
significantly higher correlation with human judgment than Meteor on the WMT12 and WMT13 data."
"Tato práce prezentuje možnost zpřesnění hodnocení strojového překladu českých vět. Náš algoritmus dostává na vstupu referenční větu a upravuje jí tak, aby byla bližší výstupu strojového překladu a současně si zachovala původní význam a gramatickou správnost.
Tu zajišťuje systém Depfix, který byl původně navržen pro post-editaci strojových překladů z angličtiny do češtiny, zde upravený pro opravu chyb specifických pro parafrázovaní.
Kvůli šumu ve zdrojích parafrázích experimentujeme se zarovnáváním slov. Ale jako nejlepší metoda se ukázala prostá hladová metoda s pouze jednoslovnými parafrázemi, díky jejich důkladnému filtrování. 
BLEU spočítané na nových referencích vykazuje významně vyšší korelaci s lidským hodnocením než skóre počítané na původních referencích.","In this paper, we present a method of improving the accuracy of machine translation 
evaluation of Czech sentences. Given a reference sentence, our algorithm transforms it 
by targeted paraphrasing into a new synthetic reference sentence that is closer in 
wording to the machine translation output, but at the same time preserves the meaning of
the original reference sentence. 
Grammatical correctness of~the new reference sentence is provided by applying Depfix on 
newly created paraphrases. Depfix is a system for post-editing English-to-Czech machine 
translation outputs. We adjusted it to fix the errors in paraphrased sentences.
Due to a noisy source of our paraphrases, we experiment with adding word alignment. However, 
the alignment reduces the number of paraphrases found and the best results were achieved 
by~a~simple greedy method with only one-word paraphrases thanks to their intensive filtering.
BLEU scores computed using these new reference sentences show significantly higher correlation 
with human judgment than scores computed on the original reference sentences."
"Představujeme metodu cíleného parafrazování pro zpřesnění hodnocení strojového překladu. V jejím rámci, využíváme strojový překld samotný a upravujeme jej tak, aby překládal v rámci jediného jazyka.
Popisujeme tento přístup na dvou typech strojového překladu - statistickém a pravidlovém. V rámci statistického překladu experimentujeme s Mojžíšem, volně dostupným nástrojem pro statický strojový překlad. Překladové modely tvoříme uměle ze dvou dostupých zdrojů českých parafrází - českého WordNetu a parafrázovacích tabulek Meteor. Rozšiřujeme Mojžíše o nový rys, který vynucuje cílené parafrázování.
Bohužel, naše výsledky jsou spíše negativní. S ohledem na chyby, které se objevily v parafrázovaných větách, navrhujeme nové řešení - parafrázování pomocí pravidlového systému Treex.","We present a method for improving machine translation (MT) evaluation by targeted 
paraphrasing of reference sentences. For this purpose, we employ MT systems themselves 
and adapt them for translating within a single language. 
We describe this attempt on two types of MT systems -- phrase-based and rule-based. 
Initially, we experiment with the freely available SMT system Moses. We create translation 
models from two available sources of Czech paraphrases -- Czech WordNet and the Meteor 
Paraphrase tables. We extended Moses by a new feature that makes the translation targeted. 
However, the results of this method are inconclusive. In the view of errors appearing 
in the new paraphrased sentences, we propose another solution -- targeted paraphrasing 
using parts of a rule-based translation system included in the NLP framework Treex."
Tato zpráva popisuje účast týmu Univerzity Karlovy v Praze na ShARe/CLEF eHealth Evaluation Lab in 2014.,This report describes the participation of the team of Charles University in Prague at the ShARe/CLEF eHealth Evaluation Lab in 2014.
"Jak funguje rozpoznávání řeči?
Jaké je studium na Matfyzu?
Co je Alex? (dialogový systém)
Povídání o machine learning a artificial intelligence","How does automatic speech recognition work?
How are the studies at MFF UK?
What is the Alex spoken dialogue system?
Notes on machine learning and artificial intelligence"
"Tématem této práce je implementace výkonného rozpoznávače v open-source systému trénování ASR Kaldi (http://kaldi.sourceforge.net/) pro dialogové systémy. Kaldi již obsahuje ASR dekodéry, které však nejsou vhodné pro dialogové systémy. Hlavními důvody jsou jejich malá optimalizace na rychlost a jejich velké zpoždění v generování výsledku po ukončení promluvy. Cílem této práce je proto vyvinutí real-time rozpoznávače pro dialogové systémy optimalizovaného na rychlost a minimalizujícího zpoždění. Zrychlení může být realizováno například pomocí multi-vláknového dekó- dování nebo s využitím grafických karet pro obecné výpočty. Součástí práce je také příprava akustického modelu a testování ve vyvíjeném dialogovém systému ”Vystadial”.","The topic of this thesis is to implement efficient decoder for speech recognition training system ASR Kaldi (http://kaldi.sourceforge.net/). Kaldi is already deployed with decoders, but they are not convenient for dialogue systems. The main goal of this thesis to develop a real-time decoder for a dialogue system, which minimize latency and optimize speed. Methods used for speeding up the decoder are not limited to multi-threading decoding or usage of GPU cards for general computations. Part of this work is devoted to training an acoustic model and also testing it in the ""Vystadial"" dialogue system."
"Představujeme rozšíření Kaldi automatického rozpoznávání řeči toolkit pro podporu on-line rozpoznávání řeči. Výsledný rozpoznáč podporuje state-of-the-art  akustické modely. (MFCC, MLLT + LDA, BMMI) Vzhledem k tomu, že rozpoznávání produkuje slovní posteriorní lattice, je užitečné zejména v systémech statistických dialogu.
V evaluaci se zaměříme na on-line rozpoznávání řeči v dialogovém systému Alex pro doménu ""veřejné dopravy České republiky"". Dialogový systém je k dispozici na veřejném bezplatném 800 899 998 řádek.","We present an extension of the Kaldi automatic speech recognition toolkit to support on-line speech recognition. The resulting recogniser supports acoustic models trained using state-of-the-art acoustic modelling techniques. (MFCC, MLLT+LDA, BMMI) As the recogniser produces word posterior lattices, it is particularly useful in statistical dialogue systems, which try to exploit uncertainty in the recogniser's output.
The evaluation is focused on on-line speech recognition in a dialogue system Alex for the ""public Czech transportation"" domain. The dialogue system is available at a public toll-free 800 899 998 line."
"V tomto článku je presentováno rozšíření Kaldi toolkitu pro rozpoznávání řeči, které podporuje on-line rozpoznávání.
Vysledný rozpoznávač řeči podporuje moderní modelovací metody.
Jelikož rozpoznávač vytváří slovní posteriorní svazy, je obzvlášt vhodný pro statistické dialogové systémy, které umí pracovat s nejistotou rozpoznávače řeči.
Experimenty ukazují, že online rozpoznávač má výrazně lepší výsledky vzhledem k latenci pri srovnání s rozpoznávačem v cloudu.","This paper presents an extension of the Kaldi automatic speech recognition toolkit to support on-line recognition. The resulting recogniser supports acoustic models trained using state-of-the-art acoustic modelling techniques. As the recogniser produces word posterior lattices, it is particularly useful in statistical dialogue systems, which try to exploit uncertainty in the recognizer's output. Our experiments show that the on- line recogniser performs significantly better in terms of latency when compared to a cloud-based recogniser."
"Tento článek popisuje integrace on-line Kaldi rozpoznávače řeči do frameworku dialogovýho systémů Alex (ADSF). Jelikož Kaldi OnlineLatgenRecogniser je implementován v C++, bylo nejprve nutno převést API rozpoznávače do jazyka Python. Skripty pro trénování akustických a jazykových modelů byly integrovány do ADSF a příslušné modely byly natrénovány. Na závěr optimální parametry rozpoznávače byly zvoleny z dat a ověřeny na ""Public Transport Information (PTI)"" doméně.","This paper describes the integration of an on-line Kaldi speech
recogniser into the Alex Dialogue Systems Framework (ADSF). As the Kaldi OnlineLatgenRecogniser is written in C++, we first developed a Python wrapper for the recogniser so that the ADSF, written in Python, could interface with it. Training scripts for acoustic and language modelling were developed and integrated into ADSF, and acoustic and language models were build. Finally, optimal recogniser parameters were determined and evaluated. The dialogue system Alex with the new speech recogniser is evaluated on Public Transport Information (PTI) domain."
"Přehled problémů, které ve strojovém překladu způsobuje bohatá morfologie na cílové straně a naše techniky, jimiž se s nimi vyrovnáváme.","An overview of problems caused in MT by rich target-side morphology, and our techniques of addressing them."
Představil jsem projekt MosesCore (CSA FP7) a zkušenosti s jeho řešením kolegům z katedry KSI.,I have introduced the project MosesCore (CSA FP7) and my experience with its managing to the colleagues of the KSI department.
Popularizační video představuje náš překladač Chiméra včetně všech jeho tří komponent: hloubkový a frázový systém a následná korekce gramatických chyb.,"A Czech popularization videotalk introduces our MT system Chimera including its three components: deep transfer-based MT system, Moses phrase-based system and the final grammatical correction by Depfix."
"Představujeme dosažené výsledky ve statistickém strojovém překladu z angličtiny, němčiny, španělštiny a francouzštiny do češtiny. Probíráme specifické vlastnosti jednotlivých zdrojových jazyků a popisujeme techniky, které těchto vlastností využívají a zaměřují se na odstranění chyb specifických pro daný jazyk. Kromě vlastního překladu také prezentujeme náš příspěvek k chybové analýze.","We present various achievements in statistical machine translation from English, German, Spanish and French into Czech. We discuss specific properties of the individual source languages and
describe techniques that exploit these properties and address language-specific errors. Besides the translation proper, we also present our contribution to error analysis."
"Článek představuje výsledky společných úloh WMT14 -- překladu novinových textů, překladu textů z oblasti medicíny, odhadu kvality překladu a metrik strojového překladu. Do standardní překladové úlohy v 10 překladových směrech se letos zapojilo 143 systémů strojového překladu z 23 institucí. Zároveň bylo vyhodnoceno 6 anonymizovaných systémů. Úloha odhadu kvality překladu měla 4 podúlohy, kterých se zúčastnilo 10 týmů a celkem 57 systémů.","This paper presents the results of the
WMT14 shared tasks, which included a
standard news translation task, a separate
medical translation task, a task for
run-time estimation of machine translation
quality, and a metrics task. This year, 143
machine translation systems from 23 institutions
were submitted to the ten translation
directions in the standard translation
task. An additional 6 anonymized systems
were included, and were then evaluated
both automatically and manually. The
quality estimation task had four subtasks,
with a total of 10 teams, submitting 57 entries."
"Představujeme HindEnCorp, paralelní hindsko-anglický korpus, a HindMonoCorp, jednojazyčný hindský korpus ve verzi 0.5. Oba korpusy byly získány z webových zdrojů a předzpracovány primárně pro trénování systémů statistického strojového překladu. HindEnCorp sestává z 274k paralelních vět (3,9 miliónů hindských a 3,8 miliónů anglických tokenů). HindMonoCorp obsahuje 787 miliónů tokenů ve 44 miliónech vět. Oba korpusy jsou zdarma přístupné pro nekomerční výzkum a jejich předběžné vydání bylo využito řadou účastníků společné překladové úlohy WMT 2014.","We present HindEnCorp, a parallel corpus of Hindi and English, and HindMonoCorp, a monolingual corpus of Hindi in their release version 0.5. Both corpora were collected from web sources and preprocessed primarily for the training of statistical machine translation systems. HindEnCorp consists of 274k parallel sentences (3.9 million Hindi and 3.8 million English tokens). HindMonoCorp amounts to 787 million tokens in 44 million sentences. Both the corpora are freely available for non-commercial research and their preliminary release has been used by numerous participants of the WMT 2014 shared translation task."
Představili jsme přehled činností naší katedry s důrazem na nástroje NLP užitečné pro textovou analytiku.,"We presented an overview of the work of our department, highlighting NLP tools useful in text analytics."
V úvodní stati sborníku se předkládají argumenty o závažnosti zpracování valence v teoretickém i aplikačním rámci. Hlavní pozornost je věnována valenci substantiv a ověřování platnosti hypotéz uplatněných při zpracování valence sloves.,In the introductory chapter of the volume the importance of introduction of valency both in theoretical and applied description is stressed. The hypothesis submitted for the valency description of verbs are applied and verified for the valency of nouns.
"Dvojice termínů koordinace - determinace vs. hypotaxe a parataxe jsou srovnávány a popisují se přesahy, kdy je koordinace vyjádřená hypotakticky a naopak koordinace vyjádžená paratakticky. Některé konstrukce zpravidla sem řazené se z této oblasti vylučují.",The notions of coordination and subordination are compared with their counterparts hypotaxis and parataxis are discussed from the point of view of linguistic meaning.
Na příkladu atributivních vedlejších vět a jejich nominalizací pomocí slovesných adjektiv v češtině byl analyzován jejich vzájemný vztah. Demonstrovaly se případy gramatických omezení na jeden nebo druhý způsob vyjádření a poukazovalo se na jejich vzájemnou (ne)synonymii.,In this contribution the attributive dependent clauses and their corresponding nominalisations in Czech were demonstrated from the point of view of their respective synonymy and from the point of view of the restrictions on the generation of one from  these analyzed forms.
Ve zvané plenární přednášce v rámci konference českých mladých lingvistů byla zdůrazněna důležitost syntaxe a formulovány požadavky na konsistenci jejího popisu.,Within the conference of young linguists from Czech Republic in the invited talk the importance of the syntax was stressed and the reqirements   on the conistency of its description were exemplified by examples.
Přednáška určená doktorandům jazykovědných oborů FF MU v Brně sdružených v Jazykovědném spolku jako úvod do teorie Funkčního generativního popisu.,In the lecture for the post-graduate students members of Linguistic society the approach of Functional Generative Description and ite application was presented.
V přednášce pro doktorandy jazykovědných oborů FF MU byla představena valenční teorie uplatňovaná ve FGP - od slovesné valence přes valenci jména a jejich použití při anotování.,In the lecture for post-graduate students of FF MU the principles of valency theory developed within FGD was explained and exemplified by the examples of valency of verbs and nouns and their application for the annotation procedure.
Pozvaná úvodní přednáška o historii a metodologických principech zpracování valence s důrazem na kooperci při popisu gramatiky a slovníku.,In the invited introduction talk the history and methodological basis for valency studies was presented with the stress on cooperation between grammatical and lexical modules in the language description.
"Kniha je shrnutím studií získaných na základě dat uložených v PDT. Prezentuje se v ní hloubková syntax českých vět konsistentním způsobem založeným na funkčním generativním popisu. Vysvětlují se v ní principy závislostního přístupu k syntaxi, popisují se a exemlifikují jednotlivé typy syntakticko-sémantických vztahů a jejich souhra s kategoriemi morfologickými, analyzuje se úloha slovosledu v češtině. Kniha je doprovázena praktickými ukázkami závislostních stromových struktur.","In this book the description of Czech  dependency syntax based on the data stored in Prague Dependency Treebank is given. The deep syntax of Czech sentences is explained in the consistent way using the principles of Functional Generative Description. The repertoir of semantic relation is given and exemplified, the role of word-order is studied and the interplay of syntax and morphology is demonstrated here. The figures representing the dependency deep structure of selected examplesare included in the book as well."
"Text je příspěvkem k dlouhé lingvistické diskuzi ohledně hranic mezi gramatikou a lexikonem. V teoretickém rámci Funkčního generativního popisu analyzujeme valenci sloves, modalitu závislých klauzí, diateze českého slovesa a souborový význam českých substantiv s cílem ukázat potřebu zachycovat tyto jevy v gramatickém i lexikálním komponentu jazykového popisu.","The present paper contributes to the long-term linguistic discussion on the boundaries between grammar and lexicon by analyzing four related issues from Czech. The analysis is based on the theoretical framework of Functional Generative Description (FGD), which has been elaborated in Prague since 1960s. First, the approach of FGD to the valency of verbs is summarized. The second topic, concerning dependent content clauses, is closely related to the valency issue. We propose to encode the information on the conjunction of the dependent content clause as a grammatical feature of the verb governing the respective clause. Thirdly, passive, resultative and some other constructions are suggested to be understood as grammatical diatheses of Czech verbs and thus to be a part of the grammatical module of FGD. The fourth topic concerns the study of Czech nouns denoting pair body parts, clothes and accessories related to these body parts and similar nouns. Plural forms of these nouns prototypically refer to a pair or typical group of entities, not just to many of them. Since under specific contextual conditions the pair/group meaning can be expressed by most Czech concrete nouns, it is to be described as a grammaticalized feature."
"Lexikální síť DeriNet zachycuje derivační vztahy mezi zhruba 266 tisíci českými lexémy. Síť je omezena na derivační vztahy, což je reflektováno v její struktuře: každý lexém smí být spojen právě s jedním základovým slovem.",The lexical network DeriNet captures core word-formation relations on the set of around 266 thousand Czech lexemes. The network is currently limited to derivational relations because derivation is the most frequent and most productive word-formation process in Czech. This limitation is reflected in the architecture of the network: each lexeme is allowed to be linked up with just a single base word; composition as well as combined processes (composition with derivation) are thus not included.
"Kniha se zabývá stylistickými a gramatickými prohřešky proti kultivovanému vyjadřování v češtině, zejména ve stylu odborném. Na množství příkladu z oblasti lexika, morfologie, syntaxe a výstavby textu ukazuje na nedopatření proti srozumitelnosti a korektnosti vyjádření, která jsou v současné češtině běžná.","In this book the grammatical and stylistic faults in contemporary Czech, esp. in the scientific style, are demonstrated by the broad scale of examples and they are analyzed from the point of view of lexicon, morphology, syntax and text structure."
Nekrolog a přehled lingvistických vědeckých příspěvků velkého amerického lingvisty.,Obituary and a survey of the scientific contribution of a great Americal linguist to linguistics.
Článek zpracovává otázku interoperability anotačních schémat na základě testování tohoto problému ve víceúrovňových anotačních schématech u typologicky různých jazyků.,"The so-called interoperability is proposed to be viewed from three angles, each of which has its advantages and weak points. The application of the original interpretation of interoperability as a collaboration of components seems to be rather inspiring and has been already tested on several multilayered annotation schemes. One of the main obstacles for an adaptation of a single scenario for different languages is not only the different (typological) features of these languages but also the fact that each scenario (if well developed) has behind it a certain linguistic theory and people working with these theories have been ”born”. Obviously, obstacles concern the fact that there was a parallel development of some of the schemes, the older and more “elaborated” ones (more advanced, used for more languages etc.) are (obviously) not open to big changes. Communication or collaboration between different schemes requires, on the one hand, an explicit specification of each particular scheme, and, on the other, offers a reliable material for linguistic research and also for NLP applications. In the latter respect, the initiatives such as CoNNL shared tasks on multilingual dependency parsing or similar activities are important endeavors."
Popis současných právních problémů s jazykovými daty a jazykovými technologiemi.,"Curent law situation with development, storage and deployment of language data and technologies"
Situace a možné perspektivy využívání persistentních identifikátorů (PID) v LINDAT/CLARIN.,Current situation and perspective of usage of persistent IDs at LINDAT/CLARIN.
Prezentace o ustavení a budování důvěry ve vztahu poskytovatel dat - infrastruktura - uživatel.,"Presentation on building trust between the data producer, infrastructure and users."
Prezentace vývoje a současného stavu repozitáře projektu EUDAT k bezpečnému ukládání a sdílení vědeckých dat.,Presentation of development and current state of the repository for storing and sharing scientific data run by EUDAT project.
Přehled služeb poskytovaných centrem LINDAT/CLARIN a jejich demonstrace online.,Overview of the services provided by the LINDAT/CLARIN centre and their online demonstration.
"Tento balíček obsahuje datové sady pro vývoj a testování modelů strojového překladu pro krátké vyhledávací dotazy v oblasti medicíny, a to pro čestinu, angličtinu, francouzštinu a němčinu. Dotazy obsažené v datech pochází jak od zdravotnických profesionálů, tak od laické veřejnosti.","This package contains data sets for development and testing of machine translation of medical search short queries between Czech, English, French, and German. The queries come from general public and medical experts."
"Tato práce se zabývá strojovým překladem vyhledávacích dotazů pro vícejazyčné vyhledávání informací v oblasti medicíny. Hlavní pozornost je věnována jednak adaptaci překladových technik pro zvýšení překladové kvality, ale také přímo pro zlepšení výsledků vyhledávání.","In this work, we investigate machine translation (MT) of search queries in the context of cross-lingual information retrieval (IR) in the domain of medicine. The main focus is on MT adaptation techniques to increase translation quality, however we also explore MT adaptation to improve cross-lingual IR directly. The experiments described herein have been performed and thoroughly evaluated for MT quality on the datasets created within the Khresmoi project and for IR performance on the CLEF eHealth 2013 datasets on three language pairs: Czech–English, German–English, and French–English. The search query translation results achieved in our experiments are outstanding – our systems outperformed not only our strong baselines, but also the Google Translate and Microsoft Bing Translator in direct comparison carried out on all the language pairs. In terms of the retrieval performance on this particular test collection, a significant improvement over the baseline has been achieved only for French–English. Throughout the article, we provide discussion and details on the contribution of the state-of-the-art features and adaptation techniques under exploration and provide future research directions."
"Tento článek popisuje vývojové a testovací datové sady pro strojový překlad dotazů k vyhledávání informací v oboru medicíny napříč jazyky. Data sestávají z 1508 skutečných uživatelských dotazů zadaných v angličtině a přeložených do češitny, němčiny a francouzštiny. Popisujeme proces překladu a korektur, kterého se účastnili odborníci na medicínu, a představujeme základní experiment, při kterém jsou naše datové sady použity pro ladění a evaluaci systému pro strojový překlad.","This paper presents development and test sets for machine translation of search queries in cross-lingual information retrieval in the medical domain. The data consists of the total of 1,508 real user queries in English translated to Czech, German, and French. We describe the translation and review process involving medical professionals and present a baseline experiment where our data sets are used for tuning and evaluation of a machine translation system."
Článek srovnává české a anglické anotace na pozadí formalismu Abstract Meaning representation.,This paper compares Czech and English annotation using Abstract Meaning Represantation formalism.
PDT-Vallex je český valenční lexikon propojený s reálnými texty v několika korpusech s českými daty: Pražský závislostní korpus a jeho nástupci Pražský česko-anglický závislostní korpus a Pražský závislostní korpus mluvené češtiny. Obsahuje přes  11000 valenčních rámců pro více než 7000 sloves.,"The valency lexicon PDT-Vallex has been built in close connection with the annotation of the Prague Dependency Treebank project (PDT) and its successors (mainly the Prague Czech-English Dependency Treebank project, PCEDT). It contains over 11000 valency frames for more than 7000 verbs which occurred in the PDT or PCEDT. It is available in electronically processable format (XML) together with the aforementioned treebanks (to be viewed and edited by TrEd, the PDT/PCEDT main annotation tool), and also in more human readable form including corpus examples (see the WEBSITE link below). The main feature of the lexicon is its linking to the annotated corpora - each occurrence of each verb is linked to the appropriate valency frame with additional (generalized) information about its usage and surface morphosyntactic form alternatives."
Korpusová studie se zabývá víceúrovňovou specifikací slovesných víceslovných výrazů a jejich vlastnostmi v češtině a v angličtině. Zároveň na základě využití paralelního korpusu (PCEDT)  slovesné idiomy v obou jmenovaných jazycích porovnává.,"This is a corpus-based study,concentrating on multilayer specification of verbal MWEs, their properties in Czech and English,and a comparison between the two languages using the parallel Czech-English Dependency Treebank."
"Nominalizované struktury se dvěma aktanty ve formě bezpředložkového genitivu byly doposud v české odborné literatuře reprezentovány pouze jediným typem zcela přijatelných a gramatických konstrukcí, např. zbavení ženy starostí. V této studii vymezujeme tři další typy nominalizovaných struktur se dvěma aktanty v bezpředložkovém genitivu a vyhledáváme jejich frekvence v Pražském závislostním korpusu a v Českém národním korpusu. Nově vymezené struktury jsou méně přijatelné a jejich frekvence jsou velmi nízké, přesto se domníváme, že je gramatika češtiny umožňuje. Zvláštní pozornost je věnována nominalizacím verbonominálních predikátů s kategoriálním slovesem; tyto konstrukce mohou být interpretovány jako jedna lexikální jednotka, což umožňuje jejich užití v rámci nominalizovaných struktur se dvěma aktanty v bezpředložkovém genitivu.","Double post-nominal genitives in Czech have been illustrated by the only type of a nominalized
structure, e.g., zbavení ženy starostí ‘relieving woman-GEN worry-GEN.PL, i.e. relieving
the woman of worries’. In this paper, we specify three other types of double post-nominal
genitive constructions and search for their frequency in the Prague Dependency Treebank and
in the Czech National Corpus. Although the constructions are rare and less acceptable we try
to show that Czech grammar system allows them. Special attention is paid to nominalizations
of support verb constructions; they can be interpreted as one lexical unit which enables them
to be used within double post-nominal genitive constructions."
"Česká substantiva mluvení mají tři sémantické participanty, Mluvčí, Informace a Příjemce. Tyto tři participanty mohou být vyjádřeny různými formami, v různých kombinacích. V subkorpusech Českého národního korpusu zjišťujeme četnosti vybraných kombinací aktantů u pěti skupin substantiv mluvení. Srovnáváme je s četnostmi obdobných kombinací aktantů u vzorku substantiv výměny a podáváme jejich kvantitativní analýzu. Ukazujeme, že dvě zkoumané sémantické třídy se podstatně liší v četnostech kombinací zahrnujících Konatele (Mluvčího u substantiv mluvení, Posesora 1 u substantiv výměny). Zatímco u substantiv výměny je Konatel téměř vždy elidován, u substantiv mluvení je výrazně četnější, u některých typů substantiv dokonce srovnatelně častý jako participant Informace. Můžeme tedy potvrdit naši hypotézu, že nezanedbatelný výskyt Konatele (při současném vyjádření Adresátu) je charakteristickou vlastností celé skupiny substantiv mluvení.","Czech nouns of communication can mostly be modified by three participants, Speaker, Information and Addressee. These participants can be expressed by various forms but only some of them can be combined with each other. We search for frequencies of selected combinations of participants modifying several types of nouns of communication in subcorpora of the Czech National Corpus. We compare them with frequencies of similar combinations of participants modifying a sample of nouns of exchange and provide a quantitative analysis of them. The two semantic classes considerably differ in frequencies of combinations including Agent (Speaker of nouns of communication, Posesor 1 of nouns of exchange). While Agent is deleted in almost all occurrences of nouns of exchange, it is comparably frequent as Information in occurrences of some types of nouns of communication. We confirm our hypothesis that Agent plays an important role in valency behaviour of nouns of communication."
"Tato kapitola přináší detailní analýzu valenčních vlastností českých deverbativních substantiv. Zaměřuje se na formy valenčních doplnění; ty mohou být typické, odpovídající formám valenčních doplnění základového slovesa, nebo specifické, bez jakéhokoliv formálního vztahu k formám doplnění u základového slovesa. Přinášíme přehled specifických posunů v povrchových formách (realizacích) participantů. Specifické formy participantů mají dopad na syntaktické chování daného substantiva a na jeho význam. Ukazujeme, že se nejedná vždy o jasný významový posun, ale že někdy jde pouze o jemný významový odstín. Navrhujeme pro tato substantiva se specifickými formami participantů vytvořit nový valenční rámec; tato substantiva představují zvláštní kategorii substantiv na hranici mezi syntaktickou a lexikální derivací.","This chapter provides an in-depth analysis of valency properties of Czech deverbal nouns. It focuses on forms of complementations they take. These can be typical, related to the source verbs, or special, without any relationship with forms of participants of the verbs related. We present an overview of special shifts in valency. Special forms of participants have an impact for syntactic behaviour of the noun and for its meaning. We argue that it is not always a shift of the meaning but sometimes only a slight nuance. Such nouns with special forms of participants require creating a new valency frame; they represent a separate category on the boundary between syntactic and lexical derivation."
"Tato práce přináší detailní analýzu valenčních vlastností českých deverbativních substantiv. Zaměřuje se na formy valenčních doplnění; ty mohou být typické, odpovídající formám valenčních doplnění základového slovesa, nebo specifické, bez jakéhokoliv formálního vztahu k formám doplnění u základového slovesa. Nejprve shrnujeme nejnovější poznatky v oblasti typických posunů v povrchových realizacích (formách) participantů. Poté přinášíme přehled posunů specifických. Specifické formy participantů mají dopad na syntaktické chování daného substantiva a na jeho význam. Ukazujeme, že se nejedná vždy o jasný významový posun, ale že někdy jde pouze o jemný významový odstín. Navrhujeme pro tato substantiva se specifickými formami participantů vytvořit nový valenční rámec ve valenčním slovníku PDT-Vallex. Tato substantiva představují zvláštní kategorii substantiv na hranici mezi syntaktickou a lexikální derivací.","This work provides an in-depth analysis of valency properties of Czech deverbal nouns. It focuses on the forms of complementation they take. These can be typical, related to the source verbs, or specific, without any relationship to those of the source verbs. First we summarize new findings concerning typical shifts in valency. Then we present an overview of the specific shifts in valency. Specific forms of participants have an impact on the syntactic behaviour of the noun and its meaning. We argue that it is not always a plain shift in meaning but sometimes only a slight meaning nuance. Such nouns with specific forms of participants require creating a new valency frame in the valency lexicon PDT-Vallex; they represent a separate category on the boundary between syntactic and lexical derivation."
"Článek má tři cíle. Za prvé seznamuje čtenáře se současnou verzí anotačního nástroje pro diskurzní vztahy v Pražském závislostním korpusu 3.0. Za druhé představuje samotné diskurzní vztahy v tomto korpusu, včetně novinek ve srovnání s předchozím vydáním. A za třetí ukazuje, jak v tomto korpusu vyhledávat, se zaměřením na diskurzní vztahy.","The aim of the paper is threefold. First, it introduces the current version of the annotation tool for discourse relations in the Prague Dependency Treebank 3.0. Second, it presents the discourse relations in the treebank themselves, including new additions in comparison with the
previous release. And third, it shows how to search in the treebank, with focus on the discourse
relations."
"Cíl příspěvku je poměrně skromný: sebrat jednoduché statistiky z různých rovin Pražského závislostního korpusu a na nich ukázat jejich užitečnost pro jazykový výzkum, a to jako doklad pro existující jazykové teorie nebo jako inspirace pro nové směry výzkumu či nová vysvětlení existujících otázek. Za tímto účelem jsme shromáždili data z již publikovaných článků o PDT (s odkazy na příslušných místech), přidali některé novější výsledky a vyvodili obecnější důsledky podstatné pro autory zabývající se českou gramatikou.","The goal of the present contribution is rather modest: to collect simple statistics carried out on different layers of the annotation scenario of the Prague Dependency Treebank in order to illustrate their usefulness for linguistic research, either by supporting existing hypotheses or suggesting new research questions or new explanations of the existing ones. For this purpose, we have collected the data from the already published papers on PDT (quoted at the relevant places), adding some more recent results and drawing some more general consequences relevant for Czech grammar writers."
"Lingua::Interset je univerzální sada morfosyntaktických rysů, do které je možné zobrazit všechny sady značek všech korpusů a jazyků. Verze 2.026 pokrývá 64 různých sad značek pro 37 jazyků.",Lingua::Interset is a universal morphosyntactic feature set to which all tagsets of all corpora/languages can be mapped. Version 2.026 covers 64 different tagsets of 37 languages.
"HamleDT 2.0 je sada 30 existujících treebanků (syntakticky anotovaných korpusů), harmonizovaných do jednotného anotačního stylu, tzv. Pražských závislostí, a dále transformovaných do Stanfordských závislostí, anotačního stylu, který se v poslední době stal populární. Používáme nejnovější verzi tzv. základních Universal Stanford Dependencies, bez přidaných jazykově závislých podtypů.","HamleDT 2.0 is a collection of 30 existing treebanks harmonized into a common annotation style, the Prague Dependencies, and further transformed into Stanford Dependencies, a treebank annotation style that became popular recently. We use the newest basic Universal Stanford Dependencies, without added language-specific subtypes."
"Představujeme HamleDT – Harmonizovaný vícejazyčný závislostní korpus (HArmonized Multi-LanguagE Dependency Treebank). HamleDT je sbírka existujících závislostních korpusů (nebo jiných korpusů převedených do závislostní syntaxe), transformovaných tak, aby všechny odpovídaly jednotnému anotačnímu stylu. V tomto článku představujeme podrobný rozbor řady jevů, které jsou v různých jazycích srovnatelné, jejich zachycení v korpusech se však často liší. Tvrdíme, že je možné navrhnout takové transformační procedury, které většinu zmíněných jevů automaticky rozpoznají a převedou do jednotného stylu. Tato normalizace je důležitá jak pro komparativní lingvistiku, tak pro strojové učení syntaktické analýzy.","We present HamleDT – a HArmonized Multi-LanguagE Dependency Treebank. HamleDT is a compilation of existing dependency treebanks (or dependency conversions of other treebanks), transformed so that they all conform to the same annotation style. In the present article, we provide
a thorough investigation and discussion of a number of phenomena that are comparable across languages, though their annotation in treebanks often differs. We claim that transformation procedures can be designed to automatically identify most such phenomena and convert them to a unified annotation style. This unification is beneficial both to comparative corpus linguistics
and to machine learning of syntactic parsing."
"Jedním ze způsobů, jak učit gramatiku, tj. tvaroslovný a větný rozbor, je kreslit diagramy, které zachycují vztahy mezi slovy ve větě. Podobně, ale mnohem komplexněji jsou tyto vztahy zachyceny v korpusech, které představují základní stavebni kameny v počítačovém zpracování přirozeného jazyka. Ovšem budování korpusů je velmi náročná aktivita, proto hledáme alternativní levnější a rychlejší způsoby organizace anotování, jako je např. crowdsourcing. Cílem této práce je prozkoumat možnosti získávání větných rozborů od žáků a jejich učitelů. V naší pilotní studii pracujeme s češtinou a větnými rozbory vyučovanými na českých školách.","One way of teaching grammar, namely morphology and syntax, is to visualize sentences as diagrams capturing relationships between words. Similarly, such relationships are captured in a more complex way in treebanks serving as key building stones in modern natural language processing. However, building treebanks is very time consuming, thus we have been seeking for an alternative cheaper and faster way, like crowdsourcing. The purpose of our work is to explore possibility to get sentence diagrams produced by students and teachers.
In our pilot study, the object language is Czech, where sentence diagrams are part of elementary school curriculum."
"Technická zpráva shrnuje nová anotační pravidla pro anotovaní českých textů na tektogramatické rovině Pražských závislostních korpusů, která doplňují velký anotační manuál (ÚFAL/CKL TR-2005-28). Pravidla vznikla v souvislosti s anotováním korpusů PCEDT 2.0 a PDTSC 2.0.",Technical report provides new annotation rules for annotation of czech text on tectogrammatical level of the Prague Dependency Treebanks. The rules supplement main annotation manual (ÚFAL/CKL TR-2005-28) and were formed with respect to annotation of PCEDT 2.0 and PDTSC 2.0.
"Článek přináší odpověď na otázku, co je a co není elipsa, a stanovuje kritéria určování elips ve větě. Analýzu jednotlivých typů elips podává z pohledu významové (sémanticko-syntaktické) reprezentace vět. Nezabývá se podmínkami a příčinami vzniku elips (kdy a proč je možné něco elidovat), zaměřuje se výhradně na identifikaci eliptických míst (zda je ve větě něco elidováno a co) a na jejich významovou reprezentaci, konkrétně na jejich zachycení na tektogramatické rovině pražských závislostních korpusů.","This article answers the question what is and what is not ellipsis and specifies criteria for identification of elliptical sentences. It reports on an analysis of types of ellipsis from the point of view of semantic representation of sentences. It does not deal with conditions and causes of the constitution of elliptical positions in sentences (when and why is it possible to omit something in a sentence) but it focuses exclusively on the identification of elliptical positions (if there is something omitted and what) and on their semantic representation in a treebank, specifically on their representation on the deep syntactic level of the Prague Dependency Treebanks. The theoretical frame of the approach to ellipsis presented in this article is dependency grammar."
"Přednáška se zaměří na základní syntaktické vztahy, především závislost a slovosled. Přiblížíme si jejich vzájemné vazby a ukážeme příklady vzájemného ovlivňování (včetně tzv. neprojektivních konstrukcí). Seznámíme se s Pražským závislostním korpusem, který zprostředkovává ""znalost"" češtiny i některých jiných jazyků počítačům, a tak umožňuje jejich automatické zpracování.","The talk focuses on basic syntactic relations, namely dependency and word order. We will discuss their mutual relations and show their inferences (including so called non-projectivity). We will get familiar with Prague Dependency Treebank, which provide ""knowledge"" of Czech (and other languages) to computers and makes their automatic processing possible."
"Přirozený jazyk a matematika: jak popsat češtinu tak, aby jí „porozuměly“ počítače? Přednáška se zaměří na základní syntaktické vztahy, především závislost a slovosled. Přiblížíme si jejich vzájemné vazby a ukážeme příklady vzájemného ovlivňování (včetně tzv. neprojektivních konstrukcí). Seznámíme se s Pražským závislostním korpusem, který zprostředkovává ""znalost"" češtiny i některých jiných jazyků počítačům, a tak umožňuje jejich automatické zpracování.","Natural Language and Mathematics: How to describe Czech for Computers? The talk focuses on basic syntactic relations, namely dependency and word order. We will discuss their mutual relations and show their inferences (including so called non-projectivity). We will get familiar with Prague Dependency Treebank, which provide ""knowledge"" of Czech (and other languages) to computers and makes their automatic processing possible."
"Tento příspěvek se věnuje identifikaci zajímavých konstrukcí v syntakticky anotovaném korpusu (Pražském závislostním korpusu, PDT) metodou auto- matické redukční analýzy. Rozšiřujeme zkoumané konstrukce zejména o koordinační a apoziční vztahy, které mají zřetelně ne-závislostní charakter a vedou tedy k zobecnění používané redukční metody. Přinášíme klasifikaci zkoumaných konstrukcí a soustřeďujeme se na popis a analýzu jednotlivých jazykových jevů, které při zpracování působí problémy. Tato studie je motivací pro formální modelování metod zpracování přirozeného jazyka.",The article focuses on the identification of interesting phenomena in the syntactically annotated corpus (Prague Dependency Treebank) using a method of Analysis by Reduction. Investigated phenomena are enriched with coordination and apposition. The study supports and motivated formal modeling of natural languages.
"Příspěvek nabízí lingvistická pozorování jako motivaci pro studium formální redukční analýzy. Využívá přitom třídu restartovacích automatů s metainstrukcemi, které pracují s ""oblázky"" a se dvěma operacemi - delete a shift.","The paper provides linguistic observations as a motivation for a formal study of analysis by
reduction (AR). It concentrates on a study of the whole mechanism through a class of restarting
automata with meta-instructions using pebbles, delete, and shift operations (DS-automata). The
complexity of DS-automata is naturally measured by the number of deletions, and the number
of word order shifts used in a single meta-instruction. We study reduction languages, backward correctness preserving AR, correctness preserving AR, and show unbounded hierarchies (scales) for various classes of reduction languages by the same finite witness languages. The scales make it possible to estimate relevant complexity issues of analysis by reduction for natural languages."
"Příspšvek se zabývá minimalismem redukční analýzy pomocí restartovacích automatů. Definují se v něm 4 třídy jazyků - základní jazyky nad slovními formami oznašenými gramatickými kategoriemi, vlastními jazyky nad slovními formami, hategoriální jazyky a jazyk redukcí. Složitost jazyků je měřena počtem ""oblázků"", počtem vyouštění a počtem přsunů během analýzy.","The paper provides linguistic observations as a motivation for a formal study of an analysis by reduction. It concentrates on a study
of the whole mechanism through a class of restarting automata with meta-instructions using pebbles, with delete and shift operations (DSautomata).
Four types of (in)finite sets defined by these automata are considered as linguistically relevant: basic languages on word forms marked
with grammatical categories, proper languages on unmarked word forms, categorial languages on grammatical categories, and sets of reductions
(reduction languages). The equivalence of proper languages is considered for a weak equivalence of DS-automata, and the equivalence of reduction languages for a strong equivalence of DS-automata.
The complexity of a language is naturally measured by the number of pebbles, the number of deletions, and the number of word order shifts
used in a single reduction step. We have obtained unbounded hierarchies (scales) for all four types of classes of finite languages considered here,
as well as for Chomsky’s classes of infinite languages. The scales make it possible to estimate relevant complexity issues of analysis by reduction for natural languages."
The European project Khresmoi aims to develop a multilingual and multimodal search and access system  for bilomedical information and documents.,Evropský projekt Khresmoi vyvíjí multilinguální a multimodální vyhledávací systém v oboru biomedicíny.
"Vyhledávání tzv. stupňovaných sloves, tj. sloves s intenzifikační předponou, v korpusech řady SYN. Vyhodnocení spolehlivosti intenzifikační interpretace.",Processing of intensified verbs (verbs with an intensifying prefix) using corpora SYN. Evaluation of the results.
"Příspěvek uvádí sadu slovesných předpon, které spolu s reflexním morfémem mění význam slovesa, a to vždy stejným způsobem.
Předpony tvoří posloupnost podle stupně intenzity, kterou pozměňují akci popisovanou daným slovesem.
Představujeme proces intenzifikace slovesa ve třech slovanských jazycích, a to v češtině, slovenštině a ruštině.","The paper discusses a~set of verbal prefixes which, when added to a~verb together with a~reflexive morpheme,
change the verb's meaning always in the same manner. 
The prefixes form a~sequence according to the degree of intensity with which they modify the verbal action. 
We present the process of verb intensification in three Slavic languages, namely Czech, Slovak and Russian."
"Software slouží pro vícejazyčné (české a anglické) vyhledávání relevantních slov či krátkých frází v archivu přeživších Holocaustu, spravovaném USC (University of Southern California) Shoah Foundation Institute (http://dornsife.usc.edu/vhi/). Tento archiv obsahuje více než 110 tisíc hodin záznamů v 32 jazycích, přičemž přibližně polovina těchto rozhovorů je vedena v angličtině. Pro účely vyhledávání v systému MCLAAS jsou česká a anglická řečová data nejprve zpracována příslušným modulem rozpoznávání řeči (SEASR-CZE - viz http://www.kky.zcu.cz/cs/sw/SEASR-CZE, resp. SEASR-ENG - viz http://www.kky.zcu.cz/cs/sw/SEASR-ENG) a poté je vytvořen tzv. index, což je strojová reprezentace rozpoznaných promluv, která umožňuje co nejrychlejší vyhledání požadovaného slova či fráze. Oba vyhledávací systémy pracují momentálně pouze s indexem založeným na slovní reprezentaci – fonémové vyhledávání bude implementováno později. Každý ze systémů v současnosti hledá výskyty slov či frází zhruba v 1000 hodin videozáznamů. V případě češtiny jde o veškerá dostupná data; v angličtině je k dispozici více než 50 tisíc hodin, ale rozpoznání a zaindexování celého tohoto objemu bude vyžadovat paralelizaci jednotlivých procesů. Pro křížové vyhledávání (dotaz v češtině, data/rozhovory v angličtině a češtině) byl použit systém překladu dotazu. Implementace byla provedena jako zvláštní verze systému MTMonkey (http://ufal.mff.cuni.cz/mtmonkey).","This software is used for multi-lingual (Czech and English) search for relevant words or short phrases in the archive of Holocaust survivors, managed by USC (University of Southern California) Shoah Foundation Institute (http://dornsife.usc.edu/vhi/), which contains more than 110,000 hours of records in 32 languages, with approximately half of these interviews is conducted in English. Czech part of the archive accounts for approximately one thousand hours. For the purposes of searching in the system MCLAAS are Czech and English speech data first processed with the appropriate speech recognition module (SEASR-CZE - see http://www.kky.zcu.cz/en/sw/SEASR-CZE or SEASR-ENG - see http://www.kky.zcu.cz/en/sw/SEASR-ENG) and then a so-called index is created, which is a machine representation of recognized utterances, which speeds up the search for a desired word or phrase. Both retrieval systems currently operate only with an index based on word representation - phonetic search will be implemented later. Each system is currently looking for occurrences of words or phrases in about 1000 hours of video. Those are all data available in the case of Czech; in English there are more than 50,000 hours, but the recognition and indexing of all this volume will require parallelization of individual processes. Cross-searching (query in English, data / interviews in English and Czech) in the system is facilitated by automatic query translation. Implementation was carried out as a special version of MTMonkey (http://ufal.mff.cuni.cz/mtmonkey)."
Článek rozebírá výsledky překladu z češtiny do slovenštiny pomocí dvou systémů - Google Translate a Česílko. Součástí článku je také rozbor chyb obou systémů.,"This paper describes an experiment compar-
ing results of machine translation between two
closely related languages, Czech and Slovak.
The comparison is performed by means of two
MT systems, one representing rule-based ap-
proach, the other one representing statistical
approach to the task. Both sets of results are
manually evaluated by native speakers of the
target language. The results are discussed both
from the linguistic and quantitative points of
view."
"Článek popisuje plně automatické propojování dvou valenčních slovníku českých sloves: VALLEXu a PDT-Vallexu. I přes společný teoretický základ, z něhož oba vycházejí, a přes stejné jazykové jevy, na něž se zaměřují, není plně automatické propojování snadné.

Ukážeme, že konverze slovníku do společného formátu představuje tu snadnější část úlohy, kdežto automatická identifikace dvojic odpovídajících si valenčních rámců přináší obtíže.

Celkovou dosaženou přesnost 81% lze považovat za uspokojivou. Je však třeba si uvědomit, že s rostoucím počtem lexikálních jednotek slovesa klesá přesnost automatického mapování. Ukážeme, že značně pomůže, pokud (i) poskytneme doplňující informace o lexikálních jednotkách a (ii) odhalíme a sladíme pravidelné nesrovnalosti v anotaci v obou slovnících.","This paper presents the fully automatic linking of two valency lexicons of Czech verbs: VALLEX and PDT-VALLEX. Despite the same theoretical background adopted by these lexicons and the same linguistic phenomena they focus on, the fully automatic mapping of these resouces is not straightforward.

We demonstrate that converting these lexicons into a common format represents a relatively easy part of the task whereas the automatic identification of pairs of corresponding valency frames (representing lexical units of verbs) poses difficulties. The overall achieved precision of 81% can be considered satisfactory. However, the higher number of lexical units a verb has, the lower the precision of their automatic mapping usually is. Moreover, we show that especially (i) supplementing further information on lexical units and (ii) revealing and reconciling regular discrepancies in their annotations can greatly assist in the automatic merging."
V posteru ukazujeme anotaci vnitřní struktury vybraných typů víceslovných pojmenovaných entit. Porovnáváme tuto strukturu se syntaktickou strukturou uvnitř i vně těchto VV.,What we demonstrate in this poster is annotation of structure of selected types of multiword named entities and how this structure relates to the syntactic structures around and inside these MWEs.
"Práce se zabývá syntaktickou identifikací výskytů víceslovných výrazů (VV) ze slovníku v textovém korpusu.
Porovnáváme tři přístupy odlišné v hloubce lingvistické analýzy -- od povrchového pořadí slov po hloubkovou syntax.","We deal with syntactic identification of occurrences of multiword expression (MWE) from an existing dictionary in a text corpus. The MWEs we identify can be of arbitrary length and can be interrupted in the surface sentence. We analyse and compare three approaches based on linguistic analysis at a varying level, ranging from surface word order to deep syntax. We use the dictionary of multiword expressions SemLex, that includes deep syntactic dependency trees of its MWEs."
"The development of a database of Czech derived words is described, focusing on linguistic aspects of this task. In Czech, which is a Slavic language with both rich inflectional and derivational morphology, derivation is the most frequent and most productive word-formation process. The database of Czech derived words was designed as a lexical network, which consists of lexemes and derivational relations (links) between them, oriented from the base to the derived word. The derivational relations were processed automatically under a thorough manual supervision in order to ensure efficiency and consistency on the one hand and theoretical adequacy on the other.","V příspěvku je popisováno budování databáze českých derivátů, pozornost je zaměřena na lingvistické aspekty tohoto procesu. V češtině je derivace nejfrekventovanějším a nejvíce produktivním slovotvorným procesem. Budovaná databáze je navržena jako lexikální síť, která sestává z lexémů (uzlů) a derivačních vztahů (hran) mezi nimi. Derivační vztahy byly generovány automaticky, ovšem za důkladné ruční kontroly."
"Článek se zabývá českými deadjektivními deriváty s příponou -ost. V české lingvistice je tento sufix popisován jako monofunkční sufix odvozující substantiva s významem kvality (př. sladkost; kvalitativní význam). Korpusová data ovšem ukazují, že jsou tato substantiva v současné češtině běžně používána také pro odvozování jmen s významem nositele vlastnosti (sladkost ve významu cukrovinka; nekvalitativní význam). Navrhujeme proto jak názvy vlastností tak názvy jejich nositelů hodnotit jako přímé deadjektivní deriváty s příponu -ost. Návrh je podložen analýzou rozsáhlého materiálu z korpusu SYN2010. Tato analýza potvrdila vztah mezi frekvencí substantiva s příponou -ost a jeho užíváním v nekvalitativním významu a také popisovanou skutečnost, že existence plurálových forem může být interpretována jako signál, že dané substantivum (s výjimkou vysoce frekventovaných jmen) má nekvalitativní význam.","The present study deals with Czech deadjectival derivates with the suffix -ost. In the Czech linguistics, the suffix is described as a monofunctional suffix that derives names of qualities (e.g. sladkost `sweetness’; qualitative meaning). However, as the corpus data demonstrate that the suffix is commonly used for deriving names of bearers of quality (sladkost `sweet thing’; non-qualitative meaning) in contemporary Czech as well, we propose to consider both the names of qualities and the names of their bearers as direct deadjectival derivates with the suffix -ost. The proposal is supported by an analysis of large data from the SYN2010 corpus. The material documents that, first of all, there is a relation between the frequency of a noun with the suffix -ost and its usage in the non-qualitative meaning and, secondly, that the existence of plural forms can be interpreted as a signal that the particular noun (except for the most frequent nouns) has a non-qualitative meaning."
"Pojetí produktivity a její zjišťování patří k základním otázkám slovotvorného výzkumu; s etablováním korpusů jako materiálových zdrojů lingvistické práce se výzkum produktivity stal ústředním tématem (především evropského) slovotvorného bádání. V zahraničních pracích je od 90. let 20. století diskutována možnost vyčíslit produktivitu jednotlivých formantů na základě frekvenčních údajů z korpusových dat, zásadní důležitost je přitom přikládána derivátům, které jsou v korpusových datech doloženy jediným výskytem. V příspěvku ilustrujeme problematičnost zjišťování slovotvorné produktivity z korpusových dat analýzou čtyř přípon, které v češtině vystupují jako součást názvů vlastností (zpravidla vedle jiných užití). Aplikací etablovaných kvantitativních přístupů a pokusem o důsledný rozbor systémových vlastností této sady přípon totiž dospíváme k různým výsledkům, tzn. jako nejproduktivnější jsou stanoveny různé přípony.","In the “corpus age” of linguistics, the research in productivity in word-formation has focused on development of measures that enable to calculate productivity from frequency data gained from large corpora. In the contribution, we determine productivity of four suffixes that are used in names of qualities in Czech. The results obtained by respected productivity measures are compared with a tentative approach (inspired esp. by Dokulil, 1962) to determine productivity of the suffixes on the basis of their systemic features. The disparity of results based on quantitative data vs. systemic features are interpreted in favor of combining both aspects."
"Lexikální síť AdjDeriNet zachycuje derivační vztahy mezi téměř 18 tisíci adjektivy a 26 tisíci lexémy od nich odvozenými (patřícími k různým slovním druhům); data tak obsahují celkem 44 tisíc lexémů. Nejfrekventovanějším deadjektivními deriváty jsou adverbia s příponou -e/ě, substantiva s příponou -ost a adverbia na -sky/-cky. Substantiva s příponou -as (př. kliďas), slovesa na -at (zelenat) nebo adjekiva s příponou -ičký (maličký) patří k nejméně frekventovaným derivátům v těchto datech.","The lexical resource contains nearly 18 thousand adjective lexemes, which are base words for about 26 thousand lexemes of several parts of
speech; the database thus consists of 44 thousand derivationally interlinked lexemes in total. The most frequent derivatives are adverbs with the suffix -e/ě, nouns with the suffix -ost and adverbs ending in -sky/-cky. Nouns ending in -as (ex. kliďas ‘phlegmatic person’), verbs with -at (zelenat ‘to turn green’), or adjectives with the suffix -ičký (maličký ‘very small’) belong to the least frequent deadjectival derivatives in the database."
"V příspěvku popisujeme vývoj lexikální sítě DeriNet, která zachycuje slovotvorné vztahy mezi zhruba 266 tisíci českými lexémy. Síť je v současné době omezena na procesy odvozování, které je v české slovotvorbě nejčastější a také nejproduktivnější. Toto omezení je reflektováno v architektuře sítě: každý lexém smí být spojen pouze s jedním základovým slovem; skládání a kombinované slovotvorné procesy (kompozice s derivací) nejsou do sítě zahrnuty. Po krátkém shrnutí teoretického popisu derivace v češtině a prací věnujících se české derivaci z komputačního hlediska popisujeme lingvistická rozhodnutí, ze kterých návrh sítě vychází, a následně formální strukturu sítě a poloautomatickou anotaci.","In the present paper, we describe the development of the lexical network DeriNet, which captures core word-formation relations on the set of around 266 thousand Czech lexemes. The network is currently limited to derivational relations because derivation is the most frequent and most productive word-formation process in Czech. This limitation is reflected in the architecture of the network: each lexeme is allowed to be linked up with just a single base word; composition as well as combined processes (composition with derivation) are thus not included. After a brief summarization of theoretical descriptions of Czech derivation and the state of the art of NLP approaches to Czech derivation, we discuss the linguistic background of the network and introduce the formal structure of the network and the semi-automatic annotation procedure. The network was initialized with a set of lexemes whose existence was supported by corpus evidence. Derivational links were created using three sources of information: links delivered by a tool for morphological analysis, links based on an automatically discovered set of derivation rules, and on a grammar-based set of rules. Finally, we propose some research topics which could profit from the existence of such lexical network."
"Tento článek popisuje metodu faktorového diskriminativního porozumění řeči, vhodnou pro parsování rozpoznané řeči v reálném čase. Je založena na sadě klasifikátorů logistické regrese, které se používají pro převod vstupních textů do dialogových aktů. Navrhovanou metodu evaluujeme na řečovém korpusu z domény informací o veřejné dopravě. Ta představuje soubor záznamů telefonních hovorů uživatelů dialogového systému, kteří hledají spojení městské nebo meziměstské veřejné dopravy, popř. se ptají na počasí v určitém městě. Výsledky ukazují, že za podmínek nepříznivých pro statistické rozpoznávání řeči náš statistický parser funguje lépe než základní dobře vyladěný pravidlový parser.","This paper describes a factored discriminative spoken language understanding method suitable for real-time parsing of recognised speech. It is based on a set of logistic regression classifiers, which are used to map input utterances into dialogue acts. The proposed method is evaluated on a corpus of spoken utterances from the Public Transport Information (PTI) domain. In PTI, users can interact with a dialogue system on the phone to find intra- and inter-city public transport connections and ask for weather forecast in a desired city. The results show that in adverse speech recognition conditions, the statistical parser yields significantly better results compared to the baseline well-tuned handcrafted parser."
"Tento článek popisuje framework dialogových systémů Alex (ADSF).
ADSF v současné době zahrnuje komponenty pro telefonii, detekci hlasu, rozpoznávání řeči, porozumění řeči a pravěpodobností sledování stavu dialogu. ADSF je používáno v reálné aplikace pro poskytování informací o veřejné dopravě, ""PTI"" doméně. V ""PTI"" doméně uživatelé komunikují s dialogovým systémem pomocí telefonu, aby získali informace o dopravních spojeních jak v MHD tak mezi městy.
Na základě uživatelských hodnocení je naprostá většina uživatelů se systémem spokojena.","This paper describes the Alex Dialogue Systems Framework (ADSF).
The ADSF currently includes mature components for public telephone network connectivity, voice activity detection, automatic speech recognition, statistical spoken language understanding, and probabilistic belief tracking. The ADSF is used in a real-world deployment within the Public Transport Information (PTI) domain. In PTI, users can interact with a dialogue system on the phone to find intra- and inter-city public transport connections and ask for weather forecast in a desired city. Based on user responses, vast majority of the system users are satisfied with the system performance."
"Přesné sledování stavu dialogu je zásadní pro návrh efektivního mluveného dialogového systému. Až do nedávné doby bylo kvantitativní srovnání různých metod sledování stavu obtížné. Soutěž sledování stavu dialogu v roce 2013 (DSTC) zavedla společou datovou a metriky, které umožňují vyhodnotit výkon různých systémů na jedné standardizované úloze. V tomto příspěvku předtsavujeme náš systém založený na modelu HIS (Hidden Information State) s upravenou komponentou uživatelského modelu. Dále uvádíme výsledky našeho trackeru na datovém souboru test3 z DSTC. Náš tracker je konkurenceschopný s trackery z DSTC, a to i bez dalšícho trénovaní. Dosahuje nejlepších výsledků v metrikách L2 a provádí přesnost mezi druhým a třetím místem. Po dotrénování systémů pomocí poskytnutých dat naše metoda překonala ostatní systémy v přesnosti a ještě zlepšila v metrice L2. Dále předkládáme předběžné výsledky o dalších dvou sadách dat test1 a test2, které byly použity v DSTC. Výsledky metrice L2 znamenají, že náš systém vytváří hypotézy s dobře kalibrovanými pravděpodobnostmi.","Accurate dialog state tracking is crucial for the design of an efficient spoken dialog system. Until recently, quantitative comparison of different state tracking methods was difficult. However the 2013 Dialog State Tracking Challenge (DSTC) introduced a common dataset and metrics that allow to evaluate the performance of trackers on a standardized task. In this paper we present our belief tracker based on the Hidden Information State (HIS) model with an adjusted user model component. Further, we report the results of our tracker on test3 dataset from DSTC. Our tracker is competitive with trackers submitted to DSTC, even without training it achieves the best results in L2 metrics and it performs between second and third place in accuracy. After adjusting the tracker using the provided data it outperformed the other submissions also in accuracy and yet improved in L2. Additionally we present preliminary results on another two datasets, test1 and test2, used in the DSTC. Strong performance in L2 metric means that our tracker produces well calibrated hypotheses probabilities"
Tento článek představuje dvě diskriminativní znalostní metody sledování stavu dialogu a jejich výsledky na datových sadách DSTC 2 a 3. První systém byl zařazen do soutěže DSTC3 a umístil se na druhém místě. Druhý tracker vyvinutý po termínu soutěze dává ještě lepší výsledky. Metoda nabízí srovnatelné výsledky jako nejlepší existující systémy a zorveň je dobře interpertovatelná. Na základě výsledků DSTC2 a DSTC3 analyzujeme vhodnost různých technik pro každý z dílčích problémů sledování stavu dialogu. Výsledky systémů ukazují důležitost sémantické analýzy (SLU) pro poslední dvě DSTC.,"Abstract:
This paper presents two discriminative knowledge-based dialog state trackers and their results on the Dialog State Tracking Challenge (DSTC) 2 and 3 datasets. The first tracker was submitted to the DSTC3 competition and scored second in the joint accuracy. The second tracker developed after the DSTC3 submission deadline gives even better results on the DSTC2 and DSTC3 datasets. It performs on par with the state of the art machine learning-based trackers while offering better interpretability. We summarize recent directions in the dialog state tracking (DST) and also discuss possible decomposition of the DST problem. Based on the results of DSTC2 and DSTC3 we analyze suitability of different techniques for each of the DST subproblems. Results of the trackers highlight the importance of Spoken Language Understanding (SLU) for the last two DSTCs."
"Představil jsem chatbota Pohádkové dítě návštěvníkům Dne otevřených dveří, t.j. zejména možných studentů MFF a potenciálně ÚFALu. Návštěvníci měli možnost si sami popovídat s chatbotem, kterou mnoho z nich využilo a užilo si.","I presented the Fairytale Child Chatbot to visitors of the Day of Open Doors, i.e. especially prospective students of MFF and potentially ÚFAL. The visitors had the opportunity to chat with the chatbot themselves, which many of them used and enjoyed."
"Manuál podává instrukce pro instalaci a běh Depﬁxu, našeho open-source nástroje pro automatickou post-editaci strojového překladu. V dokumentu pokrýváme kroky potřebné k užití Depﬁxu pro zpracování Vašich vlastních dat. Manuál také obsahuje popis Depﬁxové pajplajny, včetně instrukcí, které vám umožní změnit fungování Depﬁxu.","The manual gives instructions on installing and running Depﬁx, our open-source tool for automatic post-editing of machine translation. We cover the steps required to use Depﬁx to process your own data. The manual also contains a description of the Depﬁx pipeline, including instructions that will enable you to modify the operation of Depﬁx."
"Představujeme Depfix -- open-souce systém pro automatickou post-editaci výstupů frázového strojového překladu. Depfix zapojuje řadu nástrojů pro automatické zpracování přirozeného jazyka, pomocí nichž získává rozbor vstupních vět, a používá sadu pravidel pro opravu závažných chyb či chyb obvyklých ve výstupech strojových překladačů. Depfix je momentálně implementován pouze pro překladový směr z angličtiny do češtiny, ale v plánu je jeho rozšíření na další jazyky.","We present Depfix, an open-source system for automatic post-editing of phrase-based machine translation outputs. Depfix employs a range of natural language processing tools to obtain analyses of the input sentences, and uses a set of rules to correct common or serious errors in machine translation outputs. Depfix is currently implemented only for English-to-Czech translation direction, but extending it to other languages is planned."
"Depfix je open-souce systém pro automatickou post-editaci výstupů frázového strojového překladu. Depfix zapojuje řadu nástrojů pro automatické zpracování přirozeného jazyka, pomocí nichž získává rozbor vstupních vět, a používá sadu pravidel pro opravu závažných chyb či chyb obvyklých ve výstupech strojových překladačů. Depfix je momentálně implementován pouze pro překladový směr z angličtiny do češtiny.","Depfix is an open-source system for automatic post-editing of phrase-based machine translation outputs. Depfix employs a range of natural language processing tools to obtain analyses of the input sentences, and uses a set of rules to correct common or serious errors in machine translation outputs. Depfix is currently implemented only for English-to-Czech translation direction."
"Depfix is a system for automatic post-editing of phrase-based English-to-Czech machine translation outputs, based on linguistic knowledge. We analyzed the types of errors that a typical machine translation system makes, and created a set of rules and a statistical component that correct some of the errors. We use a range of natural language processing tools to provide us with analyses of the input sentences. Moreover, we reimplemented the dependency parser and adapted it in several ways to parsing of statistical machine translation outputs. We performed both automatic and manual evaluations which confirmed that our system improves the quality of the translations.","Depfix je systém pro samočinnou post-edititaci výstupů frázových strojových překladů z angličtiny do češtiny, založený na jazykovědných znalostech. Nejprve jsme rozebrali druhy chyb, kterých se dopouští typický strojový překladač. Poté jsme vytvořili sadu pravidel a statistickou komponentu, které opravují takové chyby, které jsou běžné nebo závažné a může přicházet v úvahu jejich oprava pomocí našeho přístupu. Používáme řadu nástrojů pro zpracování přirozeného jazyka, které nám poskytují rozbor vstupních vět. Navíc jsme reimplementovali závislostní analyzátor a několika způsoby jej upravili pro provádění rozboru výstupů statistických strojových překladačů. Provedli jsme automatická i ruční vyhodnocení, která potvrdila, že kvalita překladů se zpracováním v našem systému zlepšuje."
"Popularizační přednáška pro účastníky České lingvistické olympiády. Jak funguje frázový statistický strojový překlad, jaké má problémy, a jak se dají opravovat Depfixem, systémem pro automatickou post-editaci.",A popularization talk about Statistical machine translation and Automatic post-editing for the participants of Czech Linguistics Olympics.
"Pohádkové dítě je jednoduchý chatbot, simulující zvídavé dítě. Požádá uživatele, aby mu vyprávěl pohádku, ale často ho přerušuje, aby se zeptal na detaily a vysvětlení. Pamatuje si ale, co mu uživatel řekl, a snaží se to pokud možno dát najevo.  Chatbot umí komunikovat česky a anglicky. Analyzuje tvarosloví každé uživatelovy věty pomocí NLP nástrojů, pokusí se nalézt chodnou otázku, a tu pak položí. Aby tvořené české věty zněly co nejpřirozeněji, využívá se pro skloňování tvaroslovný generátor.","Fairytale Child is a simple chatbot trying to simulate a curious child. It asks the user to tell a fairy tale, often interrupting to ask for details and clarifications. However, it remembers what it was told and tries to show it if possible.  The chatbot can communicate in Czech and in English. It analyzes the morphology of each sentence produced by the user with natural language processing tools, tries to identify potential questions to ask, and then asks one. A morphological generator is employed to generate correctly inflected sentences in Czech, so that the resulting sentences sound as natural as possible."
"Pohádkové dítě (Fairytale Child) je jednoduchý chatbot, snažící se napodobovat zvídavé dítě. Žádá uživatele, aby mu vyprávěl pohádku, a často jej přerušuje, aby se zeptal na podrobnosti či si ujasnil některé věci. Pamatuje si nicméně, co mu bylo řečeno, a snaží se to dát pokud možno najevo. 
Chatbot umí komunikovat česky a anglicky. Analyzuje morfologii každé věty, kterou uživatel zadal, za pomoci nástrojů pro zpracování přirozeného jazyka, snaží se rozpoznat potenciální otázky, na které by se mohl zeptat, a poté jednu z nich uživateli položí. Ke stvoření správně vyskloňované české věty se používá morfologický generátor.","Fairytale Child (Pohádkové dítě) is a simple chatbot trying to simulate a
curious child. It asks the user to tell a fairy tale, often interrupting to
ask for details and clarifications. However, it remembers what it was told and
tries to show it if possible.
The chatbot can communicate in Czech and in English. It analyzes the
morphology of each sentence produced by the user with natural language
processing tools, tries to identify potential questions to ask, and then asks
one. A morphological generator is employed to generate correctly inflected
sentences in Czech, so that the resulting sentences sound as natural as possible."
"Jak funguje Google Translate, proč nepoužívá slovník ale fráze z internetu, jaké má problémy.
Jak to jde dělat lépe, což řeší moje diplomová práce, a proč se programátorovi někdy hodí znát českou gramatiku.","How Google Translate works, why it doesn't use a dictionary, but uses phrases from the internet instead, what problems it has.
How it can be done in a better way, which was the topic if my diploma thesis, and why it is sometimes useful for a programmer to know Czech grammar."
"MSTperl je Perlovou reimplementací MST parseru  Ryana McDonalda, s několika pokročilými funkcemi navíc, jako je podpora pro paralelní rysy.","MSTperl is a Perl reimplementation of the MST parser of Ryan McDonald, with several additional advanced functions, such as support for parallel features."
"Představení překladového systému Chiméra, zejména systémů Moses a TectoMT. Jednotlivé kroky, vstupy a výstupy, předvedeno na konkrétním příkladu.","Presentation of the Chimera translation system, especially Moses and TectoMT systems. Individual steps, inputs and outputs, shown on a concrete example."
A simple way of browsing CoNLL format files in your terminal. Fast and text-based.,Snadný způsob prohlížení souborů ve formátu CoNLL ve vašem terminálu. Rychlý a textový.
"Existuje sbírka 30 závislostních korpusů (HamleDT) a existují i další závislostní korpusy; avšak na světě je kolem 7000 jazyků, a budovat závislostní korpus pro každý z nich se zdá být nepraktickým. Proto navrhuji prozkoumat možnosti částečně řízeného závislostního větného rozboru (pravděpodobně pomocí promítnutí z více zdrojů). Taktéž navrhuji obecně použití mlhavějších vstupních rysů (zejména tvaroslovných značek).","There is a collection of 30 treebanks (HamleDT) and more treebanks exist, but there are about 7000 languages in the world, and it seems impractical to build treebanks for all of these. Therefore, I propose to explore the possibilities of semi-supervised parsing (probably via multisource projection). Also, I suggest generally adding more fuzziness to input features (especially morphological tags)."
"Představujeme HamleDT 2.0 (HArmonized Multi-LanguagE Dependency Treebank). HamleDT 2.0 je sbírka 30 existujících závislostních korpusů, harmonizovaných do společného anotačního stylu – Pražských závislostí – a dále transformovaných do Stanfordských závislostí – anotačního stylu, který se v nedávné době stal oblíbeným.

Používáme nejnovější základní Universal Stanford Dependencies, bez dodaných jazykově specifických subtypů. Popisujeme oba anotační styly, včetně úprav, které bylo nutné provést, a poskytujeme detaily o procesu konverze. Diskutujeme též rozdíly mezi těmito dvěma styly, vyhodnocujíce jejich výhody a nevýhody, a zmiňujeme vliv těchto rozdílů na konverzi.

Stanfordizaci obecně považujeme za úspěšnou, přestože uznáváme několik nedostatků – zejména v rozlišení přímých a nepřímých předmětů – kterým je nutné v budoucnosti věnovat pozornost.

Část HamleDT 2.0 volně zveřejňujeme; nemáme svolení k redistribuci celé datové sady, ale poskytujeme nástroje pro konverzi.","We present HamleDT 2.0 (HArmonized Multi-LanguagE Dependency Treebank). HamleDT 2.0 is a collection of 30 existing treebanks harmonized into a common annotation style, the Prague Dependencies, and further transformed into Stanford Dependencies, a treebank annotation style that became popular recently.

We use the newest basic Universal Stanford Dependencies, without added language-specific subtypes. We describe both of the annotation styles, including adjustments that were necessary to make, and provide details about the conversion process. We also discuss the differences between the two styles, evaluating their advantages and disadvantages, and note the effects of the differences on the conversion.

We regard the stanfordization as generally successful, although we admit several shortcomings, especially in the distinction between direct and indirect objects, that have to be addressed in future.

We release part of HamleDT 2.0 freely; we are not allowed to redistribute the whole dataset, but we do provide the conversion pipeline."
Tato práce je prvním pokusem o mezijazyčné rozpoznávaní koreference metodami strojového učení.,"This work is, to our knowledge, a first attempt at a machine learning approach to cross-lingual
coreference resolution, i.e. coreference resolution (CR) performed on a bitext. Focusing on CR of English pronouns, we leverage language differences and enrich the feature set of a standard monolingual CR system for English with features extracted from the Czech side of the bitext. Our work also includes a supervised pronoun aligner that outperforms a GIZA++ baseline in terms of both intrinsic evaluation and evaluation on CR. The final cross-lingual CR system has successfully outperformed both a monolingual CR and a cross-lingual projection system."
"Od publikace v roce 2011, ziskala CEFR vedoucí úlohu ve výuce a certifikaci cizích jazyků. Bohužel jednotlivé úrovně CEFR nejsou dostatečně ilustrovány. Cílem projektu Merlin je vyřešit tento problém pro češtinu, němčinu a italštinu.","Since its publication in 2001, the Common European Framework of Reference for Languages (CEFR) has gained a leading role as an instrument of reference for language teaching and certification and for the development of curricula. Nonetheless, there is a growing concern about CEFR reference levels being insufficiently illustrated in terms of authentic learner data, leaving practitioners without comprehensive empirical characterizations of the relevant distinctions. This is particularly the case for languages other than English (cf. e.g. Hulstijn 2007, North 2000). The MERLIN project addresses this demand to illustrate and validate the CEFR levels for Czech, German and Italian by developing a didactically motivated online platform that enables CEFR users to explore authentic written learner productions. The core of the multilingual online platform is a trilingual learner corpus composed of roughly 200 learner texts per CEFR level, produced in standardized language certifications validly related to the CEFR, covering the levels A1-C1. The aim of this paper is to both present the MERLIN project with the motivation behind and its corpus and to discuss its current state."
Článek popisuje výsledky evaluace vyhledávacího nástroje vyvinutého v rámci projektu Khresmoi. Evaluace byla zaměřena na laickou veřejnost v ČR a ve Francii.,"This article presents the results of one of the stages of the user-centered evaluation conducted in a framework of the EU project Khresmoi. In a controlled environment, users were asked to perform health-related tasks using a search engine specifically developed for trustworthy online health information. Twenty seven participants from largely the Czech Republic and France took part in the evaluation. All reported overall a positive experience, while some features caused some criticism. Learning points are summed up regarding running such types of evaluations with the general public and specifically with patients."
"Klíč k rychlému přizpůsobení jazykových technologií pro libovolný jazyk 
závisí na dostupnosti základních nástrojů a datových zdrojů, jako jsou jednojazyčné nebo paralelní korpusy, anotované korpusy, značkovače slovních druhů, syntaktické analyzátory, a podobně. Jazyky, pro něž tyto základní zdroje 
neexistují, označujeme jako zdrojově chudé jazyky.

V této práci se zabýváme otázkou závislostního syntaktického rozboru zdrojově 
chudých jazyků za pomoci zdrojů pro jiné jazyky. Pro nalezení závislostní struktury používáme tři postupy: (i) promítnutí závislostí ze zdrojově bohatého jazyka do zdrojově chudého jazyka za pomoci slovního zarovnání v paralelním 
korpusu (ii) analýze pod-zdroji jazyků pomocí parserů, jejichž modely jsou vyškoleni na 
stromových korpusů z jiných jazyků, a nedívejte se na skutečných slovních forem, ale pouze na 
POS kategorie. Zde se zabýváme problémem neslučitelnosti různých anotačních stylů používaných zdrojovými analyzátory a 
cílovými závislostně anotovanými korpusy používanými pro evaluaci, který řešíme 
pomocí harmonizace anotací do jednotného standardu; a konečně (iii) zavádíme 
nový postup, ve kterém pro promítnutí závislostí do zdrojově chudého jazyka používáme paralelní korpusy vytvořené pomocí strojového překladu namísto lidského překladu.

Výše uvedené postupy jsme použili na pět indických jazyků: hindštinu, urdštinu, 
telugštinu, bengálštinu a tamilštinu (seřazeno sestupně podle dostupnosti závislostně anotovaných dat). Abychom prokázali použitelnost uvedených postupů v praxi, vyvinuli jsme závislostně anotovaný korpus pro tamilštinu, pro niž dosud žádný takový zdroj neexistoval, a takto získaná data využíváme pro evaluaci a také jako zdroj pro závislostní rozbor jiných indických jazyků. Nakonec jsme seznam se strategie, které může být použit k získání závislost struktury pro cílových jazyků pod jiný scénáře s omezenými zdroji.","Key to fast adaptation of language technologies for any language hinges on the availability of fundamental tools and resources such as monolingual/parallel corpora, annotated corpora, part-of-speech (POS) taggers, parsers and so on. The languages which lack those fundamental resources are often referred as under-resourced
languages.

In this thesis, we address the problem of cross-lingual dependency parsing of under-resourced languages. We apply three methodologies to induce dependency structures: (i) projecting dependencies from a resource-rich language to under-resourced languages via parallel corpus word alignment links (ii) parsing under-
resourced languages using parsers whose models are trained on treebanks of other
languages, and do not look at actual word forms, but only on POS categories. Here
we address the problem of incompatibilities in annotation styles between source side parsers and target side evaluation treebanks by harmonizing annotations to a common standard; and finally (iii) we add a new under-resourced scenario in which we use machine translated parallel corpora instead of human translated corpora for
projecting dependencies to under-resourced languages.

We apply the aforementioned methodologies to five Indian languages (ILs): Hindi, Urdu, Telugu, Bengali and Tamil (in the order of high to low availability of treebank data). To make the evaluation possible for Tamil, we develop a depen
dency treebank resource for Tamil from scratch and we use the created data in
evaluation and as a source in parsing other ILs. Finally, we list out strategies that
can be used to obtain dependency structures for target languages under different
resource-poor scenarios."
"Tento dokument se vrací k přístupu projekce založené na závislost gramatiky indukční úkol. 
Tradiční cross-kulturní závislost indukční úkoly jeden tak či onak, závisí na existenci 
z bitexts nebo cílového jazyka nástrojů, jako je část-of-speech (POS) značkovače, abychom získali přiměřenou analýze přesnosti. V tomto článku jsme se přenést závislost analyzátory pomocí pouze orientační zdroje, tj, stroje přeloženy bitexts namísto ručně vytvořených bitexts. Děláme to tak, 
získání zdrojového stranu textu ze strojového překladu (MT) systém a pak použít Přenos přístupy k vyvolání analyzátor pro cílové jazyky. Dále snižují potřebu Informace o dostupnosti značených cílového jazyka zdrojů pomocí voze cílové tagger. 
Ukázali jsme, že náš přístup stále překonává bez dozoru analyzátory o větší rozpětí 
(8,2% absolutní), a výsledky v podobném provedení, kdy ve srovnání s delexicalized převodem 
analyzátory.","This paper revisits the projection-based approach to dependency grammar induction task.
Traditional cross-lingual dependency induction tasks one way or the other, depend on the existence
of bitexts or target language tools such as part-of-speech (POS) taggers to obtain reasonable
parsing accuracy. In this paper, we transfer dependency parsers using only approximate
resources, i.e., machine translated bitexts instead of manually created bitexts. We do this by
obtaining the the source side of the text from a machine translation (MT) system and then apply
transfer approaches to induce parser for the target languages. We further reduce the need
for the availability of labeled target language resources by using unsupervised target tagger.
We show that our approach consistently outperforms unsupervised parsers by a bigger margin
(8.2% absolute), and results in similar performance when compared with delexicalized transfer
parsers."
"Jedním z nejdůležitějších aspektů cross-kulturní přenos závislostí 
je to, jak různé anotace styly, které často podceňují přesnost syntaktické jsou zpracovány. 
Novým trendem je, že styl anotace různých jazykových stromových korpusů může být
harmonizovány do jednoho stylu, a tak se lze vyhnout těžkopádné pravidla manuální transformace. 
V tomto článku budeme používat harmonizované stromových korpusů (POS tagsets a závislost struktury původní 
stromových korpusů mapované do společného stylu) pro vyvolání závislosti na nastavení cross-kulturní. 
Nabízíme převod závislostí pomocí delexicalized analyzátory, které používají harmonizované verze původních stromových korpusů. 
Tento přístup aplikovat na pět indických jazyků (Hindština, Urdu, Telugu, bengálský a Tamil) a ukazují, že 
Nejlepšího výkonu lze získat delexicalized analýze, kdy dojde k přemístění z indického jazyka (IL) na IL stromových korpusů.","One of the most important aspect of cross-lingual dependency transfer 
is how different annotation styles which often underestimate the parsing accuracy are handled. 
The emerging trend is that the annotation style of different language treebanks can be 
harmonized into one style and the cumbersome manual transformation rules thus can be avoided.
In this paper, we use harmonized treebanks (POS tagsets and dependency structures of original 
treebanks mapped to a common style)  for inducing dependencies in a cross-lingual setting. 
We transfer dependencies using delexicalized parsers that use harmonized version of the original treebanks. 
We apply this approach to five Indian languages (Hindi, Urdu, Telugu, Bengali and Tamil) and show that
best performance can be obtained in delexicalized parsing when the transfer takes place from Indian language (IL) to IL treebanks."
"Tento článek prezentuje výsledky úlohy 3 z ShARe/CLEF eHealth Evaluation Lab 2014 zaměřené na 
uživatelskou evaluace vyhledávání informací v oblasti zdraví",This paper presents the results of task 3 of the ShARe/CLEF eHealth Evaluation Lab 2014 focused on user-centred health information retrieval.
Test Your Bot (teyb) je framework pro testování dialogových systémů přes internet proti sdíleným simulátorům uživatele.,"Test Your Bot (teyb) is a framework for testing dialog systems over the internet against a shared collection of user simulators.

Features:

Written in Django & Python & AngularJS
Web interface
Task creation
Team registration
Statistics
REST API for communication"
"Prezentace aplikace JTagger, která detekuje reference v českých soudních rozhodnutích. Tento úkol chápeme jako typický úkol pro identifikaci jmenných entit, kde entity jsou reference (odkazy) na jiné dokumenty. Aplikujeme přístupy strojového učení s učitelem, konkrétně skryté Markovovy modely. Protože metody strojového učení s učitelem vyžadují manuálně anotovaná trénovací data, anotovali jsme 300 soudních rozhodnutí.","We address the task of reference detection and classification in Czech court decisions. This task is a typical named-entity recognition task where the entities are references (links) to other documents. We apply a supervised machine learning approach, namely Hidden Markov Models. A supervised methodology requires manual annotation of training data so we annotated 300 court decisions."
"Aplikace detekuje reference v českých soudních rozhodnutích. Tento úkol chápeme jako typický úkol pro identifikaci jmenných entit, kde entity jsou reference (odkazy) na jiné dokumenty. Aplikujeme přístupy strojového učení s učitelem, konkrétně skryté Markovovy modely. Protože metody strojového učení s učitelem vyžadují manuálně anotovaná trénovací data, anotovali jsme 300 soudních rozhodnutí.","We address the task of reference detection and classification in Czech court decisions. This task is a typical named-entity recognition task where the entities are references (links) to other documents. We apply a supervised machine learning approach, namely Hidden Markov Models. A supervised methodology requires manual annotation of training data so we annotated 300 court decisions."
"Předkládáme detailní studii automatické lexikální disambiguace na pilotním vzorku třiceti anglických sloves za použití lexikonu vzorů slovesných užití (patterns), který vychází z Corpus Pattern Analysis (CPA). Tato inovátorská lexikografická metoda namísto na abstraktních definicích jednotlivých významů staví na souhře morfosyntaktické, lexikální a sémantické/pragmatické podobnosti slovesných užití. Natrénovali jsme několik statistických klasifikátorů na rozpoznávání těchto vzorů. Klasifikátory využívají jak morfosyntaktických, tak sémantických rysů. V naší studii se soustředíme na procedury pro extrakci rysů, jejich výběr a jejich evaluaci. Ukazujeme, že rysy na míru uzpůsobené jednotlivým slovesům, jež jsou implicitně obsaženy v definici každého vzoru v lexikonu, mají potenciál významně zvýšit přesnost statistických klasifikátorů s učitelem.","We give a report on a detailed study of automatic lexical disambiguation of 30 sample English verbs. We have trained and evaluate several statistical classifiers that use both morphosyntactic and semantic features to assign semantic patterns according to a pattern lexicon. Our system of semantic classification draws on the Corpus Pattern Analysis (CPA) — a novel lexicographic method that seeks to cluster verb uses according to the morpho-syntactic, lexical and semantic/pragmatic similarity of their contexts rather than their grouping according to abstract semantic definitions. In this paper we mainly concentrate on the procedures for feature extraction and feature selection. We show that features tailored to particular verbs using contextual clues given by the CPA method and explicitly described in the pattern lexicon have potential to significantly improve accuracy of supervised statistical classifiers."
"Prezentujeme systém pro extrakci znalostní báze z nestrukturovaných textů. Bázy definujeme jako množinu entit a vztahů mezi nimi a reprezentujeme ji v ontologickém frameworku. Extrakční procedura zpracovává vstupní texty lingvistickými procedurami a extrahuje entity a vztahy mezi nimi z jejich syntaktické reprezentace. Následně jsou extrahované informace reprezentovány dle principů Linked Data. Systém je navržen nezávisle na doméně a jazyce textů tak, aby poskytl uživatelům inteligentnější vyhledávání než fulltextové. Prezentujeme první výsledky na českých legislativních dokumentech.","We present a system that extracts a knowledge base from raw unstructured texts that is designed as a set of entities and their relations and represented in an ontological framework. The extraction pipeline processes input texts by linguistically-aware tools and extracts entities and relations from their syntactic representation. Consequently, the extracted data is represented according to the Linked Data principles. The system is designed both domain and language independent and provides users with data for more intelligent search than full-text search. We present our first case study on processing Czech legal texts."
"V této práci detekujeme a klasifikujeme reference v českých soudních rozhodnutích, především reference na jiné soudní rozhodnutí a zákony. Reference chápeme jako entity v úloze rozpoznávání jmenných entit. Dále se zabýváme detekcí institucí, které publikují odkazované dokumenty. Náš přístup aplikuje metody strojového učení, konkrétně používáme Markovovy modely a Perceptron. Dosahujeme úspěšnosti nad 90% F-measure pro každý typ entity. Výsledky výrazně převyšují dosud publikované systémy.","We address the task of detection and classification of references in Czech court decisions, mainly we focus on references to other court decisions and acts. We handle these references like entities in the task of Named Entity Recognition. In addition, we are interested in detection of institutions that issued documents under consideration. Attributes like the applicability of law have been studied as well. We approach the task using machine learning methods, namely HMM and Perceptron algorithm. We report F-measure over 90% for each entity. The results significantly outperform the systems published previously."
"Podle statistik společnosti International Data Corporation, 90% všech digitálních dat je nestrukturovaných. Toto množství navyše roste dvakrát tak rychle jako množství strukturovaných dat. V mnoha doménách tvoří obrovské kolekce nestrukturovaných dokumentů hlavní zdroj informací. Jejich efektivní prohlížení a  dotazování přestavuje klíčový aspekt v mnoha oblastech lidské činnosti. Projekt INTLIB (Inteligentní knihovna) očekává na vstupu velké množství dokumentů souvisejících s určitou doménou. V první fáze jsou z dokumentů extrahována základní informace pomocí nástrojů pro zpracování přirozeného jazyka. V druhé fáze se zaoberáme efektivní a uživatelsky přívětivou vizualizací a dotazováním nad extrahovanými znalostmi. Prezentujeme naše výsledky na legislativní a enviromentální doméne.","According to the statistics provided by the International Data Corporation, 90% of all available digital data is unstructured and its amount currently grows twice as fast as structured data. In many domains, large collections of unstructured documents form main sources of information. Their efficient browsing and querying present key aspects in many areas of human activities. The project INTLIB, an INTelligent LIBrary, assumes a collection of documents related to a particular problem domain on the input. In the first phase we extract a knowledge base from the collection using natural language processing tools. In the second phase we deal with efficient and user friendly visualization and querying the extracted knowledge. We will present our results on both legislative and environmental domain."
"V této práci popisujeme projekt INTLIB - inteligentní knihovna, kterého císlem je vytvořit více sofistikovaný a uživatelsky přívětivější systém pro dotazování nad textovými dokumenty než full-text. Na vstupu předpokládáme kolekci dokumentů související s určitou doménou (např. legislatíva, medicína, enviromentální doména). V první fáze extrahujeme z dokumenů znalostní bázy - kolekci objektů a vztahů mezi nima. Ve druhé fáze se zaoberáme vizualizací a prohlížením extrahovaných znalostí. Celý systém je navhován jako obecní framework který může být modifikován a rozšířen na specifikované domény. V pilotní fázy projektu pracujeme s legislativní doménou.","In this paper we describe the project INTLIB – an INTelligent LIBrary whose aim is to provide a more sophisticated and user-friendly tool for querying textual documents than full-text search. On the input we assume a collection of documents related to a particular problem domain (e.g., legislation, medicine, environment, etc.). In the first phase we extract from the documents a knowledge base, i.e. a set of objects and their relationships, which is based on a particular
ontology (semantics). In the second phase we deal with sophisticated and user friendly visualization and browsing (querying) of the extracted knowledge. The whole system is proposed as a general framework which can be modified and extended for particular data domains. To depict its features we use the legislation domain."
"Korpus Merlin je žákovský korpus s psanými texty v čestině, němčině a italštině. Jeho cílem je ilustrovat úrovně CEFR autentickými daty.","The MERLIN corpus is a written learner corpus for Czech, German, and Italian that has been designed to illustrate the Common European Framework of Reference for Languages (CEFR) with authentic learner data. The corpus contains 2,290 learner texts produced in standardized language certiﬁcations covering CEFR levels A1–C1. The MERLIN annotation scheme includes a wide range of language characteristics that enable research into the empirical foundations of the CEFR scales and provide language teachers, test developers, and Second Language Acquisition researchers with concrete examples of learner performance and progress across multiple proﬁciency levels. For computational linguistics, it provide a range of authentic learner data for three target languages, supporting a broadening of the scope of research in areas such as automatic proﬁciency classiﬁcation or native language identiﬁcation. The annotated corpus and related information will be freely available as a corpus resource and through a freely accessible, didactically-oriented online platform."
"Článek představuje výsledky soutěže v automatickém hodnocení kvality strojového překladu (WMT14 Metrics Shared Task). Úkolem účastníků bylo vyhodnotit kvalitu překladových systémů, které se zúčastnily překladové úlohy WMT14. Získaných 23 metrik od 12 týmů jsme pak společně se 6 základními metrikami (BLEU, NIST, WER, PER, TER a CDER) porovnali z hlediska korelace s lidským hodnocením pro celý testset i pro jednotlivé věty.","This paper presents the results of the
WMT14 Metrics Shared Task. We asked
participants of this task to score the
outputs of the MT systems involved in
WMT14 Shared Translation Task. We col-
lected scores of 23 metrics from 12 re-
search groups. In addition to that we com-
puted scores of 6 standard metrics (BLEU,
NIST, WER, PER, TER and CDER) as
baselines. The collected scores were eval-
uated in terms of system level correlation
(how well each metric’s scores correlate
with WMT14 official manual ranking of
systems) and in terms of segment level
correlation (how often a metric agrees with
humans in comparing two translations of a
particular sentence)."
"V příspěvku jsme se zabývali jedním typem rozdílu v zachycení valenčních struktur v českém a anglickém valenčním slovníku a paralelním česko-anglickém syntakticky anotovaném korpusu. Syntakticky jde o konstrukce, které se projevují např. v tzv. alternaci subjektu a instrumentu (Instrument-Subject Alternation) (1), alternaci subjektu a abstraktní příčiny (Abstract Cause-Subject Alternation) (2) nebo alternaci subjektu a locata (Locatum Subject Alternation) (3) (Levin, 1993). Vzhledem k hloubkové valenci jde o dvojí možnou valenční strukturaci slovesa, přičemž vnější (non-core) argument přechází do pozice vnitřního (core) argumentu, a zároveň dochází k dekauzativizaci významu, tj. odsunutí původního aktora do pozadí situační perspektivy.","In the talk, we have dealt with one type of valency complementation mismatch in a paralel Czech-English dependency treebank, the so-called Instrument-Subject Alternation. In this type of transformation, the non-core argument takes the position of the core-argument, with the decausativisation of meaning."
"Tutoriál a vedení workshopu Emoce v jazyce, zaměřeného na zkoumání různých způsobů vyjadřování emocionality v psaném i v mluveném projevu.","Hands-on tutorial and supervision of ""Emotions in language"" workshop focused on different approaches to evaluation expression in both spoken and written language."
"V příspěvku se zabýváme syntaktickou a sémantickou analýzou slovesných hesel v českém slovníku subjektivních výrazů Czech Sublex 1.0. Zabýváme se jejich sémantickými a valenčními vlastnostmi v souvislosti s jejich subjektivním a hodnotícím charakterem. Ukazujeme, že hodnotící slovesa sdílejí určité abstraktní vzorce v nichž je zdroj a cíl evaluativního stavu mapován na valenční pozice. Podobnost sloves vzhledem k těmto vzorcům odpovídá podobnosti jejich sémantických vlastností.",In this paper we present a syntactic and semantic analysis of verbal entries in the Czech subjectivity lexicon Czech SubLex 1.0 concerning their semantic and valency properties with respect to the roots and degree of subjectivity and evaluativeness. We demonstrate that evaluative verbs share certain abstract syntactic patterns with valency positions encoding the position of the source and target of evaluative stance. These patterns then roughly correspond to semantic properties of the verbs.
"V příspěvku ukazujeme, jak syntakticky anotovaný korpus pomáhá při zkoumání aplikovatelnosti a revizích vyvinuté lingvistické teorie. Na materiálu Pražského česko-anglického závislostního koprusu zkoumáme případy, kdy se liší provázání valenčních doplnění v odpovídajících větách a hledáme důvody nekorespondence aktantových označení.","In this paper, we would like to exemplify how a syntactically annotated bilingual treebank can help us in exploring and revising a
developed linguistic theory. On the material of the Prague Czech-English Dependency Treebank we observe sentences in which an
Addressee argument in one language is linked translationally to a Patient argument in the other one, and make generalizations about
the theoretical grounds of the argument non-correspondences and its relations to the valency theory beyond the annotation practice.
Exploring verbs of three semantic classes (Judgement verbs, Teaching verbs and Attempt Suasion verbs) we claim that the Functional
Generative Description argument labelling is highly dependent on the morphosyntactic realization of the individual participants, which
then results in valency frame differences. Nevertheless, most of the differences can be overcome without substantial changes to the
linguistic theory itself."
"Článek popisuje pokus o vyřešení problému rozpoznávání klauzí a jejich vzájemných vztahů v českých souvětích na základě omezených informací, jmenovitě informací toliko získaných morfologickou analýzou. Metodu popsaná v tomto článku lze v budoucnu použít pro rozdělení procesu automatické syntaktické analýzy do dvou fází, a to 1) určení klauzí a jejich vzájemných vztahů a 2) syntaktická analýza jednotlivých klauzí. Tento přístup by měl zlepšit úspěšnost automatické syntaktické analýzy dlouhých souvětí.","This paper describes an attempt to solve the problem of recognizing clauses and their mutual relationship in complex Czech sentences on the basis of limited information, namely the information obtained by morphological analysis only. The method described in this paper may be used in the future for splitting the parsing process into two phases, namely 1) Recognizing clauses and their mutual relationships; and 2) Parsing the individual clauses. This approach should be able to improve the result of parsing long complex sentences."
"Poster je zaměřen na popis možností vyjadřování textových vztahů v češtině. Textové vztahy bývají vyjadřovány zejména diskurzními konektory, ale také jejich alternativními lexikálními vyjádřeními, jako např. ""důvodem je"".","The paper focuses on various possibilities of expressing textual relations in Czech. This possibility is held mainly by 
discourse connectives but also by their 
alternatives lexicalizations like ""the reason is""."
"Cílem prezentace bylo představit průzkum širších možností vyjadřování textových vztahů, resp.  představit, které jazykové prostředky (kromě ""klasických"" konektorů jako ""a"" nebo ""avšak"") mají schopnost signalizovat určitý vztah mezi dvěma jednotkami v textu.","The aim of the presentation was to examine broader possibilities of expressing textual 
relations, in other words which language means (apart from “classic” connectives like ""and"" or 
""however"") have an ability to signal certain relation between two units within a text."
Prezentace představila výsledky výzkumu diskurzních konektorů v širším smyslu založeném na korpusové analýze (s využitím Pražského závislostního korpusu a korpusu DIALOG).,The presentation described results of the research on discourse connectives in broader sense based on  corpus probe (Prague Dependency Treebank; corpus DIALOG).
"Článek se zabývá definicí diskurzních konektorů v obecné rovině. Věnuje se konektorům v širším smyslu, tj. všem jazykovým prostředkům, které mají schopnost  vyjadřovat diskurzní vztah v textu (např. spojkám jako ""ale"", ""a"", ""nebo"", ale i vyjádřením typu ""podmínkou pro to je"", ""kvůli této situaci"" ap.).","The paper tries to contribute to the general definition of discourse connectives. It examines connectives in broader sense, i.e. all language expressions that have an ability to express discourse relations within a text (e.g. both conjunctions like ""but"", ""and"", ""or"" and expressions like ""the condition for this is"", ""due to this situation"" etc.)."
"Článek představuje možnosti využití vícevrstvé anotace Pražského závislostního korpusu. Zaměřuje se přitom na překrývání koreferenčních vztahů a diskurzních vztahů vyjádřených víceslovnými konektory. Článek se snaží prozkoumat, jaké aspekty tyto dvě jazykové oblasti spojují a jakým způsobem můžeme toto vzájemné překrývání využít při automatickém vyhledávání konektivních spojení typu ""navzdory tomu"", ""díky této skutečnosti"", která mají v textu platnost víceslovných konektorů.","The paper introduces a possibility of new research offered by a multi-dimensional annotation of the Prague Dependency Treebank. It focuses on exploitation of the annotation of coreference for the annotation of discourse relations expressed by multiword expressions. It tries to find which as-pect interlinks these linguistic areas and how we can use this interplay in automatic searching for Czech expressions like ""despite this"" (""navzdory tomu""), ""because of this fact"" (""díky této skutečnosti"") functioning as multiword discourse markers."
"Současné přístupy ke statistickému strojovému překladu spoléhají na jednoduché rysy, které předpokládají nezávislost jednotlivých frází nebo pravidel SCFG. Přesto je obecně známo, že diskriminativní modely dokážou využít bohaté rysy extrahované z kontextu zdrojové věty mimo aktuální frázi nebo pravidlo. Tento kontext je během překladu dostupný. Představujeme framework pro open-source nástroj Moses, který umožňuje snadno trénovat a aplikovat diskriminativní modely zdrojového kontextu s využitím velkého počtu trénovacích příkladů.","Current state-of-the-art statistical machine translation (SMT) relies
on simple feature functions which make independence assumptions at the 
level of phrases or CFG rules. However, it is well-known that
discriminative models can benefit from rich features extracted from
the source sentence context outside of the applied phrase or CFG rule,
which is available at decoding time. We present a framework for the 
open-source decoder Moses that allows discriminative models over
source context to easily be trained on a large number of examples and 
then be included as feature functions in decoding."
"Představujeme naše systémy pro překlad angličtina→čeština a
angličtina→hindština, se kterými jsme se zúčastnili letošní překladové soutěže WMT. Pro směr
angličtina→čeština vycházíme z loňského systému CHIMERA a vyhodnocujeme několik nastavení.
Angličtina→hindština je letos novým jazykovým párem. Provedli jsme pokusy se zpětným
samoučením pro získání většího množství (umělých)
paralelních dat a s modelováním tvarosloví cílové strany.","We present our English→Czech and
English→Hindi submissions for this
year’s WMT translation task. For
English→Czech, we build upon last year’s
CHIMERA and evaluate several setups.
English→Hindi is a new language pair for
this year. We experimented with reverse
self-training to acquire more (synthetic)
parallel data and with modeling target-side
morphology."
Aktuálny stav infraštruktúry umožňujúcej Autorizáciu a Autentizáciu ukazuje odlišné vnímanie požiadavkov autormi a používateľmi. Predkladáme naše skúsenosti s vytvorením služby pre užívateľov z celého sveta.,Looking at the current state-of-the-art of the services and frameworks for Authentication and Authorization Infrastructure (AAI) reveals different visions and requirements by the creators and the potential users. We summarise our expectations and requirements together with our experience. The text is divided into blocks containing general guidelines and examples.
Prezentácie popisuje skúsenosti a rozhodnutia s vytvorením lingvistického repozitára.,The presentation describes our experience with building a sustainable linguistic repository built on DSpace
Použitie EUDAT B2SAFE replikácie z repozitára postavenom na DSpace vrátane implementácie,Description of EUDAT B2SAFE safe replication from a DSpace digital repository.
Přednáška představuje projekt anotace nadvětných vztahů v Pražském závislostním korpusu 3.0.,"The talk introduces the project of large-scale manual annotation of language phenomena ""beyond the sentence boundary"" in Czech. It was conducted as a part of the Prague Dependency Treebank version 3.0 project and released in 2013. It provides annotations for 50k sentences of Czech journalistic text, emphasizing (1) discourse connectives and their arguments and senses, (2), textual coreference, and (3), bridging (or associative) anaphora. Together with the linguistic information already annotated earlier on the same data (morphology, surface and deep syntax, information structure), this resource is particularly useful for linguistic and NLP tasks that combine features from various levels of language description."
"Tato studie je teoreticko-metodologickou
úvahou o tom, jak a do jaké míry je v současné době možné korpusově zpracovávat a značit jevy „nadvětné“, jevy textové lingvistiky.","The present contribution is a theoretical and methodological study of the possibilities of
discourse processing by corpus methods. Despite the description complexity of phenomena
“beyond the sentence boundary”, we argue that, keeping in mind all the specific issues this
task brings along, even more ways of a systematic analysis are possible. Taking into account
various attempts of the last decade in creating discourse-annotated corpora, a reliable way to
proceed in any such analysis shows to be to distinguish among different layers of discourse
analysis (in particular between “semantic” and “pragmatic” aspects) and to stick with the language
form in opposition to classifying phenomena with no surface realization."
Článek se zabývá klasifikací žánrů v Pražském závislostním korpusu a distribucemi diskurzních vztahů v jednotlivých typech žánrů v PDT.,"We present the project of classification of Prague Discourse Treebank documents (Czech journalistic texts) for their genres. Our main interest lies in opening the possibility to observe how text coherence is realized in different types (in the genre sense) of language data and, in the future, in exploring the ways of using genres as a feature for multi-sentence-level language technologies. In the paper, we first describe the motivation and the concept of the genre annotation, and briefly introduce the Prague Discourse Treebank. Then, we elaborate on the process of manual annotation of genres in the treebank, from the annotators' manual work to post-annotation checks and to the inter-annotator agreement measurements. The annotated genres are subsequently analyzed together with discourse relations (already annotated in the treebank) ― we present distributions of the annotated genres and results of studying distinctions of distributions of discourse relations across the individual genres."
"Článek popisuje metriku pro automatickou evaluaci strojového překladu, odeslanou jako řešení soutěžního úkolu WMT14 Metrics Task. Jedná se o jednoduchou modifikaci známého BLEU skóre, která používá párování slov v testovací a referenční větě v cílovém jazyce. Počítá se vždy nejmenší párování zhledem k relativní editační vzdáleností prefixů a sufixů slov. Spárovaná slova v testovací věty jsou nahrazena slovy z referenčního překladu. Při výpočtu n-gramové přestnoti jsou pak n-gramy obsahující taková slova penalizovány proporcionálně ke vzdálenosti, podlé které se slova párovala.","This paper describes a machine translation metric submitted to the WMT14 Metrics Task. It is a simple modification of the standard BLEU metric using a monolingual alignment of reference and test sentences. The alignment is computed as a minimum weighted maximum bipartite matching of the translated and the reference sentence words with respect to the relative edit distance of the word prefixes and suffixes. The aligned words are included in the n-gram precision computation with a penalty proportional to the matching distance. The proposed tBLEU metric is designed to be more tolerant to errors in inflection, which usually does not effect the understandability of a sentence, and therefore be more suitable for measuring quality of translation into morphologically richer languages."
"V článku popisujeme automatické generování česko-ruských valenčních rámců (formémů) na základě Vallexu, paralelního korpusu a slovníku.","This paper describes an experiment combining several existing data resources (parallel corpora, valency lexicon, morphological taggers, bilingual dictionary etc.) and exploiting
them in a task of building a valency lexicon for a related language (Russian) derived from a high quality manually created valency lexicon for Czech (Vallex) containing several thousands of verbs with very rich syntactic and semantic information. The experiment is restricted only to nominal constituents in both simple and prepositional cases. The results discussed
in the second half of the paper seem to justify the method used and to encourage further experiments in this direction. The paper also discusses most frequent sources of errors."
"Článek popisuje prototyp japonsko-českého strojového překladače založeného
na hloubkovém větném rozboru. Tento typ strojového překladu není v~současné
době ve srovnání s~jinými metodami tolik rozšířen, věříme však, že některé jeho
aspekty jsou schopny přispět k~celkově lepší kvalitě výstupu. Nutnou součástí
našeho úkolu je i získání a zpracování potřebných paralelních dat. Jelikož
japonsko-česká paralelní data nejsou prakticky vůbec dostupná, snažili jsme se
vyzkoušet různé postupy, které by nám pomohly tento nedostatek nahradit.
Náš systém je založen na stejném principu jako anglicko-český překladač TectoMT.
V~naší práci jsme se snažili zachytit alespoň základní jazykové jevy
charakteristické pro japonštinu. Náš hloubkový systém též porovnáváme se zavedeným frázovým
modelem překladu. Navzdory počátečním očekáváním pracuje frázový překlad lépe
i při relativním nedostatku paralelních dat.",The article describes a prototype of Japanese-Czech machine translation system based on deep syntactic analysis. A required preparation step includes the collection and processing of parallel data. We circumvent the lack of directly parallel data by machine-translating the English side of our collection of Japanese-English data into Czech.
"Potřeba dat o akvizici češtiny cizinci vedla k vytvoření prvního žákovského korpusu češtiny. Po představení jeho základního designu a parametrů, se zaměřujeme na technické aspekty: přepis ručně psaných textů, proces anotace a možnosti využití výsledků, spolu s nástroji používanými pro tyto úkoly.","The need for data about the acquisition of Czech by non-native learners prompted the compilation of the first learner corpus of Czech. After introducing its basic design and parameters, including a multi-tier manual annotation scheme and error taxonomy, we focus on the more technical aspects: transcription of hand-written source texts, process of annotation, and options for exploiting the result, together with tools used for these tasks and decisions behind the choices. To support or even substitute manual annotation we assign some error tags automatically and use automatic annotation tools (tagger, spell checker)."
"Kurz seznámí studenty s metodami zpracování morfologie přirozených jazyků. Začíná lingvistickým přehledem morfologie. Dále se zabývá korpusy, tagsety a anotací. Jádrem kurzu jsou supervised, unsupervised, a částečně supervised metody morfologické analýzy, morfologické segmentace, tvorba slovníků atd. Kurz zahrnuje jak standardní metody, tak diskuzi nedávných důležitých článků například Yarowsky & Wicentowski 2000, Creutz & Lagus 2007, Monson 2009 a Tepper & Xia 2010.","The course will introduce the students to the methods of processing morphology of natural languages. It starts with a linguistic overview of morphology, discussing features of a wide variety of languages including fusional languages such as German and Czech and agglutinative such as Turkish and Esperanto. After that, a discussion of corpora, tagsets and annotation will follow. The core of the course covers supervised, unsupervised and semi-supervised methods of morphological analysis, morpheme segmentation, lexicon creation, etc. The course covers standard and well established methods (two level morphology, Porter stemmer), but also includes discussion of recent important papers, for example, Yarowsky & Wicentowski 2000, Creutz and Lagus 2007, Monson 2009, and Tepper & Xia 2010."
Prezentace představila připravované zásady anotace aktuálního členění v anglické části Pražského česko-anglického závislostního korpusu.,The presentation demonstrated the upcoming principles of annotation of information structure in the English part of Prague Czech-English Dependency Treebank.
"Popis subjektivního slovosledu v češtině, okrajově v němčině a v angličtině.","Description of subjective word order in Czech, partly in German and in English."
Přednáška představila současné zásady a proces anotací aktuálního členění v Pražském česko-anglickém závislostním korpusu.,The lecture demonstrated current principles and process of annotation of topic-focus articulation in the Prague Czech-English Dependency Treebank.
Přednáška představila možnosti zkoumání slovosledu a aktuálního členění větného s pomocí anotovaného závislostního korpusu.,The lecture presented possibilities of exploring of word order and topic-focus articulation with help of  the annotated treebank.
"Přednáška popisovala výzkum kontextové zapojenosti na základě dat Pražského závislostního korpusu. Sledována byla například kontextová zapojenost závislých vět vs. větných členů vyjádřených nevětně, míra kontextové zapojenosti jednotlivých funktorů nebo lemmat.","The lecture described research on contextual boundness based on the data from the Prague Dependency Treebank. The contextual boundness of depencent clauses vs. sentence elements expressed as non-clauses, the degree of contextual boundness of individual functors or lemmas were monitored."
Prezentace představila zjištěné tendence v povrchovém slovosledu českých aktantů a volných slovesných doplnění v datech Pražského závislostního korpusu.,The presentation demonstrated the tendencies in the surface word order of Czech actants and free verbal modifications in data from Prague Dependency Treebank.
"Článek popisuje lingvistickou soutěž Olympiáda v českém jazyce - uvádí přehled soutěžních úkolů, jejich rozbor a komentář.","The paper describes a competition in linguistics the Olympiad in the Czech language - it provides an overview of the tasks, their analysis and comment."
"Představujeme naši práci o generování Karminy, staromalajské poetické formy indonéštiny. Karmina je báseň o dvou řádcích, kde první řádek obsahuje ""háček"" (sampiran) a druhá obsahuje poselství. Jedním z jedinečných rysů Karminy je chybějící diskursní vztah mezi háčkem a poselstvím. Proto generujeme háčky a poselství v oddělených procesech s využitím předdefinovaných schémat a ručně vybudované báze znalostí. Karminy byly vytvořeny náhodným párováním poselství s háčky při splnění podmínek na rýmy a strukturální podobnost.","We present our work in generating Karmina, an old Malay poetic form for Indonesian language. Karmina is a poem with two lines that consists of a hook (sampiran) on the first line and a message on the second line. One of the unique aspects of Karmina is in the absence of discourse relation between its hook and message. We approached the problem by generating the hooks and the messages in separate processes using predefined schemas and a manually built knowledge base. The Karminas were produced by randomly pairing the messages with the hooks, subject to the constraints imposed on the rhymes and on the structure similarity. Syllabifications were performed on the cue words of the hooks and messages to ensure the generated pairs have matching rhymes. We were able to generate a number of positive examples while still leaving room for improvement, particularly in the generation of the messages, which currently are still limited, and in filtering the negative results."
"Cílem workshopu bylo vytvořit prostor pro diskuzi o textových jevech a o využitelnosti jejich anotace v lingvistických aplikacích. Textovými jevy jsou např. aktuální členění, koreference, asociační anafora nebo mezivýpovědní významové vztahy.","The aim of this workshop was to trigger a discussion about textual phenomena and its usage in linguistic applications. Textual phenomena are topic focus articaluation, coreference, anaphora or discourse relations."
"Tento článek je zaměřen na popis hypotaktických
konstrukcí (konstrukce s podřadicí spojkou s ""elaborativními"" významy v češtině a angličtině.","This paper is focused on description of hypotactic
constructions (constructions with subordinating
conjunctions) with “elaborative” meanings. In dependency based linguistic literature,
they are referred to as hypotactic coordinations
or also (a subset of) false dependent clauses. The analysis makes use of syntax and discourse annotated corpora of Czech and English and thus offers an empirically grounded contrastive study of the phenomena."
"Cílem této studie je zjistit zda žákovský text ve flektivním jazyce jako je čeština obsahují příznaky, pomocí kterých lze identifikovat rodný jazyk autora.","The goal of this study is to investigate whether learners’ written data in highly inflectional Czech can suggest a consistent set of clues for automatic identification of the learners’ L1 background. For our experiments, we use texts written by learners of Czech, which have been  automatically and manually annotated for errors. We define two classes of learners: speakers of Indo-European languages and speakers of non-Indo-European languages. We use an SVM classifier to perform the binary classification. We show that non-content based features perform well on highly inflectional data. In particular, features reflecting errors in orthography are the most useful, yielding about 89% precision and the same recall. A detailed discussion of the best performing features is provided."
"Článek představuje SubLex 1.0, nový lexikální zdroj pro klasifikaci polarity v češtině. Slovník SubLex obsahuje 4947 hodnotících výrazů s příslušným slovním druhem a pozitivní nebo negativní polaritou. V článku popisujeme metodologii vytváření slovníku a kritéria pro jeho ruční čištění a případné další rozšiřování. Dále testujeme spolehlivost slovníku, a sice jeho implementací v rámci již existujících klasifikátorů.","This paper introduces Czech subjectivity lexicon – the new lexical resource for sentiment analysis in Czech. The lexicon is a dictionary of 4947 evaluative items annotated with part of speech and tagged with positive or negative polarity. We describe the method for building the basic vocabulary and the criteria for its manual refinement. Also, we suggest possible enrichment of the fundamental lexicon. We evaluate the current version of the dictionary by implementing it to the classifiers for automatic polarity detection and compare the results of both plain and supplemented system."
"Rozvoj Webu 2.0 přinesl množství textů generovaných samotnými uživateli Internetu. Jejich příspěvky nezřídka obsahují subjektivní názory, emoce, hodnocení… K čemu a jak můžeme tato data použít? Je možné emoce v textu spolehlivě automaticky třídit? Příspěvek z oblasti postojové analýzy představí metody a úspěchy automatické extrakce emocí z textu s důrazem na využití detailní lingvistické analýzy – a možná vyřeší i otázku, jak vybrat ten správný vejcovar.","The rise of Web 2.0 brought large quantity of texts generated by the Internet users themselves. Their contributions usually contain subjective opinions, emotions, reviews... How can we use this data? Is it possible to classify online emotions? The presentation from the area of sentiment analysis introduces methods and success rate of automatic emotion extraction with emphasis on linguistic analysis - and may also answer the question on how to buy the good egg boiler."
"V anonymizovaném prostředí internetových diskusí a sociálních sítí pravidelně dochází k verbálním výpadům, které nezřídka naplňují skutkovou podstatu trestného činu (např. hanobení rasy a národa nebo pomluvy). Pachatele kybernetických útoků lze jen obtížně dohledat a jejich činy proto často zůstávají nepotrestány. O řešení tohoto problému se v posledních letech pokouší evropská forenzní lingvistika s přispěním postojové analýzy, která se v nedávné době začala rozvíjet také v tuzemsku (viz např. Veselovská, 2012).

Postojová analýza se zabývá možnostmi extrakce subjektivní informace z textu a zkoumáním takovéto informace z jazykovědného hlediska (viz Liu, 2009). Jedním z hlavních cílů postojové analýzy je detekce hodnotících výrazů, tedy slov a frází, které inherentně obsahují pozitivní nebo negativní hodnocení (viz také Wiebe et al., 2004). Povaha a frekvence těchto výrazů (zejména pak těch s negativní polaritou), pro češtinu shromážděných ve slovníku SubLex1.0 (Veselovská a Bojar, 2013), může mít zásadní vliv na odhalení nesnášenlivého textu a při existenci i krátkých referenčních pasáží také jeho autora. Úspěšnost postupu roste zejména v kombinaci s analýzou funkčních slov, která určují gramatické vztahy v souvětích, a celkového projevu pisatele, jak dokazuje například výzkum Brennana et al. (2011).

V příspěvku budou představeny metody současné stylometrie (automatické identifikace autora na základě jím vyprodukovaného textu) a možnosti uplatnění postojové analýzy ve forenzní lingvistice, včetně včasného odhalování sebevražedných tendencí nejen na sociálních sítích (viz také Pestian et al., 2012) nebo ověřování pravdivosti výpovědí žadatelů o evropský azyl (Eades, 2009).","In this paper I will introduce methods employed in current stylometry (the automatic authorship identification) and possible use of sentiment analysis in forensic linguistics, including e.g. automatic detection of suicidial tendencies on social networks (see also Pestian et al., 2012)."
"Cílem workshopu je vytvořit prostor pro diskuzi o textových jevech a o využitelnosti jejich anotace v lingvistických aplikacích. Textovými jevy jsou např. aktuální členění, koreference, asociační anafora nebo mezivýpovědní významové vztahy.","The aim of this workshop is to trigger a discussion about textual phenomena and its usage in linguistic applications. Textual phenomena are topic focus articaluation, coreference, anaphora or discourse relations."
Prezentovaný výzkum měl za cíl vylepšit automatickou detekci a kontrolu správnosti zarovnání pleonastického it a jeho českých protějšků v Prague Czech-English Dependency Treebank (Hajič et al. 2011) na základě pravidel vypozorovaných porovnáváním české a anglické části paralelního korpusu InterCorp.,"The aim of presented contribution was to improve automatic detection and control of alignment of pleonastic it and its Czech counterparts in Prague Czech-English Dependency Treebank (Hajič et al., 2011) with the help of cs-en data from parallel corpus InterCorp."
"Český slovník hodnotících výrazů, tedy seznam hodnotících slov pro sentiment analysis v češtině. Seznam obsahuje 4626 hodnotících položek (1672 pozitivních a 2954 negativních) označkovaných morfologicky a s příslušnou orientací hodnocení.","Czech subjectivity lexicon, i.e. a list of subjectivity clues for sentiment analysis in Czech. The list contains 4626 evaluative items (1672 positive and 2954 negative) together with their part of speech tags, polarity orientation and source information."
"Slovníkový klasifikátor je z dlouhodobého hlediska jedním z nejvyužívanějších klasifikátorů v oblasti postojové analýzy. Přestože dosahuje relativně dobrých výsledků také pro češtinu, vykazuje tento klasifikátor jistou míru chybovosti. Článek nabízí detailní analýzu chyb v klasifikaci způsobených jak systémově, tak vinou recenzentů, a na základě této analýzy navrhuje další úpravy systému.","Lexicon-based classifier is in the long term one of the main and most effective methods of polarity classification used in sentiment analy-sis, i.e. computational study of opinions, sen-timents and emotions expressed in text (see Liu, 2010). Although it achieves relatively good results also for Czech, the classifier still shows some error rate. This paper provides a detailed analysis of such errors caused both by the system and by human reviewers. The identified errors are representatives of the chal-lenges faced by the entire area of opinion min-ing. Therefore, the analysis is essential for fur-ther research in the field and serves as a basis for meaningful improvements of the system."
Příspěvek je založen na první korpusové analýze vyjadřovacích prostředků českého evaluativního jazyka a je z velké části věnován modelování evaluativního významu v rámci konstrukčně-gramatického formalismu.,"This contribution presents the first corpus-based analysis of Czech evaluative language and the first steps towards a model of evaluative meaning in Czech.
For the current study, we have used three main sources of data:
•	the newly created Czech subjectivity lexicon SubLex 1.0 (see [2])
           containing 4950 unique evaluative lemmas tagged with positive 
	or negative polarity
•	the Czech National Corpus (see [1]).
•	the manually annotated evaluative data from three different domains 
           (news, movie reviews and kitchen appliances reviews)
	First, we will confront selected SubLex items with the evidence in Czech National Corpus and offer a complex linguistic analysis of the obtained evaluative sentences, observing especially lexical and morphological means of expressing evaluation in the text. However, since we are aware of the fact that evaluative items are subject to the interaction with context both at the sentence level, and in a larger text span (including e.g. the influence of negation or changes in aspect), we will briefly analyze the syntactic and semantic structure of the evaluative sentences. In addition, we will introduce and examine the most common Czech evaluative idioms. To put our general findings under a more specific scrutiny, we will then explore the use of evaluation in different domain-specific corpora of evaluative sentences.
	Finally, as a result of the above mentioned analysis, we will introduce the overview of generalized structures bearing evaluative meaning in Czech."
"Even though the quality of unsupervised
dependency parsers grows, they often fail
in recognition of very basic dependencies.
In this paper, we exploit a prior knowledge
of STOP-probabilities (whether a given
word has any children in a given direction), which is obtained from a large raw
corpus using the reducibility principle. By
incorporating this knowledge into Dependency Model with Valence, we managed to
considerably outperform the state-of-the-art results in terms of average attachment
score over 20 treebanks from CoNLL 2006
and 2007 shared tasks","Even though the quality of unsupervised
dependency parsers grows, they often fail
in recognition of very basic dependencies.
In this paper, we exploit a prior knowledge
of STOP-probabilities (whether a given
word has any children in a given direction), which is obtained from a large raw
corpus using the reducibility principle. By
incorporating this knowledge into Dependency Model with Valence, we managed to
considerably outperform the state-of-the-art results in terms of average attachment
score over 20 treebanks from CoNLL 2006
and 2007 shared tasks."
Tato technická zpráva se zabývá alternativními reprezentacemi koordinačních struktury a vlivem jednotlivých řešení na úspěšnost závislostního parsingu.,In this report we explore alternative representations of coordination structures within dependency trees and study the impact of particular solutions on performance of two selected state-of-the-art dependency parsers across a typologically diverse range of languages.
"Článek uvádí do problému generovaní přirozeného jazyka a podává krátké shrnutí nedávného vývoje tohoto oboru, přičemž se zaměřuje na využití statistických metod. Největší důraz je kladen na generování jazyka v hlasových dialogových systémech, ale ostatní oblasti využití jsou také zmíněny. Článek končí přehledem problémů, je nutné vyřešit při vývoji vícejazyčného generátoru jazyka pro hlasový dialogový systém.","We present an introduction to the problem of Natural Language Generation (NLG) an give a brief survey of recent advances in this field, focusing on the usage of statistical methods. Most stress is put on NLG within Spoken Dialogue Systems, but other usage areas are included as well. The paper concludes with an overview of problems posed by the development of a multilingual NLG system for a Spoken Dialogue System."
"Prezentujeme novou metodu statistického generování morfologie, tj. predikce konkrétní slovní formy z lemmatu, slovního druhu a morfologických kategorií, která cílí na robustnost vůči neznámým vstupům. Náš systém používá trénovatelný klasifikátor pro predici „editačních scénářů“, které posléze použije k transformaci lemmat na cílové slovní formy. Pro dosažení robustnosti jsou jako atributy pro klasifikaci použity také sufixy lemmat. Náš systém byl vyhodnocen na šesti jazycích s různým stupněm morfologické bohatosti. Výsledky ukazují, že systém je schopen se naučit většinu morfologických jevů a generalizuje na neznámé vstupy, takže dosahuje signifikatně lepších výsledků než baseline založený na slovníku.","We present a novel method of statistical morphological generation, i.e. the prediction  of  inflected  word  forms  given lemma, part-of-peech and morphological features, aimed at robustness to unseen inputs. Our system uses a trainable classifier to predict “edit scripts” that are then used to transform lemmas into inflected word forms. Suffixes of lemmas are included as features to achieve robustness.  We evaluate our system on 6 languages with a varying degree of morphological richness. The results show that the system is able to learn most morphological phenomena and generalize to unseen  inputs, producing significantly better results than a dictionary-based baseline."
"Příspěvek prezentuje experimenty strojového překladu
z angličtiny do češtiny s použitím
velkého množství ručně anotovaných textových konektorů.","The paper presents machine translation experiments
from English to Czech with a
large amount of manually annotated discourse
connectives. The gold-standard
discourse relation annotation leads to better
translation performance in ranges of
4–60% for some ambiguous English connectives
and helps to find correct syntactical
constructs in Czech for less ambiguous
connectives. Automatic scoring confirms
the stability of the newly built discourseaware
translation systems. Error analysis
and human translation evaluation point to
the cases where the annotation was most
and where less helpful."
"Článek představuje koncept korespondenčního semináře jakožto prostředku, jak doplnit a podpořit jednorázové soutěže, zejména olympiády. Vyhodnocujeme jednotlivé výhody tohoto způsobu výuky lingvistiky a porovnáváme jeho charakter s charakterem lingvistické olympiády. Věříme, že korespondenční seminář je výborný způsob, jak přivést talentované středoškolské studenty k lingvistice.","We present the concept of a correspondence seminar as a way to complement and support one-time contests, especially olympiads. We evaluate specific payoffs of this way of teaching linguistics, and compare its nature to that of a linguistics olympiad. We believe that the correspondence seminar is a great way to introduce talented high school students to linguistics."
"V této studii se zabýváme vztahy mezi užitími téhož slovesného lexému, které jsou charakterizovány změnou v přiřazení situačních participantů a povrchových syntaktických pozic; tyto vztahy označujeme jako alternace. Tato práce se soustředí na lexikalizované alternace, které jsou vyjádřeny prostředky lexikálně-sémantickými, tj. změnou lexikální jednotky slovesa. V češtině jsou lexikalizované alternace konverzní (tzv. lexikálně-sémantické konverze, např. naložit seno na vůz -- naložit vůz senem), nebo nekonerzní (tzv. různé strukturní vyjádření téhož participantu, např. vyjít na kopec -- vyjít kopec, a strukturní rozpad situačního participantu, např. rozpad tématu a dikta). V práci představujeme zachycení těchto vztahů ve valenčním lexikonu VALLEX.","In this paper, we study specific relations between uses of the same verb lexeme that stem from the changes in the linking of situational participants, valency complementations and surface syntactic positions – we refer to them as to alternations. The focus is on those types that are expressed by lexical-semantic means and result in changes in valency frames of verbs. 
We present and analyze three basic types of lexicalized alternations in Czech. They may be characterized as either conversive, or non-conversive. The conversive lexicalized alternations represent the central ones in the language system and here are referred to as (i) the lexical-semantic conversions (e.g., to load hay on the truck -- to load the truck with hay). On the other hand, the non-conversive alternations are rather peripheral; we can introduce esp. (ii) the different structural expression of a single situational participant (e.g., to climb up the hill - to climb the hill) and (iii) the structural splitting of a situational participant (e.g., theme-dictum splitting for Czech verbs of communication and mental action).
Further, we propose a formal framework that allows us to represent different types of lexicalized alternations in the valency lexicon of Czech verbs, VALLEX."
Příspěvek popisuje formální lexikografickou reprezentaci konstrukcí s tzv. lehkým slovesem. Informaci o daných konstrukcí rozdělujeme mezi valenční rámec lehkého slovesa a rámec predikativního jména. Povrchově syntaktickou realizaci (včetně morfematického vyjádření) valenčních doplnění lze snadno odvodit pomocí formálních syntaktických pravidel.,"Light verb constructions (LVCs) pose a serious
challenge for both theoretical and applied
linguistics as their syntactic structures
are not solely determined by verbs
alone but also by predicative nouns. In this
contribution, we introduce an initial step to
a new formal lexicographic representation
of LVCs for the valency lexicon of Czech
verbs, VALLEX.
The main idea underlying our representation
is to decompose the information on an
LVC between (i) the verbal valency frame
and (ii) the nominal valency frame. Both
deep and surface syntactic structures of
LVCs can be easily derived from the information
given in the verbal and nominal
frames by application of formal rules
as they are introduced in this contribution."
"Článek popisuje experiment identifikující analytické predikáty v českém textu. Prvním cílem experimentu bylo vytvoření seznamu českých sloves, které umožňují vazbu s predikativními substantivy; druhým cílem bylo ověřit stanovená kritéria pro určení, zda je daný výskyt slovesa analytickým, či plnovýznamovým predikátem.

Tři anotátoři paralelně anotovali stejné věty s vybranými slovesy podle stanovených kritérií. Mezianotátorská shoda měřená váženou kappou dosáhla hodnoty 0,686.

Výsledkem experimentu je 893 verbonominálních kombinací českých analytických predikátů s predikativními substantivy.","In this paper, we describe a corpus based experiment focused on the possibility of identifying Czech light verbs. The experiment had two main aims: (i) to establish the inventory of Czech light verbs entering into combinations with predicative nouns, and (ii) to verify the adopted criteria for distinguishing light usages from full usages of the given verbs. As for the inventory of light verbs, we propose and verify the hypothesis that the possibility of light usages of verbs is related to their semantic class membership rather than to their high frequency.

In the second part of the experiment, we exploited the compiled inventory of Czech verbs inclined to occur as light verbs. The criteria adopted for distinguishing light usages of a verb from its full ones were applied to selected corpus sentences with these verbs. Three annotators were asked to determine whether a verb occurrence in an extracted corpus sentence corresponds to the full or to the light usage of the given verb. The feasibility of this task has been proven by the achieved κw statistics 0.686 and by the interannotator agreement 85.3%.

As a result of this experiment, we obtained 893 verbonominal combinations of Czech light verbs and predicative nouns. These combinations will be further utilized for the lexicographic representation of these phenomena."
"Představujeme nový rozpoznávač pojmenovaných entit pro český jazyk, který dosahuje 82.82 F-measure na korpusu Czech Named Entity Corpus 1.0 a statisticky významně překonává dříve publikované české rozpoznávače pojmenovaných entit. Na anglické úloze CoNLL-2003 shared task dosahuje 89.16 F-measure. Tento výsledek je srovnatelný s anglickými současnými výsledky. Rozpoznávač je založen na maximum entropy markovském modelu a optimální sekvence pojmenovaných entit je dosaženo globálním dekódováním Viterbiho algoritmem pomocí pravděpodobností odhadnutých maximum entropy klasifikátorem. Klasifikátor využívá morfologickou analýzu, dvojúrovňovou predikci, clusterizaci slov a gazetteers.","We present a new named entity recognizer for the Czech language. It reaches 82.82 F-measure on the Czech Named Entity Corpus 1.0 and significantly outperforms previously published Czech named entity recognizers. On the English CoNLL-2003 shared task, we achieved 89.16 F-measure, reaching comparable results to the English state of the art. The recognizer is based on Maximum Entropy Markov Model and a Viterbi algorithm decodes an optimal sequence labeling using probabilities estimated by a maximum entropy classifier. The classification features utilize morphological analysis, two-stage prediction, word clustering and gazetteers."
Nová verze ručně anotovaného korpusu zaměřeného na pojmenované entity.,"A new version of the Czech corpus with manually annotated named entities, classified using a rich hierarchy of types."
"Závislostní syntaktické analyzátor jsou většinou vyhodnocovány pomocí podílu správně zavěšených hran, to ale nevypovídá přesně o závažnosti a důsledcích jednotlivých chyb pro reálné aplikace. V tomto článku popisujeme úspěšnost sedmi analyzátorů a tří jejich kombinací z hlediska jejich vlivu na kvalitu strojového překladu využívajícího hloubkovou syntax.","Dependency parsers are almost ubiqui-
tously evaluated on their accuracy scores,
these scores say nothing of the complex-
ity and usefulness of the resulting struc-
tures. The structures may have more com-
plexity due to their coordination structure
or attachment rules. As dependency parses
are basic structures in which other systems
are built upon, it would seem more reason-
able to judge these parsers down the NLP
pipeline.
We show results from 7 individual parsers,
including dependency and constituent
parsers, and 3 ensemble parsing tech-
niques with their overall effect on a Ma-
chine Translation system, Treex, for En-
glish to Czech translation. We show that
parsers’ UAS scores are more correlated
to the NIST evaluation metric than to the
BLEU Metric, however we see increases
in both metrics."
Závislostní anotace anglických vět z datové sady WMT 2012 (vzniklé pro Workshop in Machine Translation) je popsána v článku Improvements to Syntax-based Machine Translation using Ensemble Dependency Parsers presented at The Second Workshop on Hybrid Approaches to Translation (HyTra) at ACL 2013. Anotace byly provedeny podle pravidel analytické roviny Pražského závislostního korpusu.,"WMT annotations are described in the paper Improvements to Syntax-based Machine Translation using Ensemble Dependency Parsers presented at The Second Workshop on Hybrid Approaches to Translation (HyTra) at ACL 2013. The annotations are done on the analytically layer of the Czech to English Data set from the Workshop on Machine Translation 2012 data.

 

The main purpose of this data set is to give researchers gold level dependency annotations for a data set that contains a gold level translations. This should allow researchers to analyze dependency annotations effect on machine translation."
"Popisujeme naše pokusy s frázovým strojovým překladem pro společnou úlohu WMT 2013. Natrénovali jsme jeden systém pro 18 překladových směrů mezi angličtinou nebo češtinou na jedné straně a angličtinou, češtinou, němčinou, španělštinou, francouzštinou nebo ruštinou na straně druhé. Popisujeme sadu výsledků s různými velikostmi trénovacích dat. Pro páry obsahující ruštinu navíc popisujeme sadu nezávislých pokusů s lehce odlišnými překladovými modely.","We describe our experiments with phrase-based machine translation for the WMT 2013 Shared Task. We trained one system for 18 translation directions between English or Czech on one side and English, Czech, German, Spanish, French or Russian on the other side. We describe a set of results with different training data sizes and subsets. For the pairs containing Russian, we describe a set of independent experiments with slightly different
translation models."
Článek popisuje experimenty s přiřazováníém sémantických kategorií českým podstatným jménům pomocí metod strojového učení.,"In this paper we experiment with supervised machine learning techniques for the task of assigning semantic categories to nouns in Czech. The experiments work with 16 semantic categories  based on available manually annotated data.  The paper compares two possible approaches - one based on the contextual information,  the other based upon morphological properties  - we are trying to automatically extract final segments  of lemmas which might carry semantic information. The central problem of this research is finding the features for machine learning  that produce better results for relatively small training data size."
"Vyhľadávanie relevantných webových stránok a využívanie odkazov na relevantný obsah je rozšírený a efektívny prístup k vyhľadávaniu informácií. Existujúce práce, ktoré sa zaoberajú vyhľadávaním informácií v multimédiách sú však zamerané buď na vyhľadávanie jednotlivých relevantných položiek alebo na prepájanie obsahu bez toho aby sa zaoberali vyhľadávaním. V našej práci popisujeme prepojenie multimodálneho vyhľadávania a následné prepojenie multimediálnych dát. Experimenty sú založené na Search and Hyperlinking tasku organizovanom v rámci MediaEval 2012 Benchmarku.","Searching for relevant webpages and following hyperlinks to related content is a widely accepted and effective approach to information seeking on the textual web. Existing work on multimedia information retrieval has focused on search for individual relevant items or on content linking without specific attention to search results. We describe our research exploring integrated multimodal search and hyperlinking for multimedia data. Our investigation is based on the MediaEval 2012 Search and Hyperlinking task. This includes a known-item search task using the Blip10000 internet video collection, where automatically created hyperlinks link each relevant item to related items within the collection. The search test queries and link assessment for this task was generated using the Amazon Mechanical Turk crowdsourcing platform. Our investigation examines a range of alternative methods which seek to address the challenges of search and hyperlinking using multimodal approaches. The results of our experiments are used to propose a research agenda for developing effective techniques for search and hyperlinking of multimedia content."
"Dôležitosť vyhľadávania v audio-vizuálnych nahrávkach kvôli prudko rastúcemu počtu audio-vizuálnych nahrávok dostupných on-line v súčasnosti stúpa. V porovnaní s tradičným IR metódami vyžaduje táto úloha špeciálne techniky ako je napríklad passage retrieval, ktorý môže urýchliť celý proces vyhľadávania tak, že je vyhľadaný presný relevantný úsek nahrávky namiesto celého dokumentu. Pri využití passage retrievalu sú nahrávky rozdelené na kratšie segmenty. V tejto práci porovnávame dva prístupy využité v passage retrieval: segmentáciu na prekrývajúce sa úseky rovnakej dĺžky a segmentáciu na rôzne dlhé úseky na základe sémantiky.","The importance of Information Retrieval (IR) in audio-visual recordings has been increasing with steeply growing numbers of audio-visual documents available on-line. Compared to traditional IR methods, this task requires specific techniques, such as Passage Retrieval which can accelerate the search process by retrieving the exact relevant passage of a recording instead of the full document. In Passage Retrieval, full recordings are divided into shorter segments which serve as individual documents for the further IR setup. This technique also allows normalizing document length and applying positional information. It was shown that it can even improve retrieval results.

In this work, we examine two general strategies for Passage Retrieval: blind segmentation into overlapping regular-length passages and segmentation into variable-length passages based on semantics of their content.

Time-based segmentation was already shown to improve retrieval of textual documents and  audio-visual recordings. Our experiments performed on the test collection used in the Search subtask of the Search and Hyperlinking Task in MediaEval Benchmarking 2012 confirm those findings and show that parameters (segment length and shift) tuning for a specific test collection can further improve the results. Our best results on this collection were achieved by using 45-second long segments with 15-second shifts.

Semantic-based segmentation can be divided into three types: similarity-based (producing segments with high intra-similarity and low inter-similarity), lexical-chain-based (producing segments with frequent lexically connected words), and feature-based (combining various features which signalize a segment break in a machine-learning setting). In this work, we mainly focus on feature-based segmentation which allows exploiting various features from all modalities of the data (including segment length) in a single trainable model and produces segments which can eventually overlap.

Our preliminary results show that even simple semantic-based segmentation outperforms regular segmentation. Our model is a decision tree incorporating the following features: shot segments, output of TextTiling algorithm, cue words (well, thanks, so, I, now), sentence breaks, and the length of the silence after the previous word. In terms of the MASP measure, the relative improvement over regular segmentation is more than 19%."
"V článku popisujeme prístup, ktorý sme použili v
Search Subtasku v úlohe Search and Hyperlinking vrácmi Benchmarku MediaEval 2013. Popisujeme rôzne prístupy k segmentácii nahrávok na menšie úseky, ktoré sú potom využité pri štandardnom vyhľadávaní. Na segmentáciu používame rozdelenie na krátke úseky rovnakej dĺžky a tiež metódy strojového učenia, založené na našom riešení použitom v úlohe Similar Segments in Social Speech.","We describe our approach to the Search Subtask of the Search and Hyperlinking Task at MediaEval 2013. We experiment with various methods for segmentation of the recordings into shorter segments which are then used in a standard
retrieval setup to search for relevant passages. We use regular segmentation into equilong segments and experiment with machine-learning based segmentation expanding our approach to Similar Segments in Social Spech Task."
"V článku popisujeme naše experimenty vrámci úlohy Similar Segments in Social Speech v Benchmarku MediaEval 2013. Zameriavame sa najmä na segmentáciu nahrávok na kratšie úseky, na ktoré aplikujeme štandardné metódy vyhľadávania. Ďalej popisujeme naše pokusy so segmentáciou založenou na technikách strojového učenia, pričom využívame textové (n-gramy slov, n-gramy tagov, veľké písmená, lexikálnu konzistentnosť, ...) a prozodické vlastnosti (dĺžka ticha).","We describe our experiments for the Similar Segments in Social Speech Task at MediaEval 2013 Benchmark. We mainly focus on segmentation of the recordings into shorter passages on which we apply standard retrieval techniques. We experiment with machine-learning-based segmentation employing textual (word n-grams, tag n-grams, letter cases, lexical cohesion, etc.) and prosodic features (silence) and compare the results with those obtained by regular segmentation."
"V práci popisujeme dva anglicko-české prekladové systémy, ktoré boli odoslané do WMT 2013 shared tasku: TectoMT a PhraseFix. TectoMT je systém založený na syntaktickom preklade, PhraseFix používa štatistickú posteditáciu (SPE), ktorá je aplikovaná na výstup systému TectoMT. V krátkom prehľade porovnáme SPE a ďalšie techniky kombinácie prekladových systémov - použijeme dáta, ktoré vznikli prekladom pomocou systému TectoMT, aby sme natrénovali štatistický prekladový systém (SMT). V práci ďalej potvrdíme hypotézu, že PhraseFix (SPE) zlepšuje výsledky TectoMT, zároveň však ukážeme, ze pridanie trénovacích dát do SMT je napriek tomu stále efektívnejšie.","We present two English-to-Czech systems that took part in the WMT 2013 shared task: TectoMT and PhraseFix. The former is a deep-syntactic transfer-based system, the latter is a more-or-less standard statistical post-editing (SPE) applied on top of TectoMT. In a brief survey, we put SPE in context with other system combination techniques and evaluate SPE vs. another simple system combination technique: using synthetic parallel data from TectoMT to train a statistical MT system (SMT). We confirm that PhraseFix (SPE) improves the output of TectoMT, and we use this to analyze errors in TectoMT. However, we also show that extending data for SMT is more effective."
"Rozhovor pro anglické vysílání Radia Praha o strojovém překladu a nové knížce, která jej přibližuje českému čtenáři.",An interview on machine translation and a new book that introduces the field to the Czech reader.
"Archiv Hlasy uprchlíků (Refugee Voices) je sbírkou svědectví o holocaustu obsahující 150 filmových interview s židovskými přeživšími a uprchlíky před nacismem, kteří začali nový život ve Velké Británii. Archiv byl vytvořen Asociací židovských uprchlíků (Association of Jewish Refugees – AJR) v letech 2003–2007. Projekt vedli Dr. Anthony Grenville a Dr. Bea Lewkowicz. Kompletní archiv a přidružené databáze jsou od února 2013 dostupné v CVH Malach. Sbírka sestává z více než 450 hodin filmového materiálu a je neocenitelným zdrojem pro akademiky, výzkumníky, vzdělávací pracovníky a další zájemce o studium migrace nebo holocaustu. Archiv byl od samého počátku vytvářen s ohledem na potřeby a požadavky akademiků a dalších profesionálů. Všechny rozhovory jsou katalogizovány a v plném rozsahu přepsány. Aby bylo umožněno snadné odkazování na konkrétní pasáže interview, jsou přepisy i nahrávky opatřeny časovým kódem, díky čemuž je možné s minimálním úsilím najít specifické úseky rozhovorů. Součástí archivu je rozsáhlá databáze obsahující seznam rozhovorů s podrobnostmi o narátorech a jejich životních příbězích. Interview byla katalogizována prostřednictvím 44 samostatných kategorií.","Refugee Voices is a groundbreaking Holocaust testimony collection of 150 filmed interviews with Jewish survivors and refugees from Nazism who rebuilt their lives in Great Britain. It was commissioned by the Association of Jewish Refugees (AJR), with Dr Anthony Grenville and Dr Bea Lewkowicz directing the project. The archive is available at the Malach Centre since February 2013. The collection consists of more than 450 hours of film and forms an invaluable resource for academics, researchers, educationalists and others with a professional interest in the field of refugee, migration and Holocaust studies. The collection has been designed precisely with the requirements of scholars and other professionals in mind. All interviews have been fully transcribed and catalogued enabling a researcher to be able to see an interview and then to read a transcript of the words spoken in it, or vice versa. For ease of reference, both the films and the transcripts are time-coded, making it possible to locate specific passages with a minimum of effort. Accompanying the collection is a comprehensive database, containing an index of the interviews and details of the interviewees and their life stories. The interviews have been catalogued with 44 separate categories."
"Archiv vizuální historie USC Shoah Foundation (VHA) obsahuje více než 52 000 interview s přeživšími a svědky holocaustu. Vzhledem k povaze dat je archiv využíván nejen v historickém bádání, ale také dalších oborech jako je ekonomie, právo, medicína, literatura, antropologie či sociologie. V příspěvku reflektuji svou uživatelskou zkušenost s archivním rozhraním v rámci probíhajícího sociologického výzkumu, jenž tvoří součást mé disertační práce. Ukazuji, že stávající uživatelské rozhraní VHA lze sice pro podobné účely efektivně využít, ale zároveň před badatele klade různé problémy a překážky.","USC Shoah Foundation's Visual History Archive (VHA) contains almost 52,000 interviews with Holocaust survivors and witnesses. Although the interviews are focused mostly on the World War II era, they were conducted as the narrators' complete life stories. VHA can therefore be effectively used in different scientific fields apart from historiography, e.g. economics, law, medicine, literature, anthropology or sociology. I will reflect on my user experience with the VHA during the ongoing sociological research, which is a crucial part of my dissertation thesis. On one hand, it is clear that the VHA user interface already provides very effective facilities for the identification and analysis of the relevant interviews and segments. On the other hand, however, there are still some serious technical limitations for this kind of research practice."
"Zpráva ze slavnostního setkání ke 3. výročí založení CVH Malach, které se konalo 28. ledna 2013.",Report from the third annual meeting of the Malach Centre for Visual History.
"Valenční lexikony typicky zachycují pouze bezpříznakové užití slovesa (aktivum), zatímco přirozený jazyk umožňuje řadu pravidelných změn v počtu, typu a/nebo povrchové formě valenčních doplnění (např. při pasivizaci).
Vzhledem k jejich pravidelnosti je výhodné tyto změny zachytit v pravidlové komponentě slovníku.
Jednotlivé změny typicky nacházíme u některých, ale ne u všech slovníkových jednotek (rámců), a proto je nutné u každého rámce uvést, která pravidla na něj lze aplikovat.
Ve článku popisujeme třífázový přístup k určení, které diateze lze aplikovat na daný slovesný význam.","The valency behavior (argument structure) of lexical items  is so varied that it cannot be described by general rules and must be captured in lexicons separately for each lexical item.
For verbs, lexicons typically describe only unmarked usage (the active form), while natural languages allow for certain regular changes in the number, type and/or realization of complementations (e.g. passivization).
Thanks to their regularity, such changes may be described in a separate rule component of the lexicon;
however, they are typically seen in many but not all verbs and their applicability to a given lexical unit (verb meaning) is not predictable from its valency alone.
In this paper, we describe our initial experiments with using a large morphologically annotated corpus of Czech for determining which diatheses are applicable to a given lexical unit."
"Korpus Merlin je žákovský korpus s psanými texty v čestině, němčině a italštině. Jeho cílem je ilustrovat úrovně CEFR autentickými daty. Článek popisuje metodologii tvorby korpusu (sběr dat, transkripci, anotaci, ověření kvality, atd.), možnosti jeho použití při validaci CEFR.","Since its publication in 2001, the Common European Framework of Reference for Languages (CEFR) has gained a leading role as an instrument of reference for language teaching and certification. Nonetheless, there is a growing concern about CEFR levels being insufficiently illustrated in terms of authentic learner data. Such concern grows even stronger when considering languages other than English (cf., e.g., Hulstijn 2007, North 2000). In this paper, we present the MERLIN project that addresses this need by illustrating and validating the CEFR levels for Czech, German, and Italian. To achieve its goal, we are developing a didactically motivated online platform to enable CEFR users to explore authentic written learner productions that have been related in a methodologically sophisticated and rigorous way to the CEFR levels. By making a significant number of learner productions freely accessible and easily searchable in a form that is richly annotated with linguistic characteristics and learner error types, the platform will assist teachers, learners, test developers, textbook authors, teacher trainers, and educational policy makers in developing a more comprehensive conceptualization of CEFR levels based on authentic learner data. 

In the first, methodology-oriented part of this paper, we explain how the learner textual data were collected, re-rated, transcribed, double-checked and prepared for additional manual and automatic processing. We then illustrate the indicators we built to analyze L2 productions. Indicators were derived through (a) linguistic analyses of the performance samples, (b) the operationalization of the CEFR scale descriptors, (c) the study of relevant literature on SLA and language testing, (d) textbook analyses and (e) a questionnaire study. This study allowed us to devise a harmonized annotation schema taking into account both common and language-specific features (e.g., gender/article in German, reflexive possessive pronouns in Czech, pronoun particles in Italian).

In the second, application-oriented part, we explain how, by offering a large corpus of freely accessible empirical material, the project helps provide a fine-grained characterization of the CEFR levels and how it serves language teaching and learning. MERLIN thereby aims at responding to the suggestions of the Council of Europe itself, which solicits the development of supplementary tools for illustrating the CEFR levels (http://purl.org/net/CEFR-Goullier.doc). Furthermore, we explain how the platform enables the targeted users to retrieve authentic information about the relationship of the CEFR levels to a wide spectrum of well-defined, user-need-oriented L2 challenges. MERLIN users, such as teacher or learners, can thus compare their students’ or their own performances and get a clearer picture of their strengths and weaknesses. 

In the third, research-oriented part, we situate MERLIN with regards to two current topics in Second Language Acquisition: validation of CEFR scales and natural language processing for learner language"
Projekt Khresmoi vyvýjí multilinguální a multimodální vyhledávací a přístupový systém pro medicínské a zdravotní informace a dokumenty.,"The Khresmoi project is developing a multilingual multimodal search and access system for medical and health information and documents. This scientific demonstration presents the current state of the Khresmoi integrated system, which includes components for text and image annotation, semantic search, search by image similarity and machine translation. The flexibility in adapting the system to varying requirements for different types of medical information search is demonstrated through two instantiations of the system, one aimed at medical professionals in general and the second aimed at radiologists. The key innovations of the Khresmoi system are the integration of multiple software components in a flexible scalable medical search system, the use of annotation cycles including manual correction to improve semantic search, and the possibility to do large scale visual similarity search on 2D and 3D (CT, MR) medical images."
"V dnešní době stoupá zájem a potřeba inovativních řešení pro medicínské vyhledávání. V tomto článku představujeme systém Khresmoi pro medicínské vyhledávání a získávání informací, podporovaný Evropskou unií, na kterém se podílí dvanáct partnerů a který je momentálně ve třetím roce vývoje ze čtyř. Systém Khresmoi používá architekturu založenou na komponentách a provozovanou v cloudu, tak aby umožňovala vývoj několika inovativních aplikací, uspokojujících medicínské informační potřeby cílových uživatelů. Vyhledávací systémy Khresmoi založené na této architektuře byly navrženy tak, aby podporovaly vícejazyčné a víceúčelové informační potřeby tří cílových skupin: všeobecné veřejnosti, praktických lékařů a radiologů. V tomto článku se zaměřujeme na představení systémů pro praktické lékaře a radiology s využitím sémantického vyhledávání, vícejazyčného textového vyhledávání a vyhledávání založeného na obrázcích (zahrnujícího 2D a 3D radiologické obrázky).","There is increasing interest in and need for innovative solutions to medical search. In this paper we present the EU-funded Khresmoi medical search and access system, currently in year 3 of 4 of development across 12 partners. The Khresmoi system uses a component-based architecture housed in the cloud to allow for the development of several innovative applications to support target users' medical information needs. The Khresmoi search systems based on this architecture have been designed to support the multilingual and multimodal information needs of three target groups: the general public, general practitioners and consultant radiologists. In this paper we focus on the presentation of the systems to support the latter two groups using semantic, multilingual text and image-based (including 2D and 3D radiology images) search."
"V tomto článku se analyzují problémy anotace generických jmenných frází ve velkém jazykovém  korpusu. Podává se přehled existujících teorií referencí generických NP, tyto teorie se pak srovnávají s přístupy k generickým NP v aplikačních projektech a se situací v anotací koreference v různých korpusech. Po představení anotace generických NP v Pražském závoslostním korpusu se rozebírají typické problematické situace a obecné potíže a nabízí se některá řešení vylepšující kvalitu anotace.","This paper discusses the problem of annotation
of  coreference  relations  with  generic 
expressions in a large scale corpus. We present 
and  analyze  some  existing  theories  of 
genericity,  compare  them  to  the  approaches  to generics  that  are  used  in  the  state-of-the-art coreference  annotation  guidelines  and  discuss how  coreference  of  generic  expressions  is processed  in  the  manual  annotation  of  the Prague  Dependency  Treebank.  After  analyzing some  typical  problematic  issues  we  propose some  partial  solutions  that  can  be  used  to enhance  the  quality  and  consistency  of  the annotation"
Představujeme výsledky anotace koreference a asociační anafory v Pražském závislostním korpusu 2.0. Anotace byla provedena na závislostních stromech tektogramatické roviny. Popisujeme měření mezianotátorksé shody a klasifikujeme a analyzujeme nejčastější typy anotátorské neshody. Na dvou vybraných delších textech jsme požádali anotátory o značení jistoty jejich rozhodnutí; tuto jistotu porovnáváme s výsledky měření mezianotátorské shody.,"We present the results of the coreference and bridging annotation in the Prague Dependency Treebank 2.0. The annotation is carried out on dependency trees (on the tectogrammatical layer). We describe the inter-annotator agreement measurement, classify and analyse the most common types of annotators’ disagreement. On two selected long texts,  we asked the annotators to mark the degree of certainty they have in some most problematic points; we compare the results to the inter-annotator agreement measurement."
"Zkoumáme výhody závislostních stromů a tektogramatických struktur použitých v Pražském závislostním korpusu pro anotaci jazykových jevů překračujících hranici věty, jmenovitě koreference a asociační anafory. Uvádíme výhody závislostních stromů jako podrobné zpracování elips, syntaktické řešení koordinace a apozice umožňující značkování koreference v případech, které jsou přímo na textu složitější.","We explore the benefits of dependency trees and tectogrammatical structure used in the Prague Dependency Treebank for annotating language phenomena that cross the sentence boundary, namely coreference and bridging relations. We present the benefits of dependency trees such as the detailed processing of ellipses, syntactic decisions for coordination and apposition structures that make possible coding coreference relations in cases that are not so easy when annotating on the raw texts."
"Představujeme ukončený projekt anotace koreference a asociační anafory na Pražském závislostním korpusu. Korpus obsahuje ruční anotace textové  koreference včetně koreference jmenných frází a tzv. bridging anafory, to vše na 50k větách korpusu. Také podáváme stručný popis automatických experimentů na těchto datech.","The paper presents an overview of a finished project focused on annotation of grammatical, pronominal and extended nominal coreference and 
bridging relations in the Prague Dependency Treebank (PDT 2.0). We give an overview of existing similar projects and their interests and compare them with our project. We describe the annotation scheme and the typology of coreferential and bridging relations and give the statistics of these types in the annotated corpus. Further we give the final results of the interannotator agreement with some explanations. We also briefly present the anaphora resolution experiments trained on the coreferentially annotated corpus and the future plans."
Standardní metrika pro hodnocení strojového překladu BLEU nebere v úvahu synonymii mezi referenční větou a překladem. Tuto nevýhodu zkoušíme zmírnit cíleným parafrázováním referenční věty. Nově vzniklá věta by si tak zachovává význam a správnost původní referenční věty a současně je bližší strojovému překladu.,"In this paper, we discuss the possibility of making the automatic evaluation of machine translation (MT) more accurate by targeted paraphrasing. The most common automatic metric for MT evaluation BLEU disregards synonymous phrases and word order variants. One way how to alleviate this drawback is to transform the reference translation into a one that is closer to the MT output and keeps its original meaning. We start with a basic algorithm for lexical substitution and discuss extending the process with word order changes and grammar checking."
"Toto je vydání PyKaldi pro rok 2013 - verze 1.0.

Tento kód obsahuje modifikace gmm-lat-gen-faster dekodéru, které umožňují jeho použití v úloze rozpoznávání mluvené řeči v reálném čase. Změny jsou založeny na povrchové modifikaci původního kódu pomocí dědění z původního dekodéru a přidání online zpracování vstupu včetně LDA+MLLT transformací.

Navíc, tento kód obsahuje Python knihovnu takže samotný dekodér může být použit z libovolného programu napsaného v Python programovacím jazyku.","This is the PyKaldi - release 2013.

This code include modification of the gmm-lat-gen-faster decoder so that it can be used for online decoding. The modification based on a light weight modification to the original code by subclassing the main decoder class and adding online processing of input, including LDA+MLLT transforamtions.

In addtition, this code includes a Python wrapper so that the decoder can be used from any python application."
"Tento článek se zabývá neřízenou metodu pro morfologické značkování, založené na projekci morfologické informace v paralelních datech a konstrukci prediktivního modelu pro optimální výběr zdrojového jazyka.","Bilingual corpora offer a promising bridge between resource-rich and resource-poor languages, enabling the development of natural language processing systems for the latter. English is often selected as the resource-rich language, but another choice might give better performance. In this paper, we consider the task of unsupervised cross-lingual POS tagging, and construct a model that predicts the best source language for a given target language. In experiments on 9 languages, this model improves on using a single fixed source language. We then show that further improvements can be made by combining information from multiple source languages."
"Tento článek popisuje neřízenou metodu pro morfologické značkování založenou na projekci značek v bilinguálním paralelním korpusu. Ve srovnání s existujícími metodami je tato metoda jednodušší a rychlejší, vybírá spolehlivější trénovací příklady využívá tzv. selftraining.","We present an unsupervised approach to part-of-speech tagging based on projections of tags in a word-aligned bilingual parallel corpus. In contrast to the existing state-of-the-art approach of Das and Petrov, we have developed a substantially simpler method by automatically identifying “good” training sentences from the parallel corpus and applying self-training. In experimental results on eight languages, our method achieves state-of-the-art results."
Popularizační přednáška o počítačové lingvistice a strojovém překladu na tzv. Science Café v Kladně.,A popularizing talk on computational linguistics and machine translation given at Science Café in Kladno.
"Seznámení zájemců o studium informatiky s naším překladovým systémem, který v soutěži při překladu do češtiny dopadl lépe než Google Translate.",A brief description of our machine translation system that performed better than Google Translate in an English-to-Czech translation task.
Stručné seznámení účastníků Semináře TMC pořádaného CESNETem s výzkumem na naší katedře s důrazem na potenciální styčné body pro budoucí spolupráce.,"A brief introduction to UFAL research presented at the seminar TMC organized by CESNET, with the focus on possible shared interests and future collaboration."
"Článek popisuje naše příspěvky na WMT, systémy CU-BOJAR a CU-DEPFIX, později nazvaný ""chiméra"", protože kombinuje tři rozdílné přístupy: TectoMT, systém s transferem na úrovni hloubkové syntaxe, faktorový frázový překlad pomocí nástroje Moses, a konečně automatický pravidlový korektor častých gramatických a významových chyb. Nepoužíváme žádnou standardní metodu systémové kombinace.","This paper describes our WMT submissions CU-BOJAR and CU-DEPFIX, the latter
dubbed ""chimera"" because it combines on three diverse approaches: TectoMT, a system
with transfer at the deep syntactic level of representation, factored
phrase-based translation using Moses, and finally automatic rule-based correction
of frequent grammatical and meaning errors.
We do not use any off-the-shelf system-combination method."
"Představujeme výsledky společných úloh z workshopu WMT: strojový překlad a odhad kvality překladu. Úloha metrik strojového překladu je prezentována v samostatném článku.
Letos se překladové soutěže účastnilo 143 systémů z celkem 23 institucí. Dalších 6 anonymních systémů jsme do hodnocení přidali sami. Ruční i automatické hodnocení výstupů bylo provedeno v dosud největším rozsahu. Úloha odhadu kvality překladu měla čtyři části a celkem se jí účastnilo 55 příspěvků od 14 týmů.","We present the results of the WMT13 shared tasks, which included a translation task, a task for run-time estimation of machine translation quality, and an unofficial metrics task. This year, 143 machine translation systems were submitted to the ten translation tasks from 23 institutions. An additional 6 anonymized systems were included, and were then evaluated both automatically and manually, in our largest manual evaluation to date. The quality estimation task had four subtasks, with a total of 14 teams, submitting 55 entries."
"Jedna z hlavních obtíží při automatickém vyhodnocování strojového překladu je závislost na několika (typicky na jediném) lidských referenčních překladech, se kterými se výstup překladového systému srovnává. Navrhujeme metodu, jak zachytit milióny možných překladů, a implementujeme nástroj, s jehož pomocí mohou překladatelé takové překlady popsat v kompaktní reprezentaci. Vyhodnocujeme takto vzniklou novou referenční sadu s použitím editační vzdálenosti a korelace s lidským hodnocením kvality překladu.",One of the key obstacles in automatic evaluation of machine translation systems is the reliance on a few (typically just one) human-made reference translations to which the system output is compared. We propose a method of capturing millions of possible translations and implement a tool for translators to specify them using a compact representation. We evaluate this new type of reference set by edit distance and correlation to human judgements of translation quality.
"Představujeme emana, nástroj pro správu velkého množství výpočetních experimentů. V průběhu let našeho výzkumu strojového překladu (MT) jsme sesbírali několik nápadů pro efektivní experimentování. Věříme, že tyto nápady jsou obecně použitelné v (počítačovém) výzkumu v libovolném oboru. Zahrnuli jsme je do emana, aby byly dostupné v prostředí příkazové řádky Unixu. Cílem článku je zvýraznit hlavní myšlenky v pozadí těchto nápadů. Doufáme, že text bude sloužit jako sbírka tipů pro správu experimentů pro každého, nezávisle na konkrétním oboru nebo počítačové platformě. Konkrétní příklady, které ukazujeme v současné syntaxi nástroje eman, jsou méně důležité, ale umožňují užití konkrétních termínů. Článek tedy zároveň vyplňuje mezeru v dokumentaci emana tím, že podává abstraktnější pohled na tento nástroj.","We present eman, a tool for managing large numbers of computational experiments. Over
the years of our research in machine translation (MT), we have collected a couple of ideas for
efficient experimenting. We believe these ideas are generally applicable in (computational)
research of any field. We incorporated them into eman in order to make them available in a
command-line Unix environment.
The aim of this article is to highlight the core of the many ideas. We hope the text can serve
as a collection of experiment management tips and tricks for anyone, regardless their field of
study or computer platform they use. The specific examples we provide in eman’s current syntax
are less important but they allow us to use concrete terms. The article thus also fills the gap in eman documentation by providing some high-level overview."
"Spojená morfologická a syntaktická analýza pro jazyky s bohatou flexí je založena na datech pro několik slovanských jazyků a finštinu, a porovnána s angličtinou.","Joint morphological and syntactic analysis has been proposed as a way of improving parsing accuracy for richly inflected languages. Starting from a transition-based model for joint part-of-speech tagging and dependency parsing, we explore different ways of integrating morphological  features into the model. We also investigate the use of rule-based morphological analyzers to provide hard or soft lexical constraints and the use of word clusters to tackle the sparsity of lexical features. Evaluation on five morphologically rich languages (Czech, Finnish, German, Hungarian, and Russian) shows consistent improvements in both morphological and syntactic accuracy for joint prediction over a pipeline model, with further improvements thanks to lexical constraints and word clusters. The final results
improve the state of the art in dependency parsing for all languages."
"Předkládají se protipříklady k běžnému tvrzení, že všeobecný konatel (PRO-arbitrary) nemůže být ve větě vyjádřen. Jde o okrajové případy recipročních konatelů vyjadřovaných v češtině předložkovým pádem mezi + Instrumentál. Zvažují se i jiné možnosti interpretace této konstrukce.",Some counterexamples to the view that the general Actor (PRO-arbitrary) has no slot in the surface structure of the sentence are submitted. The reciprocal actors expressed in Czech by the prepositional case mezi + Instrumental case (among/between) are anlyzed from the point of view of their possible actor function.
"K prezentaci hloubkových syntaktických struktur vyžadujících doplnění povrchové reprezentace do vyhovujícícho formátu byly vybrány: srovnávací struktury, dvojznačné struktury uvozené výrazem kromě a tzv. konstrukce substituční (uvozeneé výrazem místo).","The necessity to fill the surface structures of selected ellipsis by reconstruction of predicates was demonstrated by the comparison konstructions, by the ambiguous constructions introduced by the expression kromě and by the so-called substituting constructions introduces by the expression místo."
"Ve stati se ilustruje kooperace gramatického komponentu se slovníkovými údaji týkajícími se valence slovesa, jeho gramatických diatezí, požadavků na koreferenci. Ve slovníku je třeba zachytit omezení na tvorbu analyzovaných konstrukcí. Tyto požadavky se exemplifikují několika pravidly pro uplatnění slovníkových údajů při vytváření rezultativu a infinitivní konstrukce.","The cooperation of the grammatical component and lexical information included in the lexical entry is exemplified by the valency of verbs, grammatical diathesis and constructions with coreference.  The restrictions must be reflected in the lexical entries. Several rules for the combining of lexical and syntactical information are demonstrated."
"V rámci tematického bloku Vztah gramatiky a slovníku byla přednesena přednáška o lexikálních omezeních některých gramatických (morfologických) kategorií (pasiva, rezultativu, recipientu). Byl zvažován způsob jejich zachycení v explicitním popisu češtiny.","Within the  workshop The relations between grammar and lexicon the lexical restrictions on the application of some grammatical (morphological) categories to the lexicon were demonstrated by the examples of Czech passive, rezultativ and recipient constructions."
"Nekrolog je věnován přední české lingvistce, která pracovala jako zástupkyně ředitele Ústavu pro jazyk český, měla bohatou publikační činnost, působila zejména v oblasti výzkumu mluveného jazyka a textové lingvistiky.","The article was devoted to the memory of Světla čmejrková, the famous Czech linguist. Her contribution to the domain of science as well as in the domain of management of science are evaluated."
"Příspěvek se zabývá vybranými morfologickými a syntaktickými rysy českých sloves, které jsou v teoretickém rámci Funkčního generativního popisu je uváděny ve slovníkovém hesle daného slovesa. Probírány jsou slovesné diateze (kromě pasiva také dva typy rezultativní diateze a recipinentní diatezi), reciprokalizace, kontrola a modalita závislých klauzí.","The present paper deals with selected morphological and syntactic features of Czech verbs. Working within the framework of Functional Generative Description (FGD), we demonstrate which features of lexical entries are required by the syntactic component of the description. In addition to the passive voice, traditionally described as diathesis, we briefly describe other kinds of proposed diatheses (resultative-1, resultative-2, and recipient). The constraints for their application will be present as features in the corresponding lexical entry; they will be a part of verbal paradigm in formal morphology. Regular operations within hierarchy of valency participants and their surface-syntactic positions are introduced into the grammatical component. Reciprocalization is characterized as a kind of shifting of valency complementations into the surface-syntactic position We also specify the requirements of the verbs governing the infinitive and content clauses and point out to the interplay between the governing verb and modality of the content clause."
"Příspěvek zaujímá kritické stanovisko k názoru, že vícerovinný popisu přirozeného jazyka již vyčerpal své možnosti a mohl by sehrát limitující úlohu, a ukazuje, že vztah mezi rovinami popisu lze vymezit na základě přísných kritérií a že při vymezení rovin je třeba brát v úvahu rozdíl mezi jazykovým významem a mimojazykovým obsahem.",The contribution presents a criticism of the opinion that a multilevel language model has already exhausted the possibilites it offered and may play a limited role. The author argues that the specification of the relation between levels can be based on strict criteria taking into account the difference between linguistic meaning and extralinguistic content.
"Zamyšlení nad dílem významného českého lingvisty a slavisty prof. L. Matějky, který byl významným propagátorem české lingvistiky i kultury vůbec v mezinárodnim měřítku.","A summary of the life achievements of a well-known Czech linguist and slavisist prof. L. Matejka, who was an important propagator of Czech linguistics and Czech culture in general in international community."
"O velkém českém lingvistovi a jeho přispění lingvistice, zejména o jeho aktuálním členění.","About a great Czech linguist Vilém Mathesius and his scientific contribution, in particular, about  his functional sentence perspective."
"Většina systémů počítačového zpracování přirozeného jazyka pracuje s kontextem. Tj. se znalostí slov a vztahů mezi nimim.
My pracujeme s konceptem aktivovanosti, formulovaným v rámci funkčně-generativního popisu jazyka.",We work with the notion of the degrees of salience (activation) of the items in the stock of shared knowledge together with the representation of the dynamic development of the discourse by means of changes of these degrees.
"Kniha Bitext Alignment od Jörga Tiedemanna je kompletním a detailním přehlededm početných a rozličných technik pro zarovnávání paralelních textů na různých úrovních: dokumentech, větách, slovech i syntaktických strukurách.","The book Bitext Alignment by Jörg Tiedemann is a complete and detailed survey of numerous and diverse techniques for alignment of bitexts on various levels of granularity. It covers the full range of alignment tasks: document alignment, sentence alignment, word alignment, and tree structure alignment. The main text is divided into seven chapters (covering 124 pages) accompanied by three appendices (27 pages)."
"Při práci na propojení českého a anglického valenčního slovníku bylo nutno navhnout, jak zacházet s víceslovními jednotkami, jejichž základem je sloveso; bylo stanoveno jejich formální zachycení. Ve studii založené na paralelních korpusech PCEDT a PDT popisujeme, jak si tyto jednotky odpovídají v textech, jak byly anotovány v obou jazycích a porovnáváme jejich charakteristiky jak v originále, tak v překladu.","While working on valency lexicons for Czech
and English, it was necessary to define treatment
of multiword entities (MWEs) with the
verb as the central lexical unit. We
present a corpus-based study, concentrating on
multilayer specification of verbal MWEs, their
properties in Czech and English, and a comparison
between the two languages using the
parallel Czech-English Dependency Treebank
(PCEDT). This comparison revealed interesting
differences in the use of verbal MWEs in
translation (discovering that such MWEs are
actually rarely translated as MWEs, at least
between Czech and English) as well as some
inconsistencies in their annotation."
"Tato studie se zabývá valenčními vlastnostmi českých deverbativních substantiv odvozených ze sloves s předmětovým genitivem (GenAdverb). Věnuje se otázkám vztahu adverbálních vyjádření valenčních doplnění a jejich adnominálních protějšků; zvláštní pozornost je věnována možnosti vyjádření adnominálního aktantu odpovídajícího adverbálnímu předmětovému genitivu pomocí posesivního adjektiva nebo zájmena (Adjpos/Pronpos). Užívání formy Adjpos/Pronpos (← GenAdverb) bylo ověřováno na datech Českého národního korpusu: tato forma byla nalezena u jedenácti produktivně tvořených substantiv (např. zanechání studia // jeho zanechání) a u dvou neproduktivně tvořených substantiv (např. dotyk volantu // jeho dotyk). Předpokládáme, že alternace GenAdnom // Adjpos / Pronpos (← GenAdverb) je v češtině užívána analogicky k běžnější alternaci GenAdnom // Adjpos / Pronpos (← Ak).","In the present paper, valency properties of Czech nouns derived from verbs with an object expressed by prepositionless genitive (GenAdverb) are studied. Special attention is paid to the possibility of the participant with an object function to be expressed by a possessive adjective or a possessive pronoun (Adjposs / Pronposs), when it modifies the derived noun. Usage of Adjposs / Pronposs (← GenAdverb) was verified in data of the Czech National Corpus; the form was found with eleven nouns derived from verbs by productive means (e.g. zanechání studia ‘quitting study-Gen.Sg’, i.e. ‘quitting one’s studies’ // jeho zanechání ‘it-Poss quitting’, i.e. ‘its quitting’) and with two nouns derived from verbs by non-productive means (e.g. dotyk volantu ‘touch wheel-Gen.Sg’, i.e. touch of wheel // jeho dotyk ‘it-Poss touch’, i.e. ‘its touch’). We suppose that the alternation GenAdnom // Adjposs / Pronposs (← GenAdverb) is used in Czech as an analogy to the more frequent alternation GenAdnom // Adjposs / Pronposs (← Ak)."
"Tato studie, založená na korpusovém mateiálu, popisuje česká deverbativní substantiva, která umožňují rozvití pomocí Aktora v bezpředložkovém instrumentálu, tj. A1(Ins). Jako východisko pro možné srovnání uvádíme frekvenční údaje týkající se vybraných substantiv odvozených z tranzitivních sloves. Poté se zaměřujeme na substantiva odvozená z intranzitivních sloves a ukazujeme, že rozvití pomocí A1(Ins) je možné nejen u substantiv odvozených ze sloves, která mohou být převedena do pasiva, ale také u substantiv odvozených ze sloves, která pasivizaci neumožňují. Vzhledem k tomu, že možnost vyjádření A1(Ins) u substantiv bývá s možností pasivizace základových sloves spojována, je užívání A1(Ins) u substantiv odvozených ze sloves, ktará pasivizaci neumožňují, zajímavým jevem. Týká se to především substantiv odvozených z reflexivních sloves, a to jak intranzitivních, tak tranzitivních. Studie také přispívá k dosavadnímu popisu tím, že zkoumá nejen česká produktivně tvořená deverbativní substantiva (např. domlouvání), ale rovněž substantiva neproduktivně tvořená (např. domluva), která jsou často opomíjena. Poukazuje rovněž na skutečnost, že korpusový materiál podává důkazy o užívání teoreticky negramatických konstrukcí, ve kterých je vyjádřen pouze A1(Ins), zatímco druhé doplnění A2 je povrchově vypuštěno, např. vyhrožování zaměstnavatelem, domluva strážníky; domníváme se, že nalezené korpusové doklady vedou k přehodnocení tvrzení o negramatičnosti těchto konstrukcí.","The present paper aims to provide corpus-based description of Czech deverbal nouns that allow for modification by Agent expressed by prepositionless instrumental, A1(Ins). As the starting point we give frequency data of selected nouns derived from transitive verbs. Then we focus on nouns derived from intransitive verbs and show that modification by A1(Ins) is possible not only with nouns derived from verbs that can be passivized, but also with nouns the source verbs of which cannot be changed to passive. The latter issue represents the most contributive finding of the paper; it concerns especially nouns derived from reflexive verbs, both transitive and intransitive. We also improve the up-to-now description by taking into consideration not only Czech nouns derived from verbs by productive means (e.g. domlouvání ‘talking’) but also the non-productively derived ones (e.g. domluva ‘caution’), mostly left aside. Finally, the corpus material also gives an evidence for usage of theoretically ungrammatical constructions in which the second complementation (A2) is omitted on the surface and only A1(Ins) is expressed, e.g. vyhrožování zaměstnavatelem ‘threatening by the employer’, domluva strážníky ‘caution by police officers’; the corpus-based examples lead to the revision of the statement about ungrammaticality of such constructions."
"Popis valenčních vlastností substantiv odvozených od sloves s předmětovým genitivem nám umožňuje upřesnit teoretické poznatky týkající se čtyř následujících skupin jevů z oblasti teorie valence substantiv:
(i) korespondence adverbálního a adnominálního genitivu (dotknout se puku - dotknutí se puku / dotyk puku);
(ii) nominalizované struktury se dvěma aktanty ve formě bezpředložkového genitivu (kromě tradičně uváděných konstrukcí typu zbavení ženy.ADDR starostí.PAT popisujeme další typy, tříděné podle typu aktantů v základové větné struktuře, např. dotek včelky.ACT pestíku.PAT květu, a podle příslušnosti k víceslovným predikátům, např. zanechání činnosti.PAT řady.ACT klíčových hráčů);
(iii) posesivum odpovídající adverbálnímu objektu (např. zanechání studia.PAT // jeho.PAT zanechání, dotyk volantu.PAT // jeho.PAT dotyk);
(iv) konatel vyjádřený bezpředložkovým instrumentálem u substantiv odvozených z intranzitivních sloves (např. ujímání se zvířátek.PAT hodnými lidmi.ACT).
Jazykový materiál byl získán z dat morfologicky značkovaných subkorpusů ČNK.","Czech nouns derived from verbs with an objective genitive considerably contribute to the theoretical description of valency of Czech deverbal nouns. We focus on four topics, namely (i) Correspondence GENAdverb – GENAdnom?;
(ii) Double post-nominal genitives; 
(iii) Possessives corresponding to an adverbal objective genitive;
(iv) Agents expressed by a prepositionless intrumental modifying nouns derived from intransitive verbs.
We used morphologically annotated subcorpora of the Czech National Corpus."
"Popis valenčních vlastností substantiv odvozených od sloves s předmětovým genitivem nám umožňuje upřesnit teoretické poznatky týkající se tří následujících skupin jevů z oblasti teorie valence substantiv:
(i) posesivum odpovídající adverbálnímu objektu (např. zanechání studia.PAT // jeho.PAT zanechání, dotyk volantu.PAT // jeho.PAT dotyk);
(ii) nominalizované struktury se dvěma aktanty ve formě bezpředložkového genitivu (kromě tradičně uváděných konstrukcí typu zbavení ženy.ADDR starostí.PAT popisujeme další typy, tříděné podle typu aktantů v základové větné struktuře, např. dotek včelky.ACT pestíku.PAT květu, a podle příslušnosti k víceslovným predikátům, např. zanechání činnosti.PAT řady.ACT klíčových hráčů);
(iii) konatel vyjádřený bezpředložkovým instrumentálem u substantiv odvozených z intranzitivních sloves (např. ujímání se zvířátek.PAT hodnými lidmi.ACT).
Jazykový materiál byl získán z dat morfologicky značkovaných subkorpusů ČNK.","Czech nouns derived from verbs with an objective genitive considerably contribute to the theoretical description of valency of Czech deverbal nouns. We focus on three topics, namely (i) Possessives corresponding to an adverbal objective genitive;
(ii) Double post-nominal genitives; 
(iii) Agents expressed by a prepositionless intrumental modifying nouns derived from intransitive verbs.
We used morphologically annotated subcorpora of the Czech National Corpus."
Cílem příspěvku je představit anotaci aktuálního členění v české části Pražského česko-anglického závislostního korpusu. Podáváme zprávu o tomto prvním kroku v procesu vytváření paralelní anotace aktuálního členění v tomto korpusu a podrobně popisujeme automatickou předanotaci české části. Výsledky předanotace jsou vyhodnoceny na základě srovnání automatické a ruční anotace.,"The objective of the present contribution is to give a survey of the annotation of information structure in the Czech part of the Prague Czech-English Dependency Treebank. We report on this first step in the process of building a parallel annotation of information structure in this corpus, and elaborate on the automatic pre-annotation procedure for the Czech part. The results of the pre-annotation are evaluated, based on the comparison of the automatic and manual annotation."
"Keynote přednáška bloku Paralelní slavistické korpusy. Obsahem přednášky bylo představení anotačních principů Pražského závislostního korpusu a rovněž představení dalších korpusů, které tyto anotační principy využívají, včetně korpusů paralelních.","A keynote speech in the section Parallel slavic corpora. The speech presented annotation principles of the Prague Dependency Treebank, as well as other corpora based on these principles, incl. parallel corpora."
"Pražský závislostní korpus arabštiny, verze 1.5, je kolekce textů v moderní arabštině, obohacená o ruční morfologickou a závislostní anotaci.","The Prague Arabic Dependency Treebank, version 1.5 (PADT 1.5) is a collection of  texts in Modern Standard Arabic, entiched with morphological and analytical (surface-syntax dependency) annotation."
"Omezená webová demoverze aplikace statistického strojového překladu z angličtiny, němčiny, španělštiny a francouzštiny do češtiny.","Restricted web-based demo version of application of statistical machine translation from English, German, Spanish and French to Czech."
"Tato stránka vznikla jako doprovodný web k semináři o lingvistických nástrojích pro studenty bohemistiky na Univerzitě Palackého v Olomouci. Zabývá se především daty a nástroji poskytovanými ÚFALem, ale nejenom jimi. Občas upozorňuje i na související software vzniklý buď zcela na jiném pracovišti, nebo jako výsledek společného projektu ÚFALu s dalšími ústavy.","Accompanying website to the workshop on linguistic tools for students of Czech at Palacký University in Olomouc. Most of the time it describes data and tools provided by ÚFAL, but not solely. Sometimes it draws attention to related software created at a different institute or as a result of a common project of ÚFAL and other institutes."
"Vztah mezi větou v přirozeném jazyce, tak jak je napsaná, a jejím významem je velmi složitý jev. Existuje mnoho variant téže věty, které zachovávají význam, zatímco jiné, povrchově velmi malé změny mohou význam zkreslit nebo zcela otočit. Abychom mohli věty algoritmicky zpracovávat a generovat, musíme najít způsob, jak zachytit jejich sémantickou identitu a podobnost.","The relationship between a sentence in a natural language as written down and
its meaning is a very complex phenomenon. Many variations of the sentence
preserve the meaning while other superficially very small changes can distort or
completely reverse it. In order to process and produce sentences
algorithmically, we need to somehow capture the semantic identity and similarity
of sentences.

The issue has been extensively studied from a number of directions, starting
with thesauri and other lexical databases that capture synonymy of indivitual
words (most notably the WordNet \cite{wordnet}), automatic paraphrasing
of longer phrases or even sentences
(e.g.
\cite{bannard-callison-burch-2005},
\cite{kauchak-barzilay},
\cite{denkowski-lavie:2010:WMT}) or
textual entailment \cite{textual-entailment}.
We are still far away from a satisfactory solution.

The field of machine translation
makes the issue tangible in a couple of ways, most importantly within the
task of automatic MT evaluation.
Current automatic MT evaluation techniques rely on the availability of some
reference translation, i.e. the translation as produced by a human translator.
Obtaining such reference translations is relatively costly, so most datasets
provide only one reference translation, see e.g.
\cite{callisonburch-EtAl:2012:WMT}.

While there are many possible
translations of a given input sentence, only a handful of them are available as
reference translations. The sets of hypotheses considered or finally selected by
the MT system can be completely disjoint from the set of reference translations.
\cite{bojar-kos:2010:WMT} observed that only about 5--10\% of reference translations were \emph{reachable} for
Czech-to-English translation , regardless whether the system
would actually search towards them.
Relying mostly on unreachable reference translations is detrimental for MT
system development. Specifically, automatic MT evaluation methods perform worse
and consequently automatic model optimization suffers.

Occasionally there are a few more references available.
For example, in the NIST OpenMT evaluation\footnote{\url{http://www.itl.nist.gov/iad/mig/tests/mt/2006/doc/mt06eval_official_results.html}}
or in the Prague Czech-English Dependency Treebank \cite{pcedt}
there are four.
Difficult as they may be to obtain, even four references fail to provide
an adequate representation of the enormous space of correct translations.

We want to trigger discussion about how many and what sort of references
we actually need for MT, how can we obtain and use them.

Obviously the set of possible translations is exponentional in the length of the sentence.
Dreyer and Marcu \cite{dreyer-marcu} generated translation networks for the HyTER
evaluation metric; the networks provided them with a compact representation
of the large space of possible translations.
Along the same lines, we propose unification-based approach to describe the space
\cite{tsd-hyter}.
Using a Prolog-based annotation tool
and applying a 2-hour upper working limit per sentence,
our translators were able to generate tens of thousands (or more) Czech references
for each English sentence; the record figure was 19 billion translations
of one long sentence.
The way of actually using such data is an open question.
If we just take the \texttt{mteval} script and run it with 19 billion references instead of four,
we will probably not live long enough to see the results.
Randomly selected and manually checked samples from these generated translations
indicated that the translations are indeed plausible.
We used a Levenshtein-based string similarity measure to confirm diversity of the generated set.

We also measured the string similarity between system outputs and various reference translations:
those from the generated set
and also two manually post-edited system outputs.
Unsurprisingly, each of the two post-edited translations were much closer to the
original system outputs than the single reference translation that was
originally available for that test set.
However, our annotators managed to produce references which are almost
exactly as close as the post-edited translations,
even though they did not have access to them or the system outputs.

\cite{wmt2013} showed that with several references (and with the BLUE and NIST metrics)
smaller test set with multiple post-edited references
has the same level of correlation with human judgments
as a much larger test set with just one reference, created independently of MT.
In future we might further investigate that in terms of
\textit{which} system outputs to post-edit (average? good? all?)

During the past 20 years we have accummulated impressive amount of bitext and it keeps growing.
Our current conclusion is that not every bitext is equally valuable.
Diversity of translation alternatives in either language is at least as important.
So where will we be after the next 20 years?
Quite likely, the amount of bitext available will multiply accordingly.
However, we also hope that for every sentence ``pair'', the number of available translation variants
will also multiply."
Úvodní kurz je věnován teoretickému a praktickému pohledu na základní principy a algoritmy strojového učení v počítačovém zpracování přirozeného jazyka. Posluchačům jsou představeny základy statistického systému R.,"The course provides a concise introduction to principles and algorithms of machine learning in natural language processing both theoretically
and practically. We will focus on fundamental ideas in machine learning and the basic theory behind them. The principles of machine learning
will be presented in a gentle way so that students do not have to be afraid of scary mathematical formulas. We will give a brief introduction to the R system for statistical computing, which we use as a tool for practical demonstration. Students
will gain practical know-how needed to apply the machine learning techniques to new problems.
The presented methods of machine learning will be practically demonstrated on selected tasks from the field of natural language processing. Understanding these tasks will not require any extra linguistic knowledge. We will show how to master NLP tasks using the R
system and how to experiment with real data sets."
"Naším cílem je predikovat rodný jazyk (L1) autorů anglických esejí za pomoci korpusu TOEFL11, ve kterém jsou známy jazykové úrovně autorů a témata esejí. Úlohu řešíme jako klasifikační úlohu pomocí řízených metod strojového učení. Zaměřujeme se na ladění atributů, mezi které jazykovou úroveň a témata nezahrnujeme. Atributy navrhujeme napříč jazyky L1. Experimentujeme s několika technikami pro filtrování a kombinaci atributů s ohledem na kritéria z informační teorie. Celkem jsme natrénovali čtyři modely SVM a pomocí většinového hlasování je zkombinovali do modelu dosahujícího úspěšnosti 72.5%.","Our goal is to predict the ﬁrst language (L1)
of English essays’s authors with the help of
the TOEFL11 corpus where L1, prompts (topics) and proﬁciency levels are provided. Thus
we approach this task as a classiﬁcation task
employing machine learning methods. Out
of key concepts of machine learning, we focus on feature engineering. We design features across all the L1 languages not making
use of knowledge of prompt and proﬁciency
level. During system development, we experimented with various techniques for feature ﬁltering and combination optimized with respect
to the notion of mutual information and information gain. We trained four different SVM
models and combined them through majority
voting achieving accuracy 72.5%."
"Tvaroslovné a větné rozbory jsou povinnou součástí hodin češtiny, pravděpodobně tou nejméně oblíbenou. Pro zařízení iPhone a iPad připravujeme editor Čapek (publikace na AppStore duben 2013), díky kterému by mohlo být provádění rozborů ""hustý"". Z akademického pohledu jsou školské rozbory základnou pro rozšíření banky dat, kterou využíváme v aplikacích počítačového zpracování přirozeného jazyka.","Manual tagging and parsing are obligatory parts of Czech lessons, probably the most unpopular. We implement Capek editor for iPhone and iPad (to be published at AppStore in April 2013) to make tagging and parsing cool. Annotations by school children are automatically transformed into the Prague Dependency Treebank annotation framework."
"Technická zpráva shrnuje nová anotační pravidla pro anotovaní českých textů na tektogramatické rovině Pražských závislostních korpusů, která doplňují velký anotační manuál (ÚFAL/CKL TR-2005-28). Pravidla vznikla v souvislosti s anotováním korpusů PCEDT 2.0 a PDTSC 2.0.",Technical report provides new annotation rules for annotation of czech text on tectogrammatical level of the Prague Dependency Treebanks. The rules supplement main annotation manual (ÚFAL/CKL TR-2005-28) and were formed with respect to annotation of PCEDT 2.0 and PDTSC 2.0.
"Technická zprava popisuje inovace, které byly provedeny ve verzi PDT 3.0 oproti verzi PDT 2.0. Vysvětluje jejich lingvistickou podstatu, zdůvodnění, pokyny pro anotaci a exemplifikaci. Její jedna část je věnována nově zavedeným nebo upraveným jevům tektogramatické roviny. V její další části jsou představeny jevy textové koreference, mezivětných vztahů, žánrové klasifikace dat a způsob jejich anotování v PDT 3.0.","Technical report describes improvement of the older scenario of PDT 2.0 that was applied in PDT 3.0. The description of changes and additions for the annotation procedure, the motivation for them, the procedure of their annotation and exemplification are given in the first part of this report. The extensions of the textual coreference, inter-sentential relations and genre classification of the texts included in PDT 3.0 are described in the other part of the report."
"Technická zprava popisuje inovace, které byly provedeny ve verzi PDT 3.0 oproti verzi PDT 2.0.  Vysvětluje jejich lingvistickou podstatu, zdůvodnění, pokyny pro anotaci a exemplifikaci. Její jedna část je věnována nově zavedeným nebo upraveným jevům tektogramatické roviny. V její další části jsou představeny jevy textové koreference, mezivětných vztahů, žánrové klasifikace dat a způsob jejich anotování v PDT 3.0.","Technical report describes improvement of the older scenario of PDT 2.0 that was applied in PDT 3.0. The description of changes and additions for the annotation procedure, the motivation for them, the procedure of their annotation and exemplification are given in the first part of this report. The extensions of the textual coreference, inter-sentential relations and genre classification of the texts included in PDT 3.0 are described in the other part of the report."
"V tomto článku představujeme PDTSC a jeho anotaci, která vedla k rozšíření slovníku PDT-Vallex, valenčnímu slovníku českých sloves, původně vytvořenému pro psané texty.","In this article, we introduce the Prague Dependency Treebank of Spoken Czech.
The syntactic and semantic annotation of this corpus has led to the expansion of PDT-Vallex,
a valency lexicon of Czech verbs, which has previously been linked only to the annotation of written
texts."
"Přednáška se soustřeďuje na základní syntaktické vztahy, jmenovitě na závislostní relace a na slovosled, a dále na jejich vzájemnou souhru. Prezentujeme formální rámec, který nám umožňuje ekonomicky a přitom jazykově adekvátně popsat tyto vztahy a jejich automatizované zpracování. Nakonec krátce zmiňujeme využití tohoto formálního ránce v aplikacích NLP.","The talk focuses on basic syntactic relations, namely on dependency and word order, and on their mutual interplay. We present a formal framework that gives us a possibility of an economic and linguistically adequate description of these relations as well as their automatic processing. Finally, we shortly mention the application of the framework in language resources and NLP tools."
"Přednáška se zaměří na základní syntaktické vztahy, především závislost a slovosled, na jejich vzájemné vztahy a příklady vzájemného ovlivňování (včetně tzv. neprojektivních konstrukcí). Dále představíme formální rámec, který umožňuje popis těchto vztahů a jejich automatické zpracování. V závěru bude krátce zmíněno využití tohoto rámce v jazykových zdrojích a (na nich budovaných) nástrojích NLP.","The talk focuses on basic syntactic relations, dependency relationship and word order in particular, on their mutual relations, and examples of mutual interplay (including so called non-projective constructions). Then we present a formal frame allowing us to describe these relations ant their automated processing. Finally, we shortly mention various applications of the proposed framework in NLP tasks."
"Fenomén volného slovosledu hraje důležitou roli v syntaktické analýze mnoha přirozených jazyků.
Tento příspěvek zavádí pojem slovosledného posunu ('shiftu'), který odrážející stupeň volnosti slovosledu. Slovosledný posun je operace založená na slovosledných změnách zachovávajících syntaktickou správnost, jednotlivé slovní tvary, jejich morfologické charakteristiky a jejich syntaktické vztahy v průběhu tzv. redukční analýzy, tedy postupného zjednodušování věty.
Příspěvek přináší lingvistickou motivaci pro tuto operaci a zaměřuje se na formální popis celkového
mechanismu pomocí speciální třídy automatů, tzv.
restartovacich automatů s operací shift  obohacených strukturovaným výstupem strukturovaný výstup.
Cílem této studie je objasnit vlastnosti výpočtů
potřebných k provedení (rozšířené) redukční analýzy pro přirozené jazyky s volným slovosledem.","The phenomenon of word order freedom plays
an important role in syntactic analysis of many natural languages. This paper introduces a notion of a word order shift, an operation reflecting the degree of word order freedom of natural languages. The word order shift is an operation
based upon word order changes preserving syntactic
correctness, individual word forms, their morphological characteristics, and their surface dependency relations in a course of a stepwise simplification of a sentence, a so called analysis by reduction.
The paper provides linguistic motivation for this operation and concentrates on a formal description of the whole mechanism through a special class of automata, so called restarting automata with the shift operation enhanced with
a structured output, and their computations.
The goal of this study is to clarify the properties of computations needed to perform (enhanced) analysis by reduction for free word order languages."
"Budu mluvit o tématu, kterému se říká ""automatické zpracování přirozeného jazyka"" a myslí se tím způsoby, jak přimět počítač, aby rozuměl nějaké lidské řeči. Povíme si něco o jazykových korpusech, různých úrovních a způsobech lingvistického značkování, elektronických slovnících, metodách analýzy a syntézy přirozeného jazyka, automatickém překladu. Vše si ukážeme na skutečných příkladech.","I will talk about a topic called ""natural language processing"" which deals with ways of getting the computer to understand human languages. I will tell you something about language corpora, different levels and methods of linguistic tagging, electronic dictionaries, methods of analysis and synthesis of natural languages, automatic translation. Everything will be shown on real examples."
"Wikipedie slouží nejen jako rozsáhlá encyklopedie zasahující do mnoha odvětví, ale v poslední době stále častěji i jako zdroj jazykových dat pro nejrůznější aplikace. Jednotlivé jazykové mutace umožňují získat i paralelní data ve více jazycích. Zařazení článků wikipedie do kategorií potom může sloužit k filtrování jazykových dat. 
V našem projektu se zabýváme automatickým překladem textů v oboru biologie a lékařství, proto jsme potřebovali větší množství paralelních dat. Jedním ze zdrojů byla právě wikipedie. Pro výběr dat splňujících daná kritéria – tedy dané obory v daných jazycích – jsme využili projektu Dbpedia, který ze stránek wikipedie extrahuje strukturované informace a ve formátu RDF je zpřístupňuje uživatelům.
V příspěvku popíšeme postup extrakce dat a problémy, které jsme museli řešit, neboť u otevřeného projektu jako wikipedie, do něhož může přispívat kdokoli, nelze spoléhat na konzistenci.","Wikipedia is not only a large encyclopedia, but
lately also a source of linguistic data for various applications.
Individual language versions allow to get the parallel data in multiple languages. Inclusion of Wikipedia articles into categories can be used to filter the language data according to a domain.
In our project, we needed a large number of parallel data for training systems of machine translation in the field of biomedicine. One of the sources was Wikipedia. To select the data from the given domain we used the results of
the DBpedia project, which extracts structured information from the Wikipedia articles and makes them available to users in RDF format.
In this paper we describe the process of data extraction and the problems that we had to deal with, because the open source project like Wikipedia, to which anyone can contribute, is not very reliable concerning consistency."
"V češtině a v ruštině existuje množina prefixů, které mění význam nedokonavých sloves vždy stejným způsobem. Změna často (v českém jazyce vždy) vyžaduje přidání reflexivního morfému. Tato vlastnost nedokonavých sloves může být použita pro automatické rozpoznávání slov, aniž by bylo nutné ukládat takto vzniklé tvary do morfologických slovníků.","In Czech and in Russian there is a set of prefixes changing the meaning of imperfective verbs always in the same manner. The change often (in Czech always) demands adding a reflexive morpheme. This feature can be used for automatic recognition of words, without the need to store them in morphological dictionaries."
"Vytváříme systém pravidel, s jejichž pomocí značkujeme slovesa a jejich kolokáty v závislostním korpusu. Místo klasických syntaktických kategorií používáme šablonu, do níž zařazujeme nalezené kolokáty v přesně daném pořadí. Porovnáním jednotlivých pozic pro nejčastější syntaktické alternace daného slovesa získáme jeho přesnější syntaktický popis.","We report on a rule-based procedure of extracting
and labeling English verb collocates from a dependency-parsed corpus. Instead of relying on the syntactic labels provided by the parser, we use a simple topological sequence that we fill with the extracted collocates in a prescribed
order. A more accurate syntactic labeling
will be obtained from the topological fields
by comparison of corresponding collocate
positions across the most common syntactic
alternations. So far, we have extracted and labeled verb forms and predicate complements according to their morphosyntactic structure. In the next future, we will provide the syntactic labeling of the complements."
"Článek zkoumá jev volného slovosledu. Soustředí se na vztak mezi (formální) závislostí a slovosledem. Zkoumání je provedeno aplikací poloautomatické metody redukční analýzy na česká syntaktický anotovaná data.
Volnost slovosledu je vyjádřena pomocí počtu nutných záměn v průběhu redukční analýzy. Článek ukazuje, že tato míra je ortogonální k mírám vyjadřujícím volnost slovosledu pomocí počtu neprojektivních konstrukcí či klitik ve větě.","The paper aims at the investigation of the phenomenon of free word order. It concentrates on the relationship between (formal) dependencies and word order. The investigation is performed by means of a semiautomatic application of a method of analysis by reduction to Czech syntactically annotated data.
The freedom of word order is expressed by means of a number of necessary shifts in the process of analysis by reduction. The paper shows that this measure provides a new view of the problem, it is orthogonal to measures reflecting the word order freedom based on a number of non-projective constructions or clitics in a sentence."
"Článek se zabývá metodou identifikace zajímavých konstrukcí v syntakticky anotovaném korpusu češtiny (Pražském závislostním korpusu) pomocí aplikace automatické procedury redukční analýzy na stromy tohoto korpusu. Procedura odhaluje některé lingvistické jevy, které jdou za hranici ""závislosti"".
Článek obsahuje diskuzi a analýzu jednotlivých jevů a rovněž kvantifikuje výsledky automatické procedury na podmnožině korpusu.","The paper describes a method of identifying a set of interesting constructions in a syntactically annotated corpus of Czech (the Prague Dependency Treebank) by application of an automatic procedure
of analysis by reduction to the trees in the treebank. The procedure reveals certain linguistic phenomena that go beyond `dependency
nature'.
The paper contains discussion and analysis of individual phenomena, as well as the quantification of results of the automatic procedure on a subset of the treebank."
"Závislostní korpus anotovaný na rovině morfologické (2 miliony slov), syntaktické (1,5 milionu slov) a sémantické (0,8 milionu slov). Oproti verzi 2.5 přibyly opravy morfologie, revize gramatémů, anotace diskurzních vztahů, asociační anafory, rozšířené textové koreference a žánrů.","Dependency corpus annotated at morphological, syntactic, and deep syntactic levels. Previous version 2.5 has been enriched by annotation of discourse relations, bridging anaphora, extended textual coreference, and genres. Morphological level has been improved and some grammatemes have been revised."
V tomto článku se zabýváme identifikací výskytů víceslovných výrazů z existujícího slovníku v textovém korpusu. Víceslovné výrazy mohou být libovolné délky a přerušeny v povrchovém pořádku slov. Analyzujeme a porovnáváme tři různé přístupy využívající lingvistické analýza na různých rovinách.,"We deal with syntactic identification of occurrences of multiword expression (MWE) from an existing dictionary in a text corpus. The MWEs we identify can be of arbitrary length and can be interrupted in the surface sentence. We analyse and compare three approaches based on linguistic analysis at a varying level, ranging from surface word order to deep syntax. The evaluation is conducted using two corpora: the Prague Dependency Treebank and Czech National Corpus. We use the dictionary of multiword expressions SemLex,
that was compiled by annotating the Prague Dependency Treebank and includes deep syntactic dependency trees of all MWEs."
"V příspěvku analyzujeme syntaktické funkce deadjektivních adverbií s příponou -o na základě materiálu z Českého národního korpusu. Pouze část těchto adverbií se specializuje na predikativní funkci, jiná plní kromě této funkce také funkci příslovečného určení a některá se v predikativní funkci neuplatňují vůbec. Kromě syntaktické funkce těchto adverbií zkoumáme také jejich význam a vztah k základovému adjektivu a navrhujeme, jak je reprezentovat v hloubkově syntaktické anotaci Pražského závislostního korpusu.","Both an adverb with the suffix -e and an adverb with the suffix -o are derived from many adjectives in Czech. Adverbs with the latter suffix are often a component of the predicate. The predicative syntactic function has become one of the main arguments to isolate the adverbs with the suffix -o as a separate part of speech (Komárek, 1954); nevertheless, this proposal has not been widely accepted. In the present paper, a detailed analysis of the adverbs with the suffix -o is carried out on the basis of material from the Czech National Corpus. The analysis documents that solely a part of the adverbs with the suffix -o specializes in the predicative function, other adverbs with this suffix fulfill an adverbial function as well, or do not fulfill the predicative function at all. Besides the syntactic function and the lexical meaning of these adverbs, their relation to the base adjective and the impact of context is taken into consideration when discussing the representation of these adverbs within the deep-syntactic annotation of the Prague Dependency Treebank."
"Slova odvozená od adjektiv představují zajímavý, reprezentativní vzorek slovotvorných derivačních procesů v češtině: patří ke slovním druhům substantiv, adjektiv, sloves a adverbií, vzájemně se liší v řadě aspektů, mimo jiné z hlediska sepjetí jejich lexikálního významu s významem slovotvorným. 
V příspěvku probereme možnost třídění deadjektivních derivátů právě z hlediska jejich vztahu k základovému adjektivu, pracujeme přitom s Kuryłowiczovou (1936) koncepcí derivace syntaktické a lexikální, která je v Dokulilových slovotvorných pracích reflektována. Z klasifikace deadjektivních derivátů jako syntaktických nebo lexikálních vyvodíme přímé důsledky pro zachycení těchto slov v hloubkověsyntaktické anotaci Pražského závislostního korpusu. Syntaktické deriváty je možné reprezentovat základovým adjektivem, protože jeho odlišná syntaktická funkce je v tomto syntakticky anotovaném korpusu zachycena speciálním atributem. Oproti tomu lexikální deriváty se budou od svého základového slova lišit lexikální hodnotou.","Deadjectival derivates are a representative sample of Czech derivation. On the basis of the semantic relation to their base adjectives, they can be classified into two groups: into syntactic derivates, which have the same meaning as their base adjectives but fulfill different syntactic functions (e.g. deadjectival adverbs), and lexical derivates, which share the syntactic function with the base adjectives but differ from them in meaning (e.g. diminutive adjectives). The present paper focuses on deadjectival nouns with the suffix -ost, which express a quality. Based on the analysis of data from the corpus SYN2010, we try to document that the meaning of quality is closely interconnected with the meaning of a bearer of the quality, and propose to revise Dokulil’s classification of these nouns as syntactic derivates. The classification of a derivate as a syntactic or lexical one is directly reflected in the deep-syntactic annotation of the Prague Dependency Treebank."
"V příspěvku shrnujeme základní rysy Dokulilovy teorie slovotvorné produktivity a zasazujeme ji do kontextu zkoumání produktivity v posledních desetiletích. Na materiálu z velkých korpusů češtiny zkoumáme produktivitu čtyř českých sufixů (-ost, -ství/ctví, -ismus, -ita) a ukazujeme, že jednotlivé míry používané ke kvantifikaci produktivity vedou k rozdílným výsledkům.","In the present paper, central ideas of the work on productivity by the Czech linguist Miloš Dokulil are presented and placed in the context of recent approaches to productivity. Based on material from large corpora of Czech, productivity of four Czexh suffixes (-ost, -ství/ctví, -ismus, -ita) is analyzed; it is demonstrated that productivity measures used for quantification of productivity give different results."
"V přednášce se zaměříme na Dokulilovu teorii produktivity, která je integrální součástí jeho široce respektované slovotvorné teorie, připomeneme především jeho distinkci produktivity systémové a empirické. Při analýze přípon -ost, -ství/-ctví, -ismus a -ita, které jsou v češtině používány (mimo jiné) k odvozování názvů vlastností, se kromě jejich systémových rysů pokusíme stanovit míru produktivity také na základě frekvenčních údajů z velkých korpusových dat.","Though the term of productivity in word-formation seems to be intuitively clear and the idea (under various terms) has been present in linguistics for centuries, there are many approaches to productivity in contemporary linguistics, which differ in several aspects. 
In the talk, I briefly sketch selected issues of the study of productivity focusing on the last two or three decades, during which productivity has become one of the central topics of the research into word-formation. In this context, I refer to the main ideas of the work on productivity by Miloš Dokulil, whose word-formation theory has become a widely respected and, in fact, the only common ground of word-formation descriptions in Czech linguistics. I focus on his opposition of the so-called systemic and empirical productivity and present some suggestions on how Dokulil’s ideas could be applied to the current, corpus-based research in productivity, by analyzing the productivity of four suffixes which are used to derive names of qualities in Czech (-ost, -ství/-ctví, -ismus and -ita)."
"Workshop představil Pražský závislostní korpus a základní nástroje, které lze používat k jeho prohledávání. Na rozdíl od dnes již poměrně známého Českého národního korpusu obsahuje PDT i anotace syntaktických struktur, a to hned na dvou rovinách. Seznámili jsme se s teorií funkčního generativního popisu, na jejímž základě byl korpus vybudován, a popsali jsme si aspekty, kterými se od teoretických východisek odchyluje.","The workshop presented the Prague Dependency Treebank and basic tools that can be used to search it. Unlike more widely known Czech National Corupus, the PDT contains two layers of syntactic annotation. The theory of the Functional Generative Description upon which the treebank is built was presented, and the aspects were described where the theory and the treebank diverge."
"Tutoriál přibližující práci s nástrojem PML-TQ určeným pro prohledávání syntakticky anotovaných korpusů. Představeny byly dvě verze klientského rozhraní, příklady používaly data v češtině, angličtině a němčině.","A tutorial describing PML-TQ, a tool for searching syntactically annotated corpora. Two forms of the client interface were presented, with examples over Czech, English, and German data."
"Toto je vydání Alex Dialogue Systems Framework pro rok 2013. 

Tento framework je vyvýjen skupinou zabývající se výzkumem v oblasti hlasových dialogových systémů na ÚFAL - http://ufal.mff.cuni.cz/ - Ústav formální a aplikované lingvistiky, MFF, UK. 

Hlavní cíle vývoje jsou: poskytnout základní komponenty pro vývoj SDS, poskytnout příklady hlasových dialogových systémů, poskytnout nástroje pro zpracopvání záznamů dialogů, například audio přepisy, sémantické anotace, nebo vyhodnocení dialogových systémů.

Implemntované vlastnosti: VOIP používající PJSIP 2.1, ASR používající OpenJulius, GoogleASR nebo KALDI, VAD používající Gaussian Mixure Models nebo Feed-Forward Neural Networks, SLU používající množinu klasifikátorů založených na logistické regresi, DM používající diskriminativní pravěpodobnostní aktualizaci stavu a ručně psané strategie řízení, NLG používající šablon s možností využití šablon založených na tektogramatických stromech pro správnou syntézu povrchové realizace, TTS používající flite, VoiceRSS nebo SpeechTech, vyhodnocení dialogových systémů používajáící Amazon Mechanical Turk, tvorba akustických modelů pomocí HTK a KALDI.","This is the Alex Dialogue Systems Framework - 2013 release. 

This framework is being developed by the dialogue systems group at UFAL - http://ufal.mff.cuni.cz/ - the Institute of Formal and Applied Linguistics, Faculty of Mathematics and Physics, Charles University in Prague, Czech Republic. The purpose of this work is to facilitate research into and development of spoken dialogue systems.

The main goals are: to provide baseline components need for a building spoken dialogue systems (SDSs), to provide example implementations of SDSs for several domains, to provide tools for processing dialogue system interactions logs, e.g. for audio transcription, semantic annotation, or SDSs evaluation.

Implemented features: VOIP using PJSIP 2.1 with some modifications, ASR using OpenJulius, GoogleASR or KALDI, VAD using Gaussian Mixture Models or Feed-Forward Neural Networks, SLU using a set of logistic regression classifiers for detecting dialogue acts, DM using probabilistic discriminative dialogue state tracking and handcrafted policies, NLG using template based generation possibly with efficient inflection into the correct surface form for morphologically rich languages, TTS using flite, VoiceRSS and SpeechTech, evaluation of dialogue systems using Amazon Mechanical Turk crowdsourcing platform, building acoustic models using the HTK and KALDI toolkits."
"Představujeme Depfix, systém pro samočinnou post-edititaci výstupů frázových strojových překladů z angličtiny do češtiny, založený na jazykovědných znalostech. Nejprve jsme rozebrali druhy chyb, kterých se dopouští typický strojový překladač. Poté jsme vytvořili sadu pravidel a statistickou komponentu, které opravují takové chyby, které jsou běžné nebo závažné a může přicházet v úvahu jejich oprava pomocí našeho přístupu. Používáme řadu nástrojů pro zpracování přirozeného jazyka, které nám poskytují rozbor vstupních vět. Navíc jsme reimplementovali závislostní analyzátor a několika způsoby jej upravili pro provádění rozboru výstupů statistických strojových překladačů. Provedli jsme automatická i ruční vyhodnocení, která potvrdila, že kvalita překladů se zpracováním v našem systému zlepšuje.","We present Depfix, a system for automatic post-editing of phrase-based English-to-Czech machine translation outputs, based on linguistic knowledge. First, we analyzed the types of errors that a typical machine translation system makes. Then, we created a set of rules and a statistical component that correct errors that are common or serious and can have a potential to be corrected by our approach. We use a range of natural language processing tools to provide us with analyses of the input sentences. Moreover, we reimplemented the dependency parser and adapted it in several ways to parsing of statistical machine translation outputs. We performed both automatic and manual evaluations which confirmed that our system improves the quality of the translations."
"Depfix je systém pro samočinnou post-edititaci výstupů frázových strojových překladů z angličtiny do češtiny, založený na jazykovědných znalostech. Rozebrali jsme druhy chyb, kterých se dopouští typický strojový překladač, a vytvořili jsme sadu pravidel a statistickou komponentu, které opravují některé z těchto chyby. Používáme řadu nástrojů pro zpracování přirozeného jazyka, které nám poskytují rozbor vstupních vět. Navíc jsme reimplementovali závislostní parser a několika způsoby jej upravili pro provádění rozboru výstupů statistických strojových překladačů. Provedli jsme automatická i ruční vyhodnocení, která potvrdila, že kvalita překladů se zpracováním v našem systému zlepšuje.","Depfix is a system for automatic post-editing of phrase-based English-to-Czech machine translation outputs, based on linguistic knowledge. We analyzed the types of errors that a typical machine translation system makes, and created a set of rules and a statistical component that correct some of the errors. We use a range of natural language processing tools to provide us with analyses of the input sentences. Moreover, we reimplemented the dependency parser and adapted it in several ways to parsing of statistical machine translation outputs. We performed both automatic and manual evaluations which confirmed that our system improves the quality of the translations."
"Některé veci jsou pro PB SMT obtížné -- negace, shoda, trpný rod...
Automatická post-editace může často pomoci -- i hrstka jednoduchých pravidel může fungovat velmi dobře.
NLP nástroje jsou typicky užitečné -- tagger, parser, morphologický generátor; adaptujte je pro zpracování výstupů SMT, je-li to možné.","Some things are hard for PB SMT -- negation, agreement, passives...
Automatic post-editing can often help -- a handful of simple rules might do the job very well.
NLP tools are typically useful -- tagger, parser, morphological generator; adapt them to SMT outputs if possible."
"Deepfix je statistický post-editovací systém pro zlepšování
kvality výstupů statistického strojového překladu.
Pokouší se opravovat chyby ve slovesné a substantivní valenci za použití hloubkové syntactické
analýzy a jednoduchého pravděpodobnostního valenčního modelu.
Na jazykovém páru angličtina-čeština ukazujeme že, pokud je podporována hlubokou lingvistickou znalostí, statistická post-editace
statistického strojového překladu
vede ke zlepšení 
kvality překladu.","Deepfix is a statistical post-editing system for improving
the quality of statistical machine
translation outputs.
It attempts to correct errors in verb-noun valency using deep syntactic
analysis and a simple probabilistic model of valency.
On the English-to-Czech translation pair, we show that statistical post-editing of
statistical machine translation
leads to 
an improvement
of the translation quality when helped by deep linguistic knowledge."
"Článek se věnuje překladu anglického zájmena ""it"" do češtiny. Navrhli jsme diskriminativní model a zapojili ho do překladu přes tektogramatickou rovinu systémem TectoMT. Výsledkem je zlepšení kvality překladu v 8.5% vět obsahujícich ""it"".","We present a novel approach to the translation of the English personal pronoun it to Czech. We conduct a linguistic analysis on how the distinct categories of it are usually mapped to their Czech counterparts. Armed with these observations, we design a discriminative translation model of it, which is then integrated into the TectoMT deep syntax MT framework. Features in the model take advantage of rich syntactic annotation TectoMT is based on, external
tools for anaphoricity resolution, lexical co-occurrence frequencies measured on a large parallel corpus and gold coreference annotation. Even though the new model for it exhibits no improvement in terms of BLEU, manual evaluation shows that it outperforms the original solution in
8.5% sentences containing it."
"Příspěvek se zaměřuje na zlepšování překladu anglického zájmena ""it"" a anglických reflexivních zájmen v systému strojového překladu z angličtiny do češtiny přes tektogramatickkou rovinu.","We focus on improving the translation of the English pronoun it and English reflexive pronouns in an English-Czech syntax-based machine translation framework. Our evaluation both from intrinsic and extrinsic perspective shows that adding specialized syntactic and coreference-related features leads to an improvement in trans-
lation quality."
"Od publikace v roce 2011, ziskala CEFR vedoucí úlohu ve výuce a certifikaci cizích jazyků. Bohužel jednotlivé úrovně CEFR nejsou dostatečně ilustrovány. Cílem projektu Merlin je vyřešit tento problém pro češtinu, němčinu a italštinu.","Since its publication in 2001, the Common European Framework of Reference for Languages (CEFR) has gained a leading role as an instrument of reference for language teaching and certification and for the development of curricula (cf. CEFR 2001). At the same time, there is a growing concern about CEFR reference levels being insufficiently illustrated, leaving practitioners without comprehensive empirical characterizations of the relevant distinctions. This is particularly the case for languages other than English (cf. e.g. Hulstijn 2007, North 2000).
The MERLIN project addresses this demand for the first time for Czech, German and Italian by developing a didactically motivated online platform that enables CEFR users to explore authentic written learner productions that have been related to the CEFR levels in a methodologically sophisticated and rigorous way. The core of the multilingual online platform is a trilingual learner corpus relying on a cross-linguistic design and composed of roughly 2300 learner texts produced in standardized language certifications (as used by telc, DE,  UJOP-Charles University in Prague, CZ as well as UNIcert, DE) validly related to the CEFR, covering the levels A1-C1.
The aim of this paper is both to present the MERLIN project and its corpus, and to discuss its current state. In addition to providing preliminary statistics, we detail three key aspects: (1) the data collection and transcription, (2) the creation of the annotation schemata and (3) the technical design of the workflow devised to compile and query the corpus. For each of these aspects, we highlight its requirements and the means employed for the underlying tasks. We also discuss the challenges induced by the cross-linguistic nature of the project: particularities of the languages from three different families (Slavic, Germanic and Romance) have to be covered, both on a linguistic and a technical perspective."
Tento článek prezentuje komparativní studii 5 různých typů slovních vektorových modelů a 4 různých měr pro měření kompozicionality slovních výrazů.,"This paper presents a comparative study of 5 different types of Word Space Models (WSMs) combined with 4 different compositionality measures applied to the task of automatically determining semantic compositionality of word expressions. Many combinations of WSMs and measures have never been applied to the task before. The study follows Biemann and Giesbrecht (2011) who attempted to find a list of expressions for which the compositionality assumption – the meaning of an expression is determined by the meaning of its constituents and their combination does not hold. Our results are very promising and can be appreciated by those interested in WSMs, compositionali"
Tento článek shrnuje dosavadní modely pro určování kompozicionality slovních výrazů pomocí vektorových modelů a prezentuje náš vlastní přístup založený na latentní sémantické analýze. Experimenty jsou provedeny na testovacích datech DISCO 2011.,"This research focuses on determining semantic compositionality of word expressions using word space models (WSMs). We discuss previous works employing WSMs and present differences in the proposed approaches which include types of WSMs, corpora, preprocessing techniques, methods for determining compositionality, and evaluation testbeds. We also present results of our own approach for determining the semantic compositionality based on comparing distributional vectors of expressions and their components. The vectors were obtained by Latent Semantic Analysis (LSA) applied to the ukWaC corpus. Our results outperform those of all the participants in the Distributional Semantics and Compositionality (DISCO) 2011 shared task."
"Shromáždili jsme anglicky Tamil dvojjazyčných data z některé z veřejně dostupných internetových stránek pro NLP výzkum zahrnující Tamil.Standardní sada zpracování byla použita na nezpracovaná data, než webových údaje byly k dispozici ve větě vyrovnaném anglicky Tamil paralelní korpus vhodný pro různé úlohy NLP. Paralelní korpusy krycí texty z bible, kino a zpravodajských domén.","We have collected English-Tamil bilingual data from some of the publicly available websites for NLP research involving Tamil. The standard set of processing has been applied on the the raw web data before the data became available in sentence aligned English-Tamil parallel corpus suitable for various NLP tasks. The parallel corpora cover texts from bible, cinema and news domains."
"TamilTB 1.0 zlepšuje v průběhu prvního vydání Tamil závislostní korpus (TamilTB v0.1). Aktuální verze přináší řadu vylepšení oproti pravopis a morfologické tagset údajů. Nyní, primární datový reprezentace korpusu používá kódování UTF-8.","TamilTB 1.0 improves over the very first release of the Tamil dependency treebank (TamilTB v0.1). The current version introduces many improvements over the orthography and morphological tagset of the data. Now, the primary data representation of the treebank uses UTF-8 encoding."
V článku představujeme naši práci na rozšíření projektu IBM Content Analytics o analýzu sentimentu za využití softwaru UIMA. Popisujeme jednotlivé komponenty a jejich propojení v rámci komplexnějších dataminigových aplikací.,"In this paper we present UIMA – the Unstructured
Information Management Architecture, an architecture and software framework for creating, discovering, composing and deploying a broad range of multi-modal analysis capabilities and integrating them with search technologies. We describe the elementary components of the framework and how they are deployed into more complex data mining applications. The contribution is based on our experience in work on the sentiment analysis task for IBM Content Analytics project."
"V tomto článku Srovnání Baysovských diskriminativiních a generativních modelů pro sledování dialogového stavu. Bylo zjistěno že oba prezentované modely mají přibližně stejnou přesnost, ale diskriminativní model je zhruba 20 krát výpočetně efektivnější.","In this paper, we describe two dialogue state tracking models competing in the 2012 Dialogue State Tracking Challenge (DSTC). First, we detail a novel discriminative dialogue state tracker which directly estimates slot-level beliefs using deterministic state transition probability distribution. Second, we present a generative model employing a simple dependency structure to achieve fast inference. The models are evaluated on the DSTC data, and both significantly outperform the baseline DSTC tracker."
"Prezentace prvních kroků směrem ke lingvistickému zpracování textů pro detekci sémantických vztahů v nich. Naše práce je klíčovou součastí projektu INTLIB, kterého cílem je vytvořit efektivní a uživatelsky přívětivý nástroj pro dotazování nad textovými dokumenty, odlišný od full-textu. Tento nástroj je navrhován jako obecní framework, který lze snadno modifikovat a rozšiřovat pro další domény. Pilotní doménou projektu jsou legislativní texty. Prezentujeme aplikaci JTagger, která detekuje reference v soudních rozhodnutích a aplikaci RExtractor, která extrahuje vztahy mezi entitami v českých zákonech.","We present our initial steps towards a linguistic processing of texts to detect semantic relations there. Our work is an essential part of the INTLIB project whose aim is to provide a more efficient and user-friendly tool for querying textual documents other than full-text search. This tool is proposed as a general framework which can be modified and extended for particular data domains. Currently, we focus on Czech legal texts. We present the application JTagger which detects references in court decisions and the application RExtractor which extracts relations between entities from Czech laws."
"Prezentujeme první kroky směrem k lingvistickému zpracování textů pro detekci sémantických vazeb. Naše práce je důležitou částí projektu INTLIB, který má za cíl vytvořit efektivnější a uživatelsky více přívětivý nástroj na dotazování v textových dokumentech než full-textové vyhledávání. Tento nástroj je navrhnut jako obecný framework, který bude možno modifikovat a rozšiřovat pro konkrétní datové domény. Aktuálně se zaměřujeme na české legislativní dokumenty.","We present our initial steps towards a linguistic processing of texts to detect semantic relations in them. Our work is an essential part of the INTLIB project whose aim is to provide a more efficient and user-friendly tool for querying textual documents other than full-text search. This tool is proposed as a general framework which can be modified and extended for particular data domains. Currently, we focus on Czech legal texts."
"Aplikace detekuje reference v českých soudních rozhodnutích. Tento úkol chápeme jako typický úkol pro identifikaci jmenných entit, kde entity jsou reference (odkazy) na jiné dokumenty. Aplikujeme přístupy strojového učení s učitelem, konkrétně skryté Markovovy modely. Protože metody strojového učení s učitelem vyžadují manuálně anotovaná trénovací data, anotovali jsme 300 soudních rozhodnutí.","We address the task of reference detection and classification in Czech court decisions. This task is a typical named-entity recognition task where the entities are references (links) to other documents. We apply a supervised machine learning approach, namely Hidden Markov Models. A supervised methodology requires manual annotation of training data so we annotated 300 court decisions."
"Cílem projektu INTLIB, an INTelligent LIBrary, je poskytnout efektivní a uživatelsky přívětivý nástroj pro inteligentnější dotazování než nabízí full text [1]. Projekt je financován Technolofgickou agenturou ČR, grant č. TA02010182.

Na vstupu uvažujeme kolekci dokumentů určité domény (např. legislativa, medicína, životní prostředí, architektura). V první fázi jsou z této kolekce extrahovány znalosti pomocí nástrojů počítačového zpracování přirozeného jazyka. Ve druhé fázi je navrženo inteligentní vyhledávání spolu s vizualizací.

Projektový tým tvoří badatelé z MFF UK ([2], [3]) a podnikatelé ze společnosti Sysnet Ltd. [4]. Představíme výsledky, které jsme doposud dosáhli na legislativní doméně.

[1] http://ufal.mff.cuni.cz/intlib
[2] http://www.ksi.mff.cuni.cz/xrg/
[3] http://ufal.mff.cuni.cz
[4] http://www.sysnet.cz/","The project INTLIB, an INTelligent LIBrary, aims to provide a more efficient and user-friendly tool for querying documents other than full-text [1]. The work is funded by the Technology Agency of the Czech Republic (grant no. TA02010182).

On the input we assume a collection of documents related to a particular problem domain (e.g., legislation, medicine, environment, architecture, etc.). In the first phase we extract a knowledge base from the documents using natural language processing tools. In the second phase we deal with efficient and user friendly visualization and browsing (querying) of the extracted knowledge. 

The project team consists of researchers coming from MFF UK ([2], [3]) and businessmen from Sysnet Ltd. [4]. We will present the results we achieved so far on legislative domain. In addition, we, researchers, will describe our experience gained while cooperating with the commercial partner.

[1] http://ufal.mff.cuni.cz/intlib
[2] http://www.ksi.mff.cuni.cz/xrg/
[3] http://ufal.mff.cuni.cz
[4] http://www.sysnet.cz/"
"Představujeme přístup k publikování legislativních dokumentů ve formě Propojených otevřených dat(LOD). LOD je sada principů, jak publikovat data na webu ve strojově čitelné podobě, aby bylo možné propojit různé zdroje dat.","In this paper, we present an approach of publishing legislative content as Linked Open Data (LOD). LOD is a set of principles of publishing data on the Web in a machine-readable way so that links between different data sets, possibly published by different publishers, can be created. Therefore, LOD enable not only to publish data but also enrich with other existing data published according to the principles. We present what is the motivation for publishing legislation as LOD and what benefits can be gained. We then introduce a legislative ontology which builds on existing commonly used ontologies. We also show how we converted existing sources of legislation in Czech Republic to LOD."
"Tato zpráva popisuje Addicter, nástroj pro automatickou detekci a vyhodnocení chyb, který dává uživateli k dispozici také grafické rozhraní, užitečné pro prohlížení dat.","This report describes Addicter, tool for automatic error detection and evaluation, providing its user also with graphical interface useful for browsing through the dataset."
"Článek přináší výsledky společné úlohy metrik strojového překladu na workshopu WMT13. Účastníci úlohy nechali svými systémy vyhodnotit výstupy strojového překladu. Sebrali jsme hodnocení pomocí celkem 16 metrik od 8 týmů a doplnili hodnocení pomocí 5 standardních metrik (BLEU, WER, PER ad.). Hodnocení pak byla porovnána z hlediska korelace s lidským hodnocením a to jak na úrovni jednotlivých vět, tak na úrovni celého testovacího textu.","This paper presents the results of the WMT13 Metrics Shared Task. We asked participants of this task to score the outputs of the MT systems involved in WMT13 Shared Translation Task. We collected scores of 16 metrics from 8 research groups. In addition to that we computed scores of 5 standard metrics such as BLEU, WER, PER as baselines. Collected scores were evaluated in terms of system level correlation (how well each metric’s scores correlate with WMT13 official human scores) and in terms of segment level correlation (how often a metric agrees with humans in comparing two translations of a particular sentence)."
"Popis soutěžního systému Chiméra populární formou pro HNFuture, vědeckou přílohu elektronického deníku iHNed.","A popularizing description of Chimera, our MT system, for HNFuture, the scientific supplement of the online journal iHNed."
"V příspěvku je popsán proces vytváření korpusu anotovaných vět pro účely postojové analýzy v češtině. Dále je popsán vznik slovníku subjektivních výrazů Sublex 1.0, struktura použitých dat, proces anotace evaluativních stavů a komputační experimenty hodnotící kvalitu anotace.","The paper describes the process of building a Czech language corpus of annotated sentences for sentiment analysis tasks, the SubLex 1.0 subjectivity lexicon, the data, the process of annotation and evaluating experiments."
"V tomto příspěvku představujeme kontrastivní studii jednoho případu provázání nestejných valenčních doplnění v rámci paralelních syntaktických struktur dvou jazyků. Na materiálu Pražského česko-anglického závislostího korpusu (PCEDT) sledujeme věty, v nichž je adresátové valenční doplnění z jednoho jazyka překladově provázáno s patientovým doplněním v jazyce druhém. Konkrétně se zabýváme zejména slovesy ze sémantické třídy ""Judgement"" (slovesa soudu) v širokém pojetí.","In this paper we present a contrastive study of one interesting non-correspondence between deep syntactic valency structures of two different languages. On the material of the Prague Czech-English Dependency Treebank we observe sentences in which an Addressee argument in one language is linked translationally to a Patient argument in the other one, particularly we aim our attention at the class of judgement verbs (in a broad sense)."
Popis textových anotací a jejich vybraných problémů (anotace na stromech a na lineárním textu; nesoulad mezi syntaktickou a diskurzní strukturou; nevyjádřená myšlenka jako diskurzní argument),Description of text annotations and some selected problems of the annotations (annotation on dependency trees and on a plain text; the discrepancy between syntactic structure and discourse structure; an unexpressed thought as a discourse argument)
Příspěvek představuje jednotlivé body automatické předanotace aktuálního členění v české části korpusu PCEDT.,The presentation introduces the individual points of the automatic pre-annotation of topic-focus articulation in the Czech part of the corpus PCEDT.
Příspěvek se zabývá rozlišením explikativních a kauzálních vztahů v češtině.,The paper deals with distinguishing of explicative and causal relationships in Czech.
"Současné metody pro statistický strojový překlad obvykle využívají pouze omezený kontext ve zdrojové větě. Mnoho jazykových jevů tak zůstavá mimo jejich dosah, např. gramatická shoda v morfologicky bohatých jazycích nebo lexikální výběr často vyžadují informace z celé zdrojové věty. V této práci představujeme přehled metod modelování širšího kontextu ve strojovém překladu a popisujeme naše první experimenty.","Current methods for statistical machine translation typically utilize only a
limited context in the input sentence. Many language phenomena thus remain out                                   
of their reach, for example long-distance agreement in morphologically rich
languages or lexical selection often require information from the whole source
sentence. In this work, we present an overview of approaches for including wider
context in SMT and describe our first experiments."
"MTMonkey je webová služba, která obsluhuje a distribuuje žádosti na strojový překlad předávané přes HTTP ve formátu JSON. Rozděluje je na několik strojů, na kterých běží systém pro strojový překlad, a zařizuje preprocessing a postprocessing textu.

Sestává z aplikačního serveru a jednotlivých workerů, které provádějí zpracování textu a komunikaci s překladovým systémem. Komunikace mezi aplikačním serverem a workery je založena na protokolu XML-RPC.","MTMonkey is a web service which handles and distributes JSON-encoded HTTP requests for machine translation (MT) among multiple machines running an MT system, including text pre- and post processing.

It consists of an application server and remote workers which handle text processing and communicate translation requests to MT systems. The communication between the application server and the workers is based on the XML-RPC protocol."
"Představujeme webovou službu, která zpracovává a distribuuje požadavky na strojový překlad (posílané přes HTTP ve formátu JSON). V současné době se používá pro poskytování strojového překladu mezi několika jazyky ve vícejazyčném vyhledávání informací v rámci projektu Khresmoi. Software sestává z aplikačního serveru a vzdálených workerů, kteří zajišťují zpracování textu a komunikují požadavky na překlad systémům strojového překladu. Komunikace mezi aplikačním serverem a workery je založena na protoklolu XML-RPC. Představujeme celkový návrh softwaru a výsledky testů, který dokumentují rychlost a škálovatelnost našeho řešení. Software podléhá licenci Apache 2.0 a je dostupný ke stažení v repozitáři Lindat-Clarin a na serveru GitHub.","We present a web service which handles and distributes JSON-encoded HTTP 
requests for machine translation (MT) among multiple machines running
an MT system, including text pre- and post processing.
It is currently used to provide MT between several languages 
for cross-lingual information retrieval in the Khresmoi project.
The software consists of an application server and remote workers which handle
text processing and communicate translation requests to MT 
systems. The communication between the application server and the workers is
based on the XML-RPC protocol. We present
the overall design of the software and test results which document
speed and scalability of our solution.  
Our software is licensed under the Apache 2.0 licence and is available for 
download from the Lindat-Clarin repository and Github."
"Stručně představujeme frázový strojový překlad a nástroj Moses. Popisujeme Emana, nástroj pro správu experimentů, a ukazujeme, jak ho lze využít k trénování několika jednoduchých systémů pro strojový překlad.","We give a brief introduction to phrase-based machine translation and the Moses toolkit. We present Eman, an experiment manager, and show how to use it to train several simple MT systems."
"Faktorové modely byly úspěšně nasazeny pro řadu jazykových párů, kde zlepšily různé aspekty kvality překladu. V této práci analyzujeme toto paradigma a pokoušíme se automatizovat hledání kvalitních překladových systémů. Zkoumáme prostor možných faktorových systémů a shledáváme, že plně automatické hledání není proveditelné. Ukazujeme, že i když jsou k dispozici výsledky automatické evaluace, zacílení prohledávání je obtížné kvůli malým rozdílům mezi jednotlivými systémy. Tyto rozdíly jsou dále rozmazány náhodností ladění vah. Popisujeme heuristiku pro odhad složitosti faktorových modelů. Závěrem popisujeme možnosti ""polo-automatického"" prohledávání prostoru v několika směrech a vyhodnocujeme získané systémy.","Factored models have been successfully used in many language pairs to improve translation quality in various aspects. In this work, we analyze this paradigm in an attempt at automating the search for well-performing machine translation systems. We examine the space of possible factored systems, concluding that a fully automatic search for good configurations is not feasible. We demonstrate that even if results of automatic evaluation are available, guiding the search is difficult due to small differences between systems, which are  further blurred by randomness in tuning. We  describe a heuristic for estimating the complexity of factored models. Finally, we discuss the possibilities of a ""semi-automatic"" exploration of the space in several directions and evaluate the obtained systems."
"Článek popisuje CzeSL, žákovský korpus češtiny jako druhého jazyka. Nejdříve je popsán v kontextu  Akces, souboru akvizičních korpusů češtiny. Dále je diskutováno zamýšlené využití CzeSLu. Jádro příspěvku se zabývá transkripcí a anotací.","The paper describes CzeSL, a learner corpus of Czech as a Second Language, together with its design properties. We start with a brief introduction of the project within the context of AKCES, a programme addressing Acquisition Corpora of Czech; in connection with the programme we are also concerned with the groups of respondents, including differences due to their L1; further we comment on the choice of the sociocultural metadata recorded with each text and related both to the learner and the text production task. Next we describe the intended uses of CzeSL. The core of the paper deals with transcription and annotation. We explain issues involved in the transcription of handwritten texts and present the concept of a multi-level annotation scheme including a taxonomy of captured errors. We conclude by mentioning results from an evaluation of the error annotation and presenting plans for future research."
"Popis a analýza anotace žákovského korpusu češtiny. Anotační schéma sestává ze tří propojených rovin, každá opravující jiný typ chyb. Anotační schéma bylo testováno na cca 175.000 slovech s rozumnou výslednou IAA. Na závěr diskutujeme možnost automatické anotace.","The paper describes a corpus of texts produced by non-native speakers of Czech. We discuss its annotation scheme, consisting of three interlinked tiers, designed to handle a wide range of error types present in the input. Each tier corrects different types of errors; links between the tiers allow capturing errors in word order and complex discontinuous expressions. Errors are not only corrected, but also classified. The annotation scheme is tested on a data set including approx. 175,000 words with fair inter-annotator agreement results. We also explore the possibility of applying automated linguistic annotation tools (taggers, spell checkers and grammar checkers) to the learner text to support or even substitute manual annotation."
"Radikálně nový lexikální, na korpusech založený přístup k lingvistické teorii a praktické analýze jazyka. Kniha ukazuje, že přirozený jazyk se v zásadě skládá z množství pravidelných vzorů klauzí (""norem""), ve kterých paradigmatické množiny lexikálních položek odpovídají klauzálním rolím neboli ""argumentům"", s ohledem na běžnou valenční strukturu.","A radically new lexical, corpus-driven approach to linguistic theory and the practical analysis of language. The book argues that a natural langauge consists, basically, of a number of regular clause patterns (""norms""), in which paradigm sets of lexical items map into clause roles or ""arguments"", given normal valency structure. The picture is complicated because every pattern allows certain alternations, and every aspect of normal usage can be ""exploited"" creatively by language users. The book offers a typology of linguistic exploitations."
Rozhovor pro stanici Rádio Česko popisující různé přístupy ke strojovému překladu a potíže s přirozeným jazykem obecně.,An interview for Radio Czech describing various approaches to machine translation and the difficulties with handling natural languages in general.
"Představujeme Pražský diskurzní korpus 1.0, soubor českých textů anotovaných na rovině textových jevů, tj. ""nad úrovní popisu věty"". Korpus obsahuje ruční anotace (1)textových konektorů, jejich argumentů a významů, (2) textové koreference a (3) tzv. bridging anafory, to vše na 50k větách korpusu.","We present the Prague Discourse Treebank
1.0, a collection of Czech texts annotated for
various discourse-related phenomena ""beyond
the sentence boundary"". The treebank contains
manual annotations of (1), discourse connectives,
their arguments and senses, (2), textual
coreference, and (3), bridging anaphora, all
carried out on 50k sentences of the treebank.
Contrary to most similar projects, the annotation
was performed directly on top of syntactic
trees (from the previous project of the Prague
Dependency Treebank 2.5), benefiting thus
from the linguistic information already existing
on the same data. In this article, we present
our theoretical background, describe the annotations
in detail, and offer evaluation numbers
and corpus statistics."
"V přednášce byl prezentován popis systémů strojového překladu mezi češtinou a ruštinou, a to statistických a pravidlových.",This talk described several Machine Translation systems between Czech and Russian that were developed or implemented by UFAL researchers.  We discuss which of the approaches - Statistical or Rule-Based is more suitable for MT between related morphologically rich languages. The focus is made on analyzing valency discrepancies between the two languages and their impact on MT.
V článku je popsana frekvence užití nefinitních konstrukcí s přechodníky a příčestí v češtině a ruštině.,"This paper describes one of the discrepancies between the languages that occur in non-finite clauses, namely in participial clauses and transgressives. We will concentrate mainly on
transgressives because they demonstrate greater discrepancies. The usage of Russian transgressives(gerunds) is very similar to that of
English, they are typical mostly of a written language rather than spoken, whereas in Czech they are nowadays archaic in any genres and generally not used at all. This discrepancy can pose some challenge for language learners as well as for translators or machine translation systems. We will present some examples of
Russian participial/gerund clauses and the respective translations into Czech from a parallel corpus of news and belletristic texts."
"Taxonomie strojového překladu
Online učení
Guided učení
Easy-First dekódování ve strojovém překladu
Guided učení ve strojovém překladu","Machine Translation Taxonomy
Online Learning
Guided Learning
Easy-First Decoding in MT
Guided Learning in MT"
"Treex je platforma pro nástroje zpracování přirozeného jazyka.
NIF je formát založený na RDF, který by měl sloužit k propojování takovýchto nástrojů.
Přednáška popisuje Treex a další nástroje a treebanky vyvíjené na ÚFAL. Zaměřuje se též na podobnosti a rozdíly s formátem NIF a iniciativou nlp2rdf.","Treex is a framework for NLP tools. NIF (NLP Interchange format) is an RDF/OWL-based format that aims to achieve interoperability between NLP tools, language resources and annotations. The presentation describes Treex and other tools/treebanks developed at ÚFAL. It focuses on its similarities and differences compared to NIF (and the NLP2RDF initiative)."
"O parataktických syntaktických strukturách je známo, že jejich zachycení pomocí závislostních mechanismů je obtížné, což má bolestivé důsledky jako značné množství chyb v automatické syntaktické analýze, které souvisí s koordinacemi. Jinými slovy, koordinace je nevyřešeným problémem závislostní analýzy přirozených jazyků. Tento článek se snaží vnést trochu světla do této oblasti a přináší systematický přehled různých formálních prostředků vyvinutých k zachycení souřadných struktur. Přinášíme novou taxonomii takových přístupů a aplikujeme ji na treebanky z typologicky rozličné sady 26 jazyků. Dále prezentujeme empirická pozorování, pokud jde o vzájemnou převoditelnost mezi vybranými styly zachycení.","Paratactic syntactic structures are notoriously
difficult to represent in dependency formalisms, which has painful consequences such as high frequency of parsing errors related to coordination. In other words, coordination is a pending problem in dependency analysis of natural languages. This paper tries to shed some light
on this area by bringing a systematizing view of various formal means developed for encoding coordination structures. We introduce a novel taxonomy of such approaches and apply it on treebanks across a typologically diverse range of 26 languages. Empirical observations on convertibility between selected styles of representations are shown too."
"Praktický seminář představení platformu Treex, která slouží k integraci nástrojů pro zpracování přirozeného jazyka. Semináři předcházela přednáška o překladovém systému TectoMT vyvinutém v platformě Treex.",Hands-on tutorial on using Treex - a modular framework for Natural Language Processing. The tutorial was preceded by a presentation about TectoMT deep-syntactic MT system developed in Treex.
Přednáška představuje žákovský korpus češtiny a jeho anotační schéma sestavající ze propojených tří rovin. Každá rovina zachycuje a opravuje jiný typ chyb.,"We describe a corpus of texts produced by non-native speakers of Czech. We discuss its annotation scheme, consisting of three interlinked levels to cope with a wide range of error types present in the input. Each level corrects different types of errors; links between the levels allow capturing errors in word order and complex discontinuous expressions. Errors are not only corrected, but also classified. The annotation scheme is tested on a doubly-annotated sample of approx. 10,000 words with fair inter-annotator agreement results. We also explore options of application of automated linguistic annotation tools (taggers, spell checkers and grammar checkers) on the learner text to support or even substitute manual annotation."
Tento článek popisuje kompilaci a anotaci korpusu staré češtiny.,"In this paper we describe our efforts to build a corpus of Old Czech. We report on tools, resources and methodologies used during the corpus development as well as discuss the corpus sources and structure, the tagset used, the approach to lemmatization, morphological analysis and tagging. Due to practical restrictions we adapt resources and tools developed for Modern Czech. However, some of the described challenges, such as the non-standardized spelling in early Czech and the form and lemma variability due to language change during the covered time-span, are unique and never arise when building synchronic corpora of Modern Czech."
Článek popisuje nový způsob jak získat více morfologicky a syntakticky oanotovaných dat.,"We present a new way to get more morphologically and syntactically annotated data. We have developed an annotation editor tailored to school children to involve them in text annotation. Using this editor, they practice morphology and dependency-based syntax in the same way as they normally do at (Czech) schools, without any special training. Their annotation is then automatically transformed into the target annotation schema. The editor is designed to be language independent, however the subsequent transformation is driven by the annotation framework we are heading for. In our case, the object language is Czech and the target annotation scheme corresponds to the Prague Dependency Treebank annotation framework."
"V tomto článku popisujeme Prague Markup Language (PML), generický a otevřený formát založený na XML vytvořený za účelem definice formátů lingvistických zdrojů, zvláště anotovaných korpusů.","In this paper we describe the Prague Markup Language (PML), a generic and open XML-based format intended to define format of linguistic resources, mainly annotated corpora. We also provide an overview of existing tools supporting PML, including annotation editors, a corpus query system, software libraries, etc."
Článek popisuje žákovský korpus češtiny a jeho anotační schéma sestavající ze propojených tří rovin. Každá rovina zachycuje a opravuje jiný typ chyb.,"The paper describes a corpus of texts produced by non-native speakers of Czech. We discuss its annotation scheme, consisting of three interlinked levels to cope with a wide range of error types present in the input. Each level corrects different types of errors; links between the levels allow capturing errors in word order and complex discontinuous expressions. Errors are not only corrected, but also classified. The annotation scheme is tested on a doubly-annotated sample of approx. 10,000 words with fair inter-annotator agreement results. We also explore options of application of automated linguistic annotation tools (taggers, spell checkers and grammar checkers) on the learner text to support or even substitute manual annotation."
Tento článek shrnuje jednojazyčné přístupy k morfologické analýze a tagování nenáročné na zdroje.,"This article surveys resource-light monolingual approaches to morphological analysis and tagging. While supervised analyzers and taggers are very accurate, they are extremely expensive to create. Therefore, most of the world languages and dialects have no realistic prospect for morphological tools created in this way. The weakly-supervised approaches aim to minimize time, expertise and/or financial cost needed for their development. We discuss the algorithms and their performance considering issues such as accuracy, portability, development time and granularity of the output."
"Článek popisuje, které typy volných slovesných doplnění vystupují jako obligatorní a jak často.",The paper describes which types of free verbal modifications may be obligatory and how often.
"The poster deals with the sentence information structure (functional sentence perspective) in Czech, focusing on the tendency of the particular sentence constituents to appear in Czech sentence as topic or focus.",Poster se týká aktuálního členění větného v češtině - prezentuje tendenci jednotlivých větných participantů objevovat se v české větě jako téma nebo réma.
"Podle současných studií je okcipito-temporální ERP komponenta N170 levostranně modulována a posílena řetězci znaků, narozdíl od nelingvistických vstupů podobné vizuální komplexity. Tento výsledek je konzistentní s neurálními mechanismy, které zajišťují vizuální rozpoznávání slov. Avšak závěry o úrovních analýzy, které ovlivňují projevy N170, jsou nejednoznačné. V této studii jsme zkoumali časový průběh a kvalitu reakcí mozku na podněty předpokládané nižší a vyšší úrovně zpracování. Podněty nižší úrovně byly modulovány manipulací rotace písmen parametricky v 0 stupních, 22,5 stupních, 45 stupních, 67,5 stupních a 90 stupních. Vyšší úroveň zpracování byla modulována manipulací s lexikálnim statutem (slova vs. pseudoslova). Při zvyšování úhlu rotace písmen se amplituda N170 monotonicky zvyšovala až do úhlu 67,5, ale pak při úhlu 90 stupňů se opět snížila. Pseudoslova v porovnání se slovy zvětšila amplitudu N170 v levé okcipito-temporální oblasti. Tyto kombinované výsledky jsou konzistentní s kaskádovou, interaktivní architekturou, ve které nižší úroveň analýzy (např. rozpoznání tvaru slov) časově předchází vyšší úrovni analýzy (např. lexikální status), ale již v čase 170 ms reakce mozku na vizuální slovní podnět obsahuje paralelní, interaktivní zpracování na obou úrovních.","Recent studies report that the occipito-temporal N170 component of the ERP is enhanced by letter strings, relative to non-linguistic strings of similar visual complexity, with a left-lateralized distribution. This finding is consistent with underlying mechanisms that serve visual word recognition. Conclusions about the level of analysis reflected within the N170 effects, and therefore the timecourse of word recognition, have been mixed. Here, we investigated the timing and nature of brain responses to putatively low- and high-level processing difficulty. Low-level processing difficulty was modulated by manipulating letter-rotation parametrically at 0 degrees, 22.5 degrees, 45 degrees, 67.5 degrees, and 90 degrees. Higher-level processing difficulty was modulated by manipulating lexical status (words vs. word-like pseudowords). Increasing letter-rotation enhanced the N170 led to monotonic increases in P1 and N170 amplitude up to 67.5 degrees but then decreased amplitude at 90 degrees. Pseudowords enhanced the N170 over left occipital-temporal sites, relative to words. These combined findings are compatible with a cascaded, interactive architecture in which lower-level analysis (e.g., word-form feature extraction) leads higher-level analysis (e.g., lexical access) in time, but that by approximately 170 ms, the brain's response to a visual word includes parallel, interactive processing at both low-level feature extraction and higher-order lexical access levels of analysis."
"Příspěvek se zabývá vlastnostmi nejčastějších konektivních prostředků kauzálního vztahu v Pražském závislostním korpusu (konkrétně jde o výrazy protože, neboť, proto, takže, tak, tedy a totiž).  Některé vlastnosti těchto konektivních prostředků popisuje nezávisle na kontextu (např. pozici ve větě, kombinovatelnost s jinými spojovacími výrazy), u většiny vlastností si všímá i charakteristik frekvenčních (jak často spojují dané výrazy části textu v rámci jednoho větného celku, jak často přes jeho hranice, jak často se užívají ke spojování verbálních frází a jak často jinde apod.). Jeho cílem je ukázat, jaké vlastnosti tyto prostředky sdílejí a které vlastnosti jsou naopak pro jednotlivé prostředky specifické. Zároveň chce přispět k diskusi o slovnědruhové charakteristice zkoumaných výrazů – pozorované vlastnosti jsou vztaženy k charakteristikám uváděným ve vybrané odborné literatuře a jsou uvedena kritéria, podle kterých je možné zkoumané výrazy slovnědruhově popisovat. Jako materiálová základna výzkumu byla zvolena data uvolněná v Pražském závislostním korpusu pro lingvistický výzkum (43 955 vět (740 532 slov)), protože současná podoba značkování v tomto korpusu umožňuje měřit vlastnosti zkoumaných výrazů v rámci jednoho větného celku i přes jeho hranice.","This contribution deals with properties of most common connective means of the causal relation in the Prague Dependency Treebank (namely with expressions protože (because), neboť (because), proto (therefore), takže (so), tak (so), tedy (thus) and totiž (because, namely, sometimes untranslatable)). Some properties of these connectives are described independently of context (e.g. position in the sentence, compatibility with other connectives), the majority of properties is characterized also with regard to frequency (how often these expressions connect parts of one sentence and how often parts of text across sentence boundaries, how often they are used to connect verbal phrases and how often something else, etc.). Its general aim is to show which properties are shared by all these connectives (or by some of them) and which are, on the contrary, specific for each of them. This paper also wants to contribute to the discussion of the part-of-speech characteristics of these connectives – a relation of the observed properties of connectives to the characteristics reported in the relevant Czech literature is described and some criteria for their part-of-speech characteristics are stated. As the material base, data released in the Prague Dependency Treebank for linguistic research (43,955 sentences (740,532 words)) were chosen, because the current state of tagging in this corpus enables us to measure the properties of all connectives regardless of whether they connect parts of one sentence or parts of text across sentence boundaries."
Článek prezentuje analýzu nejčastějších anotátorských chyb v projektu anotace mezivýpovědních textových vztahů v PDT,"We present an analysis of the inter-annotator discrepancies of the Czech discourse annotation in the Prague Dependency Treebank 2.0. Having finished the annotation of the inter-sentential semantic discourse relations with explicit connectives in the treebank, we report now on the results of the evaluation of the parallel (double) annotations, which is an important step in the process of checking the quality of the data. After we shortly describe the annotation and the method of the inter-annotator agreement measurement, we present the results of the measurement and, most importantly, we classify and analyze the most common types of annotators’ disagreement."
"Článek popisuje a vyhodnocuje proces poloautomatické anotace vnitrovětných textových vztahů v Pražském závislostním korpusu, což je část projektu jinak především manuální anotace všech (vnitro- i mezi-větných) diskurzních vztahů s explicitními konektory v tomto korpusu. Bohatá anotace korpusu nám umožnila ve většině případů automaticky najít vnitrovětné diskurzní vztahy, jejich konektory a argumenty.","In the present paper, we describe in detail and evaluate the process of semi-automatic annotation of intra-sentential discourse relations in the Prague Dependency Treebank, which is a part of the project of otherwise mostly manual annotation of all (intra- and inter-sentential) discourse relations with explicit connectives in the treebank. The rich annotation of the treebank allowed us to automatically detect the intra-sentential discourse relations, their connectives and arguments in most of the cases."
V posledních letech se výzkum v oblasti strojového překladu zaměřil na hybridní strojový překlad a kombinaci překladových systémů za účelem vylepšení překladové kvality. Jako první krok ke splnění tohoto cíle jsme vytvořili paralelní korpus vět přeložených několika různými systémy opatřenými různými metadaty a anotacemi získanými při překladu.,"In recent years, machine translation (MT) research has focused on investigating how hybrid machine translation as well as system
combination approaches can be designed so that the resulting hybrid translations show an improvement over the individual “component”
translations. As a ﬁrst step towards achieving this objective we have developed a parallel corpus with source text and the corresponding
translation output from a number of machine translation engines, annotated with metadata information, capturing aspects of the
translation process performed by the different MT systems. This corpus aims to serve as a basic resource for further research on
whether hybrid machine translation algorithms and system combination techniques can beneﬁt from additional (linguistically motivated,
decoding, and runtime) information provided by the different systems involved. In this paper, we describe the annotated corpus we have
created. We provide an overview on the component MT systems and the XLIFF-based annotation format we have developed. We also
report on ﬁrst experiments with the ML4HMT corpus data."
Tato kapitola popisuje metody učení z dat vhodné pro vývoj systémů porozumění mluvené řeči pro dialogové systémy.,This chapter described data-driven methods suitable for development of spoken language understanding components in dialogue systems.
V příspěvku představím kroky vedoucí k spolehlivým klasifikátorům polarity založeným na českých datech. Popíšu metodologické základy anotování českých struktur a unigramové klasifikátory trénované na třech druzích dat. Rovněž zanalyzuji existující výsledky pro manuální i automatickou anotaci.,"In this talk I present work towards building a reliable polarity classifiers based on Czech data. I will describe a method for annotating Czech evaluative structures and introduce a standard unigram-based Naive Bayes classifier together with the lexicon-based classifier, both trained on three different types of data. Also, I will analyze existing results for both manual and automatic annotation.

Joint work with Jan Hajič, jr. and Jana Šindlerová."
Reportáž z první mezinárodní konference v závislostní lingvistice spojená se zamyšlením nad jejím současným stavem.,Report on the first international conference in dependency grammar and reflexion of its current state.
V článku je prezentována počáteční fáze výzkumu postojové analýzy v češtině: metoda anotování evaluativních struktur a první výsledky manuální i automatické anotace.,This paper presents initial research in the area of sentiment analysis in Czech. We will describe a method for annotating Czech evaluative structures and analyze existing results for both manual and automatic annotation of the plain text data which represents the basis for further subjectivity clues learning.
"Tento článek má dvojí cíl: jednak chceme prezentovat tu část anotačního schématu nedávno vydaného korpusu PCEDT2.0, která je spjata s anotací anglického zájmene “it” na tektogramatické rovině, jednak představujeme experimenty týkající se automatické identifikace anglického “it” a jeho českého protějšku. Navrhli jsme soubor pravidel pro stromové struktury, která v rámci anglické části korpusu kombinujeme se současnými statistickými systémy, což v důsledku vede ke zlepšení automatické detekce. Mimoto jsme také navrhli a úspěšně aplikovali pravidla, která využívají informace z paralelních českých struktur.","In this paper we have two goals. First, we want to present a part of the annotation scheme of the recently released Prague Czech-English Dependency Treebank 2.0 related to the annotation of personal pronoun it on the tectogrammatical layer of sentence representation. Second, we introduce experiments with the automatic identification of English personal pronoun it and its Czech counterpart. We design sets of tree-oriented rules and on the English side we combine them with the state-of-the-art statistical system that altogether results in an improvement of the identification. Furthermore, we design and successfully apply rules, which exploit information from the other language."
"Článek popisuje první kroky vedoucí ke spolehlivé automatické klasifikaci větné polarity v češtině. Objasňujeme metodu anotace českých evaluativních struktur a trénování základního bayesovského klasifikátoru na třech typech dat, včetně analýzy dosažených výsledků, z nichž některé jsou srovnatelné s výsledky, jichž bylo dosud docíleno v oblasti postojové analýzy jako takové (viz např. Cui, 2006).","This paper presents the first steps towards reliable polarity classification based on Czech data. We describe a method for annotating Czech evaluative structures and build a standard unigram-based Naive Bayes classifier on three different types of annotated texts. Furthermore, we analyze existing results for both manual and automatic annotation, some of which are promising and close to the state-of-the-art performance, see Cui(2006)."
"Nerízená závislostní analýza je alternativní zpusob urcování vztahu mezi slovy ve vete. Nepotrebuje žádný anotovaný závislostní korpus, je nezávislý na jazykové teorii a univerzální pro velké množství jazyku. Jeho nevýhodou je ale zatím relativne nízká úspešnost.
V této práci diskutujeme nekteré predchozí práce a predstavujeme novou metodu nerízenéhé analýzy.
Náš závislostní model se skládá ze ctyr podmodelu: (i) hranový model, který rídí rozdelení dvojic rídících a závislých clenu, (ii) model plodnosti, který rídí pocet clenu závislých na uzlu, (iii) model vzdálenosti, který rídí délku závislostních hran a (iv) model vypustitelnosti. Tento model je založen na
predpokladu, že slovau která se mohou z vety vypustit, aniž by se porušila její gramaticnost jsou v závislostním slove listy.
Odvození závislostních struktur provádíme pomocí Gibbsova vzorkovace. Predstavujeme vzorkovací
algoritmus, který zachovovává projektivitu závislostních stromu, cože je velmi užitecnou vlastností. V našich experimentech na 30 jazycích srovnáváme výsledky pro ruzné parametry modelu.
Naše metoda prekonávvá dríve publikované výsledky pro vetšinu zkoumaných jazyku.","Unsupervised dependency parsing is an alternative approach to identifying relations
between words in a sentence. It does not require any annotated treebank, it
is independent of language theory and universal across languages. However, so far
quite low parsing quality is its main disadvantage.
This thesis discusses some previous works and introduces a novel approach to
unsupervised parsing. Our dependency model consists of four submodels: (i) edge
model, which controls the distribution of governor-dependent pairs, (ii) fertility
model, which controls the number of node's dependents, (iii) distance model, which
controls the length of the dependency edges, and (iv) reducibility model. The reducibility
model is based on a hypothesis that words that can be removed from a
sentence without violating its grammaticality are leaves in the dependency tree.
Induction of the dependency structures is done using Gibbs sampling method.
We introduce a sampling algorithm that keeps the dependency trees projective,
which is a very valuable constraint.
In our experiments across 30 languages, we discuss the results of various settings
of our models. Our method outperforms the previously reported results on a
majority of the test languages."
"The possibility of deleting a word from a sentence without violating its syntactic correctness belongs to traditionally known manifes
tations of syntactic dependency. We introduce
a novel unsupervised parsing approach that is
based on a new n-gram reducibility measure.
We perform experiments across 18 languages
available in CoNLL data and we show that
our approach achieves better accuracy for the
majority of the languages then previously reported results.",Predstavujeme novy pristup k nerizenemu zavislostnimu parsingu zalozenemu na mire vypustitelnosti jednotlivych sekvenci slov.
"This paper describes a system for unsuper-
vised dependency parsing based on Gibbs
sampling algorithm. The novel approach in-
troduces a fertility model and reducibility
model, which assumes that dependent words
can be removed from a sentence without vio-
lating its syntactic correctness.",Popis systemu nerizeneho zavislostniho parsingu zalozeneho na Gibbsove samplingu. Novy pristup predstavuje vlastnosti vypusttelnsti a fertility.
"Jedním z nejvýznamnějších nedávných vylepšení anglicko-českého překladače TectoMT je systematická a teoreticky podložená revize formémů. Formémy jsou anotací mofo-synaktických rysů plnovýznamových slov v hloubkově syntaktické závislostní syntaxi založené na tektogramatice. Naše úpravy měly za cíl snížit řídkost dat, zvýšit konzistenci anotace napříč jazyky a otevřít nové oblasti využití formémů. Formémy jsou využívány ve strojovém překladu i v dalších úlohách zpracování přirozeného jazyka.","One of the most notable recent improvements of the TectoMT English-to-Czech translation is a systematic and theoretically supported revision of formemes—the annotation of morpho-syntactic features of content words in deep dependency syntactic structures based on the Prague tectogrammatics theory. Our modifications aim at reducing data sparsity, increasing consistency across languages and widening the usage area of this markup. Formemes can be used not only in MT, but in various other NLP tasks."
"V disertační práci podáváme návrh reprezentace lexikálně-sémantických konverzí
ve valenčním lexikonu. Lexikálně-sémantické konverze chápeme jako vztahy mezi
sémanticky blízkými syntaktickými konstrukcemi tvořenými odlišnými lexikálními
jednotkami lexematicky totožného slovesa. Tyto vztahy jsou spojeny se změnami
ve valenční struktuře slovesa, které vyplývají ze změn ve vzájemném přiřazení situačních
participantů a valenčních doplnění. Tyto změny mohou zasahovat počet, typ valenčních
doplnění, jejich obligatornost i morfematickou formu. Na základě sémantické a syntaktické
analýzy dvou typů lexikálně-sémantické konverze, lokativní konverze a konverze Nositel
děje-Místo, navrhujeme, aby lexikálním jednotkám vytvářejícím syntaktické varianty
ve vztahu lexikálně-sémantické konverze v datové části lexikonu odpovídaly odlišné
valenční rámce propojené atributem -conv, jehož hodnotou bude typ lexikálně-sémantické
konverze. Součástí pravidlové komponenty valenčního lexikonu pak budou pravidla
určující změny ve vzájemné korespondenci situačních participantů a valenčních doplnění.
Ačkoli reprezentaci lexikálně-sémantické konverze primárně navrhujeme pro účely popisu
valence českých sloves ve valenčním slovníku VALLEX, předpokládáme, že poznatky
uváděné v této práci mohou být využity při popisu tohoto typu vztahu i v dalších
lexikálních zdrojích.","In this thesis, we provide an adequate lexicographic representation of lexicalsemantic
conversion. Under the term lexical-semantic conversion, the relation between
semantically similar syntactic structures which are based on separate lexical units of the
same verb lexeme is understood. These relations are associated with various changes in
valency structure of verbs – they may involve a number of valency complementations, their
type, obligatoriness as well as morphemic forms. These changes arise from differences in
the mapping of situational participants onto valency complementations. On the basis of
semantic and syntactic analysis of two types of Czech lexical-semantic conversions, the
locative conversion and the conversion Bearer of action-Location, we propose to represent
lexical units creating syntactic variants in the relation of lexical semantic conversion by
separate valency frames stored in the data component of the lexicon. The special attribute
-conv whose value is a type of lexical-semantic conversion is assigned to relevant valency
frames. Then the rule component of the lexicon consists of general rules determining
changes in the correspondence between situational participants and valency
complementations. This proposal is primarily designed for the valency lexicon of Czech
verbs, VALLEX. However, we suppose that this representation can be applied in other
lexical resources as well."
"V příspěvku jsme se zabývali syntaktickými konstrukcemi typu Včely se hemží na zahradě –- Zahrada se hemží včelami, které chápeme jako
specifický typ lexikálně-sémantické konverze, u níž dochází ke změnám
v korespondenci dvou situačních participantů (s rolí Nositel děje a Místo)
a valenčních doplnění. Tyto změny mají za následek změny v povrchově syntaktické realizaci daných participantů, které zasahují prominentní pozici subjektu,
v níž je jednou vyjádřen Nositel děje (Včely se hemží na zahradě) a podruhé Místo (Zahrada se hemží včelami). Zatímco prvně zmíněná syntaktická varianta vyjadřuje neakční elementární děj, druhá varianta označuje procesuálně pojatý
stav. Předpokládáme potom, že holistická interpretace participantu Místo
ve druhé syntaktické variantě vyplývá přímo ze stavového významu dané konstrukce. Dále příspěvek pojednává o bezpomětových konstrukcích a konstrukcích
s formálním subjektem to, které vytvářejí formální paralelu k probíraným konstrukcím. Na závěr předkládáme možnou lexikografickou reprezentaci lexikálně-sémantické konverze daného typu, v níž informaci přerozdělujeme mezi
datovou a pravidlovou část lexikonu.","In this paper, we focus on the relation between Czech syntactic constructions Bees are swarming in the garden –- The garden is swarming with bees. We refer to
this relation as a lexical-semantic conversion. This lexical-semantic conversion is associated with changes in the correspondence between two situational participants –- Bearer
of action and Location –- and valency complementations. These changes result in
a permutation of these participants which affects the prominent surface syntactic position
of subject. We demonstrate that whereas the first syntactic variant refers to a simple action, the latter expresses rather a state arising from this simple action. In the latter case,
the participant Location is usually holistically interpreted. We assume that the holistic ef-
fect of this participant follows from the fact that a state is generally attributed to
each participant expressed in the subject position as a whole. Furthermore, syntactic variants with formal subject “to” and subjectless constructions (usually conceived as formal
paraphrases of the pairs of the observed constructions) are discussed. Finally,
a lexicographic representation of these syntactic structures is presented"
"Termínem gramatické alternace označujeme změny ve valenční stuktuře sloves, které odpovídají rozdílným povrchově syntaktickým strukturám tvořeným jedinou lexikální jednotkou slovesa. České gramatikalizované alternace jsou vyjadřovány buď (i) morfologickými prostředky (diateze), nebo (ii) prostředky převážně syntaktickými (reciprocita). Změny ve valenčním rámci slovesa jsou v tomto případě omezeny na změny v morfematické realizaci valenčních doplnění, které jsou natolik pravidelné, že mohou být zachyceny formálními syntaktickými pravidly.","Under the term grammaticalized alternations, we understand changes in valency frames of verbs corresponding to different surface syntactic structures of the same lexical unit of a verb. Czech grammaticalized alternations are expressed either (i) by morphological means (diatheses),
or (ii) by syntactic means (reciprocity). These changes are limited to changes in morphemic form(s) of valency complementations; moreover,
they are regular enough to be captured by formal syntactic rules.
In this paper a representation of Czech grammaticalized alternations and their possible combination is proposed for the valency lexicon of Czech verbs, VALLEX."
"V tomto článku popisujeme projekt zaměřený na obohacení valenčního lexikonu českých sloves, VALLEX, o sémantické informace z FrameNetu. V tomto projektu bylo celkem osm skupin českých sloves anotováno sémantickými rámci z FrameNetu. Na základě sémantických rámců z horních pater relace dědičnosti byla tato slovesa rozdělena do koherentních sémantických tříd. Valenčním doplněním daných sloves byly dále přiděleny elementy sémantických rámců z horních pater relace dědičnosti jako sémantické role.","In this article, we introduce a project aimed at enhancing a valency lexicon of Czech verbs
with semantic information. For this purpose, we make use of FrameNet, a semantically ori-
ented lexical resource. At the present stage, semantic frames from FrameNet have been mapped
to eight groups of verbs with various semantic and syntactic properties. The feasibility of this
task has been verified by the achieved inter-annotator agreement measured on two semantically
and syntactically different groups of verbs –- verbs of communication and exchange (85.9% and
78.5%, respectively). Based on the upper level semantic frames from the relation of ‘Inheritance’
built in FrameNet, the verbs of these eight groups have been classified into more coherent se-
mantic classes. Moreover, frame elements from these upper level semantic frames have been
assigned to valency complementations of the verbs of the listed groups as semantic roles. As
in case of semantic frames, the achieved interannotator agreement concerning assigning frame
elements measured on verbs of communication and exchange has been promising (95.6% and
91.2%, respectively).


As a result, 1 270 lexical units pertaining to the verbs of communication, mental action,
psych verbs, social interaction, verbs of exchange, motion, transport and location (2 129 Czech
verbs in total if perfective and imperfective verbs being counted separately) have been classified
into syntactically and semantically coherent classes and their valency complementations have
been characterized by semantic roles adopted from the FrameNet lexical database."
"V tomto příspěvku přinášíme popis alternačního modelu valenčního lexikonu českých sloves, VALLEX. V práci rozlišujeme celkem dva základní typy alternací (změn ve valenční struktuře sloves): (i) gramatikalizované a (ii) lexikalizované alternace. Jak gramatikalizované, tak lexikalizované alternace mohou být konverzní či nekonverzní povahy. Zatímco gramatikalizované alternace spojují rozdílné povrchové strukturace téže lexikální jednotky, lexikalizované alternace charakterizují syntaktické struktury tvořené rozdílnými lexikálními jednotkami. Pro účely reprezentace alternací rozdělujeme lexikon na datovou a pravidlovou část. V datové části je každá lexikální jednotka reprezentována jedním valenčním rámcem. Pravidlová část obsahuje dva typy pravidel: (i) formální syntaktická pravidla zachycující gramatikalizované alternace a (ii) obecná pravidla určující změny v korespondenci participantů a valenčních doplnění typické pro lexikalizované alternace.","In this paper, alternation based model of the valency lexicon of Czech verbs, VALLEX, is described.  Two types of alternations (changes in valency frames of verbs) are distinguished on the basis of used linguistic means: (i) grammaticalized alternations and (ii) lexicalized alternations. Both grammaticalized and lexicalized alternations are either conversive, or non-conversive. While grammaticalized alternations relate different surface syntactic structures of a single lexical unit of a verb, lexicalized alternations relate separate lexical units. For the purpose of the representation of alternations, we divide the lexicon into data and rule components. In the data part, each lexical unit is characterized by a single valency frame and by applicable alternations. In the rule part, two types of rules are contained: (i) syntactic rules describing grammaticalized alternations and (ii) general rules determining changes in the linking of situational participants with valency complementations typical of lexicalized alternations."
Tato kapitola prezentuje současné poznatky v oblasti vývoje statistických dialogových systému založených na POMDP modelu řízení komunikace s uživatelem. Postupně jsou vysvětleny základy POMDP a vhodné metody pro implementaci v oblasti dialogových systémů.,This chapter presents current knowledge about statistical dialogue systems based on POMDP model of interaction with human users. The chapter introduces basic concepts of POMDP and suggest appropriate methods for implementation it the context of dialogue systems.
"Představujeme univerzální nástroj pro segmentaci a tokenizaci textů, který uživateli dovoluje nadefinovat potenciální hranice vět a slov a na základě trénovacích dat se naučí hranice hledat.","We present a universal data-driven tool for segmenting and tokenizing text. The presented
tokenizer lets the user define where token and sentence boundaries should be considered.
These instances are then judged by a classifier which is trained from provided tokenized data.
The features passed to the classifier are also defined by the user making, e.g., the inclusion
of abbreviation lists trivial. This level of customizability makes the tokenizer a versatile tool
which we show is capable of sentence detection in English text as well as word segmentation
in Chinese text. In the case of English sentence detection, the system outperforms previous
methods. The software is available as an open-source project on GitHub"
"Příprava trénovacích dat je pracná a představuje hlavní překážku ve vývoji zpracování přirozeného jazyka (NLP). Mezi hlavní aplikace NLP patří strojový překlad, který se v současnosti opírá o dostupnost velkého množství dat. Sestavování těchto dat je finančně náročné a současně náchylné k chybám. Nově se objevující technologie jako sociální sítě a ""seriózní"" hry nabízejí jedinečnou příležitost změnit způsob přípravy trénovacích dat. Hry s účelem byly zkonstruovány pro větnou segmentaci, značkování obrázků a rozpoznávání koreference. Tyto hry fungují na třech úrovních: poskytují zábavu hráčům, hráči se při nich učí a současně poskytují data pro výzkum. Většina těchto systémů se potýká s nedostatkem účastníků. V tomto článku předkládáme sadu lingvisticky orientovaných her zaměřených na sestrojení paralelního korpusu pro několik jazyků a umožňujících hráčům zlepšení jejich slovní zásoby v těchto jazycích. První zveřejněná verze GlobeOtter je dostupná na Facebooku. Jedním z cílů je zde získat dostatečné množství hráčů i mimo řady lingvistů.","Building training data is labor-intensive and presents a major obstacle to the advancement of Natural Language Processing (NLP)
systems. A prime use of NLP technologies has been toward the construction machine translation systems. The most common form of
machine translation systems are phrase based systems that require extensive training data. Building this training data is both expensive
and error prone. Emerging technologies, such as social networks and serious games, offer a unique opportunity to change how we
construct training data. These serious games, or games with a purpose, have been constructed for sentence segmentation, image labeling,
and co-reference resolution. These games work on three levels: They provide entertainment to the players, the reinforce information
the player might be learning, and they provide data to researchers. Most of these systems while well intended and well developed, have
lacked participation.
We present, a set of linguistically based games that aim to construct parallel corpora for a multitude of languages and allow players to
start learning and improving their own vocabulary in these languages. As of the first release of the games, GlobeOtter is available on
Facebook as a social network game. The release of this game is meant to change the default position in the field, from creating games
that only linguists play, to releasing linguistic games on a platform that has a natural user base and ability to grow."
"Článek ukazuje závislostní analýzu s využitím kombinace parseru a self-trainingu pro jazyky s malým množstvím jazykových dat. Ověřili jsme, že pro jazyk s malým množstvím dat je využití ladicích dat pro meta-klasifikátor efektivnější než jejich přidání do zbývajících trénovacích dat jednotlivých analyzátorů. Tento mete-klasifikátor vytváří kombinovaný závislostní parse a zvyšuje úspěšnost analýzy v průměru o 4.92% a o 1.99% ve srovnání s jednotlivým nejlepším systémem. Meta-klasifikátor se může přizpůsobit rostoucím dostupným datům. Využitím self-trainingu společně s kombinací několika parseru vzniká další zlepšení.","We also show ensemble dependency parsing and self training approaches applicable to under-resourced languages using our manually annotated dependency structures. We show that for an under-resourced language, the use of tuning data for a meta classifier is more effective than using it as additional training data for individual parsers. This meta-classifier creates an ensemble dependency parser and increases the dependency accuracy by 4.92% on average and 1.99% over the best individual models on average. As the data sizes grow for the the under-resourced language a meta classifier can easily adapt. To the best of our knowledge this is the first full implementation of a dependency parser for Indonesian. Using self-training in combination with our Ensemble SVM Parser we show additional improvement. Using this parsing model we plan on expanding the size of the corpus by using a semi-supervised approach by applying the parser and correcting the errors, reducing the amount of annotation time needed."
"Fokus hodně závislostní analýzy se na vytváření nových modelovacích technik a zkoumání nových funkcí sady pro stávající závislost modelů. Často jsou tyto nové modely mají to štěstí, aby dosahovaly rovnocenných výsledků s aktuálním stavem
že umělecké výsledky a často vedou hůř. Tyto přístupy jsou pro jazyky, které jsou často zdrojem bohaté a mají dostatek tréninková data k dispozici pro závislost rozebrat. Z tohoto důvodu, přesnost výsledky jsou často dosti vysoká. To, ze své podstaty, je to docela obtížné vytvořit výrazně velký nárůst v současném state-of-the-art. Výzkum v této oblasti se často zabývá malými změnami přesnosti nebo velmi specifickým lokalizovaných změn, jako je zvýšení přesnosti a zejména jazykovou konstrukci. S tolika technik modelování jsou k dispozici pro jazyky s velkým zdroji problém existuje o tom, jak využít stávající techniky s použitím kombinace, nebo souborem, techniky spolu s tímto množstvím dat.

Závislost analyzátory jsou téměř všude se vyskytující hodnoceny na jejich přesnost výsledků, tyto výsledky nemluvě o složitosti a užitečnosti výsledných struktur. Tyto struktury mohou mít větší složitost vzhledem k hloubce jejich co-
koordinační nebo podstatné jméno věty. Jako závislost analyzuje jsou základní struktury, ve kterých jsou ostatní systémy postavené na, by se zdálo rozumné posouzení těchto parserů dolů potrubí NLP. Typy parsování chyb, které způsobují významné
problémy v jiných aplikacích NLP je v současné době znám.","The focus of much of dependency parsing is on creating new modeling techniques and examining new feature sets for existing dependency models. Often these new models are lucky to achieve equivalent results with the current state of
the art results and often perform worse. These approaches are for languages that are often resource-rich and have ample training data available for dependency parsing. For this reason, the accuracy scores are often quite high. This, by its very nature, makes it quite difficult to create a significantly large increase in the current state-of-the-art. Research in this area is often concerned with small accuracy changes or very specific localized changes, such as increasing accuracy of a particular linguistic construction. With so many modeling techniques available to languages with large resources the problem exists on how to exploit the current techniques with the use of combination, or ensemble, techniques along with this plethora of data.

Dependency parsers are almost ubiquitously evaluated on their accuracy scores, these scores say nothing of the complexity and usefulness of the resulting structures. The structures may have more complexity due to the depth of their co-
ordination or noun phrases. As dependency parses are basic structures in which other systems are built upon, it would seem more reasonable to judge these parsers down the NLP pipeline. The types of parsing errors that cause significant
problems in other NLP applications is currently an unknown."
"V posledních letech dosáhla závislostní syntaktická analýza podstatného zlepšení, zejména pro angličtnu. Existuje několik závislostních analyzátorů, které dosahují srovnatelné úspěšnosti, přičemž produkují různé typy chyb. Tento článek se zabývá vytvářením nové závislostní struktury složením výstupů různých analyzátorů. Všechny výstupy sloučíme do váženého grafu, který je vstupem pro kombinační systém založený na algoritmu 
minimální kostry orientovaného grafu.

Výsledná kombinace založená na pěti různých analyzátorech dosahuje úspěšnosti 92,58 %, čímž překonává všechny jednotlivé analyzátory.","Dependency parsing has made many advancements in recent years, in particular for English. There are a few dependency parsers that achieve comparable accuracy scores with each other but with very different types of errors. This paper examines creating a new dependency structure through ensemble learning using a hybrid of the outputs of various parsers. We combine all tree outputs into a weighted edge graph, using 4 weighting mechanisms. The weighted edge graph is the input into our ensemble system and is a hybrid of very different parsing techniques (constituent parsers, transition-based dependency parsers, and a graph-based parser). From this graph we take a maximum spanning tree. We examine the new dependency structure in terms of accuracy and errors on individual part-of-speech values.

The results indicate that using a greater number of more varied parsers will improve accuracy results. The combined ensemble system, using 5 parsers based on 3 different parsing techniques, achieves an accuracy score of 92.58%, beating all single parsers on the Wall Street Journal section 23 test set. Additionally, the ensemble system reduces the average relative error on selected POS tags by 9.82%."
"Závislostní syntaktická analýza pomáhá některým aplikacím z oblasti zpracování přirozeného jazyka dosáhnout vyšší úspěšnosti, zejména pokud jde o jazyky s relativně volným slovosledem. Pro morfologicky bohaté jazyky typicky existuje jen malé množství trénovacích dat, přičemž kvůli větší velikosti slovníku by jich naopak bylo potřeba více. Tento článek se zabývá novými přístupy pro analýzu morfologicky bohatých jazyků s malým množstvím dat.

Testovacím jazykem je v našich experimentech tamilština. Vytvořili jsme 9 modelů pro závislostní syntaktickou analýzu, které byly natrénovány na malém množství dat. S využitím těchto modelů jsme natrénovali klasifikátor SVM, který jako rysy používá pouze informaci o shodě jednotlivých analyzátorů, díky čemuž lze tento přístup považovat za jazykově nezávislý.

Experimentálně jsme prokázali statisticky signifikantní zlepšení 5,44 % oproti průměrnému modelu a statisticky signifikantní zlepšení 0,52 % oproti nejlepšímu jednotlivému systému.","Dependency parsing has been shown to improve NLP systems in certain languages and in many cases helps achieve state of the art results in NLP applications, in particular applications for free word order languages. Morphologically rich languages are often short on training data or require much higher amounts of training data due to the increased size of their lexicon. This paper examines a new approach for addressing morphologically rich languages with little training data to start.  

Using Tamil as our test language, we create 9 dependency parse models with a limited amount of training data. Using these models we train an SVM classifier using only the model agreements as features. We use this SVM classifier on an edge by edge decision to form an ensemble parse tree. Using only model agreements as features allows this method to remain language independent and applicable to a wide range of morphologically rich languages.

We show a statistically significant 5.44% improvement over the average dependency model and a statistically significant 0.52% improvement over the best individual system."
"Segmentácia na tématicky koherentné úseky je dôležitou súčasťou vyhľadávania informácií. Vhodná segmentácia môže zlepšiť výsledky vyhľadávania a pomôcť užívateľom pri rýchlejšom hľadaní relevantného úseku. Segmentácia je zvlášť dôležitá pri audiovizuálnych nahrávkach, v ktorých je navigácia zvlášť zložitá. V článku popisujeme niekoľko prístupov ku tématickej segmentácii, založených na textovej, zvukovej a vizuálnej informácii. V článku je tiež prezentovaný náš návrh prístupu k tématickej segmentácii, založený na fúzii zvukových a vizuálnych dát.","Segmentation into topically coherent segments is one of the crucial points in information retrieval (IR). Suitable segmentation may improve the results of IR system and help users to find relevant passages faster. Segmentation is especially important in audiovisual recordings, in which the navigation is difficult. We present several methods used for topic segmentation, based on textual, audio and visual information. The proposition of our approach to topic segmentation based on the fusion of audio and visual data is presented in the article."
"Česko-slovenský paralelný korpus, vytvorený z voľne dostupných zdrojov. Korpus je prístupný v textovom formáte a s morfologickou anotáciou.",Czech-Slovak parallel corpus consisting of several freely available corpora. Corpus is given in both plaintext format and with an automatic morphological annotation.
"Anglicko-slovenský paralelný korpus, vytvorený z voľne dostupných zdrojov. Korpus je prístupný v textovom formáte a s morfologickou anotáciou.",English-Slovak parallel corpus consisting of several freely available corpora. Corpus is given in both in plaintext format and with an automatic morphological annotation
"Množstvo trénovacích dát je pre kvalitu štatistického strojového prekladu rozhodujúce. V článku popisujeme, akým spôsobom je možné zlepšiť kvalitu prekladu pre daný jazykový pár pomocou využitia paralelných dát v príbuznom jazyku. Konkrétne sme vylepšili en→sk preklad pomocou využitia veľkého česko-anglického paralelného korpusu a cs→sk prekladového systému založeného na pravidlách. Preskúmaných je niekoľko možností konfigurácie použitých systémov.","The amount of training data in statistical machine translation is critical for translation quality. In this paper, we demonstrate how to increase translation quality for one language pair by bringing in parallel data from a closely related language. In particular, we improve en→sk translation using a large Czech–English
parallel corpus and a shallow (rule-based) MT system for cs→sk. Several setup options are explored in order to identify the best possible configuration."
"Automatický preklad z češtiny do slovenčiny pre prvých 50 viet testovacej sady WMT 2010 pomocou piatich prekladových systémov (Česílko, Česílko 2, Google Translate a Moses s rôznymi nastaveniami). V prekladoch boli ručne označené chyby, ktoré boli ďalej klasifikované podľa schémy danej v článku (David Vilar, Jia Xu, Luis Fernando D’Haro, Hermann Ney: Error Analysis of Statistical Machine Translation Output, Proceedings of LREC-2006, 2006).","Outputs of five Czech-Slovak machine translation systems  (Česílko, Česílko 2, Google Translate and Moses with different settings) for first 50 sentences of WMT 2010 testing set. The translations were manually processed and the errors were marked and classified according to the scheme by Vilar et al. (David Vilar, Jia Xu, Luis Fernando D’Haro, Hermann Ney: Error Analysis of Statistical Machine Translation Output, Proceedings of LREC-2006, 2006)"
"Automatický preklad z angličtiny do slovenčiny 50 viet náhodne vybraných z testovacej sady WMT 2011 pomocou troch prekladových systémov. V prekladoch boli ručne označené chyby, ktoré boli ďalej klasifikované podľa schémy danej v článku (David Vilar, Jia Xu, Luis Fernando D’Haro, Hermann Ney: Error Analysis of Statistical Machine Translation Output, Proceedings of LREC-2006, 2006).","Outputs of three English-Slovak machine translation systems for 50 sentences randomly selected from WMT 2011 test set. The translations were manually processed and the errors were marked and classified according to the scheme by Vilar et al. (David Vilar, Jia Xu, Luis Fernando D’Haro, Hermann Ney: Error Analysis of Statistical Machine Translation Output, Proceedings of LREC-2006, 2006)"
Testovacia sada z workshopu WMT 2011 manuálne preložená z češtiny a angličtiny do slovenčiny.,WMT 2011 Workshop testing set manually translated from Czech and English into Slovak.
"Článok popisuje postup, ktorý sme použili v úlohe Search and Hyperlinking  v MediaEval 2012 Multimedia Benchmark. Pri riešení bol použitý systém Terrier, ktorý bol aplikovaný na automatické prepisy video nahrávok. Nahrávky boli segmentované na menšie časti, ktoré boli ďalej prehľadané. Pri segmentácii boli použité dva prístupy: jeden založený na pravidelnej segmentácii podľa času a druhý založený na sémantickej segmentácii pomocou algoritmu TextTiling. Najlepší výsledok bol dosiahnutý pomocou pravidelnej segmentácie, pomocou modelov Hiemstra a TF-IDF na prepisoch LIMSI.",The paper describes the Charles University setup used in the Search and Hyperlinking task of the MediaEval 2012 Multimedia Benchmark. We applied the Terrier retrieval system to the automatic transcriptions of the video recordings segmented into shorter parts and searched for those relevant to given queries. Two strategies were applied for segmentation of the recordings: one based on regular segmentation according to time and the second based on semantic segmentation by the TextTiling algorithm. The best results were achieved by the Hiemstra and TF-IDF models on the LIMSI transcripts and various segmentation.
"Článok sa zaoberá vyhodnocovaním vyhľadávania v nesegmentovanej hovorenej reči. Zameriavame sa na metriku Mean Generalized Average precision, ktorá sa vyhodnocovanie vyhľadávania v reči často využíva. Táto metrika je navrhnutá tak, aby tolerovala určitú odchýlku medzi automaticky vyhľadanými výsledkami (začiatočnými bodmi relevantných segmentov) a  ručne označenými výsledkami. Na tento účel používa metrika penalizačnú funkciu, ktorá určuje kvalitu vyhľadaných úsekov na základe ich vzdialenosti ku najbližšiemu začiatku ručne označeného relevantného úseku. Výber penalizačnej funkcie však nemusí zodpovedať kvalite vyhľadávania z pohľadu užívateľa. V článku popisujeme užívateľskú štúdiu, ktorou sme skúmali spokojnosť užívateľa pri vyhľadávaní informácií. Na základe výsledkov sme navrhli optimálnu penalizačnú funkciu.","This paper deals with evaluation of information retrieval from unsegmented speech. We focus on Mean Generalized Average Precision, the evaluation measure widely used for unsegmented speech retrieval. This measure is designed to allow certain tolerance in matching
retrieval results (starting points of relevant segments) against a gold standard relevance assessment. It employs a Penalty Function which evaluates non-exact matches in the retrieval results based on their distance from the beginnings of their nearest true relevant segments. However, the choice of the Penalty Function is usually ad-hoc and does not necessary reﬂect users’ perception of the speech retrieval quality. We perform a lab test to study satisfaction of users of a speech retrieval system to empirically estimate the optimal shape of the Penalty Function."
"(Not yet available. English version repeated)
In this paper, we study the effect of incorporating morphological information on an Indonesian (id) to English (en) Statistical Machine Translation (SMT) system as part of a preprocessing module. The linguistic phenomenon that is being addressed here is Indonesian cliticized words. The approach is to transform the text by separating the correct clitics from a cliticized word to simplify the word alignment. We also study the effect of applying the preprocessing on different SMT systems trained on different kinds of text, such as spoken language text. The system is built using the state-of-the-art SMT tool, MOSES. The Indonesian morphological information is provided by MorphInd. Overall the preprocessing improves the translation quality, especially for the Indonesian spoken language text, where it gains 1.78 BLEU score points of increase.","In this paper, we study the effect of incorporating morphological information on an Indonesian (id) to English (en) Statistical Machine Translation (SMT) system as part of a preprocessing module. The linguistic phenomenon that is being addressed here is Indonesian cliticized words. The approach is to transform the text by separating the correct clitics from a cliticized word to simplify the word alignment. We also study the effect of applying the preprocessing on different SMT systems trained on different kinds of text, such as spoken language text. The system is built using the state-of-the-art SMT tool, MOSES. The Indonesian morphological information is provided by MorphInd. Overall the preprocessing improves the translation quality, especially for the Indonesian spoken language text, where it gains 1.78 BLEU score points of increase."
"This paper describes the creation process of an Indonesian-English parallel corpus (IDENTIC). The corpus contains 45,000 sentences collected from different sources in different genres. Several manual text preprocessing tasks, such as alignment and spelling correction, are applied to the corpus to assure its quality. We also apply language specific text processing such as tokenization on both sides and clitic normalization on the Indonesian side. The corpus is available in two different formats: ‘plain’, stored in text format and ‘morphologically enriched’, stored in CoNLL format. Some parts of the corpus are publicly available at the IDENTIC homepage","This paper describes the creation process of an Indonesian-English parallel corpus (IDENTIC). The corpus contains 45,000 sentences collected from different sources in different genres. Several manual text preprocessing tasks, such as alignment and spelling correction, are applied to the corpus to assure its quality. We also apply language specific text processing such as tokenization on both sides and clitic normalization on the Indonesian side. The corpus is available in two different formats: ‘plain’, stored in text format and ‘morphologically enriched’, stored in CoNLL format. Some parts of the corpus are publicly available at the IDENTIC homepage."
"(Not yet available. English version repeated)
This paper presents a method to improve a word alignment model in a phrase-based Statistical Machine Translation system for a low resourced language using a string similarity approach. Our method captures similar words that can be seen as semi-monolingual across languages, such as numbers, named entities, and adapted/loan words. We use several string similarity metrics to measure the monolinguality of the words, such as Longest Common Subsequence Ratio (LCSR), Minimum Edit Distance Ratio (MEDR), and we also use a modified BLEU Score (modBLEU).
Our approach is to add intersecting alignment points for word pairs that are orthographically similar, before applying a word alignment heuristic, to generate a better word alignment.
We demonstrate this approach on Indonesian-to-English translation task, where the languages share many similar words that are poorly aligned given a limited training data.
This approach gives a statistically significant improvement by up to 0.66 in terms of BLEU score.","This paper presents a method to improve a word alignment model in a phrase-based Statistical Machine Translation system for a low resourced language using a string similarity approach. Our method captures similar words that can be seen as semi-monolingual across languages, such as numbers, named entities, and adapted/loan words. We use several string similarity metrics to measure the monolinguality of the words, such as Longest Common Subsequence Ratio (LCSR), Minimum Edit Distance Ratio (MEDR), and we also use a modified BLEU Score (modBLEU).
Our approach is to add intersecting alignment points for word pairs that are orthographically similar, before applying a word alignment heuristic, to generate a better word alignment.
We demonstrate this approach on Indonesian-to-English translation task, where the languages share many similar words that are poorly aligned given a limited training data.
This approach gives a statistically significant improvement by up to 0.66 in terms of BLEU score."
"(Not yet available. English version repeated)
This paper describes a work on preparing an Indonesian-English Statistical Machine Translation (SMT) System. It includes the creation of Indonesian morphological analyzer, MorphInd, and the composing of an Indonesian-English parallel corpus, IDENTIC. We build an SMT system using the state-of-the-art phrase-based SMT system, MOSES. We show several scenarios where the morphological tool is used to incorporate morphological information in the SMT system trained with the composed parallel corpus.","This paper describes a work on preparing an Indonesian-English Statistical Machine Translation (SMT) System. It includes the creation of Indonesian morphological analyzer, MorphInd, and the composing of an Indonesian-English parallel corpus, IDENTIC. We build an SMT system using the state-of-the-art phrase-based SMT system, MOSES. We show several scenarios where the morphological tool is used to incorporate morphological information in the SMT system trained with the composed parallel corpus."
"In this paper, we focus on improving part-of-speech (POS) tagging for Urdu by using existing tools and data for the language. In our experiments, we use Humayoun’s morphological
analyzer, the POS tagging module of an Urdu Shallow Parser and our own SVM Tool tagger trained on CRULP manually annotated data. We convert the output of the taggers
to a common format and more importantly unify their tagsets. On an independent test
set, our tagger outperforms the other tools by far. We gain some further improvement
by implementing a voting strategy that allows us to consider not only our tagger but also
include suggestions by the other tools. The ﬁnal tagger reaches the accuracy of 87.98%.","V článku popisujeme, jak jsme zlepšili značkování slovních druhů pro urdštinu pomocí kombinace dostupných taggerů a dostupných ručně značkovaných dat. V prvním kroku sjednocujeme sady značek užívané v jednotlivých zdrojích. Dále náš vlastní tagger natrénovaný na dostupných datech funguje výrazně lépe než dostupné nástroje. A konečně tento výsledek je možné ještě mírně zlepšit za použití návrhů od ostatních taggerů."
"Svědectví pamětníka je nezastupitelným a velice hodnotným doplňkem běžné výuky dějepisu a dalších předmětů na 2. stupni ZŠ i na různých typech středních škol. Svědectví umožňuje personalizaci „velké historie“, žáci a studenti se s konkrétním člověkem a jeho prožitky mohou lépe identifikovat, do vzdělávacího procesu vstupují emoce, což prokazatelně zvyšuje jeho účinnost. Nevyhnutelně se však blíží doba, kdy už nebude možné zvát pamětníky přímo do škol a dalších institucí – už dnes zbývá jen velice málo lidí, kteří v dospělém věku prožili 2. světovou válku a události s ní spjaté. Je tedy třeba zjišťovat možnosti a metody alternativních postupů, které mohou alespoň částečně přítomnost živého pamětníka ve třídě v budoucnu nahradit. Archiv vizuální historie Institutu USC Shoah Foundation je unikátní sbírkou takřka 52 000 audiovi­zuálních záznamů rozhovorů s pamětníky a přeživšími holocaustu, které byly natočeny během 2. poloviny 90. let v 56 zemích a 32 jazycích (v češtině a slovenštině je přes 1 000 rozhovorů). Archiv je možno prohledávat pomocí propracovaného uživatelského rozhraní: uživatelé mohou najít konkrétní úseky svědectví podle svého zájmu díky tezauru 55 000 hierarchicky uspořádaných klíčových slov, témat, událostí, jmen osob, míst atd. Praha je jedním z pěti evropských měst, kde se lze k obsahu licencovaného archivu připojit, a to z počítačů v Centru vizuální historie Malach při Matematicko-fyzikální fakultě Univerzity Karlovy. Také práce s podobným on-line archivem v reálném čase je dalším specifickým vzdělávacím postupem, který u žáků rozvíjí samostatnost, myšlení v souvislostech a kritický přístup k pramenům a informačním zdrojům. Za tímto účelem vznikl také nový edukační portál IWitness, který bude v příspěvku rovněž představen.","Witness testimonies are unsubstitutable and very important addition to the classic lessons of history and other subjects in primary and secondary education. The testimony allows a personalization of the „great history“, students can easily identify with a specific person and his/her experience, and it brings emotions into the educational process, which demonstrably improves its efficiency. However, the day will come, that there will be no more witnesses alive for certain historical events. It is thus necessary to explore and create new alternatives, that could – at least partially – substitute the presence of an eye-witness in the future classroom. The USC Shoah Foundation Institute Visual History Archive is a unique collection of almost 52 000 testimonies of the Holocaust survivors and witnesses, conducted in 56 countries and 32 languages during the late 90's (over 1 000 interviews are in Czech and Slovak language). The Visual History Archive provides complex tools for users to identify whole testimonies of relevance, as well as specific segments within testimonies that relate to their area of interest. Prague is currently one of five European cities with full access to the on-line licensed archive content from the Malach Visual History Centre at the Faculty of Mathematics and Physics of the Charles University. Real-time work with the archive is a valuable part of educational process as well, developing student's inde­pendence and critical thinking in context. This is a main purpose of the new educational portal IWitness, which is also going to be presented at the conference."
"Khresmoi je integrační projekt financovaný Evropskou Unií, který se zabývá multilingválním a multimodálním vyhledávání v medicínských datech.","Khresmoi is a European Integrated Project developing a multilingual multimodal search and access system for medical and health information and documents. It addresses the challenges of searching through huge amounts of medical data, including general medical information available on the internet, as well as radiology data in hospital archives. It is developing novel semantic search and visual search techniques for the medical domain. At the MIE Village of the
Future, Khresmoi proposes to have two interactive demonstrations of the system under development, as well as an overview oral presentation and potentially some poster presentations."
"Systémy pro detekci a korekci pravopisných chyb jsou obvykle založeny na třech komponentách: slovníku, chybovém modelu a jazykovém modelu. Zatímco většina ostatních prací se zaměřuje především na jazykový model, v této práci se ukazujeme, že vylepšení jakékoliv z těchto komponent může vést k významnému zlešení celého systému.","A spelling error detection and correction application is based on three main components: a
dictionary (or reference word list), an error model and a language model. While most of the
attention in the literature has been directed to the language model, we show how improvements in
any of the three components can lead to significant cumulative improvements in the overall
performance of the system. We develop our dictionary of 9.3 million fully inflected Arabic words
from a morphological transducer and a large corpus, cross validated and manually revised. We
improve the error model by analysing error types and creating an edit distance re-ranker. We also
improve the language model by analysing the level of noise in different sources of data and
selecting the right subset to train the system on. Testing and evaluation experiments show that
our system significantly outperforms Microsoft Word 2010, OpenOffice Ayaspell and Google
Document."
"(Not yet available. English version repeated)
We describe the development of a bidirectional rule-based machine translation system between Indonesian and Malaysian (id-ms), two closely related Austronesian languages natively spoken by approximately 35 million people. The system is based on the re-use of free and publicly available resources, such as the Apertium machine translation platform and Wikipedia articles. We also present our approaches to overcome the data scarcity problems in both languages by exploiting the morphology similarities between the two.}","We describe the development of a bidirectional rule-based machine translation system between Indonesian and Malaysian (id-ms), two closely related Austronesian languages natively spoken by approximately 35 million people. The system is based on the re-use of free and publicly available resources, such as the Apertium machine translation platform and Wikipedia articles. We also present our approaches to overcome the data scarcity problems in both languages by exploiting the morphology similarities between the two."
"Představujeme Korektor – flexibilní statistický nástroj pro opravu českých textů, jehož schopnosti přesahují tradiční nástroje pro kontrolu pravopisu. Korektor využívá kombinace jazykových modelů a chybového modelu jak k tomu, aby setřídil pořadí nabízených náhrad pro neznámé slovo podle pravděpodobnosti výskytu na daném místě v textu, tak také, aby nalezl i překlepy, které se nahodile shodují s existujícím českým slovním tvarem. Prostou náhradou chybového modelu náš pracuje Korektor také jako systém pro doplnění diakritiky („oháčkování textu“) s nejvyšší publikovanou úspěšností. Systém neobsahuje žádné významné jazykově specifické komponenty s výjimkou natrénovaných statistických modelů. Je tedy možné jej snadno natrénovat i pro jiné jazyky. Ukážeme, jakých zlepšení náš systém dosahuje v porovnání se stávajícími českými korektory pravopisu i systémy pro doplnění diakritiky. Ukážeme také, že kombinace těchto schopností pomáhá při anotaci chyb v korpusu češtiny jako druhého jazyka.","We present Korektor – a flexible and powerful purely statistical text correction tool for Czech that goes beyond a traditional spell checker. We use a combination of several language models and an error model to offer the best ordering of correction proposals and also to find errors that cannot be detected by simple spell checkers, namely spelling errors that happen to be homographs of existing word forms. Our system works also without any adaptation as a diacritics generator with the best reported results for Czech text. The design of Korektor contains no language-specific parts other than trained statistical models, which makes it highly suitable to be trained for other languages with available resources. The evaluation demonstrates that the system is a state-of-the-art tool for Czech, both as a spell checker and as a diacritics generator. We also show that these functions combine into a potential aid in the error annotation of a learner corpus of Czech."
"Knížka přináší aktuální souborný popis problematiky strojového překladu, různých přístupů k němu a jejich výhod a nevýhod a zabírá se i otázkami vyhodnocování kvality překladu. Čeština jako podkladový jazyk potvrzuje svou vynikající roli: pro podchycení českých jazykových jevů je zapotřebí bohaté teorie, přitom je pro ale češtinu dostatek nástrojů a anotovaných i neanotovaných textových dat.","An up-to-date broad study of various approaches of machine translation and translation evaluation techniques, highlighting their advantages and disadvantages. The book is written in Czech and also primarily focuses on aspects of Czech, documenting that Czech is not only interestingly complex but it is also well supplied with linguistic tools and data."
"Přednáška o strojovém překladu spojená se zamyšlením, k jaké regeneraci či degeneraci díky překladu spějeme.",A talk on machine translation and a deliberation on the progress and regress it can lead to.
"Seznámení zájemců o informatiku s úlohou strojového překladu, současnými metodami a jejich omezeními.","An introduction to the task of machine translation, current methods and their inherent limitations for those interested in computer science."
Stručný článek představuje problematiku strojového překladu širšímu publiku.,This is short article describing the field of machine translation to a broad audience.
Seznámení studentů středních škol a jejich pedagogů s problematikou strojového překladu.,An introduction to machine translation for high school students and their teachers.
"Dáta z troch zdrojov (časť korpusu Acquis, časť testovacej sady z WMT a vety vybrané z kníh) automaticky preložené pomocou piatich systémov (Česílko, Česílko 2, Google Translate a Moses s rôznymi nastaveniami) z češtiny do slovenčiny a ohodnotené troma anotátormi. Preklady boli ručne zoradené podľa ich kvality.","Data from three sources (part of Acquis, WMT test set and sentences selected from the set of books) translated by 5 machine translation systems (Česílko, Česílko 2, Google Translate and Moses with different settings) from Czech to Slovak and evaluated by three annotators. The translations were manually ordered according to their quality."
"Představujeme taxonomii pro faktorové modely frázového překladu a provádíme sérii experimentů s konfiguracemi z navržené taxonomie. Odhalujeme přitom řadu chyb v návrhu překladových modelů, jichž je vhodné se vyvarovat. Článek slouží rovněž jako popis našich systémů CU-BOJAR a CU-POOR-COMB v soutěži WMT12.","We introduce a taxonomy of factored phrase based
translation scenarios and conduct a
range of experiments in this taxonomy. We
point out several common pitfalls when designing
factored setups. The paper also describes
our WMT12 submissions CU-BOJAR
and CU-POOR-COMB."
"HMEANT (Lo, Wu, 2011) je technika ručního hodnocení kvality strojového překladu založená na predikátově-argumentové struktuře věty. V článku dáváme HMEANT do souvislosti se zavedeným Funkčním generativním popisem a současně poprvé aplikujeme HMEANT na jiný jazyk než angličtinu, konkrétně na češtinu.","HMEANT (Lo and Wu, 2011a) is a manual MT evaluation technique that focuses on
predicate-argument structure of the sentence.
We relate HMEANT to an established lin-
guistic theory, highlighting the possibilities of
reusing existing knowledge and resources for
interpreting and automating HMEANT. We
apply HMEANT to a new language, Czech
in particular, by evaluating a set of English-
to-Czech MT systems. HMEANT proves to
correlate with manual rankings at the sentence
level better than a range of automatic met-
rics. However, the main contribution of this
paper is the identification of several issues
of HMEANT annotation and our proposal on
how to resolve them."
Závěrečná technická zpráva grantu EuroMatrixPlus popisující strojový překlad prostřednictvím stromových struktur s bohatou anotací.,The final technical report on rich tree-based translation for the EuroMatrixPlus project.
"CzEng 1.0 je aktualizovaná verze česko-anglického paralelního korpusu, volně použitelného pro nekomerční použití. Oproti předchozí verzi je velikost korpusu dvojnásobně zvětšena na 15 milionů větných párů (řádově 200 milionů slov pro každý jazyk). Data jsou pečlivě profiltrována, aby se omezil výskyt neodpovídajících si větných párů apod. CzEng 1.0 je automaticky zarovnán po větách i po slovech. Krom čistě textové verze dáváme k dispozici anotaci korpusu na několika rovinách: morfologické, větně členské (analytické, povrchová závislostní syntax) a tektogramatické (hloubková syntax). Obsažena je také automatická anotace koreference pro oba jazyky.","CzEng 1.0 is an updated release of our Czech-English parallel corpus, freely
available for non-commercial research or educational purposes. In this
release, we approximately doubled
the corpus size, reaching 15 million sentence
pairs (about 200 million tokens per language). More importantly, we carefully
filtered the data to reduce the amount of non-matching sentence pairs.
CzEng 1.0 is automatically aligned at the level of sentences as well as words.
We provide not only the plain text representation, but also automatic
morphological tags, surface syntactic as well as deep syntactic dependency parse
trees and automatic co-reference links in both English and Czech.
This paper describes key properties of the released resource including the
distribution of text domains,
the corpus data formats, and a toolkit to handle the provided rich annotation. We also
summarize the procedure of the rich annotation (incl. co-reference
resolution) and of the automatic filtering. Finally, we provide some suggestions
on exploiting such an automatically annotated sentence-parallel corpus."
"Tři přídavné české referenční překlady celé datové sady WMT 2011 (http://www.statmt.org/wmt11/test.tgz), přeložené z němčiny. Původní segmentace dat z WMT 2011 byla zachována.","Additional three Czech reference translations of the whole WMT 2011 data set (http://www.statmt.org/wmt11/test.tgz), translated from the German originals. Original segmentation of the WMT 2011 data is preserved."
"Bílá kniha prezentuje stav podpory jazykových technologií pro češtinu. Je částí série, která analyzuje dostupné jayzkové zdroje pro 30 evropských jazyků.",This white paper presents the state of language technology support for the Czech language. It is a part of a series that analyses the available language resources and technologies for 30 European languages.
"Eman („experimentální manažer“) je softwarový nástroj, který umožňuje řídit rozsáhlé soubory vzájemně provázaných experimentů, při kterých se zpracovávají velké datové soubory, typicky na výpočetním clusteru. Byl vyvinut jako infrastruktura pro statistický strojový překlad, ale uplatní se i v jiných úlohách.","Eman (“experimental manager”) is a software tool capable of maintaining large networks of mutually interconnected experiment processing large datasets, typically on a computational cluster. Eman was developed as an infrastructure for statistical machine translation but it can be used for other tasks as well."
"Návod, jak provádět širokou sérii experimentů (se zaměřením na strojový překlad).",A tutorial on conducting a very broad range of experiments (for MT in particular).
"ÚFAL je pracovištěm, které je přátelsky nakloněné jak lingvistice, tak strojovému učení. Protože statistika je klíčovým pojmem strojového učení, je ÚFAL přátelsky spřízněn i se statistikou.",UFAL is a department well disposed to both linguistics and machine learning. It's well disposed to statistics as well because statistics is a key part of machine learning.
"Představujeme významnou aktualizaci Pražského česko-anglického závistostního korpusu (PCEDT), paralelního korpusu, který je ručně anotován na hloubkové syntaktické rovině.","We introduce a substantial update of the Prague Czech-English Dependency Treebank, a parallel corpus manually annotated at the deep
syntactic layer of linguistic representation. The English part consists of the Wall Street Journal (WSJ) section of the Penn Treebank.
The Czech part was translated from the English source sentence by sentence. This paper gives a high level overview of the underlying
linguistic theory (the so-called tectogrammatical annotation) with some details of the most important features like valency annotation,
ellipsis reconstruction or coreference."
"V příspěvku se klade otázka, zda jsme oprávněni u typů (i) - (iii) mluvit o asymetrickém vztahu ""hypotaktické koordinace"". Jde o typy (i) asociativ vs slučovací koordinace, (ii) tzv. nepravé věty vedlejší, (iii) konstrukce uvozené výrazy ""místo, kromě, mimo"". Dochází se k názoru, že na hypotaktickou koordinaci kandiduje část příkladů typu (a).","The question about boundaries of so-called ""hypotactical coordination"" is discussed in connection with three types of constructions: (i) asociative constructions vs simple conjunctions, (ii) so-called ""false"" subordinated clauses, (iii) constructions introduced by the expressions ""místo"" (instead), ""kromě"" (beside/with exception)."
"Jde o nekrology věnované prof. Rudolfu Růžičkovi z Univerzity v Lipsku, předním představiteli teoretické a formální lingvistiky v Německu (1920-2011) a prof. Milce Ivicové z Univerzity v Nověm Sadu a z Institutu srbského jazky SAVU v Bělehradě (1923-2011).","These obituaries are devoted to couple of famouse linguists, first of all Slavists: prof. Rudolf Růžička from the University of Leipzig (1920-2011) and to prof. Milka Ivic, professor of the University in Novi Sad and Institute of Serbian Language in Beograd (1923-2011)."
Ve stati se analyzují české konstrukce srovnávací a konstrukce uvedené výrazy kromě/mimo. Navrhuje se jejich hloubková (tektogramatická) reprezentace rozvinutá v zapuštěnou predikaci a označovaná jako gramatikalizovaná elipsa. Zavádí se dva nové syntaktické vztahy (adice - ADDIT a výjimka - EXC) související s víceznačností konstrukcí s kromě.,"The Czech constructions of comparison and the constructions introduced by kromě/mimo are analyzed. For their deep structure it is necessary to expand them into the embedded predication, which is considered to be a grammaticalized ellipsis. The two new syntactic relations are introduced (ADDIT - an addition, EXC - an exception). They are connected with the ambiguity of kromě constructions."
V článku se hodnotí metodologické směry užívané v české syntaxi od 40. let minulého století. Jako nejvlivnější modely se hodnotí Danešova Dvourovinná valenční syntax a Sgallův Funkční generativní popis.,The metodological approaches used in Czech syntactic research since the 40-ies of the last century are analyzed. The Daneš´s Two-Level Valency Syntax and Sgall´s Functional Generative Description are evaluated as most comprehensive models in the Czech syntax.
Korpusová anotace je důležitou součástí lingvistické analýzy a počítačového zpracování jazyka. Tento článek se zabývá problémy spojenými se syntaktickou anotací mluvených textů na pozadí syntaktické anotace ČAKu.,"Corpus annotation plays an important role in linguistic analysis and computa-tional processing of both written and spoken language. Syntactic annotation of spoken texts becomes clearly a topic of considerable interest nowadays, driven by the desire to improve auto-matic speech recognition systems by incorporating syntax in the language models, or to build language under-standing applications."
"V přednášce představím software, který jsem vyvinul pro převod Kodaňského závislostního korpusu (CDT) do systému Treex. CDT je vícejazyčný korpus vyvinutý v Copenhagen Business School. Treex je multilinguální softwarový systém vyvinutý na Karlově univerzitě v Praze. Treex se používá mimo jiné pro vývoj systémů strojového překladu.

Přednáška bude mít dvě části. V první představím konverzní proceduru. Ve druhé části předvedu možné způsoby, jak s daty v novém formátu pracovat.","I would like to present my recent efforts on converting the Copenhagen Dependency Treebank (CDT) data into Treex. CDT is a multilingual treebank developed at CBS. Treex is a multi-purpose Natural Language Processing software framework developed at Charles University in Prague. Treex is used in a number of projects aimed at building language data resources as well as at developing NLP applications such as Machine Translation systems.
                     
The talk will have two parts. In the first part I will give an overview of the conversion procedure, with focus on pecularities of CDT that made the conversion a challenging task. In the second part I will show how the CDT data in the new format can be browsed and further processed."
The present work focuses on using tree-shaped syntactic structures as an intermediate sentence representation in an experimental English-Czech machine translation system.,Předložená práce je zaměřená na využití stromových syntaktických struktur jakožto reprezentace věty přirozeného jazyka v experimentálním systému pro anglicko-český strojový překlad.
"Předkládáme detailní studii automatické lexikální disambiguace na pilotním vzorku
třiceti anglických sloves za použití lexikonu vzorů slovesných užití (patterns), který vychází
z Corpus Pattern Analysis (CPA). Tato inovátorská lexikografická metoda namísto na
abstraktních definicích jednotlivých významů staví na souhře morfosyntaktické, lexikální a
sémantické/pragmatické podobnosti slovesných užití. Natrénovali jsme několik statistických
klasifikátorů na rozpoznávání těchto vzorů. Klasifikátory využívají jak morfosyntaktických,
tak sémantických rysů. V naší studii se soustředíme na procedury pro extrakci rysů, jejich
výběr a jejich evaluaci. Ukazujeme, že rysy na míru uzpůsobené jednotlivým slovesům, jež
jsou implicitně obsaženy v definici každého vzoru v lexikonu, mají potenciál významně zvýšit
přesnost statistických klasifikátorů s učitelem.","We give a report on a detailed study of automatic lexical disambiguation of 30 sample English
verbs. We have trained and evaluate several statistical classifiers that use both morphosyntactic
and semantic features to assign semantic patterns according to a pattern lexicon.
Our system of semantic classification draws on the Corpus Pattern Analysis (CPA) — a novel
lexicographic method that seeks to cluster verb uses according to the morpho-syntactic, lexical
and semantic/pragmatic similarity of their contexts rather than their grouping according to
abstract semantic definitions. In this paper we mainly concentrate on the procedures for feature
extraction and feature selection. We show that features tailored to particular verbs using
contextual clues given by the CPA method and explicitly described in the pattern lexicon have
potential to significantly improve accuracy of supervised statistical classifiers."
Rozbor různých přístupů k pojetí a popisu stupňovitosti z hlediska aktuálního členění.,Analysis of different approaches to the concept and the description of hierarchy of element from the point of view of topic-focus articulation.
Hlavní principy explicitního pražského závislostního modelu jazyka postupující od funkce k formě.,The article is about main principles of the explicit description of language based on dependency syntax.
Srovnání dvou teoretických přístupů k aktuálnímu členění a uplatnění pražského přistupu v anotovaném počítačovém korpusu češtiny.,A comparison of two theoretical approaches to the information structure and the application of the Praguian approach in an annotated corpus of Czech.
"Srovnání přístupu k aktuálnímu členění v české lingvistice, od základní práce Mathesiovy až po práce současné.","A comparison of different Praguian approaches to information structure, from Vilem Mathesius up today."
"Článek shrnuje lingvistické problémy, na které jsme narazili a které řešili anotátoři při anotování informační struktury ve větách Pražského závislostního korpusu.",Linguistic issues that had to be analyzed and resolved during the annotation of information structure in the Prague Dependency Treebank.
"Akademický korpus češtiny zpracovaný v ÚJČ AV byl jedním z prvních anotovaných počítačových korpusů přirozeného jazyka, a to na rovině morfosyntaktické. Odtud vedla cesta k bohatě anotovanému Pražskému závislostnímu korpusu.",Academic corpus of the Czech language created in the Institute of Czech Language belongs to the first annotated corpora of natural languages ever in existence. This activity was one of the stimuli for the development of the richly annotated corpus of the Prague Dependency Treebank.
"Tento software je modifikací a konfigurací Dspace 1.6, která umožňuje centrům Clarin, která používají Dspace jako svůj software pro repozitáře, využít službu Handle od konzorcia EPIC, doporučenou Clarinem, v rámci Dspace.",This software is a modification and configuration of Dspace 1.6 that allows Clarin centres that employ Dspace as their repository software to use Clarin recommended Handle Service from EPIC Consortium within Dspace.
V této práci se zabýváme doménovou adaptací statistického strojového překladu s využitím dat automaticky stažených z internetu. Experimenty jsou provedeny na doménách životního prostředí a pracovní legislativy.,"We tackle the problem of domain adaptation of Statistical Machine Translation by exploiting domain-specific data acquired by domain-focused web-crawling. We design and evaluate a procedure for automatic acquisition of monolingual and parallel data and their exploitation for training, tuning, and testing in a phrase-based Statistical Machine Translation system. We present a strategy for using such resources depending on their availability and quantity supported by results of a large-scale evaluation on the domains of Natural Environment and Labour Legislation and two language pairs: English--French, English--Greek. The average observed increase of BLEU is substantial at 49.5% relative."
"Současné systémy statistického strojového překladu jsou založeny na logaritmicko-lineárních modelech, které pro hodnocení překladových hypotéz ve fázi dekódování kombinují sadu příznakových funkcí. Tyto modely jsou parametrizovány vektorem vah, které se optimalizují na tzv. vývojových datech, tj. množině vět a jejich referenčních překladů. V tomto článku se zabýváme (častou a pro průmyslové nasazení relevantní) situací, kdy je třeba překladový systém natrénovaný na datech z obecné domény adaptovat na nějakou specifickou doménu, pro kterou jsou k dispozici paralelní data jen ve velice omezeném (či žádném) množství. Ukazujeme, že takové systémy mohou být vhodně adaptovány pomocí optimalizace parametrů za použití jen překvapivě malého množství paralelních doménově-specifických dat nebo tzv. křížovou optimalizací. Možností je také nepoužití optimalizace vůbec. Jednotlivé přístupy analyzujeme a porovnáváme jejich cekovou náročnost. Dále se zabýváme analýzou systémových hyperparametrů (např. maximální délkou frází a velikostí vývojových dat) a jejich optimalizací.","Current state-of-the-art Statistical Machine Translation systems are based on log-linear models
that combine a set of feature functions to score translation hypotheses during decoding. The
models are parametrized by a vector of weights usually optimized on a set of sentences and
their reference translations, called development data. In this paper, we explore a (common
and industry relevant) scenario where a system trained and tuned on general domain data
needs to be adapted to a specific domain for which no or only very limited in-domain bilingual
data is available. It turns out that such systems can be adapted successfully by re-tuning model
parameters using surprisingly small amounts of parallel in-domain data, by cross-tuning or no
tuning at all. We show in detail how and why this is effective, compare the approaches and
effort involved. We also study the effect of system hyperparameters (such as maximum phrase
length and development data size) and their optimal values in this scenario."
"Tento příspěvek se zabývá vztahem korpusu a valenčního slovníku. Slovník vznikl jako vedlejší produkt anotace Pražského závislostního korpusu, stal se důležitým zdrojem jak pro další lingvistický výzkum, tak pro počítačové zpracování češtiny.","In our contribution, we relate the development of a richly annotated corpus and a computational valency dictionary. Our valency dictionary has been created as a “byproduct” of the annotation of the Prague Dependency Treebank (PDT) but it became an important resource for further linguistic research as well as for computational processing of the Czech language."
"Příspěvek se věnuje valenčním vlastnostem českých neproduktivně tvořených (dějových) substantiv odvozených od sloves s předmětovým genitivem. Prvotní motivací bylo zjistit, zda si tato substantiva (např. obava, dotaz, dotek) uchovávají původní adverbální genitivní vazbu, tj. GenAdnom (← GenAdverb). Valenční slovníky ani odborná literatura tuto vazbu u daných substantiv neuvádějí. V subkorpusech ČNK se u některých substantiv vyskytuje, např. naděje úspěchu, jeho dotek puku; vedle ostatních forem daného participantu (např. předložkových skupin) se jedná spíše o okrajovou možnost vyjádření. Za možností / nemožností užití GenAdnom (← GenAdverb) u dějových substantiv stojí různorodé faktory, související patrně především s příslušností daných substantiv k určité sémantické skupině, příp. podskupině (srov. pozitivní vs. negativní duševní stavy, např. odvaha spolupráce vs. *obava zkoušky, snaha vyhnout se strukturní homonymii u substantiv mluvení, např. *dotaz kamaráda.ADDR vs. dotaz kamaráda.ACT).","In the present paper, adnominal counterparts of adverbal objects expressed by prepositionless Genitive (Gen; e.g. obávat se čeho ‘to-be-afraid of-sth’, dotázat se koho ‘to-ask of-sb’) are studied. The intention was to find out if Czech nouns derived from verbs by non-productive means can be modified by Patient (PAT) or Addressee (ADDR) expressed by Gen as well; neither other papers nor valency dictionaries mention this form of the participants. It has turned out that several nouns modified by PAT expressed by Gen can rarely be found in the corpus (e.g. CNC SYN2005, cf. odvaha spolupráce ‘courage of-cooperation’, jeho dotek puku ‘his touch of-the-puck’; other forms of PAT, i.e. prepositional groups, sometimes also infinitive or an embedded objective clause, are more frequent). Factors that influence possibility or impossibility to be modified by PAT or ADDR expressed by Gen are typically connected with the type of the semantic group the noun belongs to (cf. the difference between nouns denoting “positive” vs. “negative” mental state or dispositions, e.g. naděje úspěchu ‘hope of-success’ vs. *obava následků ‘fear of-consequences’, or the tendency to avoid syntactic homonymy of Actor (ACT) and ADDR expressed by Gen, which is typical of nouns of saying, cf. dotaz kamaráda.ACT vs. *dotaz kamaráda.ADDR ‘question of-the-friend’)."
Systém Dialogy.Org je softwarový nástroj určený především k podpoře vytváření a sdílení anotovaných audio-video dat lingvistickou komunitou. Dialogy.Org umožňuje formou webového rozhraní editaci a vyhledávání v přepisech audio-visuálních nahrávek dialogů. Vyhledané úseky textu je možné přehrávat a analyzovat pomocí webového prohlížeče.,Dialogy.Org system is a software tool designed primarily to support the creation and sharing of annotated audio-visual data by linguistic community. The software tool allows editing and searching in the transcripts of audio-visual recordings of dialogues. The dynamic web application provides access for registered users to the digitised archive. Playing and exploring of selected parts is possible in the web browser.
"V tomto příspěvku hodnotíme přínos, který představují syntacticko-sémantické stromy
(tektogramatická rovina anotace) a celá bohatá anotace Pražského závislostního korpusu pro
anotaci diskurzní struktury textu, tedy pro anotaci diskurzních vztahů, jejich konektorů a
argumentů. Rozhodnutím anotovat diskurzní strukturu přímo na stromech se náš přístup liší od
většiny podobně zaměřených projektů, které jsou obvykle založeny na anotaci lineárního textu.
Naším základním předpokladem je, že některé syntaktické rysy větné analýzy odpovídají jistým
rysům z roviny diskurzní struktury. Proto využíváme některé vlastnosti rozsáhlého závislostního
korpusu češtiny k ustanovení nezávislé diskurzní anotační vrstvy. V tomto příspěvku
odpovídáme na otázku, jaké výhody tento přístup přináší.","In the following paper, we discuss and evaluate the benefits that deep syntactic trees
(tectogrammatics) and all the rich annotation of the Prague Dependency Treebank bring to the
process of annotating the discourse structure, i.e. discourse relations, connectives and their
arguments. The decision to annotate discourse structure directly on the trees contrasts with the
majority of similarly aimed projects, usually based on the annotation of linear texts. Our basic
assumption is that some syntactic features of a sentence analysis correspond to certain discourselevel
features. Hence, we use some properties of the dependency-based large-scale treebank of
Czech to help establish an independent annotation layer of discourse. The question that we
answer in the paper is how much did we gain by employing this approach."
Příspěvek popisuje systém použitý pro závislostní syntaktickou analýzu hindských dat v rámci soutěže na Colingu 2012.,The paper describes our system used for dependency parsing of Hindi data during the shared task at Coling 2012.
"Popisujeme naše pokusy s frázovým strojovým překladem pro soutěž WMT 2012. Natrénovali jsme jeden systém pro 14 překladových párů mezi angličtinou nebo češtinou na jedné straně a angličtinou, češtinou, němčinou, španělštinou nebo francouzštinou na druhé straně. Popisujeme sadu výsledků s různými velikostmi trénovacích dat a jejich podmnožin.","We describe our experiments with phrase-based machine translation for the WMT 2012 Shared Task. We trained one system for 14 translation directions between English or Czech on one side and English, Czech, German, Spanish or French on the other side. We describe a set of results with different training data sizes and subsets."
Postřehy z letošních pokusů na ÚFALu v rámci mezinárodní soutěže ve strojovém překladu.,Observations from this year's experiments at ÚFAL for the WMT shared translation task.
"Představujeme HamleDT – harmonizovaný mnohojazyčný závislostní korpus. HamleDT je kolekce existujících závislostních korpusů (nebo do závislostí převedených jiných syntakticky anotovaných korpusů), transformovaných tak, aby odpovídaly jednotnému anotačnímu stylu. Licenční podmínky nám nedovolují dále šířit samotné korpusy, většina z nich je ovšem pro vědecké účely snadno dostupná a my nabízíme software, který tato data převede do normalizované podoby.","We propose HamleDT – HArmonized Multi-LanguagE Dependency Treebank. HamleDT is a compilation of existing dependency treebanks (or dependency conversions of other treebanks), transformed so that they all conform to the same annotation style. While the license terms prevent us from directly redistributing the corpora, most of them are easily acquirable for research purposes. What we provide instead is the software that normalizes tree structures in the data obtained by the user from their original providers."
"Organizátoři každoročního Semináře o strojovém překladu (WMT) připravují a šíří paralelní korpusy, které lze použít při trénování systémů pro soutěžní úlohy. Mezi hlavní typy korpusů patří korpusy News Commentary a Europarl. Oba jsou k dispozici v několika jazykových párech, vždy mezi angličtinou a dalším evropským jazykem: cs-en, de-en, es-en a fr-en. Tyto korpusy nejsou paralelní přes více než dva jazyky. Pocházejí ze stejného zdroje a významně se překrývají, přesto však jsou některé věty přeloženy jen do některých jazyků. Dvojjazyčné paralelní podmnožiny nemají všechny stejný počet párů vět. Takové korpusy nemůžeme přímo nasadit při trénování systému pro např. de-cs (němčina-čeština). Můžeme nicméně použít angličtinu jako pivotní jazyk. Pokud rozpoznáme průnik anglických částí cs-en a de-en, můžeme použít jejich neanglické protějšky a vytvořit z nich paralelní korpus de-cs. Tuto úlohu plní tento software.","The organizers of the annual Workshop on Machine Translation (WMT) prepare and distribute parallel corpora that can be used to train systems for the shared tasks. Two core types of corpora are the News Commentary corpus and the Europarl corpus. Both are available in several language pairs, always between English and another European language: cs-en, de-en, es-en and fr-en. The corpora are not multi-parallel. They come from the same source and there is significant overlap but still some sentences are translated to only a subset of the languages. The bi-parallel subsets do not all have the same number of sentence pairs. Such corpora cannot be directly used to train a system for e.g. de-cs (German-Czech). However, we can use English as a pivot language. If we identify the intersection of the English parts of cs-en and de-en, we can take the non-English counterparts of the overlapping English sentences to create a de-cs parallel corpus. That is what this software does."
"Valenční slovník českých sloves VALLEX, verze 2.6 
obsahující přibližně 2730 záznamů o lexémech pokrývajících cca. 6460 lexikálních jednotek (významů). Slovník je volně k dispozici pro účely výzkumu. Nová verze slovníku je - oproti starší verzi - kvalitativně i kvantitativně obohacena (zejm. jsou pro vybraná slovesa doplněny korpusové příkladů).","The Valency Lexicon of Czech Verbs, Version 2.6 (VALLEX 2.6), is a collection of linguistically annotated data and documentation, resulting from an attempt at formal description of valency frames of Czech verbs. VALLEX 2.6 has been developed at the Institute of Formal and Applied Linguistics, Faculty of Mathematics and Physics, Charles University, Prague. 

VALLEX 2.6 provides information on the valency structure (combinatorial potential) of verbs in their particular senses. VALLEX 2.6 is a successor of VALLEX 1.0, extended in both theoretical and quantitative aspects (including corpus evidence)."
"Článek se soustřeďuje na popis kolekce vět, u kterých byla ručně analyzována větná struktura. Ukazuje, že koncept založený na lineárních segmentech, které lze snadno automaticky detekovat, slouží jako dobrý základ pro identifikaci klauzí v češtině. Anotace segmentů zahrnuje takové jevy jako je závislost kauzí, jejich koordinace, apozice či parenteze.  
Anotace větné struktury doplňuje závislostní přístup k popisu jazyka o explicitní informaci o vztazích mezi klauzemi.","The focus of this article is on the creation of a collection of sentences manually annotated with respect to their sentence structure. We show that the concept of linear segments—linguistically motivated units, which may be easily detected automatically—serves as a good basis for the identification of clauses in Czech. The segment annotation captures such relationships as subordination, coordination, apposition and parenthesis; based on segmentation charts, individual clauses forming a complex sentence are identified. The annotation of a sentence
structure enriches a dependency-based framework with explicit syntactic information on relations among complex units like clauses. We have gathered a collection of 3,444 sentences from the Prague Dependency Treebank, which were annotated
with respect to their sentence structure (these sentences comprise 10,746 segments forming 6,341 clauses). The main purpose of the project is to gain a development data—promising results for Czech NLP tools (as a dependency parser or a machine translation system for related languages) that adopt an idea of clause segmentation have been already reported. The collection of sentences with annotated sentence structure provides the possibility of further improvement of such tools."
Popularizační prezentace pro studenty gymnázia Na Zatlance v rámci Dne profesí. Cílem bylo přiblížit studentům matematickou lingvistiku jako zajímavý obor a obecně propagovat studium přírodních věd.,"Presentations to high school students within the ""Day of professions"". The aim was to introduce students to mathematical linguistics as an interesting field, and generally promote the study of natural sciences."
"V češtině i v ruštině existuje množina předpon, jejichž připojením k nedokonavému slovesu a přidáním zvratného zájmena pozměníme význam původního slovesa vždy téměř stejným způsobem. Toho lze využít při automatickém rozpoznávání slovních tvarů, aniž by bylo třeba je ukládat do morfologických slovníků.","There is a set of prefixes in Czech as well as in Russian, which, added to imperfective verbs together with a reflexive pronoun, change the meaning of the verb in the same manner. This feature is so regular that could help automatically recognize words without using morphological dictionaries."
Článek se věnuje problematice sémantické analýzy sloves a lexikálnímu popisu sloves se zřetelem k vytvoření trénovacích dat pro automatický sémantický analyzátor. Vychází z metody Corpus Pattern Analysis a zkoumá její uplatnění v lexikálním popisu sloves pro účely NLP pomocí měření mezianotátorské shody.,"There is no objectively correct way to create a monolingual entry of a polysemous verb. By structuring a verb into readings, we impose our conception onto lexicon users, no matter how big a corpus we use in support. How do we make sure that our structuring is intelligible for others? 

We are performing an experiment with the validation of the fully corpus-based Pattern Dictionary of English Verbs (Hanks & Pustejovsky, 2005), created according to the lexical theory Corpus Pattern Analysis (CPA). The lexicon is interlinked with a large corpus, in which several hundred randomly selected concordances of each processed verb are manually annotated with numbers of their corresponding lexicon readings (“patterns”). It would be interesting to prove (or falsify) the leading assumption of CPA that, given the patterns are based on a large corpus, individual introspection has been minimized and most people can agree on this particular semantic structuring. We have encoded the guidelines for assigning concordances to patterns and hired annotators to annotate random samples of verbs cotained in the lexicon. Apart from measuring the interannotator agreement, we analyze and adjudicate the disagreements. The outcome is offered to the lexicographer as feedback. The lexicographer revises his entries and the agreement can be measured againg on a different random sample to test whether or not the revision has brought an improvement of the interannotator agreement score. A high interannotator agreement suggests that lexicon users are likely to find a pattern corresponding to a random verb use of which they seek explanation. A low agreement score gives a warning that there are patterns missing or vague.  

We focus on machine-learning applications, but we believe that this procedure is of interest even for quality management in human lexicography."
"Představujeme VPS-30-En, malý lexikální zdroj, který obsahuje následujících 30 sloves: access, ally, arrive, breathe,
claim, cool, crush, cry, deny, enlarge, enlist, forge, furnish, hail, halt, part, plough, plug, pour, say, smash, smell, steer, submit, swell,
tell, throw, trouble, wake and yield. 
VPs-30-En jsme vytvořili a používáme jej k výzkumu potenciálu mezianotátorské shody u sémantického značkování podle anotačního schématu CPA.","We are presenting VPS-30-En, a small lexical resource that contains the following 30 English verbs: access, ally, arrive, breathe,
claim, cool, crush, cry, deny, enlarge, enlist, forge, furnish, hail, halt, part, plough, plug, pour, say, smash, smell, steer, submit, swell,
tell, throw, trouble, wake and yield. We have created and have been using VPS-30-En to explore the interannotator agreement potential
of the Corpus Pattern Analysis. VPS-30-En is a small snapshot of the Pattern Dictionary of English Verbs (Hanks and Pustejovsky,
2005), which we revised (both the entries and the annotated concordances) and enhanced with additional annotations. It is freely
available at http://ufal.mff.cuni.cz/spr. In this paper, we compare the annotation scheme of VPS-30-En with the original PDEV. We
also describe the adjustments we have made and their motivation, as well as the most pervasive causes of interannotator disagreements."
"Nízká mezianotátorská shoda (IAA) je známým problémem v sémantickém značkování. IAA koreluje s granularitou lexií a oboje koreluje s množstvím informace i s její spolehlivosí. Představujeme Reliable Gain (RG), míru, která optimalizuje sémantickou granularitu se zřetelem ke spolehlivosti informace.","Low interannotator agreement (IAA) is a
well-known issue in manual semantic tagging
(sense tagging). IAA correlates with
the granularity of word senses and they
both correlate with the amount of information
they give as well as with its reliability.
We compare different approaches to semantic
tagging in WordNet, FrameNet, Prop-
Bank and OntoNotes with a small tagged
data sample based on the Corpus Pattern
Analysis to present the reliable information
gain (RG), a measure used to optimize the
semantic granularity of a sense inventory
with respect to its reliability indicated by
the IAA in the given data set. RG can also
be used as feedback for lexicographers, and
as a supporting component of automatic semantic
classifiers, especially when dealing
with a very fine-grained set of semantic categories."
"Experimenty se sémantickou anotací založenou na Corpus Pattern Analysis a lexikálním zdroji PDEV (Hanks a Pustejovsky, 2005) ukázaly potřebu evaluační míry, která by identifikovala optimální vztah mezi sémantickou granularitou sémantických kategorií v lexikálním  popisu slovesa a spolehlivostí anotace, která se měří pomocí mezianotátorské shody. Představujeme takovou míru.","Experiments with semantic annotation based on the Corpus pattern Analysis and the lexical resource PDEV (Hanks and Pustejovsky, 2005), revealed a need of an evaluation measure that would identify the optimum relation between the semantic granularity of the semantic categories in the description of a verb and the reliability of the annotation expressed by the interannotator agreement (IAA). We have introduced the Reliable Information Gain (RG), which computes this relation for each tag selected by the annotators and relates it to the entry as a whole, suggesting merges of unreliable tags whenever it would increase the information gain of the entire tagset (the number of semantic categories in an entry). The merges suggested in our 19-verb sample correspond with common sense. One of the possible applications of this measure is quality management of the entries in a lexical resource."
Článek popisuje přístu k automatické a manuální anotaci žákovského korpusu.,"We present an approach to building a learner corpus of Czech, manually corrected and annotated with error tags using a complex grammar-based taxonomy of errors in spelling, morphology, morphosyntax, lexicon and style. This grammar-based annotation is supplemented by a formal  classification of errors based on surface alternations. To supply additional information about non-standard or ill-formed expressions, we aim at a synergy of manual and automatic annotation, deriving information from the original input and from the manual annotation."
Příspěvek se zabývá volným slovosledem z pohledu redukční analýzy. Využívá jejích formálních základů a datové struktury. Navrhujeme několik variant míry volnosti slovosledu založených na operaci posouvání (shift). tedy operaci spočívající ve slovosledných změnách zachovávajících syntaktickou správnost věty. Tyto míry umožňují pochopit a studovat rozdíl mezi komplexitou slovosledu (jak složité je analyzovat věty s komplexním slovosledem) a volností slovosledu (jak je možné měnit slovosled při zachování závislostních relací ve větě).,"The paper focuses on a phenomenon of free word order through the analysis by reduction.
It exploits its formal background and data types and studies the word order freedom
of a (natural) language. We propose and discuss several variants of a measure based on
a number of word order shifts (i.e., word order changes preserving syntactic correctness,
individual word forms, their morphological characteristics and their surface dependency
relations). Such measure helps to understand the difference between word order complexity
(how difficult it is to parse sentences with more complex word order) and word
order freedom (to which extent it is possible to change the word order without causing a
change of individual word forms, their morphological characteristics and/or their surface
dependency relations)."
"Tento článek se zabývá formalizací popisu volného slovosledu přirozených jazyků. Využívá mechanismu redukční analýzy a definuje míru volnosti slovosledu na základě počtu přesunů provedených v průběhu analýzy. Tato míra umožňuje rozlišit složitost slovosledu (jak obtížné je analyzovat věty se složitějším slovosledem) a volnost slovosledu (do jaké míry je možné měnit slovosled, aniž by došlo ke změně jednotlivých slovních tvarů, jejich morfologické charakteristiky a / nebo jejich povrchově syntaktických vztahů). Tento rozdíl je ilustrován na pilotní studii českých vět s klitikami.","This paper contains an attempt to formalize the degree of word order freedom for natural languages. It exploits the mechanism of the analysis by reduction and defines a measure based on a number of shifts performed in the course of the analysis. This measure helps to understand the difference between the word order complexity (how difficult it is to parse sentences with more complex word order) and word order freedom in Czech (to which extent it is possible to change
the word order without causing a change of individual word forms, their morphological characteristics and/or their surface dependency relations). We exemplify this distinction on a pilot study on Czech sentences with clitics."
"Příspěvek zkoumá fenomén volného slovosledu přirozeného jazyka metodou redukční analýzy. Využívá přitom formální rámec a datový typ této analytické metody a uplatňuje ho na zkoumání minimálního počtu slovosedných posunů (tj. slovosledných změn zachovávajících syntaktickou správnost, jednotlivé slovní tvary, jejicj morfologickou a syntaktickou charakteristiku).
Zkoumání se soustřeďují na dva vzájemně se ovlivňující jevy související se slovosledem: (ne)projektivitu a počet přesunů. Tyto jevy jsou ilustrovány na vzorlu českých vět obsahujících klitiky.","The paper investigates a phenomenon of free word order through the analysis by reduction. It exploits its formal background and data types and studies the word order freedom by means of the minimal number of word order shifts (word order
changes preserving syntactic correctness, individual word forms, their morphological characteristics and/or their surface dependency relations).
The investigation focuses upon an interplay of two phenomena related to word order: (non-)projectivity of a sentence and number of word order shifts within the analysis by reduction. This interplay is exemplified on a sample of Czech sentences with clitics."
"Kapitola popisuje historii pokusů s automatickým překladem mezi příbuznými jazyky, použité metody a dosažené výsledky.","This chapter describes the history of experiments in the field of machine translation among related Slavic languages, methods used and results achieved."
"Představujeme nejnovější verzi Pražského závislostního treebanku PDT 2.5, který bude poprvé vydán pod veřejnou licencí. Výhody PDT 2.5 ukážeme na srovnání s nejmodernějšími treebanky. Představíme nové vlastnosti verze 2.5, popíšeme, jak byly anotovány i jak spolehlivá tato anotace je. Ukážeme, jakými dotazy lze nové jevy hledat a jak se zobrazují v nástrojích dodávaných spolu s treebankem.","We present the Prague Dependency Treebank 2.5, the newest version of  PDT and the first to be released under a free license. We show the benefits of PDT 2.5 in comparison to other state-of-the-art treebanks. We present the new features of the 2.5 release, how they were obtained and how reliably  they are annotated. We also show how they can be used in queries and how they are visualised with tools released alongside the treebank."
"Od řady českých adjektiv se tvoří jak adverbium s příponou -e, tak adverbium s příponou -o, př. deštivý – deštivě/deštivo, drahý – draze/draho. Deadjektivní adverbia s příponou -o často vystupují jako součást verbonominálního predikátu se slovesem být v neosobních konstrukcích, některá z nich se na tuto větněčlenskou funkci dokonce omezují (př. na horách bylo deštivo), jiná plní kromě této funkce i funkce jiné (srov. je tam draho vs. přišlo ho to draho). Predikativní funkce deadjektivních adverbií na -o se stala hlavním argumentem pro úvahy o vyčlenění těchto adverbií (spolu s dalšími výrazy) jako samostatného slovního druhu, tzv. predikativ. V příspěvku probíráme syntaktické a sémantické vlastnosti těchto adverbií na -o na základě aktuálního korpusového materiálu. Jako výhodnější se ukazuje popisovat tato adverbia jako samostatné lexikální jednotky, nikoli jako skupinu.","From a number of Czech adjectives, both an adverb with the suffix -o and an adverb with the suffix -e are derived, cf. deštivý `rainy’ – deštivo/deštivě, drahý `expensive’ – draho/draze. These pairs of adverbs have often the same meaning but the adverb with the suffix -o occurs as a part of the predicate (with the verb být `to be’; ráno bylo deštivo `in the morning it was rainy’) while the adverb with the suffix -e is often specialized for the adverbial function (e.g. ráno vypadalo deštivě/*deštivo `the morning looked rainy’). On the functional specialization Komárek’s (1954) proposal to separate the adverbs with the suffix -o as an autonomous part of speech was based. Since the actual corpus material indicates that both the adverb with the suffix -o and the adverb with -e are acceptable in the same context (cf. je tam draho/draze `it is an expensive place to live’, draho/draze prodat `to sell dear’ VS. přišlo ho to draho/*draze ` it cost him dear’, draze/*draho za to zaplatil `he paid for this’) but the (non)acceptability cannot be probably explained by a grammatical principle, it seems to be appropriate to consider these words further as adverbs and to describe them as separate lexical units rather than a homogenous group."
"Článek se zabývá anotací větné modality v Pražském závislostním korpusu (PDT). Větná modalita je v češtině vyjádřena kombinací několika faktorů, především slovesným způsobem a koncovou interpunkcí. V PDT 2.0 byla větná modalita přiřazena poloautomaticky kořeni každé věty (stromu) a dále kořenům stromů reprezentujících vsuvku nebo přímou řeč. Tento přístup byl příliš zjednodušující pro adekvátní zachycení daného jevu, proto byla metoda přiřazení větné modality pro příští vydání treebanku (PDT 3.0) zrevidována a rozpracována.","The paper focuses on the annotation of sentence modality in the Prague Dependency Treebank (PDT). Sentence modality is expressed by a combination of several means in Czech, from which the category of verbal mood and the final punctuation of the sentence are the most important ones. In PDT 2.0, sentence modality was assigned semi-automatically to the root node of each sentence (tree) and further to the roots of parenthesis and direct speech subtrees. As this approach was too simple to adequately represent the linguistic phenomenon in question, the method for assigning the sentence modality has been revised and elaborated for the forthcoming version of the treebank (PDT 3.0)."
"Zpětno vazební učení již bylo úspěšně použito k optimalizaci statisktických dialogových systémů. Typicky zpětnovazební učení se učí online on-policy tj. v přímé interakci s uživatelem. Alternativou k tomuto přístupu je off-policy učení kdy otimální strategie řízení je určena z korpusu již dříve pořízených dialogů. Tento článek prezentuje a nový zpětnovazební algoritmus založený na přirozených gradientech a vhodné adaptaci samplování dat. Experimenty ukazují, že prezentovaný algoritmus je schopen se naučit strategii řízení, která je lepší než manuálně vytvořená strategie řízení.","Reinforcement learning methods have been successfully used
to optimise dialogue strategies in statistical dialogue systems.
Typically, reinforcement techniques learn on-policy i.e., the
dialogue strategy is updated online while the system is interacting
with a user. An alternative to this approach is off-policy
reinforcement learning, which estimates an optimal dialogue
strategy offline from a fixed corpus of previously collected
dialogues.
This paper proposes a novel off-policy reinforcement
learning method based on natural policy gradients and importance
sampling. The algorithm is evaluated on a spoken
dialogue system in the tourist information domain. The experiments
indicate that the proposed method learns a dialogue
strategy, which significantly outperforms the baseline handcrafted
dialogue policy"
"Představujeme značkovač závislostních vztahů založený na metodě MIRA, vyladěný na češtině.","We present a MIRA-based labeller designed to assign dependency relation labels to edges in a dependency parse tree, tuned for Czech language. The labeller was created to be used as a second stage to unlabelled dependency parsers but can also improve output from labelled dependency parsers. We evaluate two existing techniques which can be used for labelling and experiment with combining them together. We describe the feature set used. Our final setup significantly outperforms the best results from the CoNLL 2009 shared task."
"Prezentujeme vylepšenou verzi systému DEPFIX pro automatický post-editing výstupu z anglicko-českého strojového překladu, který se snaží zlepšovat jeho plynulost. Rozšířili jsme sadu pravidel použitou původním systémem DEPFIX a změřili výkon jednotlivých pravidel. Navíc jsme dvěma způsoby upravili parser McDonalda et al. (2005) pro zvýšení kvality parsingu výstupu strojového překladu. Ukazujeme, že náš systém je schopný zlepšit výstup nejmodernějších překladových systémů.","We present an improved version of DEPFIX, a system for automatic rule-based post-processing of English-to-Czech MT outputs designed to increase their fluency. We enhanced the rule set used by the original DEPFIX system and measured
the performance of the individual rules.
We also modified the dependency parser of
McDonald et al. (2005) in two ways to adjust
it for the parsing of MT outputs. We show that
our system is able to improve the quality of the
state-of-the-art MT systems."
"Představujeme dvě metody pro trénování závislostního parseru vhodného pro parsing výstupů strojového překladu. Upravili jsme MST parser použitím dalších rysů ze zdrojového jazyka a zavedením umělých gramatických chyb do trénovacích dat parseru, takže tato více odpovídají výstupu storjového překladu. Upravený parser evaluujeme na systému DEPFIX, který zlepšuje výstupy anglicko-českého strojového překladu automatickými opravami založenými na pravidlech. Obě úpravy parseru vedou ke zvýšení skóre BLEU; jejich kombinace byla evaluována manuálně a vykazuje statisticky signifikantní zlepšení kvality překladu.","In this paper, we present two dependency
parser training methods appropriate for parsing outputs of statistical machine translation (SMT), which pose problems to standard
parsers due to their frequent ungrammaticality. We adapt the MST parser by exploiting
additional features from the source language,
and by introducing artificial grammatical errors in the parser training data, so that the
training sentences resemble SMT output.
We evaluate the modified parser on DEPFIX, a system that improves English-Czech
SMT outputs using automatic rule-based corrections of grammatical mistakes which requires parsed SMT output sentences as its input. Both parser modifications led to improvements in BLEU score; their combination was evaluated manually, showing a statistically significant improvement of the translation quality."
"Množstvo pozornosti v MT komunitě bylo v nedávne době věnováno zlepšování lexikálního výběru v cílovém jazyce pomocí zachycení kontextu širšího nežli jedna věta. V této přednášce prezentuji náš příspěvek k těmto snahám, konkrétně pokrok v obohacování překladových modelů pro překlad z angličtiny do češtiny systémem TectoMT.
Ze všeho nejdřív jsme provedli čistě techický krok. Nahradili jsme doteď používaný modul MaxEnt na strojové učení nástrojem Vowpal Wabbit. Ten nám nejenom umožňuje trénovat modely rychleji a tím využít víc trénovacích příkladů a rysů, ale také nabízí bohaté možnosti parametrizace, co dohromady může vést k zlepšení našeho MT systému.
Nicméně, hlavním cílem tohoto pořád běžícího projektu je prozkoumat potenciál lexikálních kontextových rysů na vylepšení překladu. Činíme tak přidáním standardních bag-of-words rysů a zavedením nových rysů reprezentujících koncepty z Explicitní Sémantické Analýzy, co je metoda původně vyvynuta v oboru Dobývaní znalostí.","Much of the attention in the MT community has recently been devoted to improving the lexical choice in the target language by capturing a context wider than just a single sentence.
In this talk I will present our contribution to these efforts, particularly the progress in enriching translation models for English to Czech translation within the TectoMT system.
First of all, we performed a pure technical step. We replaced the MaxEnt learning module used so far with the Vowpal Wabbit learning toolkit. It
not only allows us to train our models faster, to exploit more training examples and features, but it also offers rich parametrization options, which can together lead to improvement of our MT system.
However, the main objective of this ongoing work is to explore the potential of lexical context features to improve the translation. We do so by including the standard bag-of-words features and by introducing novel features representing concepts coming from Explicit Semantic
Analysis, which was originally developed in the field of Information Retrieval."
V této přednášce jsem prezentoval posun témy mojeho výzkumu z využití koreference na využití textového kontextu všeobecně v úloze strojového překladu. Představil jsem lexikální diskriminativní překladové modely a prvotní experimenty s nimi v rámci překladu z angličtiny do češtiny systémem TectoMT.,In this talk I presented the shift of my research from utilization of coreference to utilization of text context in general in the task of Machine Translation. I introduced lexical discriminative translation models and the initial experiments with them integrated within the English to Czech translation scenario in TectoMT system.
"Identifikace jazyku psaného textu se zkoumá již několik desetiletí. Navzdory tomuto faktu se většina vůzkumů soustředila pouze na pár nejčastěji používaných jazyků zatímco ty ostatní jsou ignorovány. Při identifikaci velkého množství jazyků je nutné řešit jiné problémy než u identifikace malého množství jazyků, protože v opačném případě nastává pokles přesnosti. Cílem tohoto článku je prozkoumat důvody tohoto poklesu. Aby bylo možné izolovat jednotlivé faktory použili jsme 5 různých algoritmů a 3 různé počty jazyků. SVM algoritmus dosáhl úspěšnosti 98% pro 90 jazyků a YALI algoritmus založená na ohodnocující funkci dosáhl úspěšnosti 95,4%. YALI algoritmus je sice nepatrně horší, ale jazyky identifikuje 17x rychleji a jeho trénování je dokonce 4000x rychlejší.

Připravili jsme také 3 různé datasety s různým počtem jazyků a velikostí vzorků, abychom překonali nedostatek veřejně dostupných trénovacích dat.","Language identification of written text has been studied for several decades. Despite this fact, most of the research is focused on a few most spoken languages, whereas the minor ones are ignored. The identification of a larger number of languages brings new difficulties that do not occur for a few languages. These difficulties are causing decreased accuracy. The objective of this paper is to investigate the sources of such degradation. In order to isolate the impact of individual factors, 5 different algorithms and 3 different number of languages are used. The Support Vector Machine algorithm achieved an accuracy of 98% for 90 languages and the YALI algorithm based on a scoring function had an accuracy of 95.4%. The YALI algorithm has slightly lower accuracy but classifies around 17 times faster and its training is more than 4000 times faster.

Three different data sets with various number of languages and sample sizes were prepared to overcome the lack of standardized data sets. These data sets are now publicly available."
"Vytvořili jsme korpus obsahující texty ve 106 jazycích z dokumentů, které jsou dostupné na Internetu a Wikipedii. W2C Web Corpus obsahuje 54,7 GB textu a W2C Wiki Corpus obsahuje 8,5 GB textu. W2C Web Corpus obsahuje více než 100 MB textu pro 75 jazyů a alespoň 10 MB textu pro 100 jazyků. Tyto korpusy jsou jedinečným zdrojem dat pro lingvistiku, protože překonávají všechny dosud publikované práce, jak v množství nashromážděných textů, tak i v množství obsažených jazyků. Tento zdroj dat může být především užitečný pro vědce specializujícící se na vývoj vícejazyčných technologií. Také jsme vyvinuli software, který výrazně usnadňje tvorbu korpusů pro libovolný jazyk z textů volně dostupných na Internetu. Při vývoji jsme se hlavně zaměřili na komponenty pro filtrovaní a odstraňování duplicit, což nám umožnilo dosáhnout vysoké kvality výsledných dat.","We have built a corpus containing texts in 106 languages from texts available on the Internet and on Wikipedia. The W2C Web Corpus contains 54.7 GB of text and the W2C Wiki Corpus contains 8.5 GB of text. The W2C Web Corpus contains more than 100 MB of text available for 75 languages. At least 10 MB of text is available for 100 languages. These corpora are a unique data source for linguists, since they outclass all published works both in the size of the material collected and the number of languages covered. This language data resource can be of use particularly to researchers specialized in multilingual technologies development. We also developed software that greatly simplifies the creation of a new text corpus for a given language, using text materials freely available on the Internet. Special attention was given to components for filtering and de-duplication that allow to keep the material quality very high."
"Různé experimenty z literatury naznačují, že ve statistickém strojového překladu (SMT), předzpracování nebo závěrečné úpravy pro morfologicky bohaté jazyky vedou k lepší kvalitě překladu. V této práci jsme se zaměřili na jazykový pár angličtina-tamilština.","Various experiments from literature suggest that in statistical machine translation (SMT), applying either pre-processing or post-processing to morphologically rich languages leads to better translation quality. In this work, we focus on the English-Tamil language pair. We implement suffix-separation rules for both of the languages and evaluate the impact of this
preprocessing on translation quality of the phrase-based as well as hierarchical model in terms of BLEU score and a small manual evaluation. The results confirm that our simple suffix-based morphological processing helps to obtain better translation performance. A by-product of our 
efforts is a new parallel corpus of 190k sentence pairs gathered from the web."
"Anotované korpusy jako treebanks jsou důležité pro vývoj analyzátorů, jazykové aplikace, stejně jako porozumění
Jazyk sám. Jen velmi málo jazyků mají tyto omezené zdroje. V tomto článku si popíšeme naše úsilí v syntakticky anotace
malé korpusy (600 vět) z Tamil jazyce. Naše anotace je podobný Pražského závislostního korpusu (PDT) a skládá se z
Anotace na 2 podlažích či vrstev: (i) Morfologická rovina (m-layer) a (ii) analytické vrstvy (vrstvy). U obou vrstev, uvádíme
anotace programů, tj. poziční značení pro m-layer a vztahy závislosti na několika vrstev. Na závěr budeme diskutovat některé otázky v
korpus vývoj pro Tamil.","Annotated corpora such as treebanks are important for the development of parsers, language applications as well as understanding of the
language itself. Only very few languages possess these scarce resources. In this paper, we describe our efforts in syntactically annotating
a small corpora (600 sentences) of Tamil language. Our annotation is similar to Prague Dependency Treebank (PDT) and consists of
annotation at 2 levels or layers: (i) morphological layer (m-layer) and (ii) analytical layer (a-layer). For both the layers, we introduce
annotation schemes i.e. positional tagging for m-layer and dependency relations for a-layers. Finally, we discuss some of the issues in
treebank development for Tamil."
"Morph délka je jedním z orientační funkce
, která pomáhá učit morfologii jazyků,
zejména aglutinační jazyky.
V tomto článku vám představíme jednoduchý bez dozoru
model pro morfologické segmentace
a pozorujete, jak se znalosti morph
Délka ovlivnit výkon segmentaci
úkol v rámci bayesovského rámce.
Model je založen na (Goldwater et
al., 2006) unigram slovo segmentace modelu
a předpokládá jednoduchou distribuci přes předchozí
morph délka. Jsme experimentovat tento model
na dvou velmi příbuzných a aglutinační jazyky
Tamil a Telugu to, a porovnávat
naše výsledky s nejmodernější Morfessor
systém. Ukazujeme, že znalost
morph délka má pozitivní vliv a poskytuje
konkurenceschopných výsledků, pokud jde o celkový
výkon.","Morph length is one of the indicative feature
that helps learning the morphology of languages,
in particular agglutinative languages.
In this paper, we introduce a simple unsupervised
model for morphological segmentation
and study how the knowledge of morph
length affect the performance of the segmentation
task under the Bayesian framework.
The model is based on (Goldwater et
al., 2006) unigram word segmentation model
and assumes a simple prior distribution over
morph length. We experiment this model
on two highly related and agglutinative languages
namely Tamil and Telugu, and compare
our results with the state of the art Morfessor
system. We show that, knowledge of
morph length has a positive impact and provides
competitive results in terms of overall
performance."
Tato práce se zabývá využitím manuálně post-editovaných automatických překladů pro iterativní trénování systémů statistického strojového překladu.,"The post-editing of machine translated content has proved to be more productive than translating from
scratch in the localisation industry. A study carried out at Autodesk shows that Machine Translation (MT) and post-editing of technical documentation by professional translators provides a sustained productivity increase across different languages."
"Tato práce se zabývá evaluací výkonosti větných a slovních zarovnávačů, což je velice významný aspekt pro průmyslové nasazení, a ukazuje, že zdroje vyžadované různými nástroji se velice liší.","This paper presents a novel efﬁciencybased evaluation of sentence and word aligners. This assessment is critical in order to make a reliable use in industrial scenarios. The evaluation shows that the resources required by aligners differ rather broadly. Subsequently, we establish limitation mechanisms on a set of aligners deployed as web services. These results, paired with the quality expected from the aligners, allow providers to choose the most appropriate aligner according to the task at hand."
"Představujeme TerrorCat, metriku kvality strojového překladu s níž jsme se účastnili soutěže WMT12. TerrorCat se opírá o automaticky odhadnuté počty několika kategorií překladových chyb a předpovídá tak, která ze dvou kandidátských vět je lepší.","We present TerrorCat, a submission to the
WMT’12 metrics shared task. TerrorCat uses
frequencies of automatically obtained translation
error categories as base for pairwise comparison
of translation hypotheses, which is in
turn used to generate a score for every translation.
The metric shows high overall correlation
with human judgements on the system
level and more modest results on the level of
individual sentences."
"V nedávné době se objevily první automatické metody identifikace chyb v překladu. Představujeme materiál, na němž lze takové metody vyhodnocovat, konkrétně kolekci textů, kde lidé ručně překladové chyby označili.","Recently the first methods of automatic diagnostics of machine translation have emerged; since this area of research is relatively young,
the efforts are not coordinated. We present a collection of translation error-annotated corpora, consisting of automatically produced trans-
lations and their detailed manual translation error analysis. Using the collected corpora we evaluate the available state-of-the-art methods
of MT diagnostics and assess, how well the methods perform, how they compare to each other and whether they can be useful in practice."
"Představujeme komplexní open-source nástroj pro detailní analýzu chyb strojového překladu, který umožňuje automatickou detekci a klasifikaci chyb, poskytuje několik algoritmů pro jednojazyčné zarovnání (alignment) slov a procházení trénovacích a testovacích korpusů.","We present a complex, open source tool for detailed machine translation error analysis providing the user with automatic error detection
and classification, several monolingual alignment algorithms as well as with training and test corpus browsing. The tool is the result of
a merge of automatic error detection and classification of Hjerson (Popović, 2011) and Addicter (Zeman et al., 2011) into the pipeline
and web visualization of Addicter. It classifies errors into categories similar to those of Vilar et al. (2006), such as: morphological, reordering, missing words, extra words and lexical errors. The graphical user interface shows alignments in both training corpus and
test data; the different classes of errors are colored. Also, the summary of errors can be displayed to provide an overall view of the MT
system’s weaknesses. The tool was developed in Linux, but it was tested on Windows too."
Článek popisuje Korpus starších českých textů a ukazuje možnosti jeho využití v lingvistice.,The article describes the Corpus of older Czech texts and demonstrates how it is possible to use it in linguistics.
"V publikované verzi přednášky se syntax hodnotí jako poměrně nová disciplina jazykovědy, která však má v české lingvistice důstojnou reprezentaci od 40. let minulého století. Byla zahájena Šmilauerovou Novočeskou skladbou a pokračuje brněnskými syntaxemi Grepla a Karlíka.","The two authors, scolars suscribing to two different syntactic streams, present their views on classical syntactic handbooks from the 1940s and 1950s. The two main streams are focused here (two-level valency syntax and functional generative description)."
"Článek prezentuje systém pro kombinování lidských přepisů s automatickým rozpoznáváním řeči pro vytvoření kvalitního přepisu velkého korpusu v dobrém čase. Systém používá web jako rozhraní pro přehrávání audia, synchronní zobrazování automaticky získaného přepisu a umožnění uživateli opravovat chyby v přepisu. Lidmi zaslané opravy jsou poté použity ve statistickém rozpoznávání mluvené řeči pro zdokonalení akustického i jazykového modelu a přegenerování celého přepisu. Systém je v současnosti vyvíjen.

Článek prezentuje návrh systému, zpracovaný korpus, jakož i možnosti použití systému na jiných datech.","The paper presents a system for combining human transcriptions with automated speech recognition to create a quality transcription of a large corpus in good time. The system uses the web as interface for playing back audio, displaying the automatically-acquired transcription synchronously, and enabling the visitor to correct errors in the transcription. The human-submitted corrections are then used in the statistical ASR to improve the acoustic as well as language model and re-generate the bulk of transcription. The system is currently under development.

The paper presents the system design, the corpus processed as well as considerations for using the system in other settings."
Arabština je známá svojí bohatou a složitou morfologií. Tato práce se zabývá problémem generování arabských slovních forem za účelem kontroly textu. Námi vytvořený slovník obsahuje 9 milionů povrchových forem slov. Práce dále popisuje  konstrukci a evaluaci znakového jazykového modelu pro kontrolu pravopisu arabských slov.,"Arabic is a language known for its rich and complex morphology. Although many research projects have focused on the problem of 
Arabic morphological analysis using different techniques and approaches, very few have addressed the issue of generation of fully 
inflected words for the purpose of text authoring.  Available open-source spell checking resources for  Arabic are too small and 
inadequate. Ayaspell, for example, the official resource used with OpenOffice applications, contains only 300,000 fully inflected 
words. We try to bridge this critical gap by creating an adequate, open-source and large-coverage word list for Arabic containing 
9,000,000 fully inflected surface words. Furthermore, from a large list of valid forms and invalid forms we create a character-based 
tri-gram language model to approximate knowledge about permissible character clusters in Arabic, creating a novel method for 
detecting spelling errors. Testing of this language model gives a precision of 98.2% at a recall of 100%. We take our research a step 
further by creating a context-independent spelling  correction tool using a finite-state automaton that measures the edit distance 
between input words and candidate corrections, the  Noisy Channel Model, and knowledge-based rules. Our  system performs 
significantly better than Hunspell in choosing the best solution, but it is still below the MS Spell Checker."
"Tento článek popisuje soutěž “Shared Task on Applying Machine Learning Techniques to Optimise the Division of Labour in Hybrid Machine
Translation” (ML4HMT), zaměřenou na výzkum kombinování systémů pro strojový překlad. Úkolem soutěže bylo zkombinovat výstupy několika systémů pro strojový překlad a vylepšit tak výslednou kvalitu překladu.","We describe the “Shared Task on Applying Machine Learning Techniques to Optimise the Division of Labour in Hybrid Machine
Translation” (ML4HMT) which aims to foster research on improved system combination approaches for machine translation (MT).
Participants of the challenge are requested to build hybrid translations by combining the output of several MT systems of different types.
We ﬁrst describe the ML4HMT corpus used in the shared task, then explain the XLIFF-based annotation format we have designed for
it, and brieﬂy summarize the participating systems. Using both automated metrics scores and extensive manual evaluation, we discuss
the individual performance of the various systems. An interesting result from the shared task is the fact that we were able to observe
different systems winning according to the automated metrics scores when compared to the results from the manual evaluation. We
conclude by summarising the ﬁrst edition of the challenge and by giving an outlook to future work."
"V poslední době se výzkum v oblasti strojového překladu zaměřuje mimo jiné na hybridní a kombinavané systémy, které často vedou ke zlepšení kvality výsledného překladu.  V této práci popisujeme paralelní korpus vytvořený speciálně pro tuto úlohu. Korpus obsahuje metadata a anotace poskytované různými systémy strojového překladu, které lze v hybridních a kombinovaných systémech využít.","In recent years, machine translation (MT) research focused on investigating how hybrid MT
as well as MT combination systems can be designed so that the resulting translations give an
improvement over the individual translations.
As a ﬁrst step towards achieving this objective we have developed a parallel corpus with
source data and the output of a number of MT systems, annotated with metadata information,
capturing aspects of the translation process performed by the diﬀerent MT systems.
As a second step, we have organised a shared task in which participants were requested
to build Hybrid/System Combination systems using the annotated corpus as input. The main
focus of the shared task is trying to answer the following question: Can Hybrid MT algorithms
or System Combination techniques beneﬁt from the extra information (linguistically motivated, decoding and runtime) from the diﬀerent systems involved?
In this paper, we describe the annotated corpus we have created. We provide an overview
on the participating systems from the shared task as well as a discussion of the results."
"Příspěvěk se zabývá otázkou, jaké jazykové prostředky mohou být zahrnuty do anotace diskurzních vztahů v Pražském závislostním korpusu (PDT), a pokouší se za tímto účelem prozkoumat tzv. alternativní lexikální vyjádření diskurzních konektorů (altlexů) v češtině.","The paper concentrates on which language means may be included into the annotation of discourse relations in the Prague Dependency
Treebank (PDT) and tries to examine the so called alternative lexicalizations of discourse markers (AltLex’s) in Czech."
"Práce se zabývá otázkou, jaké jazykové prostředky mohou být zahrnuty do anotace
diskurzních vztahů Pražského závislostního korpusu (PDT). Jejím cílem je prozkoumat
alternativní vyjádření diskurzních konektorů (tzv. altlexů) v češtině. Analýza vychází
z anotovaných dat PDT, jejím předmětem je mimo jiné srovnání českých altlexů
vyskytujících se v PDT a anglických altlexů z PDTB (anotovaného pensylvánského korpusu
Penn Discourse Treebank). Práce přináší lexikálně-syntaktickou a sémantickou klasifikaci
českých altlexů a analýzu jejich současné anotace v PDT. V současné době PDT obsahuje 306
vyjádření (v 43 955 větách), která byla anotátory označena jako altlexy. Jak ovšem tato práce
dokládá, toto číslo není konečné. Předpokládáme, že počet altlexů se po důkladném
zpracování podstatně zvýší, protože altlexy nejsou syntakticky ani lexikálně omezeny a
některé z nich vykazují velký stupeň variability.","The paper concentrates on which language means may be included into the annotation of
discourse relations in the Prague Dependency Treebank (PDT) and tries to examine the
so called alternative lexicalizations of discourse markers (AltLex’s) in Czech. The analysis
proceeds from the annotated data of PDT and tries to draw a comparison between the Czech
AltLex’s from PDT and English AltLex’s from PDTB (the Penn Discourse Treebank). The
paper presents the lexico-syntactic and semantic characterization of the Czech AltLex’s and
comments on the current stage of their annotation in PDT. In the current version, PDT
contains 306 expressions (out of the total 43,955 of sentences) that were labeled by annotators
as being an AltLex. However, as the analysis demonstrates, this number is not final. We
suppose that it will increase after the further elaboration, as AltLex’s are not restricted to a
limited set of syntactic classes and some of them exhibit a great degree of variation."
"Studujeme vliv různých metod výběru dat na anglicko-český strojový překlad. Vyhodnocujeme kvalitu nové paralelního korpusu CzEng 1.0, popisujeme jednoduchou metodu jak zlepšit pokrytí slovníku extrahovaného z paralelních dat a zkoumáme několik metod filtrace paralelních dat pro lepší překlad. Příspěvek zároveň slouží jako popis našeho systému CU-TAMCH-BOJ v soutěži WMT12.","We provide a few insights on data selection for
machine translation. We evaluate the quality
of the new CzEng 1.0, a parallel data source
used in WMT12. We describe a simple technique
for reducing out-of-vocabulary rate after
phrase extraction. We discuss the benefits
of tuning towards multiple reference translations
for English-Czech language pair. We
introduce a novel approach to data selection
by full-text indexing and search: we select
sentences similar to the test set from a large
monolingual corpus and explore several options
of incorporating them in a machine translation
system. We show that this method can
improve translation quality. Finally, we describe
our submitted system CU-TAMCH-BOJ."
"Tento článek se zabývá dvěma aspekty českého žákovského korpusu: (1) vyhodnocuje praktičnost anotačního schématu na základě výsledku iaa, (2) zkoumá možnosti automatické anotace pomocí taggerů, kontrolorů pravopisu a gramatiky","Using an error-annotated learner corpus as the basis, the goal of this paper is two-fold: (i) to evaluate the practicality of the annotation scheme by computing inter-annotator agreement on a non-trivial sample of data, and (ii) to find out whether the application of automated linguistic annotation tools (taggers, spell checkers and grammar checkers) on the learner text is viable as a substitute for manual annotation."
"Článek popisuje problémy anotace Czesl, korpusu češtiny nerodilých mluvčích, jeho anotační schéma a popis anotačního procesu.","The paper presents the issues of annotation of the Czesl, a Czech learner corpus, the concept of its annotation scheme and a description of the annotation process."
"V našem článku prezentujeme hlavní výsledky českého grantového projektu Web jako jazyková korpus, jehož cílem bylo vybudovat korpus českých webových textů a vyvinout a dát veřejnosti k dispozici příslušné softwarové nástroje.","In our paper, we present main results of the Czech grant project Internet
as a Language Corpus, whose aim was to build a corpus of Czech web
texts and to develop and publicly release related software tools. Our
corpus may not be the largest web corpus of Czech, but it maintains very
good language quality due to high portion of human work involved in the
corpus development process. We describe the corpus contents (2.65 billions
of words divided into three parts -- 450 millions of words from news and
magazines articles, 1 billion of words from blogs, diaries and other
non-reviewed literary units, 1.1 billion of words from discussions
messages), particular steps of the corpus creation (crawling, HTML and
boilerplate removal, near duplicates removal, language filtering) and its
automatic language annotation (POS tagging, syntactic parsing). We also
describe our software tools being released under an open source license,
especially a fast linear-time module for removing near-duplicates on a
paragraph level."
"Příspěvek zkoumá skupinu výrazů strukturujících text typu předložka + ukazovací zájmeno; věnuje se tak vztahu koreference a diskurzu. Ukazovací zájmeno zpravidla odkazuje na antecedent, zatímco celý výraz může, ale nemusí, nést diskurzní význam ve smyslu diskurzního konektoru. Popisujeme vlastnosti těchto výrazů ve vztahu k jejich antecedentům, pozici mezi dalšími způsoby strukturování textu a jejich vlastnosti typické pro ""funkci konektoru"" ve srovnání s jejich ""nekonektorovou funkcí"". Analýza je provedena na českých datech Pražského závislostního korpusu 2.0.","This contribution explores the subgroup of text structuring expressions with the form preposition + demonstrative pronoun, thus it is devoted to an aspect of the interaction of coreference relations and relations signaled by discourse connectives in a text. The demonstrative pronoun typically signals a referential link to an antecedent, whereas the whole expression can, but does not have to, carry a discourse meaning in sense of discourse connectives. We describe the properties of these phrases/expressions with regard to their antecedents, their position among the text-structuring language means and their features typical for the “connective function” of them compared to their “non-connective function”. The analysis is carried out on Czech data from the Prague Dependency Treebank 2.0."
"Tato prírucka slouží jako anotacní manuál pro zachycování mezivýpovedních textových
vztahu (diskurzu) na materiálu Pražského závislostního korpusu (PDT) verze 2.5. V rámci
tektogramatické roviny (TR) byla podrobne popsána podkladová syntaktická struktura vety
vcetne aktuálního clenení a základních koreferencních vztahu. Anotace
textových vztahu se na tektogramatické rovine zakládá a TR je v nekterých aspektech pro úcely zachycování
textových vztahu prejímána. Tento manuál proto zachovává pojmový aparát popisující
tektogramatickou reprezentaci a predpokládá alespon základní znalost anotace na této rovine.
Nove jsou zavedeny a vysvetleny pojmy z oblasti analýzy textových vztahu, zejména pak ty,
které jsou inspirovány partnerským projektem Penn Discourse Treebank 2.0.","The report serves as an annotation manual for the portrayal of interclausal textual relations (or discourse relations) on the material of the Prague Dependency Treebank (PDT) version 2.5. Within the framework of the tectogrammatical representation (TR), the underlying syntactic structure of sentences including topic-focus articulation and basic coreference relations, has been described in detail. The annotation of discourse relations is based on the tectogrammatical representation and, in some aspects, TR is adopted for the portrayal of discourse relations. This manual maintains the terminology describing the tectogrammatical representation and presupposes at least a basic knowledge of annotation on this layer. There are some newly introduced and explained terms from the field of analysis of discourse relations, especially those that are inspired by a partnership project Penn Discourse Treebank 2.0."
"CD obsahuje data PDT 2.5 s anotací mezi- i vnitrovětných diskurzních vztahů s explicitními konektory, rozšířené textové koreference a asociační anafory. Představuje novou vrstvu anotace nad již existujícími vrstvami PDT a zachycuje lingvistické jevy z pohledu struktury a koherence textu.","The CD contains the data of PDT 2.5 with the annotation of inter- and intra-sentential discourse relations with explicit connectives, extended textual coreference and bridging anaphora. It represents a new layer of manual annotation, above the existing layers of the PDT and it portrays linguistic phenomena from the perspective of the text structure and coherence."
V článku porovnávám valenci českých a ruských sloves v rámci jejich sémantických tříd.,"In this paper we have described the dissimilarities in Czech and Russian Valency based on the material of the Czech lexicon Vallex. Our main hypothesis is that the differences in valency structure might be explained by the semantics of verbs , so we have exploited the classification of the semantic classes provided by Vallex. In almost in each verb class we have found some regular dissimilarity that is typical of this class."
V článku jsou popsané některé syntaktické rozdíly mezi češtinou a ruštinou důležité zejména pro strojový překlad.,"We present a comparative study of some constructions in Czech and Russian. Though Czech and Russian are closely related Slavic languages, they have a few differences at the level of syntax, morphology and their semantics. We discuss incongruities that we found in a parallel Czech-Russian corpus, mainly reflecting differences in the sentence structure. The linguistic evidence presented in the paper will be used while constructing the transfer
module of a rule-based machine translation system between Czech and Russian."
Představujeme nové webové rozhraní česko-ruského paralelního korpusu UMC 0.1.,"We describe the Czech-Russian parallel corpus that was initially created as training data for Machine Translation systems. The corpus has been available in a format suitable for the
computer processing, but theoretical linguists interested in the resources would not benefit much from them. So we decided to put the corpus into a user-friendly environment.
They are now accessible via a simple www interface, based on the Manatee backend. Both parts of each corpus can be queried using full CQL
syntax with regular expression based search of wordforms, lemmas and POS/morphological tags."
Feat je nástroj pro víceúrovňovou chybouvou anotaci žákovských korpusů.,Feat is an environment for layered error annotation of learners corpora.
"Morph - systém pro morfologickou analýzu a značkování, včetně podpůrných nástrojů pro konverzi korpusů, evaluaci, atd. Oproti verzi z r.2010 byly přidány nové algoritmy pro analýzu, vylepšen formát zadávání dat, přidána podpora obecných poz.tagsetů, atd.","Morph - system for morphological analysis and tagging, including supporting tools for corpus conversion, evaluation, etc. In comparison with version from 2010, this version contains additional analysis algorithms, supports better data format and general positional tagsets, etc."
Čapek (dříve Elysium) je anotační editor tvaroslovných a větných rozborů pro školáky. Je jazykově nezávislý.,Capek (Elysium formerly) is an annotation editor of morphology and syntax for school children. The editor is language independent.
"Článek popisuje tagger pro staročeštinu (1200-1500 AD), flektivní jazyk s bohatou morfologií. Praktická omezení (žádní rodilí mluvčí, limitované korpusy a slovníky, limitované možnosti financování) dělají ze staročeštiny ideální objekt metody vývoje morfologických taggerů nenáročných na zdroje, kterou vyvíjíme (např. Hana et al., 2004; Feldman and Hana, 2010). Jako aproximaci neexistujících staročeských zdrojů používáme zdroje pro současnou češtinu.","The paper describes a tagger for Old Czech (1200-1500 AD), a fusional language with rich morphology. The practical restrictions (no native speakers, limited corpora and lexicons, limited funding) make Old Czech an ideal candidate for a resource-light cross-lingual method that we have been developing (e.g. Hana et al., 2004; Feldman and Hana, 2010). We use a traditional supervised tagger. However, instead of spending years of effort to create a large annotated corpus of Old Czech, we approximate it by a corpus of Modern Czech. We perform a series of simple transformations to make a modern text look more like a text in Old Czech and vice versa. We also use a resource-light morphological analyzer to provide candidate tags. The results are worse than the results of traditional taggers, but the amount of language-specific work needed is minimal."
Příspěvek se zabývá postavením patientu a způsobového volného slovesného doplnění v povrchové struktuře výpovědi. Rozlišuje přitom obligatorní a fakultativní výskyty způsobového doplnění a zohledňuje jeho formu (adverbiální/jmenné vyjádření).,"Paper deals with the position of Patient and free verbal modification expressing Manner in the surface structure of the utterance. It distinguishes obligatory and facultative tokens of Manner and also its form (adverb, noun)."
Poster a abstrakt popisují obvyklý slovosled vybraných volných slovesných doplnění. Berou přitom v úvahu vliv působení slovesné valence. Popisují zvlášť umístění obligatorních a fakultativních doplnění.,Poster and abstract describe the usual word order of chosen free verbal modifications. They take into account the influence of verbal valency. They desribe the position of obligatory and facultative modifications.
"Příspěvek popisuje slovosledné tendence vnitřních participantů - aktoru a patientu. Na základě širokého vzorku dat z Pražského závislostního korpusu vyvozuje, jaké postavení ve větě tyto participanty mají v závislosti na působení určitých slovosledných faktorů.","Paper describes tendencies in word order of inner participants - of Actor and Patient. On the basis of large sample of data from Prague Dependency Treebank, it demonstrates what position in sentence these participants take (depending on particular factors influencing word order)."
Poster popisuje vztah sémantických vlastností funktorů a valence.,Poster describes the relation between the categories of language meaning and valency.
"V tomto příspěvku se zabýváme základními výrazy s textově strukturační funkcí, které mohou v češtině signalizovat příčinné vztahy (např. protože, proto, tedy). Na základě dat shromážděných v Pražském závislostním korpusu zkoumáme charakteristické rysy těchto výrazů s cílem podpořit nebo zpochybnit vyčleňování různých tříd pro tyto výrazy, které je běžné nejen v naší, ale i v zahraniční literatuře.","This paper is focused on basic expressions with text-structuring function which can indicate the causal meaning in Czech (e.g. protože (because), proto (therefore), tedy (thus)). Based on the data collected in the Prague Dependency Treebank, this contribution explores those features of these expressions which characterize differences in their properties and it aims at supporting or questioning the establishing of different classes of them which is common in literature."
"V tomto příspěvku je nejprve stručně představen projekt anotace mezivýpovědních významových vztahů a jeho místo v práci na Pražském závislostním korpusu (Prague Dependency Treebank, PDT). Hlavní část příspěvku se zabývá konektivními prostředky, které mezivýpovědní významové vztahy signalizují. Konkrétně jsou představeny tři jevy – (i) významová diverzita (a nejednoznačnost) výrazu tedy, (ii) některé problematické stránky pojímání rematizátorů jako mezivýpovědních konektivních prostředků ilustrované na rematizátoru také a (iii) různé interpretace výrazu tak jako prostředku textové koherence.","This paper is focused on some problematic aspects of connective means in discourse annotation in the Prague Dependency Treebank (PDT). First, the contribution introduces some basic principles of discourse annotation and its position in the PDT. It also describes expressions which can act as connectives of discourse relations. The main part is devoted to three problematic aspects of connective means: (i) semantic diversity of connective tedy (roughly: thus), (ii) ambiguous role of rhematizators among discourse connectives (illustrated in rhematizator také (also)) and (iii) various roles of expression tak (so, thus) in text coherence."
"Článek reprezentuje první krok v porovnání vlastností syntakticko-sémantických vztahů přítomných ve struktuře věty a jejich ekvivalentů ve struktuře diskurzu. Rozlišujeme řadu typů vztahů, které mohou být vyjádřeny jak v jedné větě (tj. ve stromu), tak i v delším textu, napříč hranicemi vět (mezi stromy). Tvrdíme, že tyto vztahy na jednu stranu zachovávají své sémantické vlastnosti jak uvnitř věty, tak v delším textu (např. příčinný vztah zůstává příčinným vztahem), na druhou stranu ale v souladu se sémantickými vlastnostmi vztahů je jejich distribuce uvnitř vět či mezi větami velice rozličná. V této studii toto pozorování ověřujeme na dvou případech (na podmínkovém a specifikačním vztahu) a dokládáme podobným chováním anglických dat projektu Penn Discourse Treebank.","The present contribution represents the first step in comparing the nature of syntactico-semantic relations present in the sentence structure to their equivalents in the discourse structure. We distinguish various types of relations that can be expressed both within a single sentence (i.e. in a tree) and in a larger
text, beyond the sentence boundary (between trees). We suggest that, on the one hand, each type of these relations preserves its semantic nature both within a sentence and in a larger text (e.g. a causal relation remains a causal relation) but, on the other hand, according to the semantic properties of the relations, their distribution in a sentence or between sentences is very diverse. In this study, this observation is analyzed for two cases (relations of condition and specification) and further supported by similar behaviour of the English data from the Penn Discourse Treebank."
Analýza realizace členské negace v češtině z pohledu konstrukčně-gramatického.,A constructional analysis of the constituent negation in Czech sentences.
Kronika: o mezinárodním setkání komputačních lingvistů zaměřeném na problematiku anotace závislostních korpusů.,Chronicle: on the international meeting of computational linguists focused on the dependency treebanks annotation.
"Příspěvek bude věnován problematice členské negace a způsobům jejího vyjadřování v současné češtině, respektive v datech Českého národního korpusu (především SYN2005) a Pražského závislostního korpusu (verze 2.0). Za členskou negaci byla dosud ve většině českých příruček považována taková negace, která neoperuje na predikátu. Autorka na základě analýzy dat obou korpusů a studia české i zahraniční odborné literatury týkající se dané problematiky navrhne nové, primárně sémantické vymezení členské negace v češtině a prozkoumá možnosti zachycování tohoto jevu ve strukturách tektogramatické roviny PDT.","The talk is focused on constituent negation and ways of its expressing in contemporary Czech, or more precisely in Czech National Corpus (SYN2005) and Prague Dependency Treebank (version 2.0). In most of the Czech linguistic handbooks, constituent negation was treated as such a negation that is not a part of verb. The author offers a new primarily semantic definition of constituent negation in Czech, based on data research and study of relevant literature concerning syntactic negation. Further, the author explores the possibility to express the findings on the tectogrammatical level of PDT."
"Rubrika Horizonty: zamyšlení nad smyslem a tématy pravidelného setkání odborníků z oboru psychologie, filozofie, neurověd, lingvistiky, kulturní antropologie a umělé inteligence.","Section Horizons: analysis of sense and themes of the annual meeting of psychologists, philosophers, neurologists, linguists, cultural anthropologists and artificial intellingence specialists."
"Příspěvek prezentuje předběžný průzkum o možných vztazích mezi
syntaktická struktura a polarita české věty pomocí tzv.
sentiment analýzu počítačového korpusu.Hlavním cílem analýzy je cit
detekce pozitivní nebo negativní polaritou, nebo neutralita věty (nebo, více
široce, text). Nejčastěji se tento proces probíhá tím, že hledá polarity položek,
tj. slova nebo fráze neodmyslitelně opatřené kladné nebo záporné hodnoty. Tato slova
(věty) jsou shromažďovány v subjektivity slovníků a implementovány do počítače
korpus. Nicméně, při použití věty jako základní jednotky, na které sentiment analýza
je aplikován, je vždy důležité podívat se na jejich sémantické a morfologické analýzy,
od polarity položky mohou být ovlivněny jejich morfologické kontextu. Očekává se,
že některé syntaktické (a hypersyntactic) vztahy jsou užitečné pro identifikaci
věta polarity, jako negace, diskursivní vztahů a úroveň integrace se
z polarity položky ve struktuře. Budeme tedy navrhnout takovou analýzu
vhodný zdroj dat, bohatě anotovaný Pražský závislostní korpus.","The paper presents a preliminary research on possible relations between the
syntactic structure and the polarity of a Czech sentence by means of the so-called
sentiment analysis of a computer corpus. The main goal of sentiment analysis is the
detection of a positive or negative polarity, or neutrality of a sentence (or, more
broadly, a text). Most often this process takes place by looking for the polarity items,
i.e. words or phrases inherently bearing positive or negative values. These words
(phrases) are collected in the subjectivity lexicons and implemented into a computer
corpus. However, when using sentences as the basic units to which sentiment analysis
is applied, it is always important to look at their semantic and morphological analysis,
since polarity items may be influenced by their morphological context. It is expected
that some syntactic (and hypersyntactic) relations are useful for the identification of
sentence polarity, such as negation, discourse relations or the level of embeddedness
of the polarity item in the structure. Thus, we will propose such an analysis for a
convenient source of data, the richly annotated Prague Dependency Treebank."
"Pro mnoho jazyků nemůžeme natrénovat parser, protože nemáme k dispozici žádná ručně anotovaná data. Tento problém můžeme vyřešit použitím paralelního korpusu s angličtinou naparsováním amglické strany a projekcí závislostí do druhého jazyka.","For many languages, we are not able to train any supervised parser, because there are
no manually annotated data available. This problem can be solved by using a parallel corpus
with English, parsing the English side, projecting the dependencies through word-alignment
connections, and training a parser on the projected trees. In this paper, we introduce a
simple algorithm using a combination of various word-alignment symmetrizations. We prove
that our method outperforms previous work, even though it uses McDonald's maximum-spanning-tree
parser as it is, without any ""unsupervised"" modifications."
"Několik experimentů pro neřízený parsing češtiny s různou inicializací, s různými modely a samplovací procedurou. Nejlepší konfigurace byla aplikována na 19 jazyků z CoNLL 2006 a 2007. Výsledky jsou porovnatelné ze state-of-the-art.","This paper presents a work in progress on
the task of unsupervised parsing, following the main stream approach of optimizing the overall probability of the corpus. We evaluate a sequence of experiments for Czech with various modifications of corpus initiation, of dependency edge probability model and of sampling procedure, stressing especially the treeness constraint. The best configuration is then applied to 19 languages from CoNLL-2006 and CoNLL-2007 shared tasks. Our best achieved results are comparable to the state of the art in dependency parsing and
outperform the previously published results for many languages."
Technická zpráva shrnuje výzkum v oblasti neřízeného závislostního parsingu na ÚFAL v roce 2011.,"This technical report summarizes the research on unsupervised dependency parsing at the Institute of Formal and Applied Linguistics, Faculty of Mathematics and Physics, Charles University in Prague, in the year 2011. It describes projective and non-projective approaches of sampling of dependency trees, possibility to employ reducibility feature of dependent words, and reports results obtained across various languages."
"Je zde popsán experiment, který automaticky opravuje chyby v gramatické shodě.","This paper describes an experiment in which
we try to automatically correct mistakes in
grammatical agreement in English to Czech
MT outputs. We perform several rule-based
corrections on sentences parsed to dependency
trees. We prove that it is possible to improve
the MT quality of majority of the systems participating
in WMT shared task. We made both
automatic (BLEU) and manual evaluations."
"HamleDT je sada softwarových nástrojů pro konverzi (harmonizaci) syntakticky anotovaných korpusů, které byly vytvořeny pro různé jazyky a na základě odlišných lingvistických teorií, do jednotného anotačního schématu. Účelem je usnadnění vývoje multilinguálních technologií. V současné verzi HamleDT pokrývá 28 jazyků.","HamleDT is a set of software tools for conversion (hamonizing) of treebanks, which were created for different languages and based on various linguistic formalisms, into the same annotation framework. The main aim is to facilitate development of multilingual technology. HamleDT covers as many as 28 languages in its current version."
"V prezentovaném článku se zaměřujeme na kontrolu jako podtyp anafory. Pracujeme s teorií kontroly v závislostním rámci Funkční generativní popisu, ve kterém je kontrola definována jako vztah mezi controllerem (antecedent – sémantický argument hlavní klauze) a controllee (anafor – prázdný subjekt nefinitního doplňku (kontrolované klauze)). Nejprve tento článek představí rekonstrukci controllee na základě pravidel, pak projedná určování antecedentů od controllee na základě perceptronu. Naše řešení jsme vyhodnocovali na datech Pražského závislostního korpusu 2.0. Nicméně předpokládáme, že pravidla a atributy našeho systému jsou jazykově nezávislé a mohou být testovány v budoucnu na jiných jazycích.","In the present paper we focus on control as a subtype of anaphora. We work with the theory
of control present within the dependency-based framework of Functional Generative Description (FGD1), in which control is defined as a relation of a referential dependency between a controller (antecedent – semantic argument of the main clause) and a controllee (anaphor – empty subject of the nonfinite complement (controlled clause)). First this paper presents the rule-based reconstruction of controllees, then, it discusses the perceptron-based determination of the controllees’ antecedent. We evaluated our approach on data from the Prague Dependency Treebank 2.0, however, the rules and features of our system are supposed to be language independent and can be tested on other languages in the future."
"V tomto článku se snažíme automaticky identifikovat subjekty, které nejsou vyjádřeny ale přesto rozuměny v českých větách. Náš systém využívá metodu maximální entropie k rozeznání různých druhů nevyjádřených subjektů. Systém byl trénován a testován na Pražském závislostním korpusu. Výsledky našich experimentů přináší dále úvahu nad vhodností vybraného korpusu pro naši úlohu.","In this paper we aim to automatically identify subjects, which are not expressed but nevertheless understood in Czech sentences. Our system uses the maximum entropy method to identify different types of unstated subjects and the system has been trained and tested on the Prague Dependency Treebank 2.0. The results of our experiments bring out further consideration over the suitability of the chosen corpus for our task."
"Tato technická zpráva zahrnuje výsledky obdržené během výzkumů na analýze koreference v Ústavu formální a aplikované lingvistiky, Matematicko-fyzikální fakulta, Univerzita Karlova v Praze, během 2009 - 2011. Obsahuje stručný popis zahraničních prací vztahujících k tomuto tématu, popis manuální anotace koreference v Pražském závislostním korpusu a možnosti automatické anotace koreference.","This technical report summarizes results obtained during the research on coreference resolution at the Institute of Formal and Applied Linguistics, Faculty of Mathematics and Physics, Charles University in Prague, during 2009 - 2011. It contains a brief description of foreign approaches to this topic, a description of manual coreference annotation in the Prague Dependency Treebank 2.0 and an account of possibilities of automatic coreference annotation."
V tomto příspěvku popisujeme z lexikografického hlediska lokativní sémantickou diatezi v češtině. Navrhujeme adekvátní lexikálně-sémantickou reprezentaci sloves založenou na predikátové dekompozici (tzv. lexikálně-konceptuálních strukturách).,"In this paper, we deal with locative semantic diathesis in Czech from a lexicographic point of view. We distinguish semantic diatheses from grammatical diatheses as two types of  changes in valency structure of verbs. In case of grammatical diatheses, these changes arise from changes in correspondence of valency complements and surface syntactic positions and they are regular enough to be described by formal syntactic rules. In contrast, semantic diatheses are  characterized by the changes in mapping of semantic participants and valency complements. Changes in valency structure of verbs associated with semantic diatheses vary even within one type of diathesis so that they cannot be described by formal syntactic rules. For the purpose of the description of semantic diatheses, we propose to set separate valency frames corresponding to the members of semantic diatheses and to capture the relevant changes in valency structure by general lexical rules based on an appropriate formal representation of meaning of verb. In this contribution, we focus primarily on the lexical-semantic representation of verbs which represents a first part of the description of semantic diatheses. The second part of this task, i.e., formulating lexical rules is left aside here. On the example of locative semantic diathesis, we demonstrate advantage of the lexical-sematic representation based on predicate decomposition (usually called lexical-conceptual structure) over those formulated in terms of unordered set of semantic roles. Namely, we use the lexical-conceptual structure built on the subeventual analysis in which event complexity, i.e., the fact whether an event is simple, or complex, plays a key role. On this basis, we attempt to formulate the appropriate lexical-conceptual structures reflecting semantic difference between the members of locative semantic diathesis."
"V tomto příspěvku navrhujeme reprezentaci českých diatezí ve valenčním lexikonu českých sloves, VALLEX. Diatezemi rozumíme vztahy mezi syntaktickými strukturami založenými na témže slovese, které jsou spojeny se specifickými změnami v jeho valenční struktuře. Rozlišujeme celkem tři typy diatezí: gramatické, syntaktické a sémantické. Gramatické a syntaktické diateze jsou spojeny s natolik pravidelnými změnami ve valenčním rámci slovesa, že mohou být popsány formálními syntaktickými pravidly. V případě sémantických diatezí jsou změny natolik rozmanité, že je výhodnější je zachytit pomocí lexikálních pravidel. Závěrem ukazujeme, že jednotlivé typy diatezí mohou být vzájemně kombinovány.","In this paper, we propose a method of the representation ofCzech diatheses in the valency lexicon of Czech verbs, VALLEX. Underthe term diatheses, specific relations between uses of the same verb lexeme are considered here. These relations are associated with changes in valency frames of verbs which stem from the changes in the linking of situational participants, valency complementations and surface syntactic positions. We distinguish three types of Czech diatheses according to which linguistic means they are based on: (i) grammatical, (ii) syntactic and (iii) semantic diatheses. We demonstrate that in case of grammatical and syntactic diatheses, the changes in valency structure of verbs are regular enough to be captured by formal syntactic rules whereas the changes associated with semantic diatheses can be represented rather by lexical rules. In conclusion, we show that on certain conditions the different types of diatheses can be combined together."
"Závislost analýzy byla hlavním terčem výzkumu NLP pozdě kvůli jeho schopnosti pomáhat analyzovat jazyky s volným slovosledem. Závislost analýzy bylo prokázáno, že zvýšení NLP systémů v některých jazycích av mnoha případech je považována za nejmodernější v oboru. Použití analýzy závislosti je většinou omezen na bezkontextových jazyků slovosledem, ale užitečnost závislosti staveb může přinést zlepšení v mnoha Word 6000 + jazycích. Dám přehled v oblasti závislosti rozebrat přičemž Mé cíle pro budoucí výzkum. Mnoho NLP aplikací do značné míry závisí na kvalitě závislosti rozebrat. Z tohoto důvodu budu zkoumat, jak různé analyzátory a anotace programů ovlivnit celkovou NLP potrubí, pokud jde o strojový překlad, stejně jako základní analýzu přesnosti.","Dependency parsing has been a prime focus of NLP research of late due to its
ability to help parse languages with a free word order. Dependency parsing has been shown
to improve NLP systems in certain languages and in many cases is considered the state of
the art in the field. The use of dependency parsing has mostly been limited to free word
order languages, however the usefulness of dependency structures may yield improvements
in many of the word’s 6,000+ languages.
I will give an overview of the field of dependency parsing while giving my aims for
future research. Many NLP applications rely heavily on the quality of dependency parsing.
For this reason, I will examine how different parsers and annotation schemes influence the
overall NLP pipeline in regards to machine translation as well as the the baseline parsing
accuracy."
"Byt jmenná fráze struktura byla, až do nedávné doby,
standard v anotaci na Penn
Treebanks. S nedávným Kromě vnitřních
jmenná fráze anotace, závislost parsování
dolů a aplikace na potrubí NLP
jsou pravděpodobně ovlivněny. Některé strojový překlad
systémy, jako TectoMT, používat hluboké syntaxi
jako jazyková převodu vrstvy. Navrhuje se,
že změny v závislosti jmenné fráze
analýze bude mít dominový efekt se
NLP potrubí a na konci, zlepšit stroj
Překlad výstup i při snížení
v parseru přesností, že jmenná fráze
Struktura může způsobit. Tato práce zkoumá
Toto podstatné jméno věta STRUKTURY vliv na závislost
analýze, v angličtině, s maximální
Spanning Tree parser a ukazuje 2,43%, 0,23
Bleu skóre, zlepšení pro angličtiny do češtiny
strojový překlad.","Flat noun phrase structure was, up until recently,
the standard in annotation for the Penn
Treebanks. With the recent addition of internal
noun phrase annotation, dependency parsing
and applications down the NLP pipeline
are likely affected. Some machine translation
systems, such as TectoMT, use deep syntax
as a language transfer layer. It is proposed
that changes to the noun phrase dependency
parse will have a cascading effect down the
NLP pipeline and in the end, improve machine
translation output, even with a reduction
in parser accuracy that the noun phrase
structure might cause. This paper examines
this noun phrase structure’s effect on dependency
parsing, in English, with a maximum
spanning tree parser and shows a 2.43%, 0.23
Bleu score, improvement for English to Czech
machine translation."
Představení pražské anotace textových vztahů a koreference v PDT,Introduction of the Prague annotation of discourse and coreference in PDT
Předhledová zpráva o projektu anotace textových vztahů v Pražském závislostím korpusu pro tým z University of Pennsylvania,Overview of the annotation project of discourse relations in the Prague Dependency Treebank for Penn discourse team
"Článok popisuje možné zdroje pre vytvorenie česko-slovenského paralelného korpusu, vrátane postupu, ktorý bol použitý pri vytvorení neanotovaného textového korpusu z rôznych dátových zdrojov. Popisuje výhody a nevýhody týchto zdrojov, zvlášť v
prípade, že je vytvorený korpus použitý v automatickom preklade. V článku sú tiež uvedené výsledky automatického prekladu, ktorý používa
takto vytvorený korpus.","The paper describes suitable sources for creating Czech-Slovak
parallel corpora, including our procedure of creating plain text parallel
corpora from various data sources. We attempt to address the pros and
cons of various types of data sources, especially when they are used in
machine translation. Some results of machine translation from Czech to
Slovak based on the acquired corpora are also given."
"Syntax přirozeného jazyka je v hledáčku lingvistiky již několik desítek let. Teorie komplexních sítí nabízí nový pohled na syntaktické vlastnosti jazyka. Přes řadu dílčích úspěchů ale zatím ponechává některé zásadní problémy nevyřešené. Přestože statistické vlastnosti typické pro komplexní sítě lze pozorovat ve všech syntaktických sítích, vliv syntaxe samotné na tyto vlastnosti zůstává nejasný. Předložená studie je zaměřená na vliv syntaktické funkce slovesa ve větě na strukturu komplexní sítě. Slovesa hrají rozhodující roli ve větné struktuře (lokální významnost), z čehož vyvozujeme, že budou významná i z hlediska komplexní sítě. Hypotézu testujeme na šesti jazycích.","Syntax of natural language has been the focus of linguistics for decades. The complex network theory, being one of new research tools, opens new perspectives on syntax properties of the language. Despite numerous partial achievements, some fundamental problems remain unsolved. Specifically, although statistical properties typical for complex networks can be observed in all syntactic networks, the impact of syntax itself on these properties is still unclear. The aim of the present study is to shed more light on the role of syntax in the syntactic network structure. In particular, we concentrate on the impact of the syntactic function of a verb in the sentence on the complex network structure. Verbs play the decisive role in the sentence structure (“local” importance). From this fact we hypothesize the importance of verbs in the complex network (“global” importance). The importance of verb in the complex network is assessed by the number of links which are directed from the node representing verb to other nodes in the network. Six languages (Catalan, Czech, Dutch, Hungarian, Italian, Portuguese) were used for testing the hypothesis."
"Tento článek popisuje robustní konečněstavový morfologický analyzátor pro indonéštinu (MorphInd), který se stará jak o morfologickou analýzu, tak o lematizaci daného slovního tvaru. MorphInd má větší pokrytí indonéské derivační a flexivní morfologie než existující indonéský morfologický analyzátor.","This paper describes a robust finite state morphology tool
for Indonesian (MorphInd), which handles both morphological analysis
and lemmatization for a given surface word form so that it is suitable
for further language processing. MorphInd has wider coverage on han-
dling Indonesian derivational and in
ectional morphology compared to
an existing Indonesian morphological analyzer [1], along with a more de-
tailed tagset. MorphInd outputs the analysis in the form of segmented
morphemes along with the morphological tags. The implementation was
done using finite state technology by adopting the two-level morphology
approach implemented in FOMA. It acheived 84.6% of coverage on a
preliminary stage Indonesian corpus where it mostly fails to capture the
proper nouns and foreign words as expected initially."
"Článek popisuje možnosti začlenění morfosyntaktické informace do frázového a syntaktického statistického strojového překladu. Soustředíme 
se na těžší směr, do jazyka morfologicky bohatšího.","This paper describes the integration of morpho-syntactic information in
phrase-based and syntax-based Machine Translation systems. We mainly focus on
translating in the hard direction which is translating from morphologically
poor to morphologically richer languages and also between language pairs that
have significant word order differences. We intend to use hierarchical or
surface syntactic models for languages of large vocabulary size and improve the
translation quality using two-step approach \citep{fraser}. The two-step scheme
basically reduces the complexity of hypothesis construction and selection by
separating the task of source-to-target reordering from the task of generating
fully inflected target-side word forms. In the first step, reordering is
performed on the source data to make it structurally similar to the target
language and in the second step, lemmatized target words are mapped to fully
inflected target words. We will first introduce the reader to the detailed
architecture of the two-step translation setup and later its further proposed
enhancements for dealing with the above mentioned issues. We plan to conduct
experiments for two language pairs: English-Urdu and English-Czech."
"Zkoumáme frázový statistický strojový překlad mezi angličtinou a urdštinou, dvěma indoevropskými jazyky s výrazně odlišnými preferencemi slovosledu. Přeskládání slov a frází je tudíž nezbytnou součástí překladové procedury. Zatímco lokální přeskládání lze ve frázových systémech modelovat elegantně, přesuny na velkou vzdálenost jsou problematické. Provádíme pokusy s překladovým systémem Moses a probíráme přeskládávací modely, kterými Moses disponuje. Potom předkládáme náš nový, urdštiny znalý, avšak zobecnitelný přístup založený na přeskládávání frází v syntaktickém stromu zdrojové anglické věty. Naše metoda významně zlepšuje kvalitu anglicko-urdského překladu s Mosesem, měřeno jak automatickým BLEU skórem, tak subjektivním lidským hodnocením.","We investigate phrase-based statistical machine translation between English and Urdu, two Indo-European languages that differ significantly in their word-order preferences. Reordering of words and phrases is thus a necessary part of the translation process. While local reordering is modeled nicely by phrase-based systems, long-distance reordering is known to be a hard problem. We perform experiments using the Moses SMT system and discuss reordering models available in Moses. We then present our novel, Urdu-aware, yet generalizable approach based on reordering phrases in syntactic parse tree of the source English sentence. Our technique significantly improves quality of English-Urdu translation with Moses, both in terms of BLEU score and of subjective human judgments."
"Archiv vizuální historie Institutu USC Shoah Foundation je unikátní sbírkou takřka 52 000 audiovi­zuálních záznamů rozhovorů s pamětníky a přeživšími holocaustu, které byly natočeny během 2. poloviny 90. let v 56 zemích a 32 jazycích (v češtině a slovenštině je přes 1 000 rozhovorů). Praha je jedním ze tří evropských měst, kde se lze ke kompletnímu obsahu licencovaného archivu připojit on-line pomocí vysokorychlostní sítě Internet 2, a to z počítačů v Centru vizuální historie Malach při Matematicko-fyzikální fakultě Univerzity Karlovy. V průměru dvouhodinové rozhovory byly vedeny podle jednotné metodiky a přeživší v nich hovoří jak o zkušenostech z období druhé světové války, tak o svém dětství a životě po válce. Vzniklý archiv je hodnotným souborem ohromujícího množství individuálních vzpomínek na celé 20. století. Institut USC Shoah Foundation se v současné době soustředí na vzdělávací využití tohoto materiálu. Archiv lze prohledávat pomocí velmi sofistikovaného uživatelského rozhraní: uživatelé mohou najít konkrétní úseky svědectví podle svého zájmu díky tezauru 55 000 hierarchicky uspořádaných klíčových slov, témat, událostí, časových úseků, jmen osob, míst atd. I samotná práce s archivem v reálném čase se proto může stát hodnotnou vzdělávací činností, rozvíjející počítačovou a informační gramotnost spolu se širším historickým a kulturním povědomím. Archiv vizuální historie je cenným zdrojem nejen pro historiky, ale lze jej využít i v mnoha dalších oblastech od lingvistiky přes psychologii až k sociologii, politologii či gender studies. K ilustraci možností vyhledávání a využití poslouží i praktická ukázka práce s archivem.","The USC Shoah Foundation Institute Visual History Archive is a unique collection of almost 52 000 testimonies of the Holocaust survivors and witnesses, recorded in 56 countries and 32 languages during the late 90's (over 1 000 interviews are in Czech and Slovak language). Prague is one of the three European access points to the on-line licensed archive content, connected by the high-speed Internet 2 from the Malach Visual History Centre at the Faculty of Mathematics and Physics of the Charles University. With average 2 hours duration, the interviews have been conducted with standardised methodology. The interviewees speak about their childhood, the time before World War II, the war-related experiences and also their life after the war. The Archive is thus a valuable collection of countless individual recollections of entire 20th century. In the present time, the USC Shoah Foundation Institute is focused on using the archive testimonies for educational purposes. The Visual History Archive provides sophisticated tools for users to identify whole testimonies of relevance, as well as specific segments within testimonies that relate to their area of interest. Searching is possible using a thesaurus containing more than 55 000 geographic and experiential keywords, time intervals, names, places etc. Even the real-time work with the Archive is a valuable educational experience, connecting computer and informational literacy with broader historic and cultural knowledge. The Visual History Archive is a relevant source not only for the historians, but is applicable to many more fields of study including linguistics, political science, sociology or gender studies. As an example of the Archive possibilities, a practical illustration will be included in the presentation."
"Článek pojednává o Centru vizuální historie Malach při Univerzitě Karlově, které od ledna 2010 zpřístupňuje unikátní soubor 52 000 audiovizuálních svědectví - rozhovorů s pamětníky, pořízených v letech 1994-1999 v 56 zemích a 32 jazycích. Českojazyčná část archivu obsahuje přes 550 rozhovorů, podobné množství nahrávek je k dispozici ve slovenštině. Archiv vizuální historie je v současnosti dostupný z přístupových míst v rámci smluvních institucí, mezi něž patří i UK, která se tak řadí mezi pět evropských univerzit s plným přístupem do Archivu. I když Archiv vznikal jako dokumentace konkrétní historické události (zaměřen je na přeživší a svědky holocaustu za 2. světové války), způsoby využití nashromážděných svědectví pokrývají řadu humanitních, společenských i exaktních věd. V článku jsou nastíněny možnosti využití archivního materiálu v badatelské či pedagogické praxi s důrazem na oblast aplikované lingvistiky. Přiblížen je také projekt MALACH, který proběhl mezi lety 2002-2007 za participace UK.","The article presents the Malach Centre and the USC Shoah Foundation Institute Visual History Archive. The Visual History Archive, which contains almost 52 000 witness testimonies covering the history of entire 20th century, is fully accessible through an on-line interface. The users can search for and view testimonies of interest by using more than 55 000 keywords or database of 1.1 million names. It is possible to identify relevant interviews or specific segments by using the sophisticated user search interface. Almost 25 000 interviews in English is easily accessible. The testimonies available in Malach Centre were recorded in 56 countries and in 32 languages. The content of testimonies includes material that is applicable to many different scientific fields."
"MorphCon je nový softwarový nástroj pro automatickou konverzi českých morfologických taggovacích sad (tagsetů). Software umožňuje konverzi dvou základních tagsetů češtiny: pražského pozičního a brněnského atributivního systému. MorphCon pracuje se třemi formáty dat (SimpleTag-Conversion, KWIC/Tag-Format, WPL-Format), tagsety jsou v aplikaci implementovány jako ""drivery"" (s funkcemi enkódování a dekódování). Klíčovou roli převodníku při konverzi plní univerzální knihovna DZ Interset. MorphCon je budován jako univerzální konvertor díky modularitě a možnosti přidat další tagsety či formáty dat.","MorphCon is a new software tool for automatic conversion of Czech morphological tagsets. This software enables converting of two basic tagsets of Czech: Prague positional system and Brno's attributive system. There are three basic Input/Output (I/O) formats of data (SimpleTag-Conversion, KWIC/Tag-Format, WPL-Format). Tagsets are implemented into the MorphCon as ""drivers"" with ""encode"" and ""decode"" function as well as an ""universal library"" called DZ-Interset plays key role for the process of conversion as a transcoder. The MorphCon software is thus built as an universal converter: modularity, the Interset as a transcoder, possibility of adding of another tagsets (not only Czech ones) and I/O formats."
"Termín valence označuje počet, typ a tvar argumentů, které jsou vázány k danému slovu. Jedná se o charakteristickou vlastnost jednotlivých slov, která tím pádem musí být zachycena formou slovníků. Tento článek je rešeršní studií vytvořenou s úmyslem vytvořit valenční slovník českých podstatných jmen. Na vzorku několika českých, anglických a německých valenčních slovníků (jak těch, které jsou určeny pro běžné uživatele, tak zdrojů pro počítačové zpracování přirozeného jazyka), které všechny zahrnují podstatná jména, mapujeme možné odpovědi na následující otázky:
* Komu je slovník určen?
* Které aspekty valenčního chování zahrnout?
* Jak uspořádat materiál slovníku?","The term valency refers to the number, type and form of arguments that are bound to a word. Valency is specific to any given lexical unit and therefore is covered by lexicons. This is a preliminary survey conducted with the creation
of a valency lexicon of Czech nouns in mind. The authors of such a lexicon have
to decide who will be the intended users, how the material will be presented and
which aspects of valency behaviour will be covered; we present the choices made
by the authors of several Czech, English and German resources that cover the
valency of nouns, both machine readable and printed."
"V této práci představujeme jeden z možných modelů zpracovaní rozšířené textové koreference a asociační anafory na velkém
korpusu textů, který dále používáme pro anotaci daných vztahů v textech Pražského závislostního korpusu. Na základě literatury z oblasti teorie reference, diskurzu a některých dalších poznatků teoretické lingvistiky na jedné straně a s použitím existujících anotačních metodik na straně druhé jsme vytvořili detailní klasifikaci textově koreferenčních vztahů a typů vztahů asociační anafory. 
V rámci textové koreference rozlišujeme dva typy textově koreferenčních vztahů – koreferenční vztah mezi jmennými frázemi se specifickou referencí a koreferenční vztah mezi jmennými frázemi s~nespecifickou, především generickou
referencí. 
Pro asociační anaforu jsme stanovili šest typů vztahů: vztah PART mezi částí a celkem, vztah SUBSET mezi množinou a podmnožinou/prvkem množiny, vztah FUNCT mezi entitou a určitým objektem, který má vzhledem k této entitě jedinečnou funkci, vztah CONTRAST vyjadřující sémantický a kontextový protiklad, vztah ANAF označující anaforické odkazování mezi nekoreferenčními entitami a vztah REST pro jiné případy asociační anafory. 
Jedním z úkolů výzkumu bylo vytvořit systém teoretických principů, které je nutno dodržovat při anotaci koreferenčních vztahů a asociační anafory. V rámci tohoto systému byl zaveden například princip důslednosti anotace, princip
dodržování maximálního koreferenčního řetězce, princip kooperace se syntaktickou strukturou tektogramatické roviny, princip preference koreferenčního vztahu před asociační anaforou a další. 
Vypracovanou klasifikaci jsme aplikovali na koreferenční a anaforické vztahy v~Pražském závislostním korpusu (Prague Dependency Treebank, PDT). Anotace těchto vztahů byla provedena na polovině korpusu PDT (cca 25 tis. vět). Srovnání shody mezi anotátory při navazování vztahů a určování typů těchto vztahů ukázalo, že použitá klasifikace při daném rozsahu materiálu je spolehlivá zejména pro účely teoretického
výzkumu; pro počítačové aplikační účely (strojový překlad, automatické učení atd.) je nutné rozšíření materiálové základny.","This book aims to present one of the possible models of processing extended textual coreference and bridging anaphora in a large textual corpora, which we then use for annotation of certain relations in texts of the Prague Dependency Treebank (PDT). We compare our annotation scheme to the existing ones with respect to the language to which the scheme is applied. We identify the annotation principles and demonstrate their application to the large-scale annotation of Czech texts. We further present our classification of coreferential relations and bridging relations types and discuss some problematic aspects in this area. An automatic pre-annotation and some helpful features of the annotation tool, such as maintaining coreferential chain, underlining candidates for antecedents, etc. are presented and discussed. Statistical evaluation is performed on the already annotated part of the Prague Dependency Treebank. We also present the first results of the inter-annotator agreement measurement and explain the most frequent cases of disagreement."
"Tato technická zpráva popisuje projekt manuální anotace rozšířené textové koreference a asociačních vztahů, probíhající na Ústavu formální a aplikované lingvistiky, Matematicko-fyzikální fakultě Univerzity Karlovy v Praze od roku 2009. Obsahuje typologii koreferenčních a asociačních vztahů, klasifikaci jednotek anotovaných koreferencí a aplikaci anotace na PDT 2.0.","This technical report describes the project of manual annotation of extended textual coreference and bridging relations, which runs at the Institute of Formal and Applied Linguistics, Faculty of Mathematics and Physics, Charles University in Prague, since 2009. It contains the
typology of coreference and bridging relations, classification of elements that are annotated for
coreference and the application of the annotation on PDT 2.0."
CD obsahuje data PDT 2.0 s anotací rozšířené textové koreference a asociační anafory. Představuje novou vrstvu anotace nad již existujícími vrstvami PDT a zachycuje lingvistické jevy z pohledu struktury a koherence textu.,"The CD includes the data of PDT 2.0 with the annotation of extended textual coreference and bridging relations. It represents a new layer of manual annotation, above the existing layers of the PDT and it portrays linguistic phenomena from the perspective of the text structure and coherence."
"Článek zkoumá dvě metody ručního vyhodnocení kvality překladu, které mohou pomoci identifikovat nejčastější typy chyb.","This paper examines two techniques of manual evaluation that can be used to identify error
types of individual machine translation systems. The first technique of “blind post-editing” is
being used in WMT evaluation campaigns since 2009 and manually constructed data of this
type are available for various language pairs. The second technique of explicit marking of errors
has been used in the past as well.
We propose a method for interpreting blind post-editing data at a finer level and compare
the results with explicit marking of errors. While the human annotation of either of the techniques
is not exactly reproducible (relatively low agreement), both techniques lead to similar
observations of differences of the systems. Specifically, we are able to suggest which errors in
MT output are easy and hard to correct with no access to the source, a situation experienced by
users who do not understand the source language."
Představení výsledků experimentů s kombinováním několika systémů strojového překladu za účelem lepšího pokrytí cílových slovních tvarů.,The results of my experiments with MT system combination aimed at better coverage of target-side word forms.
"Seznámení zájemců o informatiku s úlohou strojového překladu, současnými metodami a jejich omezeními.","An introduction to the task of machine translation, current methods and their inherent limitations for those interested in computer science."
"Představení úlohy slovního zarovnání pro kolegy z Katedry aplikované matematiky s cílem odhalit kombinatorickou povahu problému. Hlavním účelem bylo společně se přiblížit vhodné rigorózní formulaci problému tak, aby bylo možné použít známé algoritmy z diskrétní matematiky.",An introduction to the task of word alignment for colleagues at the Department of applied mathematics (KAM).
"Článok sa zaoberá strojovým prekladom medzi blízkymi
jazykmi, najmä medzi češtinou a slovenčinou. Popisuje špecifiká
vyhodnocovania strojového prekladu medzi blízkymi jazykmi. Cieľom
článku je potvrdenie staršieho predpokladu, že prekladové systémy
založené na pravidlách sú pre preklad medzi blízkymi jazykmi stále
vhodnejšie ako najnovšie systémy založené na štatistike, a to aj
napriek tomu, že je k dispozícii veľké množstvo dát.","We focus on machine translation between closely related
languages, in particular Czech and Slovak. We mention the specifics of
evaluating MT quality for closely related languages. The main
contribution is the test and confirmation of the old assumption that
rule-based systems with shallow transfer still work better than
current state-of-the-art statistical systems in this setting, unless
huge amounts of data are available"
"WMT (Workshop on Statistical Machine Translation) konaný každoročně od roku 2006, se stal jedním z nejvýznamnějších workshopů ACL. Součástí tohoto workshopu je úloha (soutěž) s vyhodnocením systémů strojového překladu, a to zejména na základě lidského hodnocení kvality překladů.
Závěrečná správa z každého workshopu uvádí přehled hlavních dosažených výsledků, ovšem nezbývá v ní místo pro hlubší analýzu. Cílem tohoto článku je prozkoumat a vysvětlit některé zajímavosti a rozpory v uváděných výsledcích. Provedená analýza ukazuje, jak by měly (a neměly) být interpretovány tyto výsledky. Článek také uvádí některá doporučené do budoucna pro organizátory WMT.","The Workshop on Statistical Machine Translation (WMT) has become one of ACL's
flagship workshops, held annually since 2006.  In addition to soliciting papers
from the research community, WMT also features a shared translation task for
evaluating MT systems.  This shared task is notable for having manual evaluation
as its cornerstone.
The Workshop's overview paper, playing a descriptive and administrative role, reports
the main results of the evaluation without delving deep into analyzing those results.
The aim of this paper is to investigate and explain some interesting idiosyncrasies
in the reported results, which only become apparent when performing a more thorough
analysis of the collected annotations.  Our analysis sheds some light on how the
reported results should (and should not) be interpreted, and also gives rise to some helpful
recommendation for the organizers of WMT."
"Nové vydání paralelního korpusu CzEng, tentokrát zaměřené na odstranění nesprávných větných párů.","A new release of the parallel corpus CzEng, this time with a focus on the removal of bad sentence pairs."
"Navrhujeme a vyhodnocujeme jednoduchou techniku ""zpětné samouky"" pro strojový překlad. Technika využívá jednojazyčná data v cílové řeči k obohacení překladového slovníku existujícího statistického systému.","We propose and evaluate a simple technique of ""reverse self-training"" for
statistical machine translation. The technique allows to extend target-side
vocabulary of the MT system using target-side monolingual data and it is
especially aimed at translation to morphologically rich languages."
"Používáme jednojazyčná data na cílové straně k tomu, abychom obohatili překladový model ve statistickém strojovém překladu.","We use target-side monolingual data to extend
the vocabulary of the translation model
in statistical machine translation. This method
called “reverse self-training” improves the decoder’s
ability to produce grammatically correct
translations into languages with morphology
richer than the source language esp. in
small-data setting. We empirically evaluate
the gains for several pairs of European
languages and discuss some approaches of
the underlying back-off techniques needed to
translate unseen forms of known words. We
also provide a description of the systems we
submitted to WMT11 Shared Task."
"Od konce ledna 2010 je na MFF UK zpřístupněn archív nahrávek přeživších holokaustu, poskytnutý VHI  University of Southern California. Tento archív je přístupný nejen badatelům z humanitních oborů, ale i pro další výzkum v oboru zpracování mluvené řeči a analýzy textu počítačem. Článek představuje nové výsledky v obou těchto směrech.","Since the beginning of 2010, the Shoa Foundation archive of Holocaust survivors memories is accessible at MFF UK thanks to a licence from University of Southern California. The archive serves research needs for scientists in the humanities as well as technologists in the field of computational linguistics and speech processing. The article presents new developments in both these areas."
"Pražský česko-anglický závislostní korpus  2.0 (PCEDT 2.0) nahrazuje starší verzi Pražského závislostního korpusu  1.0 (LDC2004T25). Je to manuálně parsovaný česko-anglický paralelní korpus o velikosti přes 1,2 miliónu tokenů v téměř padesáti tisících vět v každé jazykové paralele.","The Prague Czech-English Dependency Treebank 2.0 (PCEDT 2.0) is a major update of the Prague Czech-English Dependency Treebank 1.0 (LDC2004T25). It is a manually parsed Czech-English parallel corpus sized over 1.2 million running words in almost 50,000 sentences for each part."
"Na tomto CD se nachází víceúčelový korpus mluvených českých dialogů. Data jsou uspořádána do tří rovin: zvukový záznam, doslovný manuální přepis a editovaný přepis odpovídající standardům spisovného jazyka (tzv. rekonstrukce mluvené řeči).
Tématem dialogů je vzpomínání a konverzace nad osobní sbírkou fotografií jednoho ze zúčastněných. Dialogy byly nahrávány v rámci projektu Companions. Cílem tohoto projektu bylo vytvoření virtuálního společníka, který by si s lidským uživatelem povídal o jeho fotoalbu. Rozhovory byly nahrávány v nastavení Wizard of Oz.","This CD brings you a multi-purpose corpus of spoken dialog Czech which has been recorded, manually transcribed and manually edited in three interlinked layers.
The domain is reminiscing about personal photograph collections, which were recorded within the Companions project. The goal of this project was to create virtual companions that would be able to have a natural conversation with humans. The setup is Wizard of Oz."
"Na tomto CD se nachází víceúčelový korpus mluvených anglických dialogů. Data jsou uspořádána do tří rovin: zvukový záznam, doslovný manuální přepis a editovaný přepis odpovídající standardům spisovného jazyka (tzv. rekonstrukce mluvené řeči). 

Tématem dialogů je vzpomínání a konverzace nad osobní sbírkou fotografií jednoho ze zúčastněných. Dialogy byly nahrávány v rámci projektu Companions. Cílem tohoto projektu bylo vytvoření virtuálního společníka, který by si s lidským uživatelem povídal o jeho fotoalbu. Rozhovory byly částečně nahrávány v nastavení Wizard of Oz, zčásti se jedná o spontánní konverzaci dvou lidí.","This CD brings you a multi-purpose corpus of spoken dialog English. 145 469 tokens, 12 203 sentences and 864 minutes of spontaneous dialog speech have been recorded, manually transcribed and manually edited in three interlinked layers.

The domain is reminiscing about personal photograph collections, which were recorded within the Companions project. The goal of this project was to create virtual companions that would be able to have a natural conversation with humans. The setup is partly Wizard of Oz, but mostly conversation of two humans."
V této kapitole se ověřuje na datech z anotovaného korpusu PDT hypotéza o posunu referenčního bodu pro časovou orientaci dějů v souvětí obsahujícícm vedlejší větu obsahovou. Dále se studuje výskyt přechodníkových konstrukcí v několika subkorpusech ČNK.,The hypothesis about the tense shifts in the complex sentences where the content clauses are included is examined on the data from the annotated corpus PDT. The occurence of transgressives in several subcorpora of the CNC is studied as well.
"Infinitivní konstrukce s atributivní funkcí se vyskytují převážně jako součást analytických predikátů. Ty jsou v kapitole tříděny z hlediska vlastností kontroly na ""uzavřené"" a ""otevřené"". Zpravidla jde o typ gramatické kontroly.","The Czech corpus data are studied from the point of view which infinitival attributive constructions are grammatically controlled and how to determine their controller (usually omitted on the surface). The analyzed constructions enter the analytical predicates which are classified into the ""closed"" and ""opened"" class."
"Slovesná adjektiva produktivně tvořená příponami 
-ící, -vší, -ný/-tý jsou chápána jako syntaktické deriváty základového slovesa. Studuje se jejich distribuce, časové vztahy nominalizace a řídícího děje a konkurence nominalizovaných vazeb a vedlejších vět.","The verbal adjectives derived by suffixes -ící, -vší, -ný/-tý are analyzed as forms of their respective basic verbs. Their distrubution, temporal relations between nominalization and governing predication are described. The competition between nominalization and subordinated clause is studied as well."
Rezultativ je chápán jako typ diateze (morfologické kategorie). Analyzuje se jeho blízkost k jiným gramatickým diatezím a popisují se podmínky vytváření rezultativní konstrukce obejektové a posesivní v češtině.,Resulative constructions in Czech are analyzed as a type of grammatical diathesis included in the morphological pardigm of the verb. The derivation of so-called obejective and posessive resultative is studied here.
"Stať se věnuje českým infinitivním konstrukcím v pozici větného subjektu. Analyzují se slovesa s infinitivním podmětem, adjektiva přísudková (včetně verbonominálních přísudků) a sledují se vlastnosti koreference infinitivního subjektu a členu řídídcí predikace.",In this paper the Czech infinitival constructions  in the position of subject are studied. The coreference between (innere) infinitival subject and particular member of the governor are analyzed on the material from the corpora.
"Na základě teorie valence navržené ve FGP jsou zkoumány funkce předložkového pádu o + Akuzativ. Podle typu slovesa plní tato předložková skupina funkce Překážky, Rozdílu, Patientu nebo Efektu. Tyto funkce jsou zachyceny u příslušného slovesa ve valenčním rámci.","The theory of valency developed within the Functional Generative Description is applied for the prepositional group o + Accusative. The Obstacle complement, the Difference modification, the Patient, or the Effect are assigned to this form according to the valency frames of the respective verbs."
"V stati se analyzují speciální typy příslovečných určení, které se z hlediska významové struktury (tektogramatické reprezentace) jeví jako gramatikalizované elipsy zapuštěných predikací. (jde o příslovečná určení srovnání (podobnosti i rozdílu)a příslovečné určení omezení a slučování výjimkou. Navrhují se ""konstrukty"", jak lze tato určení parafrázovat v hloubkové struktuře.","This article deals with special types of adverbials, which represent from the point of view of the level of deep structure grammaticalized elliptical constructions of the embedded clauses. The adverbials of comparison, restriction and addition are concerned. The way,how to reconstruct them on the level of deep structure is proposed."
"Příspěvek se zabývá příslovečnými určeními srovnání, výjimky a slučování v češtině, které jsou sémanticky komplikované a jejich hloubková struktura vyžaduje doplnění sdílených členů řídící a závislé (rekonstruované) predikace.","The special types of Czech adverbials (comparison, exception and addition) are analyzed. Due to their semantic complexity the reconstruction of their members shared with the governing predication in  is needed. This reconstructed deep representation is presented as grammaticalized deletion."
"Článek přispívá k dlouhodobé linvistické diskuzi o hranicích mezi gramatikou a slovníkem, konkrétně se zaměřuje na čtyři témata z české gramatiky: valence, modalita v obsahových závislých klauzích, gramatické diateze a souborový význam.","The present paper contributes to the long-term linguistic discussion on the boundaries between grammar and lexicon by analyzing four related issues from Czech. The analysis is based on the theoretical framework of Functional Generative Description (FGD), which has been elaborated in Prague since 1960’s. First, the approach of FGD to the valency of verbs is summarized. The second topic, concerning dependent content clauses, is closely related to the valency issue. We propose to encode the information on the conjunction of the dependent content clause as a grammatical feature of the verb governing the respective clause. Thirdly, passive, resultative and some other constructions are suggested to be understood as grammatical diatheses of Czech verbs and thus to be a part of the grammatical module of FGD. The fourth topic concerns the study of Czech nouns denoting pair body parts, clothes and accessories related to these body parts and similar nouns. Plural forms of these nouns prototypically refer to a pair or typical group of entities, not just to many of them. Since under specific contextual conditions the pair/group meaning can be expressed by most Czech concrete nouns, it is to be described as a grammaticalized feature."
"Příspěvek se zabývá gramatickou kategorií čísla v češtině. Základní opozice singuláru a plurálu, která tuto kategorii konstituuje, navrhujeme zavést novou sémantickou distinkci prostého většího množství jednotlivin vs. souborovosti. Souborovost je v češtině typicky vyjadřována substantivy jako oči, vlasy, sirky apod. Uvádíme také stručné srovnání s dalšími slovanskými i neslovanskými jazyky.","The present contribution deals with grammatical category of number of nouns in Czech. On the basis of empirical investigations, an introduction of a new semantic distinction is being proposed within the formal forms of nouns, namely the distinction of a simple quantitative meaning versus a pair/group meaning. There are nouns in Czech that refer typically to a pair or to a (usual) group of entities and not just to a large amount of these entities (e.g. ruce ‘arms’, vlasy ‘hair’, or sirky ‘matches’). These nouns are combined with set numerals rather than with the basic ones. In the paper, arguments are presented supporting the view that the above mentioned subcategorization is grammaticalized. A brief outline of the expressions of the pair/group meaning in Czech as compared to some other languages (German, English, Slavonic languages) is also given."
Přednáška podá přehled o dostupných korpusech pro češtinu a poukáže na výhody a nevýhody jednotlivých typů korpusů pro různé lingvistické úkoly.,The talk present available corpora of Czech and gives examples how they can be used in linguistic research.
"Zkoumá se, čím je ovlivněn pád  českého adjektivního doplňku, který závisí na infinitivu. Nastávají dva případy: pád se shoduje s pádem antecedentu (CT), nebo je nezávislý na antecedentu (CI), v češtině je to nominativ.  Po některých slovesech je obtížné určit, zda jde o CT nebo o CI.","The features which influence the category of a case in the deeply embedded adjectives modified the infinitive construction are studied. Several hypothesis (raising verbs, verbs of control, the form and function of the antecedent) are studied on the Czech data."
"V přednášce bude představen otevřený modulární systém Treex, určený k vývoji aplikací z oblasti zpracování přirozeného jazyka. V systému je integrována řada nástrojů pro morfologickou a syntaktickou analýzu a syntézu několika jazyků. Nejpokročilejší aplikací systému Treex je anglicko-český překladač, který bude popsán podrobněji.","Treex, which is an open-source modular framework tailored for developing natural language processing applications, will be presented in the talk. Numerous tools for morphological and syntactical analysis and synthesis are integrated in the framework. The most advanced application of the framework is English-Czech machine translation system."
"Článek popisuje systém Treex (dříve TectoMT). Jde o víceúčelový otevřený softwarový rámec pro vývoj aplikací z oblasti zpracování přirozeného jazyka. Treex usnadňuje vývoj nových aplikací díky integraci řady existujících modulů, např. pro segmentaci textu, morfologickou analýzu, značkování slovních druhů, syntaktickou analýzu, rozpoznávání pojmenovaných entit, rozpoznávání anafor, syntézu vět atd. Treex je využíván také pro výukové účely.","The present paper describes Treex (formerly TectoMT), a multi-purpose open-source
framework for developing Natural Language Processing applications. It facilitates the development  by exploiting a wide range of software modules already integrated in Treex, such as tools for  sentence segmentation, tokenization, morphological analysis,
 part-of-speech tagging, shallow and deep syntax parsing,  named entity recognition, anaphora resolution, sentence synthesis,  word-level alignment of parallel corpora, and other tasks.
The most elaborate application of Treex is
an English-Czech machine translation system with transfer on deep syntactic (tectogrammatical) layer. Besides research, Treex is used
for teaching purposes and helps students to implement morphological and syntactic analyzers of foreign languages in a very short time."
Treex::Core je soubor modulů v jazyce Perl určený pro obecné zpracování syntaktických stromových struktur. Datová reprezentace je v maximální míře jazykově nezávislá. Treex::Core se v současnosti používá zejména jako základní datová reprezentace ve strojovém překladu využívajícím syntaxi.,Treex::Core is a set of Perl modules aimed at a general processing of syntactic tree structures. The data structures are designed to be as language independent as possible. Treex::Core is currently used especially for developing syntax-based Machine Translation systems.
Soubor vybraných česky psaných prací předního českého lingvisty zejména o češtině.,"A set of selected works, written in Czech, by a famous Czech linguist, mainly about the Czech language."
"Před sto lety byla v Praze založena Kancelář Slovníku jazyka českého, ze které pak vznikl akademický Ústav pro jazyk český. Ten se stal (za vedení B. Havránka, pak Fr. Daneše ad.) nejvýznamnějším bohemistickým pracovištěm.","Hundred years ago, the Office of the Czech Language Dictionary was founded in Prague. Later it evolved into the academic Institute of the Czech Language. Under the leadership of B. Havránek, F. Daneš and others it became the most important research institute for the Czech language."
"Tento článek nebude hlášen do RIV, proto není třeba uvádět abstrakt.","This article will not be reported to RIV, thus the abstract is not mandatory."
"Tento článek nebude hlášen do RIV, proto není třeba uvádět abstrakt.","This article will not be reported to RIV, thus the abstract is not mandatory."
"Na několika vybraných lingvistických problémech chceme ukázat, že klasická strukturní a funkcionální lingvistika dokonce se svými zdánlivě tradičními přístupy má co nabídnout formálnímu popisu jazyka a jeho aplikacím ve zpracování přirozeného jazyka, a krátkým odkazem na Funkčně-generativní gramatiku (na teoretické straně CL) a Pražský závislostní treebank (na straně aplikační) ilustrovat možnou interakci mezi lingvistikou a CL.",We want to demonstrate on some selected linguistic issues that classical structural and functional linguistics even with its seemingly traditional approaches has something to offer to a formal description of language and its applications in natural language processing  and to illustrate by a brief reference to Functional Generative Grammar (on the theoretical side of CL) and Prague Dependency Treebank (on the applicational side) a possible interaction between linguistics and CL.
"Pojednání o vzájemné souhře informační struktury věty, anaforických a koreferenčních vztahů a různých aspektů struktury diskurzu, založené na dokladech z velkého anotovaného korpusu.","Examination of the interplay of the information structure of the sentence, the anaphoric and coreferential relations and of different aspects
of discourse structure, based on the evidence from a large annotated corpus."
Příspěvek se zabýval přístupy FGP k aktuálnímu členění a popisoval nové poznatky o systémovém uspořádání.,The presentation dealt with the approaches to the sentence information structure and it described some new findings about systemic ordering.
"Cílem našeho příspěvku je představit korpusově založené srovnání češtiny a angličtiny a zvážit, které aspekty jevu informační struktury jsou univerzální povahy a které jsou jazykově závislé.",The aim of our contribution is to present a corpus-based comparison of Czech and English and to consider which aspects of the phenomenon of information structure are of a universal nature and which are language specific.
"TrEd 2.0 je nově refaktorovaná verze editoru stromů TrEd. TrEd je používán jak v Ústavu formální a aplikované lingvistiky, tak na několika zahraničních výzkumných pracovištích v projektech zaměřených na práci se syntaktickými strukturami. Výrazné změny v architektuře TrEdu podstatně usnadní jeho budoucí vývoj, údržbu, testování a distribuci.","TrEd 2.0 is a newly refactored version of the TrEd tree editor. TrEd is used in a number of research projects, at the Institute of Formal and Applied Linguistics as well as in several foreign research institutions. Recent changes in its design will substantially facilitate its future development, testing and distribution."
Recenze odborné knihy: Syntax-Based Collocation Extraction od Violety Seretan,A review of a book: Syntax-Based Collocation Extraction by Violeta Seretan
"Tato disertační práce popisuje valenci sloves v rámci anotace Pražského závislostního korpusu (PDT) a jejím hlavním cílem je popsat valenční slovník PDT-Vallex. Tento slovník vznikl při anotaci PDT a díky svému charakteru se stal významným zdrojem valenční informace využitelné jak pro lingvistický výzkum, tak pro počítačové zpracování přirozeného jazyka. V práci popisujeme nejen koncepci slovníku, která úzce souvisí s pojetím valence v rámci Funkčně generativního popisu, ale i vztah slovníku k PDT. Právě na základě tohoto vztahu - úzkého propojení slovníku s korpusem - věnujeme zvláštní pozornost popisu formálních prostředků diatezí. Navrhujeme transformační pravidla pro sekundární diateze, s jejichž pomocí se dokážeme vyrovnat s případy, kdy formy slovesných valenčních doplnění ve slovníku neodpovídají formám slovesných doplnění v korpusových textech.","This dissertation describes PDT-Vallex, a valency lexicon of Czech verbs and its relation to the annotation of the Prague Dependency Treebank (PDT). The PDT-Vallex lexicon was created during the annotation of the PDT and it is a valuable source of verbal valency information available both for linguistic research and for computerized natural language processing. In this thesis, we describe not only the structure and design of the lexicon (which is closely related to the notion of valency as developed in the Functional Generative Description of language) but also the relation between the PDT-Vallex and the PDT. The explicit and full-coverage linking of the lexicon to the treebank prompted us to pay special attention to diatheses; we propose formal transformation rules for diatheses to handle their surface realization even when the canonical forms of verb arguments as captured in the lexicon do not correspond to the forms of these arguments actually appearing in the corpus."
"Práce popisuje valenční slovník PDT-Vallex. Tento slovník vznikl při anotaci PDT a díky svému charakteru se stal významným zdrojem valenční informace využitelné jak pro lingvistický výzkum, tak pro počítačové zpracování přirozeného jazyka. Na základě úzkého propojení slovníku s korpusem věnujeme zvláštní pozornost popisu formálních prostředků diatezí.","This book describes PDT-Vallex, a valency lexicon of Czech verbs and its relation to the annotation of the Prague Dependency Treebank. The PDT-Vallex lexicon was created during the annotation of the PDT and it is a valuable source of verbal valency information available both for linguistic research and for computerized natural language processing. The book describes also the relation between the PDT-Vallex and the PDT. The explicit and full-coverage linking of the lexicon to the treebank prompted us to pay special attention to diatheses; we propose formal transformation rules for diatheses to handle their surface realization."
"Kniha zachycuje slovesnou valenci v Pražském závislostním korpusu. Popisuje vztah mezi anotací a jednotlivými významy sloves,které se v korpusu vyskytly. Slovesa (resp. jejich významy) jsou popsána svými valenčními rámci. Popis valenčních rámců je plně formalizovaný, zachycuje lema, valenční doplnění a jejich povrchové realizace (povrchové formy). Valenční rámce obsahují také ilustrativní příklady a poznámky.","The book captures verbal valency in the Prague dependency treebank. It describes the relation between the annotation and the individual verbal meanings described by their valency frames. The description is fully formalized in the form of a full list of valency frames, together with their lemmas and full description of valency slots, their surface realization, notes and examples. It thus forms a special extract from the Prague Dependency Treebank."
Systém Dialogy.Org je softwarový nástroj určený  především k podpoře vytváření a sdílení anotovaných audio-video dat lingvistickou komunitou. Dialogy.Org umožňuje formou webového rozhraní editaci a vyhledávání v přepisech audio-visuálních nahrávek dialogů. Vyhledané úseky textu je možné přehrávat a analyzovat pomocí webového prohlížeče.,"Dialogy.Org system is a software tool designed primarily to support the creation and sharing of annotated audio-visual data by linguistic community.
The software tool allows editing and searching in the transcripts of audio-visual recordings of dialogues. The dynamic web application provides access for registered users to the digitised archive. Playing and exploring of selected parts is possible in the web browser."
"Popisujeme naše pokusy s hierarchickým frázovým strojovým překladem v rámci soutěže WMT 2011. Natrénovali jsme systém pro všech 8 překladových směrů mezi angličtinou na jedné straně a češtinou, němčinou, španělštinou nebo francouzštinou na druhé. Poněkud více jsme se soustředili na směr z angličtiny do češtiny. Poskytujeme podrobný popis naší konfigurace a dat, aby bylo možné pokusy zopakovat.","We describe our experiments with hierarchical phrase-based machine translation for the WMT 2011 Shared Task. We trained a system for all 8 translation directions between English on one side and Czech, German, Spanish or French on the other side, though we focused slightly more on the English-to-Czech direction. We provide a detailed description of our configuration and data so the results are replicable."
"Addicter je zkratka za Automatic Detection and DIsplay of Common Translation ERrors. Je to soubor nástrojů (především skriptů napsaných v Perlu), které pomáhají s analýzou chyb strojového překladu. Ve druhé verzi byl podstatně rozšířen prohlížeč a přibyla řada modulů pro automatickou detekci a klasifikaci chyb.",Addicter stands for Automatic Detection and DIsplay of Common Translation ERrors. It is a set of tools (mostly scripts written in Perl) that help with error analysis for machine translation. The second version contains a greatly improved viewer and many new modules for automatic detection and classification of errors.
"Představujeme Addicter, nástroj pro automatickou detekci a zobrazování chyb strojového překladu. Tento nástroj automaticky identifikuje a klasifikuje chyby a umožňuje prohlížet testovací a trénovací korpus a slovní párování; umožňuje také propojení s dalšími lingvistickými nástroji. Klasifikace chyb je inspirována Vilarem et al. (2006), některé jejich kategorie jsou ovšem pro současnou verzi našeho systému nedosažitelné.","We introduce Addicter, a tool for Automatic Detection and DIsplay of Common Translation
ERrors. The tool allows to automatically identify and label translation errors and browse the test
and training corpus and word alignments; usage of additional linguistic tools is also supported.
The error classification is inspired by that of Vilar et al. (2006), although some of their higherlevel
categories are beyond the reach of the current version of our system. In addition to the
tool itself we present a comparison of the proposed method to manually classified translation
errors and a thorough evaluation of the generated alignments."
"Popíšeme naše nedávné experimenty se závislostní syntaktickou analýzou v mnoha jazycích. Víme o více než 30 jazycích, pro které jsou k dispozici treebanky (většinou závislostní) za přijatelných licenčních podmínek. Tyto treebanky však mají mnoho různých anotačních stylů. Aby byly výsledky pokusů porovnatelné, je třeba jednotlivé anotační styly navzájem co nejvíce přiblížit. Zajímavou otázkou je, jak by měl společný anotační styl vypadat a jaká kritéria použít k vyhodnocení vhodnosti jednotlivých přístupů.

V první části přednášky představíme data, která máme. Rozličnost anotačních stylů předvedeme na různých syntaktických jevech, jejich reprezentaci v korpusech a naše transformace do společného anotačního schématu. Ve druhé části se soustředíme konkrétně na koordinační struktury – jeden z nejobtížnějších jevů jak z pohledu autorů treebanků, tak parserů. Představíme klasifikaci možných reprezentací, vyhodnotíme jejich teoretickou vyjadřovací sílu i praktický dopad na úspěšnost syntaktické analýzy za použití dvou předních závislostních parserů: Maltu a MST.","We will present our recent parsing experiments with dependency treebanks in multiple languages. We identified more than 30 languages for which treebanks (mostly dependency-based) are available under acceptable licensing terms. However, the treebanks adhere to many different annotation styles. To make our results comparable, we need to make the annotation styles as similar as possible. An interesting question is, how should the common annotation style look like, and what criteria should we use to evaluate suitability of the various approaches.

In the first part of the talk we will present the data we have. We will demonstrate the diversity of annotation styles by giving an overview of various syntactic phenomena, their representation in treebanks and our effort to transform the representation to one common scheme. In the second part we will focus specifically on coordinating structures – one of the most difficult phenomena both for treebank designers and parsers. We will classify the possible annotation styles along several dimensions and we will evaluate both their theoretical expressive power and practical impact on parsing accuracy, using two state-of-the-art dependency parsers: Malt and MST."
"Předkládaným příspěvkem bezprostředně navazujeme na stať Proměna Českého akademického korpusu, která byla publikována ve Slově a slovesnosti v roce 2006 (Hladká – Králík, 2006). Nyní popisujeme zkušenosti ze syntaktické proměny Českého akademického korpusu, při které byly původní syntaktické anotace ponechány stranou a texty byly nově anotovány dle koncepce Pražského závislostního korpusu. Proměna, neboli anotace, byla zahájena tři roky poté, co byla dokončena syntaktická anotace již zmíněného Pražského závislostního korpusu – největšího anotovaného korpusu psané češtiny. Tento tříletý časový odstup je do jisté míry kuriózní; neznáme jiný jazyk, pro který by po anotování velkého objemu dat (více než jeden milion slov) proběhla anotace dalších dat, sice objemu menšího, ale rovněž nezanedbatelného (statisíce slov). 
Syntaktickou anotací Českého akademického korpusu jsme vstoupili podruhé do stejné řeky. Doufáme, že zkušenost, kterou si odnášíme, bude přínosná pro všechny jazykovědce.","The idea of the Czech Academic Corus (CAC) came to life in 1971 thanks to the Department of Mathematical Linguistics within the Institute of Czech Language. By the mid 1980s, a total of 540,000 words were morphologically and syntactically manually annotated.
After the Prague Dependency Treebank (PDT) – the largest treebank of Czech written texts – has been built, a conversion from the CAC to the PDT format has started. The main goal was to make the CAC and the PDT compatible thus to enable integration of the CAC into the PDT. The second version of the CAC presents such a complete conversion of the internal format and the annotation schemes.
Conversion of syntactic annotation has started three years after the syntactic annotation of PDT has been finished. Such a situation is exceptional since, at least to our knowledge, there is no other language for the annotation of indispensable amount of data is being done in two subsequent annotation projects.
This article summarizes the experience acquired during the CAC syntactic annotation conversion."
"Zabýváme se pojmem crowdsorcingu v souvislosti se zpracováním textových dat. Implementovali jsme on-line hry s texty a detailně je popisujeme; jde o hru s koreferencí (PlayCoref) a o hry se slovy a s mezerami mezi slovy (Shannon Game a Place the Space). Pravidla her jsou jazykově nezávislá a hry jsou v současné době hratelné s českými a anglickými daty.
Po dosud odehraných partiích poopravujeme poněkud svůj pohled na možnost atraktivity her s texty.","We review a notion of crowdsourcing, namely we turn our attention to crowdsourcing projects that manipulate the textual data. We carry out the implementation of the on-line games with texts. We introduce a game on coreference, PlayCoref, and games with words and white spaces in the sentence, Shannon Game and Place the Space, in great details. The game rules are designed to be language independent and the games are playable with both Czech and English texts by default. After a number of sessions played so far we revise our initial expectations and enthusiasm to design an attractive annotation game with the document."
"Práce přináší odpověď na otázku, co je a co není elipsa, a stanovuje kritéria určování eliptických vět. Analýzu jednotlivých typů elips podává z pohledu významové (sémanticko-syntaktické) reprezentace vět. Nezabývá se podmínkami a příčinami vzniku elips (kdy a proč je možné něco elidovat), zaměřuje se výhradně na identifikaci eliptických míst (zda je ve větě něco elidováno a co) a na jejich významovou reprezentaci, konkrétně na jejich zachycení na tektogramatické rovině pražských závislostních korpusů. Strukturní přístup závislostní (uplatňovaný v pražských závislostních korpusech) je v práci srovnán s přístupem složkovým (užitým v americkém korpusu PennTreebank). Tohoto srovnání je možné využít při (automatickém) převodu složkových stromů na závislostní.","The paper answers the question what is and what is not ellipsis and specify criteria for identification of elliptical sentences. It reports on an analysis of types of ellipsis from the point of view of semantic (semantico-syntactic) representation of sentences. It does not deal with conditions and causes of constitution of elliptical positions in sentences (when and why it is possible to omit something in a sentence) but it focuses exclusively on identification of elliptical positions (if there is something omitted and what) and on their semantic representation, specifically on their representation on the tectogrammatical level of the Prague Dependency Treebanks."
"Rekonstrukce standardizovaného textu z mluvené řeči v Pražském závislostním korpusu mluvené češtiny odstraňuje z přepisu mluvených projevů specifické rysy mluvenosti (prvky nespisovné z obecné češtiny i nářečí, nadbytečná „ukazovací“ zájmena a navazovací konektory, „vycpávky“, subjektivní slovosled, opakování a opravy, restarty aj.). Např. z mluveného „takže jako tam byla dobrá parta a dlouho tedy no“ vzniká standardizované „Byla tam dlouho dobrá parta.“ To umožňuje názorné a zajímavé porovnávání autentických mluvených projevů a textů standardizovaných, u nichž je otázka, jak je kategorizovat: jsou to stále ještě texty mluvené – ale korektní, spisovné? Nebo standardizace transformuje mluvený projev do podoby textu psaného? Necháme-li stranou jevy hláskoslovné a tvaroslovné a soustředíme-li se na proměny syntaxe při standardizaci, nabízí se otázka, v čem vlastně je syntaktická identita českého mluveného a psaného textu, jaké syntaktické celky/ jednotky/ konstrukce jsou „přirozené“ v mluveném a naproti tomu v psaném textu, jaký je rozdíl v hustotě kohezních spojů, v explicitní a implicitní návaznosti mezi jednotkami atd. Vede odstraňování specifických rysů mluvené syntaxe ke vzniku syntakticky „přirozeného“ psaného textu? Jaký je rozdíl mezi „světem psanosti“ a „světem mluvenosti“, jaké estetické hodnoty jsou s nimi spojeny? Vznikají standardizací skutečně „hezké“ české věty, „hezčí“ než ty mluvené? Lze vůbec mluvený projev „přeložit“ do psaného?","The reconstruction of standardized text from the Prague Dependency Treebank of Spoken Czech removes specific aspects of spoken language (non-standard elements from Common Czech and dialects, superfluous demonstrative pronouns and connectors, filler words, subjective word order, repetitions and repairs, restarts etc.). For example, the spoken utterance ""takže jako tam byla dobrá parta a dlouho tedy no"" (""so like there was a good crowd and for a long time yeah"") becomes the standardized sentence ""Byla tam dlouho dobrá parta"" (""For a long time, there was a good crowd there.""). This enables a vivid and interesting comparison of authentic spoken expressions and standardized texts. The question of how to categorize the standardized texts thus arises; they are still spoken texts - but they are correct, standard? Or does standardization transform spoken utterances into written texts? If we leave aside phonetic and morphological phenomena and concentrate on the syntactic transformations which occur during standardization, the following questions arise: What does the syntactic identity of the Czech spoken and written texts consist of? What syntactic wholes/units/constructions are natural in the spoken text and also in written text? What is the difference in the density of cohesive conjuctions, in the explicit and implicit relationship between units, etc.? Does the removal of specific aspects of spoken syntax lead to syntactically natural wtritten texts? What is the difference between the written world and the spoken world, what aesthetic values are assigned to them? Does standardization create nice Czech sentence, nicer than those that are spoken? Is even possible to translate a spoken utterance into a written text?"
"Zpracování přirozeného jazyka je poměrně nový, rychle se rozvíjející obor, který nachází široké uplatnění v mnoha aplikacích. Tato přednáška bude věnována počítačovému zpracování (zejména) češtiny. Přiblížíme si problematiku zachycení 	významu a představíme kolekce jazykových dat – slovníky a korpusy –, které se 	vytvářejí na MFF UK. Krátce se též seznámíme s některými projekty, které tato data využívají, zejména s projektem strojového překladu mezi češtinou a angličtinou.",Natural Language Processing is a modern field which is used in many applied tasks. The lecture focuses on language meaning and its representation. Data collections (lexicons and corpora) and automatic tools (esp. machine translation systems) will be introduced.
"Informace o syntaktických a sémantických vlastnostech sloves hraje zásadní roli v mnoha NLP aplikacích. V přednášce se soustředím na lexikografické zpracování sloves ve Valenčním slovníku češkých sloves.
Prototypicky jedna syntaktická struktura odpovídá jednomu významu slovesa. Nicméně je řada příkladů, kdy jsou sémanticky blízká slovesa různě syntakticky strukturována - takové změny ve strukturaci se obvykle nazývají alternace. Druhá část přednášky se bude věnovat typologii českých alternací a možností jejich zachycení ve slovníku.","Information on syntactic and semantic properties of verbs, which are traditionally considered to be the center of a sentence, plays a key role in many rule-based NLP tasks such as automated semantic role labeling, semantic parsing, machine translation, etc. 
The talk will focus on a lexicographic description of syntactic-semantic features of verbs. I will present the valency lexicon of Czech verbs VALLEX (Lopatková et al., 2007), which is closely related to the Prague Dependency Treebank project (Hajič et al., 2006). VALLEX provides information on the combinatorial potential of verbs in their individual senses: for each verb sense, the lexicon lists a number of its syntactic-semantic complementations labeled with their semantic roles and their possible morphological forms. 
Prototypically, a single syntactic structure corresponds to a single meaning of verb. However, in many cases semantically related uses of verbs can be syntactically structured in different ways.
Such changes in syntactic structure are usually referred to as `alternations’, see esp. (Levin, 1993). In the second part of my talk, I will address two basic types of alternations for Czech verbs and I will present a method of their representation in a valency lexicon (Kettnerová, Lopatková, 2011)."
"Budu mluvit o jazykových korpusech, různých úrovních lingvistického značkování, elektronických slovnících, parsování, krátce potom o hlavních aplikacích, např. strojový překlad, automatické odpovědi, analýza a syntéza řeči. Příspěvek bude ilustrován na příkladech, hlavně z českého jazyka.","I will discuss language corpora, several levels of linguistic tagging, electronic dictionaries, parsing of sentences, briefly about main applications, for instance machine translation, question answering, speech analysis and synthesis. Examples will be taken mainly from the Czech language."
"Zápis slov v~mnoha jazycích není jednoznačný, existují různé varianty. Někdy se jedná o~varianty rovnocenné, jindy jsou některé nářeční, nespisovné či jinak příznakové. Při automatickém zpracování jazyka však chceme umět rozpoznat všechny, a současně jim přiřadit stejný základní tvar, tzv. lemma. Na druhou stranu ale potřebujeme všechny varianty od sebe nějakým způsobem odlišit, abychom např. mohli při automatické syntéze zvolit tu správnou. Příspěvek se zabývá možným řešením tohoto problému, a to zavedením tzv. vícenásobného lemmatu. Uvedeme možnosti jeho využití při konkrétních aplikacích, zejména v~korpusové lingvistice.","In some languages, some words may be written in several ways. Sometimes the variants are equivalent, sometimes not. There can be standard, nonstandard, dialectical or otherwise marked variants. During automatic processing we need to recognize them all, but at the same time we need a means how to distinguish them, because during synthesis, it is important to select the right variant. One of the solutions is introduction of so called multiple lemma. We present its possible usa for concrete applications, especially in the field of corpus linguistics."
Příspěvek popisuje a porovnává automatické metody pro rozpoznávání předpon. Ukazuje výsledky experimentů s češtinou a angličtinou a porovnává rozdíly v závislosti na velikosti korpusů a na výběru typu vstupních dat (slovní tvar nebo lemma).,The paper deals with automatic methods for prefix extraction and their comparison. We present experiments with Czech and English and compare the results with regard to the size and type (wordforms vs. lemmas) of input data.
"Článek se zabývá problémem analýzy českých souvětí na základě manuálně anotovaných dat. Takováto data explicitně popisující vztahy mezi segmenty a klauzemi v souvětí poskytují základnu pro další lingvistický výzkum.
Příspěvek prezentuje kvantitativní, lingvistická a strukturní pozorování, na jejichž základě je možné navrhnout algoritmus pro automatickou analýzu struktury souvětí.","The paper deals with the problem of an analysis of complex sentences in Czech on the basis of manually annotated data. The availability of a specialized corpus explicitly describing mutual relationships between segments and clauses 
in Czech complex sentences, together with the availability of a thoroughly syntactically annotated corpus, the Prague Dependency Treebank, provide a solid background for linguistic 
investigation. The paper presents quantitative, linguistic and structural observations which provide a number of clues for building an algorithm for analyzing a structure of complex 
sentences in the future."
"Závislostní korpus anotovaný na rovině morfologické (2 miliony slov), syntaktické (1,5 milionu slov) a sémantické (0,8 milionu slov). Oproti verzi 2.0 přibyly opravy morfologie, anotace víceslovných výrazů, souborovosti a segmentace na větné klauze.","Dependency corpus annotated at morphological, syntactic, and deep syntactic levels. Previous version 2.0 has been enriched by annotation of multiword expressions, pair/group annotation, sentence clause segmentation. Morphological level has been improved."
"Víceslovné výrazy (VSV) jsou důležitou lingvistickou jednotkou, která v mnoha aplikacích počítačového zpracování přirozených jazyků vyžaduje zvláštní zacházení. Je proto vhodné, abychom je dokázali rozpoznat automaticky. Sémanticky anotované korpusy by měly vyznačovat VSV jasně a zřetelně, čímž se usnadní vývoj nástrojů pro automatické rozpoznávání.","Multiword Expressions (MWEs) are important linguistic units that require special treatment in many NLP applications. It is thus desirable to be able to recognize them automatically. Semantically annotated corpora should mark MWEs in a clear way that facilitates development of automatic recognition tools.

In the present paper we discuss various corpus design decisions from this perspective. We propose guidelines that should lead to MWE-friendly annotation and evaluate them on numerous sentence examples. Our experience of identifying MWEs in the Prague Dependency Treebank provides the base for the discussion and examples from other languages are added whenever appropriate."
"Morfologická kategorie čísla je v češtině konstituována protikladem singuláru (s významem jedné jednotliviny) a plurálu (s významem množství jednotlivin). Substantiva ""ruce"", ""boty"", ""vlasy"", ""sirky"" apod. ovšem svými plurálovými formami prototypicky odkazují nikoli k pouhému množství jednotlivin, ale k jejich páru nebo obvyklému souboru, popř. k několika párům nebo obvyklým souborům. Párový nebo šíře souborový význam proto navrhujeme chápat jako další význam plurálové formy českých substantiv. V přednášce popíšeme průběh a výsledky anotace zaměřené právě na identifikaci souborového významu u substantiv obsažených v datech Pražského závislostního korpusu. Uvedeme příklady kontextů, v nichž se paralelní anotace shodovala, i kontexty problematické a navrhneme postup, jak souborový význam včlenit do stávající tektogramatické anotace.","The grammatical category of number is constituted by the singular vs. plural opposition in Czech. Nouns such as ""hands"", ""shoes"", ""matches"" etc. prototypically denote a pair (or group) of entities, not just many of them. This meaning considered as a grammaticalized pair/group meaning and is to be annotated in the data of Prague Dependency Treebank. The talk focuses on the annotation process and its results."
Článek se zabývá zachycením gramatické kategorie čísla v připravované verzi Pražského závislostního korpusu (PDT 3.0). Představen je nový sémantický rys úzce související s kategorií čísla (tzv. souborový význam) a jeho anotace v datech PDT.,"The paper focuses on the way how the grammatical category of number of nouns will be
annotated in the forthcoming version of Prague Dependency Treebank (PDT 3.0), concentrating
on the peculiarities beyond the regular opposition of singular and plural. A new semantic
feature closely related to the category of number (so-called pair/group meaning) was introduced.
Nouns such as ruce ‘hands’ or klíče ‘keys’ refer with their plural forms to a pair or to a
typical group even more often than to a larger amount of single entities. Since pairs or groups
can be referred to with most Czech concrete nouns, the pair/group meaning is considered as a
grammaticalized meaning of nouns in Czech. In the present paper, manual annotation of the
pair/group meaning is described, which was carried out on the data of Prague Dependency
Treebank. A comparison with a sample annotation of data from Prague Dependency Treebank
of Spoken Czech has demonstrated that the pair/group meaning is both more frequent and
more easily distinguishable in the spoken than in the written data."
"Příspěvek navrhuje způsoby, jakými využít znalost o anaforických vztazích při automatickém překladu z angličtiny do češtiny.","Majority of present machine translation systems do not address the retaining of text coherency, they translate just isolated sentences. On the other hand, the authors of anaphora resolvers rarely integrate these tools into more complex scenarios, e.g. the task of machine translation. We propose the ways how machine translation systems can utilize the knowledge of anaphoric relations both in the source as well as in the target language in order to improve the quality of
translation. Specifically, we present how to incorporate anaphora resolution into the process of English to Czech translation using the TectoMT system."
Práca prezentuje první výsledky rozpoznávání koreference substantivních frází v češtině.,"In this work, we present first results on noun phrase coreference resolution on Czech data. As the data resource for our experiments, we employed yet unfinished and unpublished extension of Prague Dependency Treebank 2.0, which captures noun phrase coreference and bridging relations. Incompleteness of the data influenced one of our motivations – to aid annotators with automatic pre-annotation of the data. Although we introduced several novel tree features and tried different machine learning approaches, results on a growing amount of data shows that the selected feature set and learning methods are not able to sufficiently exploit the data."
Vytvořili jsme korpus se 106 jazyky z wikipedie a webových stránek. W2C Wiki Corpus obsahuje 8.5 GB textu a W2C Web Corpus obsahuje 54.7 GB textu. Součástí je také software pro distribuované stahování a zpracovávání webových stránek.,We built corpus containing 106 languages from texts available on the Wikipedia and on the Internet. The W2C Wiki Corpus contains 8.5 GB of text and the W2C Web Corpus contains 54.7 GB of text. The software part contains tools for distributed crawling and processing of web pages.
"W2C je kolekce software a dat. Softwarová část slouží k vytvoření rozsáhlého textového korpusu pro zvolený jazyk. Využívány jsou textové materiály volně dostupné na WWW. Významnou částí jsou komponenty pro filtrování dat, které umožní odstranit materiál s nízkou kvalitou. Datová část obsahuje již vytvořené jazykové korpusy pro více než 100 jazyků, pro každý z nich ve velikosti přibližně 10 milionů slov. Tento zdroj jazykových dat usnadní řadě pracovišť vývoj multilinguálních technologií.","W2C is a collection of software and data. The software part radically facilitates creating a new text corpora for a given language, using text materials freely available on the Internet. A special attention was given to components for filtering that allow to keep the material quality very high. The data part contains corpora for more than 100 languages, with around 10 million words in each. This language data resource can be used especially by researchers specialized at developing multilingual technologies."
"Tato diskuse je zaměřena na prezentaci naší neustálé snahy o vybudování PDT styl závislostní korpus pro Tamil jazyk. Přednáška nastíní anotace programu a anotací na morfologické a povrchové vrstvy syntax. Různé otázky, jako jsou nejednoznačné konstrukce, NP směsí, koordinace jevů a clitics s ohledem na anotace korpus se bude diskutovat. Naším konečným cílem tohoto projektu je vyvinout nabitý funkcemi analýzy rámce pro Tamil, tak my také prezentovat výsledky jsme získali v automatické analýzy (norma na základě a na základě souboru) pomocí vyvinuté prostředky. Některé problematické otázky v analýze Tamil se bude rovněž projednávat.","This talk is aimed at presenting our ongoing effort to build a PDT style dependency treebank for Tamil language. The talk will outline the annotation scheme and annotation at morphological and surface syntax layers. Various issues such as ambiguous structures, NP compounding, coordination phenomena and clitics with respect to the treebank annotation will be discussed. Our ultimate goal in this project is to develop a feature rich parsing framework for Tamil, thus we also present the results we obtained in automatic parsing (rule based & corpus based) using the developed resources. Some problematic issues in Tamil parsing will also be discussed."
"Anotovaná korpusy jako treebanks jsou důležité pro rozvoj
analyzátorů, jazyk aplikace, stejně jako znalost jazyka.
Jen velmi málo jazyků, mají tyto omezené zdroje. V tomto příspěvku popisujeme
naše eort v syntakticky anotace malé korpusy (600 vět) tamilského
jazyk. Naše poznámka je podobný Pražský závislostní korpus (PDT 2.0)
a skládá se ze 2 úrovní nebo vrstev: (i) morfologické vrstvy (m-layer) a (ii) analytické
vrstva (vrstvy). Pro obě vrstvy, jsme zavedli anotace programů, tj. polohy
Tagging pro m-vrstvě a vztahy závislosti (a jak závislost struktury
by měla být vypracována) pro vrstev. Nakonec jsme se zhodnotit naše korpusy v označování a
analýze úlohy pomocí známých značkovače a analyzátory a diskutovat některé obecné otázky
V anotaci na Tamil jazyce.","Annotated corpora such as treebanks are important for the development
of parsers, language applications as well as understanding of the language itself.
Only very few languages possess these scarce resources. In this paper, we describe
our effort in syntactically annotating a small corpora (600 sentences) of Tamil
language. Our annotation is similar to Prague Dependency Treebank (PDT 2.0)
and consists of 2 levels or layers: (i) morphological layer (m-layer) and (ii) analytical
layer (a-layer). For both the layers, we introduce annotation schemes i.e. positional
tagging for m-layer and dependency relations (and how dependency structures
should be drawn) for a-layers. Finally, we evaluate our corpora in the tagging and
parsing task using well known taggers and parsers and discuss some general issues
in annotation for Tamil language."
"Lze nalézt jen velice málo informací o syntaktické analýze tamilštiny. V tomto článku popisujeme prvotní experimenty zaměřené na syntaktickou analýzu tamilštiny na základě pravidel a s pomocí korpusu. Anotační schéma bylo odvozeno od Pražského závislostního treebanku, proběhla ruční anotace cca 3000 slov. Pro analýzu založenou na korpusu používáme MST parser a Malt parser. Pro pravidlový přístup jsme implementovali řadu gramatických pravidel. V obou přístupech překročila úspěšnost analýzy 74%.","Very few attempts have been reported in the literature on dependency parsing for Tamil. In this paper, we report results obtained for Tamil dependency parsing with rule-based and corpus-based approaches. We designed annotation scheme partially based on Prague Dependency Treebank (PDT) and manually annotated Tamil data (about 3000 words) with dependency relations. For corpus-based approach, we used two well known parsers MaltParser and MSTParser, and for the rule-based approach, we implemented series of linguistic rules (for resolving coordination, complementation, predicate identification and so on) to build dependency structure for Tamil sentences. Our initial results show that, both rule-based and corpus-based approaches achieved the accuracy of more than 74% for the unlabeled task and more than 65% for the labeled tasks. Rule-based parsing accuracy dropped considerably when the input was tagged automatically."
"Tamilský závislostní treebank (TamilTB) je
pokusem vytvořit syntakticky anotovaný korpus pro tamilštinu. TamilTB
obsahuje 600 vět obohacených o ruční morfologickou anotaci a
závislostní syntax ve stylu Pražského závislostního korpusu (PDT). TamilTB
byl vytvořen v Ústavu formální a aplikované lingvistiky, Univerzity Karlovy v Praze. Anotační pravidla jsou podrobně popsána a ilustrována příklady.","Tamil Dependency Treebank (TamilTB)  is
an attempt to develop a syntactically annotated corpora for Tamil. TamilTB
contains 600 sentences enriched with manual annotation of morphology and
dependency syntax in the style of Prague Dependency Treebank. TamilTB
has been created at the Institute of Formal and Applied Linguistics, Charles
University in Prague. This report serves the purpose of how the annotation has been done at morphological level and syntactic level. Annotation scheme has been elaborately discussed with examples."
"TamilTB je první zveřejněný syntakticky anotovaný korpus tamilštiny, který umožní rozvoj jazykových technologií (zejména morfologické analýzy a parsingu) pro tento jazyk.",TamilTB is a first published syntactically annotated corpus of Tamil. TamilTB will allow a more rapid development of language technologies for Tamil (especially parsing and morphological analysis).
Představujeme nástroj pro extrakci překladových párů z korpusu zarovnaného po slovech. Nástroj již během extrakce málo četné páry ignoruje a šetří tak čas následného zpracování a diskový prostor.,"We present a tool that extracts phrase pairs from a word-aligned parallel corpus and filters
them on the fly based on a user-defined frequency threshold. The bulk of phrase pairs to be
scored is much reduced, making the whole phrase table construction process faster with no
significant harm to the ultimate phrase table quality as measured by BLEU. Technically, our
tool is an alternative to the extract component of the phrase-extract toolkit bundled with Moses
SMT software and covers some of the functionality of sigfilter."
"V článku představujeme pokus o zlepšení strojového překladu pojmenovaných entit s využitím Wikipedie. Pojmenované entity rozpoznáváme na základě kategorií anglických článků Wikipedie, následně extrahujeme jejich potenciální překlady z odpovídajících českých článků a přidáváme je jako nové možnosti překladu do statistického systému pro strojový překlad. Automatická metrika kvality překladu značí její zhoršení, avšak podle ruční anotace se naše překlady jeví jako lepší. Docházíme k závěru, že tento přístup vede v řadě chyb v překladu a měl by být proto vždy kombinován se standardním statistickým překladovým modelem. Měla by mu také být přiřazena přiměřená váha.","In this paper we present our attempt to improve machine translation of named entities by using Wikipedia. We recognize named entities based on categories of English Wikipedia articles, extract their potential translations from corresponding Czech articles and incorporate them into a statistical machine translation system as translation options. Our results show a decrease of translation quality in terms of automatic metrics but positive results from human annotators. We conclude that this approach can lead to many errors in translation and therefore should always be combined with the standard statistical translation model and weighted appropriately."
"Článek popisuje žákovský korpus češtiny, který je kompilací krátkých prací napsaných studenty češtiny jako druhého jazyka. Věnujeme se pozadí projektu, základním požadavkům, procesu sběru textů, přepisu a anotaci. Anotace spočívá v několika vzájemně propojených rovinách, které zachycujou široké spektrum druhů chyb v textu. Ruční anotace je doplněna automatickou identifikací některých chyb. Navíc původní i opravený text je otegován morfologickými značkami. Anotační schéma je otestováno na vzorku o velikosti cca 10.000 slov oanotovaném dvěma nezávislými skupinami anotátorů s vyhovující iaa.","The paper describes a learner corpus of Czech, compiled from short essays written by students of Czech as a second or foreign language. We discuss the project’s background assumptions, the process of text acquisition, transcription and mark-up, 
and finally focus on the annotation scheme, consisting of multiple interlinked levels to 
cope with a wide range of error types present in the input. Manual annotation is complemented by automatic error identification wherever possible and morphosyntactic tags for all word forms both in the emended and the original text. The annotation schema is tested on a doubly-annotated sample of approx. 10,000 words with fair inter-annotator agreement results."
"Navrhujeme metodu pro automatickou identifikaci různých typů chyb ve výstupu strojového překladu. Přístup je převážně založen na jednojazyčném slovním zarovnání hypotézy a referenčního překladu. Kromě běžných lexikálních chyb se zjišťují také chyby slovosledu. Předkládáme srovnání s ručně klasifikovanými chybami MT. Naše klasifikace je inspirovaná klasifikací Vilara et al. (2006), přestože rozlišení některých jejich kategorií přesahuje možnosti současné verze našeho systému.","We propose a method of automatic identification of various error types in machine translation output. The approach is mostly based on monolingual word alignment of the hypothesis and the reference translation. In addition to common lexical errors misplaced words are also detected.
A comparison to manually classified MT errors is presented. Our error classification is inspired by that of Vilar et al. (2006), although distinguishing some of their categories is beyond the reach of the current version of our system."
"Článek navrhuje novou metodu ručního vyhodnocování kvality překladu, tzv. evaluaci pomocí otázek.","This paper proposes a new method of manual evaluation for statistical machine translation,
the so-called quiz-based evaluation, estimating whether people are able to extract information
from machine-translated texts reliably. We apply the method to two commercial and two experimental
MT systems that participated in WMT 2010 in English-to-Czech translation. We
report inter-annotator agreement for the evaluation as well as the outcomes of the individual
systems. The quiz-based evaluation suggests rather different ranking of the systems compared
to the WMT 2010 manual and automatic metrics. We also see that overall, MT quality is becoming
acceptable for obtaining information from the text: about 80% of questions can be answered
correctly given only machine-translated text."
"SemPOS je automatická metrika kvality strojového překladu založená na hloubkové syntaxi. Poměrně dobře koreluje s lidským hodnocením, ale je výpočetně drahá. V příspěvku zkoumáme její odlehčené verze a zapojujeme je i do iterativní optimalizace překladového modelu.","SemPOS is an automatic metric of machine
translation quality for Czech and English focused
on content words. It correlates well
with human judgments but it is computationally
costly and hard to adapt to other languages
because it relies on a deep-syntactic
analysis of the system output and the reference.
To remedy this, we attempt at approximating
SemPOS using only tagger output and
a few heuristics. At a little expense in correlation
to human judgments, we can evaluate
MT systems much faster. Additionally, we describe
our submission to the Tunable Metrics
Task in WMT11."
Příspěvek se zabýval možnostmi rozlišení explikativních a příčinných vztahů pro potřeby anotace diskurzu.,The presentation disscused the possibilities of of dictinction of explicative and causal relations for the purposes of discourse annotation.
"Článek popisuje, kterak lze využít potenciálu webových diskusních fór coby porovnatelných korpusů.","As the title suggests, our paper deals with web discussion fora, whose
content can be considered to be a special type of comparable corpora. We
discuss the potential of this vast amount of data available now on the
World Wide Web nearly for every language, regarding both general and common
topics as well as the most obscure and specific ones. To illustrate our
ideas, we propose a case study of seven wedding discussion fora in five
languages."
Ruský tagger vyvinutý nad minimálním taggerem (Hana et al 2004).,Russian tagger developed on top of the resource-light tagger (Hana et al 2004). Available either as part of the Morph system or as a simple model for the TnT tagger.
V článku popisujeme jak překlad předložek ovlivňuje kvalitu strojového překladu a navrhujeme způsob jeho vylepšení.,"In this article we explore differences in preposition usage in Czech and Russian languages and how the Machine Translation (MT) system between the languages deals with prepositions. We focus on the errors that occur in preposition phrases. Our study involves research on a parallel corpus for theoretical evidence and analysis of the output of the rule-based Machine
Translation (RBMT) system for closely related languages Česílko and the Statistical MT (SMT) system Joshua from Czech into Russian."
"Strojový překlad z angličtiny do češtiny implementovaný v systému TectoMT sestává ze tří fází: analýzy, transferu a syntézy. Transfer se provádí na tektogramatické rovině upravené pro účely překladu. Každá fáze je rozčleněna do bloků, které řeší konkrétní lingvisticky interpretovatelný úkol (např. přiřazení morfologických značek statistickým taggerem, či přesun klitik podle ručně psaných pravidel). Systém TectoMT je navržen modulárně - bloky je možné zaměňovat za alternativní implementace a také využít i pro jiné aplikace než strojový překlad. Přednáška představí základní průběh celého překladu a zaměří se na popis vylepšení, která byla provedena v posledním roce, zejména: (a) využití tektogramatického jazykového modelu a Hidden Markov Tree Models, (b) nový systém slovníků natrénovaných na paralelním korpusu CzEng pomocí metody Maximum Entropy. Volitelným dodatkem je interaktivní tutoriál o platformě Treex.","English to Czech machine translation as it is implemented in the TectoMT system consists of three phases: analysis, transfer and synthesis. The system uses tectogrammatical (deep-syntactic dependency) trees as the transfer medium. Each phase is divided into so-called blocks, which are processing units that solve linguistically interpretable tasks (e.g., statistical part-of-speech tagging or rule-based reordering of clitics). I will shortly introduce the linguistic layers of language description which are used for the translation and I will describe basic concepts of the NLP framework Treex in which the MT system is implemented. I will explain the whole translation process by step by step examples. After showing statistics on translation errors and their sources, I will describe recent improvements of the system. One of the most helpful improvements was the utilization of Maximum Entropy rich-feature translation models and Hidden Markov Tree Models in the transfer phase of translation, which is interpretable as labeling nodes of dependency trees. The translation results are evaluated using both automatic metric BLEU and human judgments from the WMT 2011 evaluation. Discussion on the manual evaluation (and meta evaluation) of MT is welcomed. For those interested in the Treex framework, I have another talk as well as a hands-on tutorial."
"Úspěšnost závislostních parserů je jedním z hlavních faktorů, které určují kvalitu závislostního strojového překladu. Tento článek zkoumá vliv různých přístupů k závislostnímu parsingu (a také různých velikostí trénovacích dat) na výslednou kvalitu anglicko-českého statistického překladového systému implementovaného ve frameworku Treex. Článek též rozebírá vztah mezi intrinsickou evaluací parsingu (UAS) a extrinsickou (BLEU).",Accuracy of dependency parsers is one of the key factors limiting the quality of dependency-based machine translation. This paper deals with the influence of various dependency parsing approaches (and also different training data size) on the overall performance of an English-to-Czech dependency-based statistical translation system implemented in the Treex framework. We also study the relationship between parsing accuracy in terms of unlabeled attachment score and machine translation quality in terms of BLEU.
Feat je prostředí pro víceúrovňovou chybovou anotaci studenských korpusů.,Flexible Error Annotation Tool (feat) is an environment for layered error annotation of learners corpora.
"Lexical Annotation Workbench (LAW) je IDE pro morfologickou anotaci. Umožňuje prostou anotaci, slučování a porovnáná různých anotací téhož textu, vyhledávání, atd. Tato verze přidává několik vstupních filtrů, podporu tagsetů (vkládání tagů, nápověda pro tagy, atd), and opravuje mnoho chyb.","Lexical Annotation Workbench (LAW) is an integrated environment for morphological annotation. It supports simple morphological annotation, integration and comparison of different annotations of the same text, serching for particular word, tag etc. This version adds several new input filters, adds tagset support (guided tag entry, tag help), and fixes many bugs."
"Morph - systém pro morfologickou analýzu a značkování, včetně podpůrných nástrojů pro konverzi korpusů, evaluaci, atd.","Morph - system for morphological analysis and tagging, including supporting tools for corpus conversion, evaluation, etc."
"Článek popisuje studentský korpus češtiny. Korpus zachycuje češtinu používanou nerodilými mluvčími. Popisujeme jeho strukturu, více-úrovňovou chybovou anotaci a proces anotace.","The  paper  describes  a  learner  corpus  of Czech, currently under development.  The corpus  captures  Czech  as  used  by  non-native speakers.  We discuss its structure, the layered annotation of errors and the annotation process."
"Flektivní jazyky mají bohaté skloňování, takže tagsety popisující jejich morfologické vlasnosti musí být nutně velké. Pro takové tagsety je vhodné použít strukturované tagy. V tomto článku popisujeme poziční tagset zachycující morfologii ruštiny. Vychází z Českého pozičního tagsetu (Hajič 2004) a rozvíjí předběžnou verzi tohoto tagsetu, kterou jsme používali v naší dosavadní práci (např. Hana et al. (2004, 2006); Feldman (2006); Feldman and Hana (2010)). Zde jednak prezentujeme systematičtější a úplnejší verzi (přidali jsme informaci o životnosti, vidu a zvratnosti) a jednak ho podrobněji popisujeme a srovnáváme s Českým pozičním tagsetem.","Fusional languages have rich inflection. As a consequence, tagsets capturing their morphological features are necessarily large. A natural way to make a tagset manageable is to use a structured system. In this paper, we present a positional tagset for describing morphological properties of Russian. The tagset was inspired by the Czech positional system (Hajic 2004). We have used preliminary versions of this tagset in our previous work (e.g., Hana et al. (2004, 2006); Feldman (2006); Feldman and Hana (2010)). Here, we both systematize and extend these preliminary versions (by adding information about animacy, aspect and reflexivity); give a more detailed description of the tagset and provide comparisons with the Czech system."
"V článku popisujeme problémy tvorby zdrojů pro resource-light tagger flektivních jazyků (Feldman and Hana, 2010). Omezení dostupných zdrojů (čas, odbornost a finance) s sebou přinášejí problémy, které se nevyskytují při tvorbě zdrojů tradičním způsobem.","We  describe  the  challenges  of  resource creation  for  a  resource-light  system  for morphological  tagging  of  fusional  languages (Feldman and Hana, 2010).   The constraints on resources (time, expertise, and money) introduce challenges that are not present in development of morphological tools and corpora in the usual, resource intensive way."
Kurz vysvětluje lingvistické a komputační základy morfologické analýzy a značkování flektivních jazyků. Důraz je kladen na analýzu a značkování nenaročné na zdroje.,"This course lays out the linguistic and computational foundations of morphological analysis and tagging of highly inflected languages, with an emphasis on resource-light analysis and tagging of fusional languages."
"Korpus obsahující cca 6000 slov z Orwelova 1984, ručně označkovaný pomocí ruského pozičního tagsetu",Corpus containing circa 6000 words from Orwel's 1984; manually annotated using Russian positional tagset
Srovnání části systémového uspořádání v české a německé větě (slovosled volných slovesných doplnění).,Comparison of a part of system ordering in Czech and German sentence (word order of free verbal modifications).
Přezkoumání systémového uspořádání volných slovesných doplnění na datech z Pražského závislostního korpusu.,Review of system ordering of the free verbal modifications on data from the Prague Dependency Treebank.
Prezentace představuje korpus starších českých textů a jeho využití k lingvistickým účelům - ke zkoumání tzv. systémového uspořádání.,Presentation of the corpus of older Czech texts and its use for linguistic purposes - for studying the so-called system ordering.
Náplní tohoto článku je ověřit možnost řešit úkol závislostního parsingu pomocí nástrojů pro sekvenční značkování. Uvádíme algoritmus pro převod závislostních stromů na značky vhodné pro algoritmus sekvenčního značkování a vyhodnocujeme několik nastavení parametrů na standardních datech z treebanku.,"The aim of this paper is to explore the feasibility of solving the
dependency parsing problem using sequence labeling tools. We introduce an
algorithm to transform a dependency tree into a tag sequence suitable for
a sequence labeling algorithm and evaluate several parameter settings on the
standard treebank data. We focus mainly on Czech, as a high-inflective
free-word-order language, which is not so easy to parse using traditional
techniques, but we also test our approach on English for comparison."
"Velké korpusy jsou základem pro moderní metody počítačové lingvistiky. V tomto článku popisujeme probíhající projekt, jehož cílem je vytvořit největší korpus českých textů.","Large corpora are essential to modern methods of computational linguistics
and natural language processing. In this paper, we describe an ongoing
project whose aim is to build a largest corpus of Czech texts. We are
building the corpus from Czech Internet web pages, using (and, if needed,
developing) advanced downloading, cleaning and automatic linguistic
processing tools. Our concern is to keep the whole process language
independent and thus applicable also for building web corpora of other
languages. In the paper, we briefly describe the crawling, cleaning, and
part-of-speech tagging procedures. Using a prototype corpus, we provide a
comparison with a current corpora (in particular, SYN2005, part of the
Czech National Corpora). We analyse part-of-speech tag distribution, OOV
word ratio, average sentence length and Spearman rank correlation
coefficient of the distance of ranks of 500 most frequent words. Our
results show that our prototype corpus is now quite homogenous. The
challenging task is to find a way to decrease the homogeneity of the text
while keeping the high quality of the data."
"Tato práce je věnována problematice členské negace a způsobům jejího vyjadřování v současné češtině, respektive v datech Českého národního korpusu (SYN2005) a Pražského závislostního korpusu (verze 2.0). Za členskou negaci byla dosud ve většině českých příruček považována taková negace, která neoperuje na predikátu. Autorka na základě analýzy dat a studia české i zahraniční odborné literatury týkající se syntaktické negace definuje nové vymezení členské negace v češtině, navrhuje formalismy pro zaznamenání struktur se členskou negací v systému konstrukční gramatiky a zkoumá možnosti zachycování tohoto jevu v PDT.

Klíčová slova: členská negace, adverzativní koordinace, konstrukční gramatika, funkční generativní popis, Pražský závislostní korpus","The thesis is focused on constituent negation and ways of its expressing in contemporary Czech, or more precisely in Czech National Corpus (SYN2005) and Prague Dependency Treebank (version 2.0). In most of the Czech linguistic handbooks, constituent negation was treated as such a negation that does not operate on predicate. The author offers a new definition of constituent negation in Czech, based on data research and study of relevant literature concerning syntactic negation. Further, the author proposes a formalization of the structure of constituent negation within the framework of construction grammar and she also explores the possibility to express the findings in PDT.

Keywords: constituent negation, adversative coordination, Construction Grammar, Functional Generative Description, Prague Dependency Treebank"
"Článek navrhuje přímý (forward) překladový model sestávající z množiny maximum entropy klasifikátorů: pro každé (dostatečně časté) zdrojové lemma je natrénován jeden klasifikátor. Tímto způsobem mohou být překladové pravděpodobnosti modelovány s ohledem na mnoho rysů (features) ze zdrojové věty, včetně nelokálních rysů využívajících syntaxe věty. Po zapojení do anglicko-českého překladového systému TectoMT bylo dosaženo signifikantního zlepšení oproti původnímu (baseline) překladovému modelu - měřeno metrikou BLEU.","Maximum Entropy Principle has been
used successfully in various NLP tasks. In
this paper we propose a forward translation
model consisting of a set of maximum
entropy classifiers: a separate classifier
is trained for each (sufficiently frequent)
source-side lemma. In this way
the estimates of translation probabilities
can be sensitive to a large number of features
derived from the source sentence (including
non-local features, features making
use of sentence syntactic structure,
etc.). When integrated into English-to-
Czech dependency-based translation scenario
implemented in the TectoMT framework,
the new translation model significantly
outperforms the baseline model
(MLE) in terms of BLEU. The performance
is further boosted in a configuration
inspired by Hidden Tree Markov Models
which combines the maximum entropy
translation model with the target-language
dependency tree model."
"V tomto příspěvku ukazujeme na příkladu lokativní sémantické diateze možnosti lexikografického popisu sémantických diatezí. Odlišujeme sémantické diateze od gramatických diatezí. Sémantické diateze charakterizují změny v korespondenci situačních participantů a valenčních doplnění, které vedou k takovým změnám ve valenční struktuře sloves, které se liší i v rámci jednoho typu diateze. Sémantické diateze navrhujeme zachycovat pomocí oddělených valenčních rámců propojených určitým typem sémantické diateze. Změny ve valenční struktuře spojené se sémantickými diatezemi jsou pak zachyceny pomocí lexikálních pravidel vycházejících z lexikálně sémantické reprezentace sloves založené na predikátové dekompozici (tzv. lexikálně-konceptuálních strukturách).","In this contribution, we demonstrate the description of semantic diatheses on the example of Czech locative semantic diathesis. We distinguish semantic diatheses from grammatical diatheses as two types of  changes in valency structure of verbs. Semantic diatheses are  characterized by the changes in mapping of situational participants and valency complementations. Changes in valency structure of verbs associated with semantic diatheses vary even within one type of diathesis so that they cannot be described by formal syntactic rules. For the purpose of the description of semantic diatheses, we propose to set separate valency frames corresponding to the members of semantic diatheses and to capture the relevant changes in valency structure by general lexical rules based on an appropriate formal representation of meaning of verb based on predicate decomposition (usually called lexical-conceptual structure)."
"V tomto příspěvku se zabýváme vybranými změnami ve valenční struktuře českých sloves z pohledu lexikografie. Nejprve vymezujeme dva typy slovesného významu, situační a strukturní význam, které společně tvoří komplexní významovou strukturu slovesa. Na základě tří typů asymetrie v korespondenci mezi komponentami situačního a strukturního významu vyčleňujeme tři typy změn ve valenční struktuře českých sloves a navrhujeme jejich zachycení ve valenčním slovníku VALLEX.","In this paper, we deal with some changes in valency structure of Czech verbs from a lexicographic point of view. As a first step,
two parts of verbal meaning are stipulated: situational and structural meaning. These two parts of meaning constitute complex meaning structure of verbs. On the basis of three types of asymmetry in the correspondence between
components of situational and structural meaning, we distinguish three typologically different
changes in valency structure of Czech verbs. We propose a method of their description in the valency lexicon of Czech verbs, VALLEX. We show that two of them can be described by lexical rules stored in the grammar component of the lexicon whereas the third one can be treated in a special attribute in the data component of the lexicon."
"V tomto článku se zabýváme diatezemi v češtině z hlediska lexikografa. Navrhujeme metodu jejich popisu ve slovníku českých sloves VALLEX. Rozlišujeme dva typy diatezí, gramatické a sémantické, jako dvě typologicky odlišné typy změn ve valenční struktuře sloves.","In the present paper, we deal with diatheses in Czech from a lexicographic point of view. We propose a method of their description in
the valency lexicon of Czech verbs VALLEX. We distinguish grammatical and semantic diatheses as two typologically different changes in verbal
valency structure. In case of grammatical diatheses, these changes are regular enough to be described by formal syntactic rules. In contrast, the changes in valency structure of verbs associated with semantic diatheses vary even within one type of diathesis. Thus for the latter type, we propose to set separate valency frames corresponding to their members and to capture the changes in verbal valency structure by lexical rules based on an adequate lexical-semantic representation of verb meaning."
"Jazyk jako jeden z nejsložitějších systémů fascinoval vědce různých oborů po desetiletí. Ať už popisujeme jazyk z pohledu klasické lingvistiky, psychologie, komputační lingvistiky, medicíny nebo neurolingvistiky, stále se objevují otázky jako ""Jak vlastně používáme a chápeme jazyk na úrovni našeho mozku?""

Nejzajímavější výsledky často vznikají ze spojeného úsilí několika vědeckých odvětví. V tomto článku ukážeme, jak statistika a informatika přispívají k zvládnutí zobrazení lidského mozku a jak tento pokrok zodpověděl některé z lingvistických otázek o lidském mozku.

Účelem tohoto článku není podat podrobný přehled o těchto výsledcích, ale spíše nabídnout srozumitelnou rešerši metod a technik na hranici neurověd a informatiky. Abychom tohoto cíle dosáhli, krátce se dotkneme základních a pokročilých metod zobrazování lidského mozku, od základní statistické analýzy a obecného lineárního modelu, přes bayesovské analýzy, až po rozpoznávání vzoru, a to z pohledu neurolingvistiky.","Human language as one of the most complex systems has fascinated scientists
from various fields for decades. Whether we consider language from a point of
view of a classical linguistics, psychology, computational linguistics,
medicine or neurolinguistics, it keeps bringing up questions such as ""How do we
actually comprehend language in our brain?""

The most interesting achievements often result from a joined effort of multiple
scientific fields. In this paper, we will explore how statistics and
informatics contributed to human brain neuroimaging and how this answered some
of the linguistic questions about human brain.

The purpose of this paper is not to survey these achievements in detail, but
rather to offer a comprehensive coverage of methods and techniques on the
border of neuroimaging and informatics. To achieve this, we will touch on some
of the basic and advanced methods for neuroimaging techniques, ranging from
fundamental statistical analysis with the General Linear Model, Bayesian
analysis methods to multivariate pattern classification, in the light of
neurolinguistic research."
Článek se zabývá vyhledávání informací v češtině za použití syntaktických jazykových modelů.,"In this paper, we deal with information retrieval approach based on language model paradigm, which has been intensively investigated in recent years. We propose, implement, and evaluate an enrichment of language model employing syntactic dependency information acquired automatically from both documents and queries. By testing our model on the Czech test collection from Cross Language Evaluation Forum 2007 Ad-Hoc track, we show positive contribution of using dependency syntax in this context.
I"
"Kronika: o pátém ročníku konference Corpus Linguistics, pořádané jednou za dva roky ve Velké Británii.","Chronicle: on the fifth Corpus Linguistic Conference, held every other year in Great Britain"
"Jedním z projektů, které PDT 2.0 obohatí o novou vrstvu lingvistického popisu, je projekt anotace mezivýpovědních textových vztahů. Cílem tohoto projektu je zachytit sémantickou výstavbu textu (ve světovém lingvistickém povědomí „discourse structure“), zejména pak sémantické vztahy mezi jednotlivými výpověďmi.",Short introduction of the discourse annotation project at the Institute of Formal and Applied Linguistics
"Článek se zabývá problematikou segmentace slov. Ukáže, k čemu lze znalosti o segmentaci slov použít, a popíše několik metod pro automatickou segmentaci slov. Závěrem představí open source nástroj Affisix implementující představené metody.",The article deals with automatic word segmentation. Several methods are presented which were implemented within the tool Affisix.
"Článek představuje nový pohled na valenci sloves, kdy se zkoumají vlastnosti sloves v rámci jejich skutečného užití. Termín ""plná valence""  značí, že jsou uvažována všechna doplnění bez rozlišení obligatornosti. Jelikož lze očekávt, že plná valence odráží určité mechanismy, které řídí chování sloves v jazyce, jsou v článku testovány tři hypotézy: distribuce plných valenčních rámců, vztah mezi počtem rámců a frekvencí výskytu slovesa a vztah mezi počtem valenčních rámců a délkou slovesa. K otestování těchto hypotéz je užit Pražský závislostní korpus.","The aim of the article is to introduce a new approach to verb valency analysis. This approach – full valency – observes properties of verbs which occur solely in actual language usage. The term ‘full valency’ means that all arguments, without distinguishing complements (obligatory arguments governed by the verb) and adjuncts (optional arguments directly dependent on the predicate verb), are taken into account. Because of an expectation that full valency reflects some mechanism which governs verb behaviour in a language, hypotheses concerning (1) the distribution of full valency frames, (2) the relationship between the number of valency frames and the frequency of the verb, and (3) the relationship between the number of valency frames and verb length were tested empirically. To test the hypotheses, a Czech syntactically annotated corpus – the Prague Dependency Treebank – was used."
článek se zabývá problémy implementace systému automatického překladu mezi indonézštinou a malajštinou pomocí systému Apertium,The article describes issues encountered in the first implementation of an MT system between Indonesian and Malaysian.
"Jednou z obtíží, kterým čelí systémy statistického strojového překladu (SMT), jsou rozdíly ve slovosledu. Při překladu z jazyka, jako je angličtina, s pevným slovosledem typu SVO, do jazyka, jehož upřednostňovaný slovosled se dramaticky liší (např. slovosled typu SOV v urdštině, hindštině, korejštině, ...) se systém musí naučit přeuspořádávat slova a fráze na velkou vzdálenost v rámci celé věty.","One of the difficulties statistical machine translation (SMT) systems face are differences in word order. When translating from a language with rather fixed SVO word order such as English, to a language where the preferred word order is dramatically different (such as the SOV order of Urdu, Hindi, Korean, ...), the system has to learn long-distance reordering of the words."
"Anglicko-urdský paralelní korpus slouží k trénování statistického strojového překladu mezi těmito dvěma jazyky. Skládá se ze čtyř částí: 1. Anglo-urdská část korpusu EMILLE; 2. texty z Wall Street Journalu (Penn Treebank); 3. překlady Koránu; 4. překlady Bible. Paralelní data, která existovala dříve (EMILLE) byla kompletně a nově ručně vyčištěna, opraveno zarovnání i řada vět na urdské straně.","English-Urdu Parallel Corpus serves training of statistical machine translation between these two languages. It consists of four parts: 1. English-Urdu part of the EMILLE corpus; 2. texts from the Wall Street Journal (Penn Treebank); 3. translations of the Quran; 4. translations of the Bible. Parallel data that existed before (EMILLE) have been completely and newly manually cleaned, corrected alignment and many sentences on the Urdu side."
"Výbor z díla Pavla Nováka (1932–2007) představuje vůbec první samostatné vydání vědeckých příspěvků českého jazykovědce – obecného lingvisty, bohemisty a albanisty, který spojil své odborné působení především s Filozofickou fakultou Univerzity Karlovy. Jeho podnětné myšlenky stále otevírají cesty k netriviálnímu uvažování o jazyce a jazykovědě, avšak dnes jsou čtenářům spíše neznámé, protože jsou rozesety po různých časopisech a sbornících nebo zůstaly ukryty v těžko dostupných výzkumných zprávách. Hlavním cílem knihy je tak umožnit současnému a budoucímu českému jazykovědnému publiku poznávat osobitý naturel lingvistického myšlení Pavla Nováka. Výbor je koncipován jako průřezový, editoři J. Křivan, J. Januška a J. Chromý do něj vybrali texty z různých tematických oblastí (metodologie lingvistiky, jazykový význam, pády, teorie syntaxe, dějiny novodobé české jazykovědy, popularizační články o jazyce aj.), s důrazem na ty příspěvky, které stále vynikají svojí aktuálností. Kniha je uvedena studiemi doc. Z. Starého, prof. J. Kořenského, prof. P. Sgalla a průvodním komentářem hlavního editora J. Křivana. Součástí výboru je rovněž Novákův životopis a nově sestavená bibliografie.","Selected works of Pavel Novák (1932-2007) is the first standalone publication of the scientific papers by Czech linguist, Bohemist and Albanist who bound his research to the Faculty of Arts of the Charles University in Prague. His stimulating thoughts keep leading us to non-trivial thinking about language and linguistics."
"V tomto článku popisujeme Exodus, společný pilotní projekt generálního ředitelství pro překlad Evropské komise a generálního ředitelství pro překlad Evropského parlamentu, který zkoumá možnosti využití nových směrů strojového překladu v evropských institucích. Zúčastnili jsme se letošní soutěže WMT10 v překladu z angličtiny do francouzštiny s použitím trénovacích dat získaných z překladových pamětí institucí.","In this paper, we describe Exodus, a joint
pilot project of the European Commission’s
Directorate-General for Translation (DGT)
and the European Parliament’s Directorate-
General for Translation (DG TRAD) which
explores the potential of deploying new ap-
proaches to machine translation in European
institutions. We have participated in the
English-to-French track of this year’s WMT10
shared translation task using a system trained
on data previously extracted from large in-
house translation memories."
Výzkum na základě probíhajícího projektu anotace rozšířené textové koreference a asociační anafory na PDT 2.0. V článku se rozebírají problematické případy a předkládá se typologie neshod mezi anotátory.,"The research is based on a developing project that aims to annotate nominal coreference and bridging anaphora in the syntactically annotated corpus of Czech texts, PDT 2.0. In the process of annotating coreferential and bridging relations it became evident that the relatively low inter-annotator agreement is, to a large extent, due to the fact that a text may have a variety of legitimate objective interpretations, rather than the annotators’ mistakes or carelessness. A classification of discrepancy types and possible causes of emergence thereof is presented. Typical examples of multiple interpretations of coreferencial and bridging relations in a text are given."
"Tento příspěvek zkoumá mapováné mezi dvěma sémantickými reprezentacemi, jmenovitě tektogramatickou rovinou Pražského závislostního korpusu (PDT) a (Robustní) Sémantikou minimální rekurze ((R)MRS). Jde o první pokus porovnat závislostní anotační schéma PDT a přístup založený na kompozicionální sémantice. Příspěvek představuje algoritmus pro konverzi PDT stromů do (R)MRS struktur.","This paper investigates the mapping between two semantic formalisms, namely the tectogrammatical layer of the Prague Dependency
Treebank 2.0 (PDT) and (Robust) Minimal Recursion Semantics ((R)MRS). It is a first attempt to relate the dependency-based annotation
scheme of PDT to a compositional semantics approach like (R)MRS. A mapping algorithm that converts PDT trees to (R)MRS structures
is developed, associating (R)MRSs to each node on the dependency tree. Furthermore, composition rules are formulated and the relation
between dependency in PDT and semantic heads in (R)MRS is analyzed. It turns out that structure and dependencies, morphological
categories and some coreferences can be preserved in the target structures. Moreover, valency and free modifications are distinguished
using the valency dictionary of PDT as an additional resource. The validation results show that systematically correct underspecified
target representations can be obtained by a rule-based mapping approach, which is an indicator that (R)MRS is indeed robust in relation
to the formal representation of Czech data. This finding is novel, as Czech, with its free word order and rich morphology, is typologically
different than languages analyzed with (R)MRS to date."
"Seznámení s úlohou strojového překladu, její atraktivitou i problémy. Představení dvou velmi odlišných přístupů k překladu a jejich empirické porovnání.",A brief introduction to the task of machine translation. Two rather different approaches to MT are described and empirically compared.
Prezentace výsledků dvouměsíční stáže zaměřené na kombinaci systémů strojového překladu do češtiny.,The results of two-month stay devoted to the combination of machine translation outputs when translating to Czech.
Přednáška pro frekventanty semináře Lucie Mladové.,An introduction to machine translation for the participants of seminar led by Lucie Mladová.
Přednáška podrobně představuje problémy strojového překladu specifické pro překlad z angličtiny do češtiny: otázky větného rozboru a bohaté morfologie na cílové straně.,The talk describes in detail the issues specific to English-to-Czech MT: sentence syntax and target-side rich morphology.
Rozhovor o přístupech ke strojovému překladu a jeho současných i budoucích možnostech.,An interview about approaches to machine translation and its current and coming potence.
CzEng 0.9 je třetí vydání velkého paralelního korpusu. V tomto vydání byl rozšířen o velké množství textů z různých typů zdrojů. Příspěvek popisuje a vyhodnocuje metody čištění paralelních dat a nabízí tak pohled na přínos jednotlivých typů zdrojů.,"CzEng 0.9 is the third release of a large parallel corpus of Czech and English. For the current release, CzEng was extended by significant
amount of texts from various types of sources, including parallel web pages, electronically available books and subtitles. This paper
describes and evaluates filtering techniques employed in the process in order to avoid misaligned or otherwise damaged parallel sentences
in the collection. We estimate the precision and recall of two sets of filters. The first set was used to process the data before their inclusion
into CzEng. The filters from the second set were newly created to improve the filtering process for future releases of CzEng. Given the
overall amount and variance of sources of the data, our experiments illustrate the utility of parallel data sources with respect to extractable
parallel segments. As a similar behaviour can be expected for other language pairs, our results can be interpreted as guidelines indicating
which sources should other researchers exploit first."
Část dat z korpusu CzEng 0.9 pro využití společností AppTek v jejích překladových systémech.,A part of CzEng 0.9 corpus data released for the company AppTek.
"Statistický strojový překlad do morfologicky bohatších jazyků je obtížná úloha, a to tím více, jestliže se zdrojový a cílový jazyk liší pořádkem slov. Nejlepší současné systémy proto neprodukují optimální výsledky. Mnohdy pomůže přidat paralelní data; pokud to nepomůže, může to být způsobeno různými problémy jako rozdílné domény, špatné párování slov nebo šum v nových datech. V tomto článku vyhodnocujeme úlohu strojového překladu z angličtiny do hindštiny z této datové perspektivy. Probíráme několik existujících zdrojů paralelních dat a poskytujeme výsledky křížových testů nad kombinacemi korpusů s použitím dvou volně dostupných statistických překladových systémů. Spolu s analýzou chyb také prezentujeme nový nástroj pro prohlížení spárovaných korpusů, díky čemuž je snadnější objevit problematické či obtížné pasáže v textech i pro vývojáře, který neovládá cílový jazyk překladu.","Statistical machine translation to morphologically richer languages is a challenging task and more so if the source and target languages differ in word order. Current
state-of-the-art MT systems thus deliver mediocre results. Adding more parallel data often helps improve the results; if it doesn't, it may be caused by various problems such as different domains, bad alignment or noise in the new data.
In this paper we evaluate the English-to-Hindi MT task from this data perspective. We discuss several available parallel data sources and provide cross-evaluation results on their combinations using two freely available
statistical MT systems. Together with the error analysis, we also present a new tool
for viewing aligned corpora, which makes it easier to detect difficult parts in the data even for a developer not speaking the target
language."
Korpus hindských textů z webu vhodný k jazykovému modelování: segmentovaný na věty a tokenizovaný.,A corpus of Hindi texts from the web suitable for language modelling: segmented into sentences and tokenized.
"Anglicko-hindský paralelní korpus sestavený z několika zdrojů, tokenizovaný a zarovnaný po větách.",English-Hindi parallel corpus collected from several sources. Tokenized and sentence-aligned.
Příspěvek popisuje naše pokusy s anglicko-českým překladem pro soutěž WMT10: dvoukrokový překlad a optimalizaci na SemPOS.,"The paper describes our experiments with
English-Czech machine translation for
WMT10 in 2010. Focusing primarily
on the translation to Czech, our additions
to the standard Moses phrase-based MT
pipeline include two-step translation to
overcome target-side data sparseness and
optimization towards SemPOS, a metric
better suited for evaluating Czech. Unfortunately,
none of the approaches bring a
significant improvement over our standard
setup."
"Ilustrujeme a vysvětlujeme problémy n-gramových metrik strojového překladu (např. BLEU), když jsou použity na jazyky s bohatou morfologií, jako je čeština. Nová metrika SemPOS problém omezuje a účinná je i angličtinu.","We illustrate and explain problems of
n-grams-based machine translation (MT)
metrics (e.g. BLEU) when applied to
morphologically rich languages such as
Czech. A novel metric SemPOS based
on the deep-syntactic representation of the
sentence tackles the issue and retains the
performance for translation to English as
well."
Česko-anglicko-ruský korpus UMC001 pro využití společností AppTek v jejích překladových systémech.,Czech-English-Russian corpus UMC001 released for the company AppTek.
"Senior Companion CZ kombinuje v jedné aplikaci poslední výsledky výzkumu v českém jazyce v oblasti: Automatické rozpoznávání řeči (ASR), Pochopení přirozeného jazyka (NLU), Generování přirozeného jazyka (NLG) a Text-to-Speech (TTS),
a magement dialogu (DM) pro přirozený dialog s člověkem. Některé součásti, speciálně vyvinuté v projektu Senior Companion CZ předčí nejlépší stávající výsledky, měřeno standardními kvantitativními metrikami používanými v této vědní oblasti (např. POS, morfologické taggery, atd.).","The Czech Companion demonstrates that recent advances in Czech language: Automatic Speech Recognition (ASR), Natural Language Understanding (NLU), Natural Language Generation (NLG) and Text to Speech (TTS) synthesis can be combined with existing dialogue management (DM) techniques to build a dialogue system for natural-sounding dialogue. Certain components specifically developed in the Companions project surpassed the best existing results, as measured by the standard quantitative metrics used in the field (e.g., Czech and English full POS and morphological taggers, etc.)."
"Ve stati se analyzují české konstrukce s infinitivem ve funkci subjektu (typy Je příjemné poslouchat hudbu a Vadilo mu jít na koncert) a konfrontují se s Karlíkovými kritérii pro zjištění, zda jde o konstrukce typu ""raising"" nebo ""control"" popř. o konstrukce monoklauzální nebo biklauzální.","P. Karlík's criteria for the distinction between raising and control constructions, and between monoclausal and biclausal constructions are tested on selecte Cyech examples where the infinitive fills the function of surface subject."
"Ve stati se analyzuje Danešovo pojetí Mathesiova učení o funkční onomatologii a funkční syntaxi. Na jednoduchém českém příkladu se ukazuje, jak jsou ve Funkčním generativním popisu aplikovány všechny tři principy rozvíjené Danešem (jazykové pojmenování, usouvztažnění pomocí kategoríí syntakticky závisle proměnných a nezávislých).",Daneš's approach to Mathesius' principles of functional onomatolgy and functional syntax is used for the description of the procedure of senetence generation in Functional generative description. All three principles used there are exemplified by the simple Czech sentence.
"Nutnost rozlišovat mezi ontologickým obsahem a jazykovým významem je zakotvena v evropské strukturní lingvistice. Příspěvek si neklade za cíl dospět k řešení této netriviální distinkce. Navzdory řadě problémů, které zmiňujeme, jsme ovšem přesvědčeni, že lingvistická analýza není bez zachování této distinkce možná.","The necessity to distinguish between ontological (cognitive, extralinguistic) content and linguistic (‚literal’) meaning has its sources in European structural linguistics. The present contribution cannot be aimed at the solution of these non-trivial distinctions; we only present some Czech examples as a challenge for consideration, which we believe to be useful for the determination of this boundary. Despite of these problems, we are convinced that without keeping the distinction between linguistic meaning and cognitive content during the analysis of language data the description of the language system is impossible."
"V plenárním referátu na zasedání Komise pro gramatickou stavbu slovanských jazyků  
a Syntaxi srbštiny byl přednesen příspěvek o povaze gramatických diatezí. Z nich byla soustředěna pozornost na diatezi rezulatativní a její vlastnosti morfologické a syntaktické.",On the plenary session within the Annual Meeting of the Committee of the Grammatical Structure of Slavonic Languages and the conference about Serbian Syntax the contribution analyzing the character of grammatical diathesis with the stress on resultative one was presented. Their morfological and syntactic features were discussed.
Stať v rubrice  Kronika připomíná životní jubileum doc. dr. Adely Rechziegelové a její zásluhy o českou bohemistiku doma a zejména za jejího dlouholetého působení v Holandsku.,"In the connection of the life anniversary of Dr. Adela Rechziegelová her achievements within Czech linguistcs at home and especially abroad (in Netherlands, where she has lived for a long time) are reminded."
"V článku se porovnávají české reciproční konstrukce s jednotlivými charakteristikami, které z hlediska typologie jazyků s různou strukturou podává V. P. Nedjalkov. Konstatuje se, že homonymie mezi reflexivitou a reciprocitou je češtině rovněž vlastní, preference se řídí jinými principy. Shledávají se rysy odlišné od polštiny, porovnává se užití recipročních adverbií v češtině s francouzštinou a bulharštinou. ""Lokální"" reciproka jsou v češtině okrajová.","The features of Czech reciprocals are compared with their typological markers given by Nedjalkov. There are similar ambiguities between reflexives and reciprocs in Czech as in other languages, however with the different preferences. The occurence of ""reciprocal"" adverbs in Czech is different from French and Bulagarian. So-called ""local"" reciprocals are marginaly in Czech."
"Významy morfologických kategorií jsou nepostradatelnou součástí popisu větného významu. V Pražském závislostním korpusu 2.0 (PDT 2.0) je význam věty zachycován jako závislostní struktura sestávající z ohodnocených uzlů a hran. Významy morfologických kategorií jsou zachycovány v atributech těchto uzlů, v tzv. gramatémech. V příspěvku představujeme revizi slovesných gramatémů, revidovaná sada gramatémů bude použita při anotaci nové verze Pražského závislostního korpusu, verze PDT 3.0.","Meanings of morphological categories are an indispensable component of representation of sentence semantics. In the Prague Dependency
Treebank 2.0, sentence semantics is represented as a dependency tree consisting of labeled nodes and edges. Meanings of
morphological categories are captured as attributes of tree nodes; these attributes are called grammatemes. The present paper focuses on
morphological meanings of verbs, i.e. on meanings of the morphological category of tense, mood, aspect etc. After several introductory
remarks, seven verbal grammatemes used in the PDT 2.0 annotation scenario are briefly introduced. After that, each of the grammatemes
is examined. Three verbal grammatemes of the original set were included in the new set without changes, one of the grammatemes was
extended, and three of them were substituted for three new ones. The revised grammateme set is to be included in the forthcoming version
of PDT (tentatively called PDT 3.0). Rules for automatic and manual assignment of the revised grammatemes are further discussed in
the paper."
"Připravovaný Pražský závislostní korpus 3.0 (PDT 3.0) se bude od stávající verze tohoto korpusu 
PDT 2.0 lišit jednak objemem anotovaných dat, jednak změnami v anotačním schématu. V přednášce představíme změny týkající se morfologických gramatémů. Morfologické gramatémy jsou atributy uzlů tektogramatického stromu, v těchto atributech jsou zachyceny významy sémanticky relevantních morfologických kategorií (např. kategorie substantivního čísla a slovesného způsobu). Podrobně popíšeme probíhající revizi slovesných gramatémů: zejména výsledky teoretického výzkumu slovesných diatezí a slovesného způsobu a promítnutí těchto výsledků do tektogramatické anotace. Naznačíme rovněž navrhované změny v zachycování kategorie čísla substantiv.","In the present talk the revision of so-called grammatemes is introduced. Grammatemes are attributes of nodes of tectorammatical trees, in these attributes the meaning of morphological categories, such as tense or number, are captured. The revised set of grammatemes will be incorporated in the new version of Prague Dependency Treebank PDT 3.0."
"Přednáška se zabývá elektronickýmmi jazykovými korpusy a jejich využitím, zejména pro lingvistickou práci. Zvláštní pozornost bude věnována Pražskému závislostnímu korpusu (PDT), představíme jeho strukturu, proces anotace a publikované verze (PDT 1.0, 2.0), zmíněny budou rovněž změny chystané pro další verzi tohoto korpusu PDT 3.0.","The talk deals with electronic language corpora and their usage, especially within linguistic research. Special attention is paid to Prague Dependency Treebank, its structure, annotation process and versions (PDT 1.0, 2.0), changes proposed for the new version (PDT 3.0) will be introduced."
"Předložená práce se skládá ze dvou částí. První část popisuje jeden z možných přístupů ke strojovému překladu, a sice překlad s využitím tektogramatické roviny jako roviny transferu. Druhá část je souborem vybraných článků autora z let 2000-2009.","The presented work is composed of two parts.
In the first part we discuss one of the possible
approaches to using the annotation scheme of the Prague Dependency Treebank for the task of Machine Translation (MT), and demonstrate it in detail within our highly modular transfer-based MT
system called TectoMT.

The second part of the work consists of a  sample
of our publications, representing our research work from 2000 to 2009. Each article is accompanied with short comments on its context from a present day perspective. The articles
are classified into four thematic groups: nnotating Prague Dependency Treebank,
Parsing and Transformations of Syntactic Trees, Verb Valency, and Machine Translation.

The two parts naturally connect at numerous points, since most of the topics tackled in the second part---be it sentence analysis or synthesis, coreference resolution, etc.---have their obvious places in the mosaic of the translation process and are now in some way implemented in the TectoMT system
described in the first part."
"Přednáška je věnována TectoMT, vysoce modulárnímu systému pro zpracovávání textů v přirozeném jazyce. Systém je implementován v Perlu. Primárně ja zaměřen na strojový překlad, využívá k tomu teoretický rámec a softwarové nástroje Pražského závislostního korpusu.","I will introduce TectoMT, which is a highly modular NLP (Natural Language Processing) software system implemented in Perl programming language under Linux. It is primarily aimed at Machine Translation, making use of the
ideas and technology created during the Prague Dependency Treebank project. At the same time, it is also hoped to significantly facilitate
and accelerate development of software solutions of many other NLP tasks, especially due to re-usability of the numerous integrated processing
modules (such as taggers, parsers, or named-entity recognizers), which are all equipped with uniform object-oriented interfaces."
"Pracuji jako výzkumný pracovník v Ústavu formální a aplikované lingvistiky (ÚFAL) Matematicko-fyzikální fakulty UK. Po absolvování Elektrotechnické fakulty ČVUT jsem tu v roce 2001 nastoupil na doktorské studium a dokončil jsem ho v roce 2005, nyní zde působím jako odborný asistent. Polovina mého úvazku je krytá projektem LC536 – Centrum komputační lingvistiky (2005–2010).","I work as a researcher in the Institute of Formal and Applied Linguistics, Charles University in Prague. After graduating at the Faculty of Electrical Engineering in 2001, I started my PhD study, which I have finished in 2005. Now I work here as an assistant professor."
"TectoMT je systém, který umožňuje rychlý a efektivní vývoj NLP aplikací. Využívá široké spektrum softwarových modulů, které jsou již integrovány do TectoMT, např. nástroje pro segmentaci textu na věty, tokenizaci, morfologickou analýzu a disambiguaci (tagging), parsing (povrchový i hloubkový), rozpoznávání pojmenovaných entit, rozpoznávání anafory, strojový překlad stromových struktur, generování vět z hloubkových struktur, slovní zarovnávání paralelních korpusů atd.","TectoMT is a multi-purpose open-source NLP framework. It allows for fast and efficient development of NLP applications by exploiting a wide range of software modules already integrated in TectoMT, such as tools for sentence segmentation, tokenization, morphological analysis, POS tagging, shallow and deep syntax parsing, named entity recognition, anaphora resolution, tree-to-tree translation, natural language generation, word-level alignment of parallel corpora, and other tasks."
"Strojový překlad z angličtiny do češtiny implementovaný v systému TectoMT sestává ze tří fází: analýzy, transferu a syntézy. Pro transfer se využívají tektogramatické stromy.","English to Czech machine translation as it is implemented in the TectoMT system consists of three phases: analysis, transfer and synthesis. The system uses tectogrammatical (deep-syntactic dependency) trees as the transfer medium."
"Článek obsahuje recenzi valenčního slovníku českých sloves autorů z Univerzity Karlovy v Praze, který před dvěma lety vydalo nakladatelství Karolinum.","The article reviews the valency dictionary of Czech verbs by authors from the Charles University in Prague, published two years ago by Karolinum."
"Výbor z díla doc. Pavla Nováka (1932–2007) představuje vůbec první samostatné vydání vědeckých příspěvků českého jazykovědce – obecného lingvisty, bohemisty a albanisty, který spojil své odborné působení především s Filozofickou fakultou Univerzity Karlovy. Jeho podnětné myšlenky stále otevírají cesty k netriviálnímu uvažování o jazyce a jazykovědě, avšak dnes jsou čtenářům spíše neznámé, protože jsou rozesety po různých časopisech a sbornících nebo zůstaly ukryty v těžko dostupných výzkumných zprávách. Hlavním cílem knihy je tak umožnit současnému a budoucímu českému jazykovědnému publiku poznávat osobitý naturel lingvistického myšlení Pavla Nováka. Výbor je koncipován jako průřezový, editoři J. Křivan, J. Januška a J. Chromý do něj vybrali texty z různých tematických oblastí (metodologie lingvistiky, jazykový význam, pády, teorie syntaxe, dějiny novodobé české jazykovědy, popularizační články o jazyce aj.), s důrazem na ty příspěvky, které stále vynikají svojí aktuálností. Kniha je uvedena studiemi doc. Z. Starého, prof. J. Kořenského, prof. P. Sgalla a průvodním komentářem hlavního editora J. Křivana. Součástí výboru je rovněž Novákův životopis a nově sestavená bibliografie.","Selected works of Pavel Novák (1932-2007) is the first standalone publication of the scientific papers by Czech linguist, Bohemist and Albanist who bound his research to the Faculty of Arts of the Charles University in Prague."
"Namísto diskuse mezi lingvisty samotnými, zvláště mezi odpůrci a zastánci pozůstatků jazykového purismu, mnozí odborníci na češtinu se stále raději obracejí k českým mluvčím a odrazují je od používání jazykových variant, které nebyly monopolní kodifikací uznány za „spisovné“.","Instead of a discussion between linguists themselves, especially between adversaries and supporters of the standing remnants and consequences of purism, many specialists in Czech prefer to turn to speakers of Czech, reproaching them for their continuing usage of language varieties that have not been acknowledged as “literary” by the monopolistic codification. A long continuation of discussions among linguists thus will be needed to overcome the post-purist dilemma concerning Standard Czech. Conditions for a transition from the present majority approach based on traditions concerning French and German to an approach closer to that proper to Anglo-Saxon linguistics are strengthened by the existence of large text corpora, with which it is possible to get better knowledge of the actual usage of morphemic and other forms. The intuition of speakers, underlying their linguistic behaviour, should be distinguished from intuition of linguists, which served as the starting point of description of Czech up to the middle of the 20th century and was then overcome by approaches based on research. Hypercorrection stems in the differences between actual usage and codification, and it is important to distinguish between hypercorrect expressions and those that came into existence as hypercorrect, but have already penetrated into the Standard norm, or into its large borderland."
"Předkládaná Mluvnice současné češtiny autorů působících na různých ústavech Univerzity Karlovy je po téměř patnácti letech novým pokusem o stručný a srozumitelný popis našeho mateřského jazyka. Mluvnice je koncipována jako dvoudílná, přičemž první díl zahrnuje poučení mj. o zvukové stránce jazyka, slovní zásobě, slovotvorbě, tvarosloví, stylistice a psací soustavě (druhý díl pak bude věnován větné skladbě).","The present Grammar of Current Czech by authors working at various institutes of the Charles University is the first attempt in almost fifteen years to concisely and comprehensibly describe our mother tongue. The grammar is split into two volumes and Volume 1 includes information on phonetics, vocabulary, morphology, stylistics and the writing system (Volume 2 will be devoted to sentence syntax)."
Autor přišel v dobách německé okupace o otce a o většinu svých příbuzných a strávil posledních šest měsíců války v koncentračním táboře v Postoloprtech.,"The author lost his father and most of his relatives in the time of the German occupation, and spent the last six months of that time in the concentration camp of Postoloprty."
"Sborník příspěvků. Z obsahu: Užívání jazyka jako kreativní proces. Pražská škola a empirický funkcionalismus: danešovské inspirace. Větná melodie v češtině v pohledu současného výzkumu. Fonetická a fonologická hlediska při zkoumání české intonace. Označování rodičů v českojazyčném prostředí. Český slovotvorný systém 21.století v databázích. Jazyk, jeho užívání a funkce při bohoslužbě. Komponentová analýza predikátu a hiearchizace propozice. Interpretace negativních zájmen v češtině. Rozvíjení tématu v akademickém a narativním textu. Perspektivy češtiny a spisovnost kolem nás i v nás. K řečové kultuře současnosti.","The usage of language as a creative process. The Prague School and the empirical functionalism: Danešian inspirations. Sentence melody in Czech from the point of view of the current research. Phonetic and phonological aspects of the Czech intonation. Marking of parents in the Czech language environment. The Czech morphological system of the 21st century in databases. Language, its usage and function for a church service. Component analysis of predicate and hierarchization of proposition. Interpretation of negative pronouns in Czech. Topic development in academic and narrative text. The future of Czech and the language standard around us and in us. On the contemporary speech culture."
"Rematizátory jsou zvláštní třídou částic, které mají svou specifickou roli v informační struktuře věty. Nejsou však nutné indikátory jejiho rématu či ohniska.","Rhematizers belong to a specific class of particles that have a special function in the information structure of the sentence, but it is argued that in spite of the name of this class, they are not necessarily indicators of the focus."
"Autorka upozorňuje na tři otevřené problémy, především z hlediska minimalistické teorie, a to popis sémantické relevance aktuálního členění, rozdíl mezi významem","Three open questions are formulated .concerning (i) the minimalist account of the semantic relevance of the topic-focus articulation, (ii) the minimalist account of the distinction between meaning and content, and (iii) how to represent  in corpus annotation syntactic ambiguities."
"V kapitole se zabýváme anotací treebanků - jejich definicí, vlastnostmi, příklady existujících treebanků, jejich vztahem k lingvistické teorii a procesem anotace a kontroly kvality. Věnujeme se také použití treebanků, zvláště pojednáváme o vyhledávání lingvistické informace v treebancích.","In the chapter, we focus on treebank annotation – the definition of treebanks, their properties, examples of existing treebanks, their relation to linguistic theory and the process of annotation and quality control. We also refer the application of treebanks, and specifically discuss searching for linguistic information in them."
Tato práce se zabývá anotací víceslovných výrazů v Pražském závislostním korpusu 2.0. Popisuje datovou reprezentaci vyvinutou pro anotaci i anotační nástroj a další software vyvinutý pro anotaci i vizualizaci a prohledávání anotovaných dat. Práce také popisuje anotační slovník obsahující víceslovné výrazy nalezené v datech a zabývá se i analýzou anotací z hlediska kvality a efektivity.,"This thesis explores annotation of multiword expressions in the Prague Dependency Treebank 2.0. We explain, what we understand as multiword expressions (MWEs), review the state of PDT 2.0 with respect to MWEs and present our annotation. We describe the data format developed for the annotation, the annotation tool, and other software developed to allow for visualisation and searching of the data. We also present the annotation lexicon SemLex and analysis of the annotation."
"Článek zkoumá datový formát CoNLL ST, jeho vlastnosti a možnosti jeho použití pro komplexní anotace. Tvrdíme, že CoNLL ST se možná navzdory původnímu záměru stal jedním z nejdůležitějších formátů syntakticky anotovaných dat současnosti. Ukazujeme meze tohoto formátu v jeho současné podobě a navrhujeme několik jednoduchých rozšíření, která je posunují dále a činí ho robustnějším a použitelnějším v budoucnosti. Analyzujeme několik lingvistických anotací různé složitosti jako příklady a ukazujeme, jak mohou být účinně reprezentovány ve formátu CoNLL ST.","In this paper, we investigate the CoNLL Shared Task format, its properties and possibility of its use for complex annotations. We argue that, perhaps despite the original intent, it is one of the most important current formats for syntactically annotated data. 
We show the limits of the CoNLL-ST data format in its current form and propose several simple enhancements that push those limits further and make the format more robust and future proof. We analyse several different linguistic 
annotations as examples of varying complexity and show how they can be efficiently stored in the CoNLL-ST format."
"Tato práce je věnovaná empirické studii lexikálních asociačních měr a jejich aplikaci v úloze automatické extrakce kolokací. Experimenty byly provedeny na třech referenčních datových množinách: závislostních bigramech z ručně anotovaného Pražského závislostního korpusu, povrchové bigramy ze stejného korpusu a instancích prvků předchozí množiny z Českého národního korpusu opatřeného automatickou lemmatizací a morfologickým značkováním. Kolokační kandidáti v referenčních  množinách byli manuálně anotováni jako kolokace nebo nekolokace. Použité evaluační schéma je založeno na měření kvality seřazení kolokačních kandidátů dle jejich pravděpodobnosti tvořit kolokaci. Metody jsou porovnány pomocí precision-recall křivek a hodnot mean average precision, které jsou převzaty  z oboru vyhle­dávání informací. Provedeny byly i testy signifikance výsledků. Dále je zkoumána možnost kombi­nování lexikálních asociačních měr a presentovány výsledky několika kombinačních metod, jejichž použití vedlo k výraznému zlepšení úspěšnosti řešení této úlohy. Dále je v práci navržen algoritmus významně redukující složitost použitých kombinačních modelů.","We present an extensive empirical evaluation of collocation extraction methods based on lexical association measures and their combination. The experiments are performed on three sets of collocation candidates extracted from the Prague Dependency Treebank with manual morphosyntactic annotation and from the Czech National Corpus with automatically assigned lemmas and part-of-speech tags. The collocation candidates were manually labeled as collocational or non-collocational. The evaluation is based on measuring the quality of ranking the candidates according to their chance to form collocations. Performance of the methods is compared by precision-recall curves and mean average precision scores. The work is focused on two-word (bigram) collocations only. We experiment with bigrams extracted from sentence dependency structure as well as from surface word order. Further, we study the effect of corpus size on the performance of the individual methods and their combination."
"Valence je důležitou součástí PZK. Je zachycena ve slovníku, jenž obsahuje všechna slovesa, která se v korpusu vyskytla. Valenční rámec je popsán z formálního hlediska, obsahuje obligatorní volná doplnění a obligatorní a fakultativní argumenty.","The Prague Dependency Treebank (PDT) contains as its integral part a valency lexicon called PDT-Vallex. PDT-Vallex lists all the verbs that occur in the PDT and it also distinguishes their senses. A valency frame is formally described for each sense. This valency frame includes a list of verb complementations and their required surface form(s), for obligatory as well as optional arguments."
"Tato práce je souborem detailních studií věnovaných syntakticky nebo sémanticky uceleným skupinám českých deverbativních substantiv (zejména substantiv s dativní valencí). Opírá se o bohatý korpusový materiál. Problematiku valence deverbativních substantiv představuje jako pružný mechanismus, který na jedné straně funguje na základě v systému pevně zakotvených a jasně stanovených primárních obecných principů, na druhé straně je ovšak ovlivněn několika různorodými principy sekundárními, umožňujícími rozličné nové, od slovesa nezděděné formy valenčních doplnění. Jako teoretický rámec pro popis valenčních vlastností zkoumaných substantiv byl zvolen funkční generativní popis.","The monograph deals with valency properties of deverbal nouns in Czech. After an overview of Czech and foreign approaches to the valency of nouns and a summary of current knowledge concerning some special issues of valency of Czech deverbal nouns, we present results consisting of our analysis of syntactically and semantically compact groups of deverbal nouns as well as theoretical conclusions following from the examined language material. We have focused our attention on Czech deverbal nouns that can be modified by a participant expressed by prepositionless dative. Such nouns were searched for in two Czech electronic corpora, Czech National Corpus (CNC) and Prague Dependency Treebank (PDT). The obtained occurrences were manually sorted and analysed and their valency behaviour is described within the theoretical framework of the Functional Generative Description (FGD)."
Softwarový nástroj zprostředkující formou webového rozhraní editaci a vyhledávání v přepisech audio-visuálních nahrávek dialogů. Vyhledané úseky textu je možné přehrávat a analyzovat pomocí webového prohlížeče.,A software tool allowing editing and searching in the transcripts of audio-visual recordings of dialogues. The dynamic web application provides access for registered users to the digitised archive. Playing and exploring of selected parts is possible in the web browser.
"Představujeme nástroj pro anotaci sémantických mezivětných vztahů na tektogramatické rovině Pražského závislostního korpusu (PDT). Uvádíme vlastnosti nástroje, které pomáhají anotátorům, jako jsou možnost kombinace anotace na větách a na reprezentaci hloubkové syntaxe, možnost definovat, zobrazit a spojovat libovolné skupiny uzlů, dále kompaktní zobrazení stromů po klauzích apod. Pro studium rozdílů v paralelních anotací nástroj poskytuje současné zobrazení paralelních anotací jedněch dat více anotátory.","We present a tool for annotation of semantic inter-sentential discourse relations on the tectogrammatical layer of the Prague Dependency Treebank (PDT). We present the way of helping the annotators by several useful features implemented in the annotation tool, such as a possibility to combine surface and deep syntactic representation of sentences during the annotation, a possibility to define, display and connect arbitrary groups of nodes, a clause-based compact depiction of trees, etc. For studying differences among parallel annotations, the tool offers a simultaneous depiction of parallel annotations of the data."
Uvádíme několik způsobů měření mezianotátorské shody v probíhající anotaci sémantických mezivětných diskurzních vztahů v Pražském závislostním korpusu (PDT). Jsou použity dva způsoby pro překonání nevýhod měření shody na přesné pozici počátečních a koncových bodů vztahů. Obě metody - přeskočení jedné úrovně stromu v počátečním či koncovém uzlu a míra založená na konektorech - jsou zaměřený spíše na rozpoznání existence vztahu a jeho typu než na přesnou pozici počátečních a koncových bodů spojujících šipek.,"We present several ways of measuring the inter-annotator agreement in the ongoing annotation of semantic inter-sentential discourse relations in the Prague Dependency Treebank (PDT). Two ways have been employed to overcome limitations of measuring the agreement on the exact location of the start/end points of the relations. Both methods – skipping one tree level in the start/end nodes, and the connective-based measure – are focused on a recognition of the existence and of the type of the relations, rather than on fixing the exact positions of the start/end points of the connecting arrows."
"Představujeme anotační nástroj pro rozšířenou textovou koreferenci a bridging anaforu v Pražském závislostním korpusu 2.0. Popisujeme způsob pomoci anotátorům pomocí několika praktických vlastností implementovaných v anotačním nástroji, jako jsou možnost kombinovat povrchovou a hloubkovou syntaktickou reprezentaci vět během anotace, automatické zachovávání koreferenčního řetězce, podtrhávání kandidátů pro antecedent apod.. Pro studium rozdílů v paralelních anotacích nabízí nástroj současné zobrazení několika anotací jedněch dat.","We present an annotation tool for the extended textual coreference and the bridging anaphora in the Prague Dependency Treebank 2.0. We describe the way of helping the annotators by several useful features implemented in the annotation tool, such as a possibility to combine surface and deep syntactic representation of sentences during the annotation, an automatic maintaining of the coreferential chain, underlining candidates for antecedents, etc. For studying differences among parallel annotations, the tool offers a simultaneous depiction of several annotations of the same data."
Slova v nadpisu této kapitoly jako by k sobě překvapivě dobře pasovala. Nejen že závislost a funkce jsou ústřední pojmy mnoha moderních lingvistických teorií a že jsou ‚inherentní‘ v informatice a logice. Neméně zajímavý je i jejich vztah ke studiu arabského jazyka a jeho významu.,"The words in the title of this chapter seem to like each other to a surprising extent. Not only are the notions of dependency and function central to many modern linguistic theories and ‘inherent’ to computer science and logic. Their connection to the study of the Arabic language and its meaning is interesting, too."
"ElixirFM je vysokoúrovňová implementace Funkční arabské morfologie zdokumentovaná na http://elixir-fm.wiki.sourceforge.net/. Jádro ElixirFM je napsáno v Haskellu, zatímco rozhraní v Perlu podporuje údržbu slovníku a další interakce.
- rozšířený a zdokonalený slovník
- zdokonalená analýza sekvencí slov
- zdokonalené uživatelské rozhraní
- zdokonalené API","ElixirFM is a high-level implementation of Functional Arabic Morphology documented at http://elixir-fm.wiki.sourceforge.net/. The core of ElixirFM is written in Haskell, while interfaces in Perl support lexicon editing and other interactions.
- extended and improved lexicon
- improved analysis of word sequences
- improved user interface
- improved API"
"Addicter je zkratka za Automatic Detection and DIsplay of Common Translation ERrors. Je to soubor nástrojů (především skriptů napsaných v Perlu), které pomáhají s analýzou chyb strojového překladu.",Addicter stands for Automatic Detection and DIsplay of Common Translation ERrors. It is a set of tools (mostly scripts written in Perl) that help with error analysis for machine translation.
"Morfologické značky jsou důležitým prostředkem anotace ve velkém množství korpusů. V různých korpusech, dokonce i pro tentýž jazyk, se však používají různé sady značek. Konverze sad značek je obtížná a řešení bývají ušitá na míru konkrétní dvojici sad. V článku probíráme Interset, univerzální metodu, díky které se dají převodní nástroje používat opakovaně. Zatímco některé mluvnické kategorie jsou jasně definované a dají se snadno přenášet z jedné sady do druhé, existují také jevy, které je těžké zachytit kvůli překrývajícím se konceptům. Zaměřujeme se na některé takové problémy, probíráme jejich výskyt ve vybraných sadách značek a navrhujeme řešení, která sjednotí přístupy jednotlivých sad.","Part-of-speech or morphological tags are important means of annotation in a vast number of corpora. However, different sets of tags are used in different corpora, even for the same language. Tagset conversion is difficult, and solutions tend to be tailored to a particular pair of tagsets. We discuss Interset, a universal approach that makes the conversion tools reusable. While some morphosyntactic categories are clearly defined and easily ported from one tagset to another, there are also phenomena that are difficult to deal with because of overlapping concepts. In the present paper we focus on some of such problems, discuss their coverage in selected tagsets and propose solutions to unify the respective tagsets' approaches."
"Popisujeme naše pokusy s hierarchickým frázovým strojovým překladem v soutěži WMT 2010. Poskytujeme podrobný popis našich dat a konfigurace, aby bylo možné naše výsledky zopakovat. U překladu z angličtiny do češtiny jsme experimentovali s několika různě velkými soubory dat a s různými způsoby předzpracování. U zbývajících 7 směrů překladu předkládáme pouze výchozí výsledky.","We describe our experiments with hierarchical
phrase-based machine translation
for WMT 2010 Shared Task. We provide
a detailed description of our configuration
and data so the results are replicable. For
English-to-Czech translation, we experiment
with several datasets of various sizes
and with various preprocessing sequences.
For the other 7 translation directions, we
just present the baseline results."
"MD-make (multidimenzionální make) je nástroj, který umožňuje zpracování datových souborů v mnoha rozměrech jako jazyky, domény, způsoby předzpracování, alternativní zpracovatelské programy, vývojová/vyhodnocovací data atd.","MD-make (multidimensional make) is a tool that enables processing of data files in many dimensions such as languages, domains, preprocessing styles, alternative processing programs, development/evaluation data etc."
"V roce 2040, musí být ACL sborníku stroje přeloženy do 20 jazyků z původního čínského. (Kevin Knight)","By 2040, the ACL conference proceedings shall be machine translated into 20 languages from the original Chinese. (Kevin Knight)"
"Tagzplorer je nástroj pro průzkum anotovaných korpusů, sumarizaci morfologických značek, dohledávání příkladů výskytů a jejich snadnou vizualizaci pomocí hypertextu.","Tagzplorer is a tool for exploring annotated corpora, summarization of POS and morphological tagsets, finding example occurrences and their easy visualization using hypertext."
"Metoda a software pro romanizaci (tj. transliteraci do písma založeného na latince) urdského textu. Cílem je odrážet pokud možno původní výslovnost, aniž by byla porušena obnovitelnost původního pravopisu.","Approach and software for Romanization (i.e. transliteration into a Latin-based alphabet) of Urdu text. My goal is to reflect the original pronunciation as well as possible, while not violating the requirement that the original spelling be restorable. To help the reader with the pronunciation, I want to insert missing short vowels and disambiguate a few other cases. I provide a Perl script that implements the deterministic part of the transliteration and marks positions where human decision is needed. Urdu uses a few characters that are not used in the original Arabic script. Moreover, some of the original Arabic letters might prefer a different Latin representation if the mapping were motivated by Arabic, instead of Urdu pronunciation. On the target side, no particular language was on my mind when modeling the pronunciation. See below for details."
"Představujeme systematické srovnání předzpracovávacích metod pro dva jazykové páry: angličtina-čeština a angličtina-hindština. Přestože oba cílové jazyky patří do indoevropské jazykové rodiny, vykazují významné odlišnosti v tvarosloví, skladbě a slovosledu. Popisujeme TectoMT, úspěšné prostředí pro analýzu a syntézu jazyka, a ukazujeme, jak ho lze využít pro předzpracování dat pro frázový systém strojového překladu.","We present a systematic comparison of preprocessing techniques
for two language pairs: English-Czech and English-Hindi. The two target languages, although both
belonging to the Indo-European language family, show significant differences in morphology, syntax and word order. We describe how TectoMT, a successful framework for analysis and generation of language, can be used as preprocessor for a phrase-based MT system.
We compare the two language pairs
and the optimal sets of source-language transformations applied to them. The following transformations are examples of possible preprocessing steps: lemmatization; retokenization, compound splitting; removing/adding words lacking counterparts in the other language; phrase reordering to resemble the target word order; marking syntactic functions. TectoMT, as well as all other tools and data sets we use, are freely available on the Web."
"Hráči je předložen text s odstraněnými mezerami mezi slovy. Jeho úkolem je mezery na správná místa vložit. Cílem hry je nejen nalákat hráče k závažnějším jazykovým hrám, ale pro jazyky jako je např. thajština i získat trénovací data.","The player fills in spaces between words in text, from which they have been previously removed. The aim of the game is not only to attract the players to more serious language games but for languages like Thai to obtain training data."
"Hráči hádají slova ve větách na základě předchozího kontextu. Cílem hry je nejen nalákat hráče k závažnějším jazykovým hrám, ale rovněž studovat entropii jazyka z pohledu rodilého mluvčího.",The players guess words in sentences on the basis of the previous context. The aim of the game is not only to attract the players to more serious language games but also to study entropy of the language from the native speaker's point of view.
PlayCoref je internetová hra pro dva hráče s cílem zábavnou metodou obohatit holý text anotací koreference.,"PlayCoref is an internet game for two players whose aim is to enrich pure text with the annotation of coreference, using an entertaining method."
"Představujeme hru PlayCoref, internetovou hru s cílem obohatit textová data anotací koreference. Uvádíme detailní popis hry, obzvláště její průběh a implementaci, a zmiňujeme se o procesu zpracování vstupních dat a o vyhodnocovací funkci.","We present the PlayCoref game, an on-line
internet game, whose purpose is to enrich
text data with coreference annotation. We
provide a detailed description of the game,
especially of its course and its implementation,
and we mention the processing of
the data and the scoring function."
"Článek představuje několik způsobů měření a evaluace anotace a anotátorů, které byly navrženy a používány při anotaci české části Pražského česko-anglického závislostního korpusu: měření mezianotátorské shody, chybovosti a výkonu anotátorů. Měření shody je komplikováno faktem, že při anotaci bylo možné přidávat i mazat uzly, takže není snadné zjistit, které uzly si odpovídají. Míra chybovosti je zjišťována pomocí sady kontrolních procedur, které sledují platnost daných invariantů v datech. Výkon anotátorů je zaznamenáván pomocí ""účetní"" webové aplikace. Všechny tři metody jsou poté porovnány a uvedeny do souvislostí.","The paper presents several ways to measure and evaluate the annotation and annotators, proposed and used during the building of the Czech part of the Prague Czech-English Dependency Treebank. At first, the basic principles of the treebank annotation project are introduced (division to three layers: morphological, analytical and tectogrammatical). The main part of the paper describes in detail one of the important phases of the annotation process: three ways of evaluation of the annotators - inter-annotator agreement, error rate and performance. The measuring of the inter-annotator agreement is complicated by the fact that the data contain added and deleted nodes, making the alignment between annotations non-trivial. The error rate is measured by a set of automatic checking procedures that guard the validity of some invariants in the data. The performance of the annotators is measured by a booking web application. All three measures are later compared and related to each other."
"Zpracování přirozeného jazyka je poměrně nový, rychle se rozvíjející obor, který nachází široké uplatnění v mnoha aplikacích. Jedním ze základních problémů zpracování jazyka je zachycení a popis významu. V této přednášce se budu věnovat zachycení významu, které vychází ze závislostní / valenční syntaxe. Krátce představím Funkční generativní popis, na jehož základě se vytvářejí soubory syntakticky a významově anotovaných dat (Pražský závislostní korpus) využívané pro takové úkoly jako je automatická syntaktická analýza či strojový překlad. Dále se budu věnovat problematice lexikálního významu a jeho popisu pomocí valenční charakteristiky (zejména) sloves.","Natural language processing is a relatively new field, which has a strong impact on many applications. One of the fundamental problems of language processing is a description of meaning. In this talk I examine the importance of meaning description based on the dependency / valence syntax. First, I briefly introduce the Functional Generative Description and its application in a large syntactically annotated corpus, Prague Dependency Treebank. This corpus is used for many applied tasks such as parsing and machine translation. Second, I address the issue of lexical meaning and its description the valency lexicon VALLEX."
"Valencí se rozumí schopnost slovesa (příp. slova jiného slovního druhu) vázat na sebe určitý počet jiných, syntakticky závislých jazykových jednotek. Valenční informace se tedy vztahuje k jednotlivým lexémům, a jako takovou je nutno popsat ji pro jednotlivé lexémy ve formě slovníku. Bez valenčních slovníků se neobejdou komplexní aplikace pro zpracování přirozeného jazyka, které jsou založeny na explicitním popisu jazykových jevů; zároveň jsou takové slovníky nepostradatelné při vytváření jazykových dat, na nichž jsou založeny nástroje využívající strojového učení.

V předkládané habilatační práci shrnujeme výsledky dosažené při vytváření lexikální databáze českých sloves. Práce se soustřeďuje na tři základní okruhy. Prvním okruhem je formální zachycení valenčních vlastností českých sloves ve valenčním slovníku. Je zde představena logická stavba bohatě strukturovaných slovníkových dat. Druhým okruhem, kterému se práce věnuje, jsou nové teoretické aspekty, které přináší zpracování rozsáhlého jazykového materiálu -- je to především koncept kvazivalenčních doplnění a adekvátní zpracování slovesných alternací. Třetí okruh předkládané práce tvoří problematika formálního modelování přirozeného jazyka. Je zde představen nový formální model závislostní syntaxe založený na originálním konceptu restartovacích automatů. 

Hlavním aplikovaným výstupem předkládané práce je Valenční slovník českých sloves VALLEX, rozsáhlý a kvalitní veřejně dostupný slovník, který obsahuje významové a valenční charakteristiky nejčastějších českých sloves. Při navrhování jeho
koncepce byl kladen důraz na možnost všestranného využití pro člověka jako uživatele jazyka i pro aplikační účely při automatickém zpracování češtiny.","Valency refers to the capacity of verb (or a word belonging to another part of speech) to take a specific number and type of syntactically  dependent language units. Valency information is thus related to particular lexemes and as such it is necessary to describe valency characteristics for separate lexemes in the form of lexicon entries. A valency lexicon is indispensable for any complex Natural Language Processing application based on the explicit description of language phenomena. At the same time such lexicons
are necessary for building language resources which provide the basis for tools using machine learning techniques. 

The present habilitation work consists of a collection of already published scientific papers. It summarizes the results of building a lexical database of Czech verbs. It concentrates on three essential topics. The first of them is the formal representation of valency properties of Czech verbs in the valency lexicon. The logical organization of richly structured lexicon data is presented here. The second topic concerns new theoretical issues that result from the extensive processing of language material, namely the concept of quasi-valency complementation and adequate processing of verb alternations.
The third topic addresses questions of formal modeling of a natural language. A new formal model of dependency syntax based on a novel concept of restarting automata is introduced here.

The main applied product of the work presented here is the publicly available Valency Lexicon of Czech Verbs VALLEX, a large-scale, high-quality lexicon which contains semantic and valency characteristics for the most frequent Czech verbs. VALLEX has been designed with emphasis on both human and machine-readability. Therefore,
both linguists and developers of applications within the Natural Language Processing domain can use it."
"V článku postupně vysvětlujeme pojem zlomového bodu introspekce (ZBI), pojem statistického zlomového bodu introspekce (SZBI) a způsob, jak a proč
jsme k těmto pojmům dospěli.","In this article, we deal with the turning point of introspection (ZBI) and with the statistical turning point of introspection."
"V tomto článku se zavádí formální model pro závislostní a stratifikační popis přirozeného jazyka, který je motivován metodou postupné redukční analýzy. Model využívá konceptu obohacených restartovacích automatů, které zpracovávané větě přiřazují paralelní DR-struktury popisující vztah mezi jednotkami různých rovin popisu jazyka.","We provide a formal model of a stratificational
dependency approach to natural language description. This formal model is motivated by an elementary method of analysis by reduction, which serves for describing correct sentence analysis. The model is based on enhanced restarting
automata that assign a set of parallel dependency structures to every reduction of an input sentence. These structures capture the correspondence of dependency trees on
different layers of linguistic description, namely layer of surface syntax and layer of language meaning."
"Přednáška se soustřeďuje na následující body:
(i) lingvistické zázemí FGD,
(ii) formální nástroje pro FGD a jejich adekvátnost,
(iii) porovnání FGD a přístupu `Abhangigkeitsgrammatik' (Jurgen Kunze), a
(iv) současné úkoly ve formálním modelování přirozeného jazyka.","The talk at the TheorieTag focuses on the following issues: 
(i) A linguistic background of FGD,
(ii) Formal tools connected with FGD and their adequacy,
(iii) A comparison between FGD and the    `Abhangigkeitsgrammatik' (developed by the group around Jurgen Kunze), and
(iv) Current tasks in formal models of natural languages."
"V tomto článku představujeme formální model pro stratifikační závislostní popis přirozeného jazyka. Tento model je motivován elementární metodou redukční analýzy, která umožňuje zachytit závislostní strukturu věty. Model je založen na obohacených restartovacích automatech, které dané větě (na základě možných redukcí) přiřazují množinu paralelnách závislostních struktur. Tyto struktury zachycují korespondenci mezi závislostními stromy pro různé roviny syntaxe, jmenovitě povrchové a hloubkové syntaxe.","We provide a formal model of a stratificational dependency approach to natural language description. This formal model is motivated by an elementary method of analysis by reduction,
which serves for describing correct sentence analysis. The model is based on enhanced restarting automata that assign a set of parallel dependency structures to every reduction of an input sentence. These structures capture the correspondence of dependency trees on different layers of linguistic description, namely the layer of surface syntax and the layer of language meaning.
The novelty of this contribution consists in the formal extension of restarting automata in
order to produce tree structures with several interlinked layers and in the application of these
automata to the stratificational description of a natural language."
"Restartovací automaty byly navrženy jako vhodný model pro redukční analýzu. V tomto příspěvku obohacujeme restartovací automaty o strukturovaný výstup v podobě závislostního stromu. Obohacené restartovací automaty slouží jako model Funkčního generativního popisu, který lze charakterizovat jako stratifikační závislostní popis přirozeného jazyka.","Restarting automata were introduced for modeling linguistically motivated analysis by reduction. In this paper we enhance these automata with a structured output in the form of a tree. Enhanced
restarting automata can serve as a formal framework for the Functional Generative Description. In this framework, a natural language is described at four layers. Working simultaneously with all these layers, tectogrammatical dependency structures that represent the meaning of the sentence are derived."
"Verse Českého Wordnetu použitá pro lexikálně-semanticé anotace PDT s úpravami UFALu: http://hdl.­handle.­net/11858/00-097C-0000-0001-4880-3

Tato verze WordNetu obsahuje 23094 synsetů, z toho 203 synsety vznikly v ÚFALu a 22891 synsetů pochází z výchozí verze WordNetu vytvořené v Centru ZPJ FI MU.","A version of Czech WordNet that was used for lexico-semantic annotation of PDT: http://hdl.­handle.­net/11858/00-097C-0000-0001-4880-3 

The Czech WordNet was developed by the Centre of Natural Language Processing at the Faculty of Informatics, Masaryk University, Czech Republic. 
 
 The Czech WordNet captures nouns, verbs, adjectives, and partly adverbs, and contains 23,094 word senses (synsets). 203 of these were created or modified by UFAL during correction of the annotation."
"V kulturně, avšak nikoli strukturně si navzájem blízkých jazycích (pár čeština-švédština) existuje strukturní i sémantické kontinuum mezi vyjádřením účinku a vyjádřením účelu. Paralelní korpus umožňuje detailní pozorování těchto přechodů v překladech. 
Česká vedlejší věta účelová je typicky uvozena podřadicí spojkou aby, zatímco věta účinková je typicky uvozena podřadicí spojkou že. Vztah účelový vyjadřuje žádoucnost, zamýšlenost děje popsaného vedlejší větou: Odešli, aby mě nerušili. Už jsem raději mlčela, aby se nerozzlobil ještě víc. Vztah účinkový vyjadřuje „následek děje nebo vlastnosti, a to větou uvozenou spojkami že (tak že, tolik že, takový že…), až, takže (div že, taktak že): Tvářil se tak, že jsem raději mlčel. (Karlík et al., 1995, s. 353).  Za strukturní i významový přechod mezi oběma typy lze považovat určení zřetelově srovnávací – speciální případ, kdy se porovnává míra děje, stavu nebo vlastnosti s očekávaným následkem (Karlík et al., 1995, s. 465 a cf. s. 457-459). S výjimkou případů, kdy je nedostatečnost/přílišnost příznaku popsaného větou řídící vyjádřena příslovcem příliš (a synonymy), které dovoluje výhradně použití spojky aby, může mluvčí volit mezi aby a tak, přičemž aby (podle Karlík et al., 1995) implikuje, že účinek je žádoucí nebo očekávaný: Petr nebyl tak zkušený, že by to pochopil. Petr nebyl tak zkušený, aby to pochopil. 
Ve švédštině jsou účinkové věty uvozeny podřadicí spojkou så att („tak že“) a účelové věty jsou uvozeny spojkou för att („pro že“). Zřetelově srovnávací vztah se také vyjadřuje pomocí spojky för att. Definice účinkové, resp. účelové věty staví do popředí fakticitu děje popsaného vedlejší větou, resp. jeho záměrnost. Účinkové věty charakterizují faktické děje bez ohledu na to, zda jsou žádané nebo zamýšlené dějem popsaným řídící větou, zatímco účelové věty charakterizují žádané nebo zamýšlené děje bez ohledu na jejich fakticitu. Sémantický rozdíl mezi oběma typy se však stírá v případech, kdy sám řídící predikát účinkové věty neoznačuje faktický děj (například proto, že je v rozkazovacím způsobu) a zůstává pouze strukturní rozdíl u predikátu vedlejší věty (různost spojek a použití pomocného slovesa skola, které vyjadřuje budoucnost, vůli a někdy povinnost). 
Příspěvek porovnává páry švédských a českých vět účinkových, účelových a zřetelově srovnávacích a pozorování doplňuje o rešerše ve větších jednojazyčných korpusech.","Three types of subordinate clauses express the dependence of the event they denote on an event that is denoted by the governing clause: these are the result clause (henceforth RC), the purpose clause (henceforth PC), and the minimum requirement clause (henceforth MRC). This paper analyzes the semantics of various forms of event consecutiveness expressed by these three clause types in Swedish (mainly based on Clausén et al., 2003, pp. 633-639) and Czech (besed on Karlík et al., 1995), respectively. Findings in a 2-million Swedish-Czech parallel corpus suggest that different languages may exhibit different clause-type preferences (RC/PC/MRC) when referring to consecutive events of the same type."
Tento příspěvek je pilotní studií validace elektronického slovníku anglických sloves PDEV pro účely NLP.,"Corpus Pattern Analysis (CPA) [4], coined and implemented
by Hanks as the Pattern Dictionary of English Verbs (PDEV) [3], appears
to be the only deliberate and consistent implementation of Sinclair’s
concept of Lexical Item [12]. In his theoretical inquiries [5] Hanks
hypothesizes that the pattern repository produced by CPA can also support
the word sense disambiguation task. Although more than 670 verb
entries have already been compiled in PDEV, no systematic evaluation
of this ambitious project has been reported yet.
Assuming that the Sinclairian concept of the Lexical Item is correct, we
started to closely examine PDEV with its possible NLP application in
mind. Our experiments presented in this paper have been performed on
a pilot sample of English verbs to provide a first reliable view on whether
humans can agree in assigning PDEV patterns to verbs in a corpus. As
a conclusion we suggest procedures for future development of PDEV."
Tento článek se zabývá automatickou extrakcí lexikálních realizací tzv. sémantických typů v elektronickém slovníku PDEV.,"This contribution reports on an ongoing analysis of the Pattern Dictionary of English Verbs (PDEV, Hanks 2007b) with respect to both its consistency and reproducibility of use by different users. We address, in particular, the assign-ment of Semantic Type labels to noun collocates of verbs, in a series of experi-ments conducted at the Institute of Formal and Applied Linguistics of the Charles University in Prague."
"Příspěvek popisuje Reduktor, program, který automaticky odstraní nepoužívané části zdrojových kódů v jazyce Mercury.","The aim of this paper is to introduce Reductor,
a program that automatically removes unused parts of the source code of valid programs written in the Mercury language. Reductor implements two main kinds of reductions: statical reduction and dynamical reduction. In the statical reduction, Reductor exploits semantic analysis of the Melbourne Mercury Compiler to nd routines which can be removed from the program. Dynamical reduction of routines additionally uses Mercury Deep Profiler and some sample input data for the program to remove unused contents of the program routines. Reductor modifies the sources of the program in a way, which keeps the formatting of the original program source so that the reduced code is further editable."
"Kapitola představuje diskriminativní techniky modelování, které opravují chyby vytvořené automatickým parserem. Model je podobný rerankingu, ale nevyžaduje generování n-best seznamů. Místo nich vytváří seznam potenciálně lepších výsledků parsování pomocí lokálních strukturálních transformací automaticky vytvořeného parsu.","This chapter presents a discriminative modeling technique which corrects the errors made by an automatic parser.
The model is similar to reranking; however, it does not require the generation of k-best lists as in MCDonald et
al. (2005), McDonald and Pereira (2006), Charniak and Johnson (2005), and Hall (2007). The corrective strategy
employed by our technique is to explore a set of candidate parses which are constructed by making structurally–
local perturbations to an automatically generated parse tree."
Článek zavádí hybridní přístup v oblasti strojového překladu mezi příbuznými jazyky. Výsledky jsou uvedeny pro jazykové páry čeština-slovenština a čeština-ruština.,"The paper introduces a hybrid approach to a very specific field in machine translation — the translation of closely related languages. It mentions previous experiments performed forclosely related Scandinavian, Slavic, Turkic and Romanic languagesand describes a novel method, a combination of a simple shallowparser of the source language (Czech) combined with a stochasticranker of (parts of) sentences in the target language (Slovak, Russian, Slovenian). The ranker exploits a simple stochastic model ofthe target language and its main task is to choose the best translation among those provided by the system. The last section of thepaper presents results indicating better translation quality comparedto the existing MT system for Czech and Slovak and compares themwith the results obtained by the translation from Czech to Russian using the same system."
Článek podrobně popisuje využití grafových metod a datových struktur v jednoduchém systému strojového překladu pro blízké jazyky. Multigrafy použité v reprezentaci víceznačných částečných výsledků v různých fázích zpracování a syntaktické analýzy umožňují modifikaci jednoduché architektury vyvinuté před deseti lety při experimentech s automatickým překladem mezi slovanskými jazyky v systému Česílko.,The paper describes in detail the exploitation of chart-based methods and data structures in a simple system for the machine translation between related languages. The multigraphs used for the representation of ambiguous partial results in various stages of the processing and a shallow syntactic chart parser enable a modification of a simplistic and straightforward architecture developed ten years ago for MT experiments between Slavic languages in the system Česílko. The number of translation variants provided by the system inspired an addition of a stochastic ranker whose aim is to select the best translations according to a target language model.
Článek popisuje metodu kombinace dvou systémů strojového překladu k získání nového jazykového páru.,"The paper describes a sophisticated method of combining two MT systems to obtain a new translation pair. Instead of a simple pipe, we use a complex data structure to pass the data from the first MT system to the second one. Evaluation results are reported for the language triplet Czech-Slovenian-Slovak."
"Článek se zabývá problémem skládání klauzí v českých souvětích z jednotlivých segmentů identifikovaných pomocí spojek a interpunkčních znamének. Množství segmentů je obvykle větší než
počet klauzí, proto je při syntaktické analýze souvětí nutné rozpoznat a spojit jednotlivé segmenty do klauzí a určit vzájemné postavení těchto klauzí. Článek navrhuje a předkládá k diskusi určitá pravidla, která vycházejí z české gramatiky a z lexikálně syntaktických vlastností českých slov. Tato pravidla se opírají o analýzu jevů, důležitých pro určení vzájemného vztahu českých klauzí, a o jejich frekvenci. Pravidla jsou vytvořena převážně na základě dat, získaných pro tento úkol z Pražského závislostního
korpusu.",The article addresses the problem of an identification of individual sentence clauses from segments that are identified on a basis of subordinating conjunctions and punctuation marks.
"Článek přináší důmyslné prohledávání valenčních slovníků. Popisuje zobrazení slovníků v editoru (TrEd) se zabudovaným vyhledáváním (PML-TQ), ve kterém jsou dotazy kresleny uživatelem v grafickém režimu. Tyto universální metody článek demonstruje na českých slovnících VALLEX a PDT-VALLEX.","This paper presents a sophisticated way to search valency lexicons. We provide a visualization of lexicons with such built-in searching that allows users to draw sophisticated queries in a graphical mode. We exploit the PML-TQ, a query language based on the tree editor TrEd. For demonstration purposes, we focus on VALLEX and PDT-VALLEX, two Czech valency lexicons of verbs. We propose a common lexicon data format supported by PML-TQ. This format offers easy viewing both lexicons, parallel searching and interlinking them. The proposed method is universal and can be used for other hierarchically structured lexicons."
"Popisujeme anotaci víceslovných výrazů v Pražském závislostním korpusu, k čemuž využíváme několikastupňové předanotace. Representaci víceslovných výrazů ve slovníku uchováváme ve formě podstromů tektogramatické roviny PDT a následující výskyty automaticky označujeme. Předkládáme způsob měření spolehlivosti takové anotace.","We describe annotation of multiword expressions (MWEs) in the Prague dependency treebank, using several automatic pre-annotation steps. We use subtrees of the tectogrammatical tree structures of the Prague dependency treebank to store representations of the MWEs in the dictionary and pre-annotate following occurrences automatically. We also show a way to measure reliability of this type of annotation."
Tato data obsahují anotaci PDT pomocí české verse WordNetu. Data jsou uložena ve formátu PML.,This dataset contains annotation of PDT using czech WordNet ontology. Data is stored in PML format.
"Tato data doplňují anotaci víceslovných výrazů a víceslovných pojmenovaných entit k původním datům PDT 2.0. Anotace je ukládána ""stand-off"" ve stejném PML formátu jako data PDT 2.0. Jsou určena k použití spolu s PDT 2.0.","This dataset adds annotation of multiword expressions and multiword named entities to the original PDT 2.0 data. The annotation is stand-off, stored in the same PML format as the original PDT 2.0 data. It is to be used together with the PDT 2.0."
"Příspěvek se pokouší ukázat , že se – oproti rozšířenému lingvistickému názoru – jako součást explicitních performativních formulí (EPF) uplatňuje nejen tvar 1. os. sg. nebo pl. indikativu prézenta nedokonavých sloves, ale běžně také tvar 1. os. sg. nebo pl. kondicionálu přítomného, a to jak sloves nedokonavých, tak dokonavých. Zaměřujeme se na kondicionál přítomný několika sloves konstatování v EPF s komunikační funkcí oznámení a na kondicionálové tvary několika sloves s výzvovými významy, které se uplatňují v EPF vyjadřujících některé typy výzvy.","The present paper focuses on the form of the first person present condition-al as a component of explicit performative formulae (EPF), which are considered to be a means directly expressing the communicative function of an utterance. We try to dem-onstrate that the performative usage of verbs is not limited to indicative forms of imper-fective verbs in Czech, as usually stated, but that also the form of the first person present conditional of imperfective as well as perfective verbs is used as an ordinary component of EPF. In Section 2, basic characteristics of EPF are briefly described. Two groups of verbs (verbs of assertion and verbs of appeal) are examined on the basis of language data from two corpora: from the Prague Dependency Treebank 2.0 and SYN2005 corpus (Sect. 3). In Section 4, the performative function of the conditional forms of these verbs is at-tested by means of Austin’s test and by some other criteria described in theoretical works. We further examine how the propositional content is expressed in analyzed utter-ances as well as what the difference between the examined EPF with the conditional verb form and the EPF with the indicative form is."
"Příspěvek se věnuje gramatické kategorii čísla v češtině. Základní opozice singularity a plurality je obohacena rozdílem mezi významem prostého počtu a významem souborovým. Stručně uvádíme, jak je kategorie čísla reprezentována v několikarovinném anotačním schématu Pražského závislostního korpusu 2.0, poté probíráme možnost zavedení navrhovaného významového rozdílu do anotace. Článek uzavírá studie distribuce plurálových preferencí českých substantiv ve větším korpusu.","The paper deals with the grammatical category of number in Czech. The basic semantic opposition of singularity and plurality is proposed to be enriched with a (recently introduced) distinction between a simple quantitative meaning and a pair/group meaning. After presenting the current representation of the category of number in the multi-layered annotation scenario of the Prague Dependency Treebank 2.0, the introduction of the new distinction in the annotation is discussed. Finally, we study an empirical distribution of preferences of Czech nouns for plural forms in a larger corpus."
"Představujeme automatický dialogový systém Senior Companion. Vede dialog, jehož cílem není splnění předem daného společného úkolu, ale naopak nezávazný kratochvilný hovor s postarším uživatelem o jeho rodinných fotografiích.","This paper presents a real-time implementation of an automatic dialogue system called ‘Senior Companion’, which is not strictly task-oriented, but instead it is designed to ‘chat’ with elderly users about their family photographs. To a large extent, this task has lost the usual restriction of dialogue systems to a particular (narrow) domain, and thus the speech and natural language processing components had to be designed to cover a broad range of possible user and system utterances."
"Článek představuje jednotný dotazovací systém pro treebanky, schopný pracovat se závislostními i složkovými stromy v libovolném jazyce. Možnosti systému jsou předváděny na 11 různých treebankách. Dotazovací jazyk systému má mnoho rysů, které v ostatní systémech chybějí, ale zachovává si výkonnost. Článek popisuje konverzi různých datových formátů do formátu postaveného na XML, který systém používá. Následně jsou představeny některé lingvisticky zajímavé otázky, na které systém umí hledat odpovědi, např. prohlížení slovesných klauzí bez podmětu, generování gramatiky ze složkového treebanku, hledání neprojektivních hran v závislotních datech, nebo typologie jazyka podle SOV pořádku. Na závěr je provedeno měření výkonu různých implementací systému.","The paper presents a system for querying treebanks in a uniform way. The system is able to work with both dependency and constituency
based treebanks in any language. We demonstrate its abilities on 11 different treebanks. The query language used by the system
provides many features not available in other existing systems while still keeping the performance efﬁcient. The paper also describes
the conversion of ten treebanks into a common XML-based format used by the system, touching the question of standards and formats.
The paper then shows several examples of linguistically interesting questions that the system is able to answer, for example browsing
verbal clauses without subjects or extraposed relative clauses, generating the underlying grammar in a constituency treebank, searching
for non-projective edges in a dependency treebank, or word-order typology of a language based on the treebank. The performance of
several implementations of the system is also discussed by measuring the time requirements of some of the queries."
"Rozpoznávání anafory je klíčové pro některé z úloh zpracování přirozeného jazyka (NLP), jako extrakce informací nebo dialogové systémy. Tato informace může byt hodnotná taky při strojovém překladu. Všechny předešlé práce týkající se rozpoznávání anafory v českém jazyce se soustředily především na zájmennou koreferenci. Díky nedávnemu projektu anotace širších anaforických vztahů v Pražském závislostním korpusu 2.0 však tato práce jde nad rámec zájmenné koreference. Pokouší se o rozpoznání koreference jmenných frází se specifickou referencí, generických jmenných frází a rozpoznání asociační anafory. Jsou v ní realizovány některé z nejúspěšnějších postupů v oblasti rozlišování anafor na základě strojového učení, konkrétně “ranking” a společné řešení úloh identifikace anaforu a nalezení antecedenta. Bylo vytvořeno množství rysů a analyzován jejích podíl na míře úspěšnosti. Nejlepší model koreference jmenných frází dosáhl F-hodnoty 39.4%.","Anaphora resolution is the key task for some of the Natural Language Processing (NLP) tasks like the information extraction or dialog systems. It can be also valuable in machine translation. All the previous works concerning the anaphora resolution in Czech language mostly focused on the pronoun coreference. Thanks to the recent project of the annotation of extended anaphoric relations in Prague Dependency Treebank 2.0 this work goes further. It attempts to resolve noun phrase coreference, identity-of-sense anaphora and part-whole bridging relations. It has adopted some of the state-of-the-art approaches in the area of machine learning approaches to anaphora resolution, particularly the ranking and the joint anaphor identification with the antecedent selection. It introduced a plenty of features and analyzed their contribution on the success rate. The best model of noun phrase coreference achieves the F-score of 39.4%."
"Rozpoznávání anafory je klíčové pro některé z úloh zpracování přirozeného jazyka, jako extrakce informací nebo dialogové systémy. Tato informace může byt hodnotná taky při strojovém překladu. Všechny předešlé práce týkající se rozpoznávání anafory v českém jazyce se soustředily především na zájmennou koreferenci. Díky nedávnemu projektu anotace širších anaforických vztahů v Pražském závislostním korpusu 2.0 je však možné provádět výzkum v oblasti automatického rozpoznávání těchto vztahů. V mé přednášce budu prezentovat probíhající projekt rozpoznávání koreference jmenných frází a asociační anafory za použití řízeného strojového učení.","Anaphora resolution is the key task for some of the Natural Language Processing tasks like the information extraction or dialog systems. It can be also valuable in machine translation. All the
previous works concerning the anaphora resolution in Czech language mostly focused on the pronoun coreference. Thanks to the recent project of the annotation of extended anaphoric relations in Prague Dependency Treebank 2.0 it is possible to carry out research in automatic resolution of these relations. In my talk I will present the
ongoing project of noun phrase coreference and bridging anaphora resolution using supervised machine learning."
"V počítačové lingvistice je běžnou praxí používat výběrová omezení a hierarchie sémantických typů jako primární zdroj znalostí pro rozlišení významu slov (srov. Jurafsky a Martin 2000). Nejrozšířenějším přístupem je začít s ontologií typů (např. Wordnet, srov. Miller a Fellbaum 2007) a pokusit se využít jimi implikované konceptuální kategorie ke specifikaci kombinatorických omezení lexikálních jednotek.","It is common practice in computational linguistics to attempt to use selectional constraints and semantic type hierarchies as primary knowledge resources to perform word sense disambiguation (cf. Jurafsky and Martin 2000). The most widely adopted methodology is to start from a given ontology of types (e.g. Wordnet, cf. Miller and Fellbaum 2007) and try to use its implied conceptual categories to specify the combinatorial constraints on lexical items. Semantic Typing information about selectional preferences is then used to guide the induction of senses for both nouns and verbs in texts. Practical results have shown, however, that there are a number of problems with such an approach. For instance, as corpus-driven pattern analysis shows (cf. Hanks et al. 2007), the paradigmatic sets of words that populate specific argument slots within the same verb sense do not map neatly onto conceptual categories, as they often include words belonging to different types. Also, the internal composition of these sets changes from verb to verb, so that no stable generalization seems possible as to which lexemes belong to which semantic type (cf. Hanks and Jezek 2008). In this paper, we claim that these are not accidental facts related to the contingencies of a given ontology, but rather the result of an attempt to map distributional language behaviour onto semantic type systems that are not sufficiently grounded in real corpus data. We report the efforts done within the CPA project (cf. Hanks 2009) to build an ontology which satisfies such requirements and explore its advantages in terms of empirical validity over more speculative ontologies."
Článek prezentuje pokus automatizace procesů k vytvoření systému strojového překladu založeného na pravidlech.,"The article presents an attempt to automate
all data creation processes of a rule-based
shallow-transfer machine translation
system. The presented methods were
tested on two fully functional translation
systems Slovenian-Serbian and Slovenian-Macedonian.
An extensive range of evaluation
tests was performed to assess the applicability
of the methods."
"V tomto článku se věnujeme srovnání valenčních vlastností českých a anglických sloves. Materiál pro výzkum této oblasti pochází ze dvou paralelních korpusů: korpusu Prague Czech-English Dependency Treebank a korpusu Intercorp. Nejprve provedeme srovnání obou korpusů a vysvětlíme, z jakých hledisek jsou pro zkoumání valenčních vlastností sloves výhodné. Dále nastíníme několik oblastí, v nichž se vyskytují asymetrie valenčních vlastností překladových ekvivalentů. V případové studii se zaměříme zejména na slovesa vyžadující doplnění tzv. směrovými doplněními a blíže ukážeme konkrétní typy asymetrií na slovesech crawl, descend a travel.",In this paper we are concerned with the comparison of valency characteristics of Czech and English verbs. As a material we use two parallel corpora: PCEDT and Intercorp. First we compare the two corpora to one another with respect to their suitability for research in valency. Then we propose several areas of crosslingustic asymmetries in verbal valency. Finally we present a case study of three pairs of Czech and English motion verbs to exemplify the asymmetries mentioned.
"Představujeme výsledky prvního vyhodnocení paralelních ručních anotací dirkurzu v Pražském závislostním korpusu. Uvádíme přehled vlastního anotačního procesu, popisujeme měření mezianotátorské shody a hlavně klasifikujeme a analyzujeme nejběžnější druhy anotátorské neshody a navrhujeme řešení pro další fázi anotací.","We present results of the first evaluation of parallel manual annotations of discourse in the Prague Dependency Treebank. We give an overview of the process of the annotation itself, describe the inter-annotator agreement measurement, and, most importantly, we classify and analyze the most common types of annotators’ disagreement and propose solutions for the next phase of the annotation."
"Mezi nejúspì¹nìj¹í metody strojového pøekladu
se v souèasné dobì øadí relativnì velmi jednoduchý frázový
statistický pøeklad, který se opírá v podstatì pouze o posloupnosti slov bez ohledu na lingvistické rozbory. Z více
dùvodù kvalita strojového pøekladu stále není uspokojivá
a lze se domnívat, ¾e èást problémù by bylo mo¾né odstranit explicitním zapojením lingvistické anotace do frázového
pøekladu. Pro èe¹tinu a angliètinu jsou navíc rozsáhlá bohatì anotovaná paralelní data k dispozici. Cílem této práce
je proto pøipravit nástroj usnadòující experimenty s bohatou lingvistickou anotací v relativnì jednoduchém prostøedí
frázových statistických pøekladù. Popisujeme formát dat i
mo¾nosti implementovaného nástroje a souèasnì uvádíme
výsledky prvních experimentù. ©iroký prostor mo¾ností, jak
lingvistická data do modelu zapojit, je otevøen pro dal¹í výzkum.",We present a simple tool for the inclusion of rich linguistic annotation in phrase-based machine translation systems.
"Přednáška pojednává o problémech anotace žákovského korpusu češtiny, tzn. čestiny jak ji používají nerodilí mluvčí.","The talk describes a challenges of annotation of learners corpus of Czech, i.e. Czech as used by non-native speakers."
"Tento článek podává přehled o hlavních tématech, která zajímají autory jednojazyčných slovníků pro rodilé mluvčí. Diskutuje vztah mezi lexikální databází a jednojazyčným slovníkem, roli korpusových příkladů, historické lexikografické principy v porovnání se synchronními, nestabilitu významu slova, potřebu plného pokrytí slovní zásoby, prinicipy psaní definic a roli slovníků ve společnosti a návod ke správnému používání slov jako jeden z hlavních úkolů jednojazyčného slovníku.","This article gives a survey of the main issues confronting the compilers of monolingual
dictionaries in the age of the Internet. Among others, it discusses the relationship between a
lexical database and a monolingual dictionary, the role of corpus evidence, historical principles in
lexicography vs. synchronic principles, the instability of word meaning, the need for full vocabulary
coverage, principles of definition writing, the role of dictionaries in society, and the need for
dictionaries to give guidance on matters of disputed word usage. It concludes with some questions
about the future of dictionary publishing."
"Elektronické slovníky budoucnosti budou velmi žádané — pro komputační, pedagogické a jiné aplikace — pokud bude možné je použít jako systematické zobrazení slovních významů na slovní výskyty.","Electronic dictionaries of the future will be much in demand—for computational, pedagogical, and other applications—if they can be used as resources for mapping word meaning systematically onto word use. Research in computational linguistics and artificial intelligence over the past twenty years, despite many declarations of success, has shown that existing dictionaries, designed for human users, coupled with existing linguistic theory of a top-down, speculative nature, have failed to be suitable for this goal. Nor are results using hierarchical ontologies such as WordNet any better. Such resources are very plausible for human users, but they fail to meet the challenges of mapping meaning systematically onto words in use in ordinary text."
"Tento příspěvek je zvanou přednáškou na téma vztahu mezi slovy a významem. Autor zde představuje svoji metodu manuální analýzy jazykových pravidelností v korpusu. Popisuje zde, jakým způsobem analyzuje anglická sloevsa, aby získal přehled o významových změnách, které nastávají s výběrem různých slovesných doplnění, a nabádá lingvisty, aby při dokládání svých teorií o významu a používání slov nepoužívali introspekci, nýbrž korpus.","The title of the present paper, “How people use words to making meanings”, carries with it a number of theoretical assumptions, some of which are more controversial than others. It is, I suppose, uncontroversial that language, used fully and meaningfully, is a uniquely human phenomenon, and that the communications and thought processes of other animals, even chimpanzees, are different in kind from human language. It is people who use words. Language does not exist in a vacuum: it exists in the brains and the interactions of humans. Humans are social animals, and language is the instrument of their sociability, as well as the vehicle of their thought processes.
Equally uncontroversial is the assumption that language is composed of words, put together into some sort of structure, which has persistent attributes. By a “persistent attribute” I mean features like the rank scale of grammar – discourse (document or conversation), paragraph, sentence, clause, phrase or group, word, morpheme). Such structures are not the exclusive property of language, for they also govern other forms of human behaviour such as games and music. Syntax is not an exclusively linguistic phenomenon, but language is the most salient, the most prototypical example of rule-governed behaviour.
At the heart of this view of language lie words. Words are central to the activity of making meanings. Each content word in a language, like a great international airport, represents a place where things come together, meet, and go off in different directions—a huge set of interchange points with various sorts of connections: internal connections to beliefs in the mind of the speaker, interpersonal connections to the beliefs of other users of the same language, intralingual connections to other words in the same language, and putative connections to objects in the world.
Associated with this account of words is the assumption that each word has a meaning. This, however, is an assumption that I will question in the course of this paper.
Another assumption implicit in the title is that meanings are events—events that are for the most part only momentary, transitory, evanescent. A speaker makes a meaning—billions of people do it every minute of every day—but the next moment the meaning is gone: lost for ever, unless some assiduous Boswell, parliamentary reporter, law clerk, or linguist happens to have transcribed the utterance of the speaker and thus preserved it for posterity. Most meaningful spoken interactions are as evanescent as the mutual sniffing of dogs—or the passing of passengers through an airport. The notion that meanings are events is, nevertheless, one that I propose to defend, against the alternative
1
view that meanings are static abstract entities. It is a commonplace among philosophers of language that speaker’s meaning and hearer’s meaning are not necessarily identical, and the. As Wright (1976) put it:
“Speaker and hearer have only their mutual pragmatic satisfaction to rely on that they mean the same thing.”
The philosopher H. P. Grice (1957) regarded meanings as events, involving a particular kind of interaction between speaker and hearer—an interchange of beliefs. The core of Grice’s account of meaning is summarized by Bennett (1976) thus: If [an utterer] U does x, thereby meaning that P, he does it intending i. that some audience A should come to believe P
ii. that A should be aware of intention (i), and
iii. that the awareness mentioned in (ii) should be part of A’s reason for believing that P.
This account of meaning applies equally well to the interaction between writer and reader, with a displacement in time, which may be very large or quite small1."
"V tomto příspěvku autor popisuje historický vývoj slovníků a hodnotí přínos knihtisku k rozvoji lexikografie, který porovnává s dopadem, který může mít na současnou lexikografii masívní rozšíření elektronického ukládání dat. Autor vysvětluje, jak došlo k nahrazení mnohajazyčných glosářů dvojjazyčnými slovníky. Opírá se o příklady těchto slovníků: Robert Cawdrey: Table Alphabeticall, Robert Estienne: Dictionarum, seu Thesaurus 
Linguae Latinae, Henri Estienne: Thesaurus Linguae Graecae.","Historians of lexicography in the English-speaking world have implied that Robert
Cawdrey's Table Alphabeticall (1604) is the first English dictionary. Landau (1984,
2001) makes this claim, adding that it is “the least inspiring of all seminal works”. In
this paper, I agree that the Table Alphabeticall is uninspiring, but I deny that it is a
seminal work. Landau overlooks the rich 16th-century tradition of Renaissance and
Humanist lexicography in Europe, in particular the Dictionarum, seu Thesaurus
Linguae Latinae of Robert Estienne (1531) and the Thesaurus Linguae Graecae of his
son Henri Estienne (1572). These seminal works are astonishing achievements—
breathtaking innovations—in terms of both scholarship and technology. They set
standards for subsequent European lexicography. Two technological innovations
made these great dictionaries possible: the invention of printing by Gutenberg in
Strasbourg in about 1440 and the typography of Nicolas Jenson in Venice in 1462.
These technological developments and the lexicographical achievements that were
made possible by them contributed, in the first place, to the Renaissance programme
of preserving the classical heritage of ancient Greece and Rome and, in the second
place, to the role of dictionaries in spreading Renaissance culture and Humanism
across Europe. The paper goes on to briefly outline the emergence of bilingual
lexicography, replacing the polyglot lexicography that was standard in the 16th
century. A comparison is made between the influence of printing technology on 16th
century lexicography and the potential influence of computer technology on 21st
century lexicography"
"Tato obšírná a velice precizní recenze se zabývá knihou A. Deignan o analýze metafory pomocí metod korpusové lingvistiky. Autor recenze knihy využívá jako odrazového můstku k obecnějším úvahám o struktuře a využití metafory v jazyce. Poukazuje na nutnost lingvistické analýzy kognitivních jevů, které se manifestují v jazyce. Autor recenze se sám problematikou metafory zabýval již ve svých dřívejších původních dílech.","With the benefit of hindsight, it is now possible to see that one of the most important themes in the study of language to emerge in the 20th century was developed, not by linguists, but primarily by philosophers of language such as Wittgenstein and Grice and anthropologists such as Malinowski and Rosch.  This theme involves, among other things, rejection of sharply defined category boundaries and adoption instead of systems of categories built by analogy around prototypes. Central and typical examples of linguistic categories are usually easy to identify, but boundaries between categories are fuzzy grey areas on a cline, rather than sharp divisions.  Metaphor is the most prototypical example of linguistic analogy, so a corpus-based study of metaphor will be a theme of central interest."
"This paper explores two aspects of word use and word meaning in terms of Sinclair's (1991, 1998)
distinction between the open-choice principle (or terminological tendency) and the idiom principle
(or phraseological tendency). Technical terms such as strobilation are rare, highly domain-specific,
and of little phraseological interest, although the texts in which such word occur do tend to contain
interesting clusters of domain-specific terminology. At the other extreme, it is impossible to know the
meaning of ordinary common words such as the verb blow without knowing the phraseological context
in which the word is used.
Many words have both a terminological tendency and a phraseological tendency. In some cases the two
tendencies are in harmony; in other cases there is tension between them. The relationship between these
two tendencies is investigated, using examples from the British National Corpus.","Tento článek se zabývá dvěma aspekty užívání slov a významu slov ve smyslu Sinclairovy distinkce mezi tzv. principem volného výběru a idiomatického výběru. Technické pojmy jako např. strobilace jsou vzácné, vázané na určitou doménu a nejsou zajímavé po stránce frazeologické, i když texty, v nichž se tato slova vyskytují, mají tendenci obsahovat zajímavé shluky doménově specifické terminologie. Na druhou stranu, význam běžně užívaných slov nelze popsat, není-li k dispozici kontext."
Tento článek popisuje kombinační systém pro strojový překlad univerzity DCU použitý  na workshopu strojového překladu Joint Fifth Workshop on Statistical Machine Translation and Metrics in ACL-2010.,"This paper describes the augmented threepass system combination framework of the Dublin City University (DCU) MT group for the WMT 2010 system combination task. The basic three-pass framework includes building individual confusion networks (CNs), a super network, and a modiﬁed Minimum Bayes-risk (mConMBR) decoder. The augmented parts for WMT2010 tasks include 1) a rescoring component which is used to re-rank the N-best lists generated from the individual
CNs and the super network, 2) a new hypothesis alignment metric – TERp – that is used to carry out English-targeted hypothesis alignment, and 3) more different backbone-based CNs which are employed to increase the diversity of the mConMBR decoding phase. We took part in the combination tasks of Englishto-Czech and French-to-English. Experimental results show that our proposed combination framework achieved 2.17 absolute points (13.36 relative points) and
1.52 absolute points (5.37 relative points) in terms of BLEU score on English-toCzech and French-to-English tasks respectively than the best single system. We also achieved better performance on human evaluation."
"Tato kniha se dotýká řady témat: typologie, morfologie, korpusové lingvistiky, kontrastivní lingvistiky, lingvistické anotace, počítačové lingvistiky a zpracování přirozeného jazyka (NLP). Budou z ní mít prospěch výzkumníci a studenti se zajmem o tyto oblasti, stejně i o mezijazykové studie.","While supervised corpus-based methods are highly accurate for different NLP tasks, including morphological tagging, they are difficult to port to other languages because they require resources that are expensive to create. As a result, many languages have no realistic prospect for morpho-syntactic annotation in the foreseeable future. The method presented in this book aims to overcome this problem by significantly limiting the necessary data and instead extrapolating the relevant information from another, related language. The approach has been tested on Catalan, Portuguese, and Russian. Although these languages are only relatively resource-poor, the same method can be in principle applied to any inflected language, as long as there is an annotated corpus of a related language available. Time needed for adjusting the system to a new language constitutes a fraction of the time needed for systems with extensive, manually created resources: days instead of years.

This book touches upon a number of topics: typology, morphology, corpus linguistics, contrastive linguistics, linguistic annotation, computational linguistics and Natural Language Processing (NLP). Researchers and students who are interested in these scientific areas as well as in cross-lingual studies and applications will greatly benefit from this work. Scholars and practitioners in computer science and linguistics are the prospective readers of this book."
"Zdroje pro morfologickou analýzu a značkování ruštiny, běloruštiny a staročeštiny. Vzory, frekventovaná slova a další obecná morfologicka, fonologická a grafémická pravidla.","Resources for morphological analysis and tagging of Russian, Belorussian and Old Czech. Paradigms, frequent forms and other morphological, phonological and graphemic rules."
V tomto článku popisujeme výrobu česko-ruského paralelního závislostního treebanku.,"In this paper we describe initial steps in constructing Czech-Russian dependency treebank and discuss the perspectives of its development. Following the experience of Czech-English Treebank
we have taken syntactically annotated ""gold standard"" text for one language (Russian) and run an automatic annotation on the respective parallel text for the other language (Czech). Our treebank includes also automatic word-alignment."
"V tomto článku popisujeme rozdíly ve valenci mezi češtinou a ruštinou. Výsledkem je malý rozdílový valenční slovník, který bude využít ve strojovém překladu Česílko.","The paper analyzes the differences in ver-
bal valency frames between two related
Slavic languages, Czech and Russian, with
regard to their role in a machine translation
system. The valency differences are a fre-
quent source of translation errors. The re-
sults presented in the paper show that the
number of substantially different valency
frames is relatively low and that a bilingual
valency dictionary containing only the dif-
fering valency frames can be used in an
MT system in order to achieve a high pre-
cision of the translation of verbal valency."
"English to Czech machine translation as it is implemented in the TectoMT system consists of three phases:
 analysis, transfer and synthesis.
The system uses tectogrammatical (deep-syntactic dependency) trees as the transfer medium.
Each phase is divided into so-called blocks, which are processing units that solve linguistically interpretable tasks
 (e.g., statistical part-of-speech tagging or rule-based placement of clitics).

This paper shortly introduces linguistic layers of language description which are used for the translation
 and describes basic concepts of the TectoMT framework. 
The translation results are evaluated using both automatic metric BLEU and human judgments from the WMT 2010 evaluation.","Strojový překlad z angličtiny do češtiny implementovaný v systému TectoMT sestává ze tří fází: analýzy, transferu a syntézy. Pro transfer se využívají tektogramatické stromy. Každá fáze je rozdělena do tzv. bloků, což jsou jednotky kódu, které řeší jednotlivé lingvisticky interpretovatelné úlohy (např. statistický tagging či přemístění klitik podle ručně psaných pravidel)."
"Strojový překlad z angličtiny do češtiny implementovaný v systému TectoMT sestává ze tří fází: analýzy, transferu a syntézy. Transfer se provádí na tektogramatické rovině upravené pro účely překladu. Každá fáze je rozčleněna do bloků, které řeší konkrétní lingvisticky interpretovatelný úkol (např. přiřazení morfologických značek statistickým taggerem, či přesun klitik podle ručně psaných pravidel). Systém TectoMT je navržen modulárně - bloky je možné zaměňovat za alternativní implementace a také využít i pro jiné aplikace než strojový překlad.
Přednáška představí základní průběh celého překladu a zaměří se na popis vylepšení, která byla provedena v posledním roce, zejména:
(a) využití tektogramatického jazykového modelu a Hidden Markov Tree Models,
(b) nový systém slovníků natrénovaných na paralelním korpusu CzEng pomocí metody Maximum Entropy.","English-to-Czech machine translation implemented in TectoMT system consists of three phases: analysis, transfer, and synthesis. Transfer is performed on the tectogrammatical layer which is modified for MT purposes. Each phase is divided into so-called blocks which solve particular linguistically interpretable tasks (e.g. tagging with statistic tagger or clitic shifting according to hand-written rules). TectoMT system is designed in a modular way - blocks can be substituted with alternative implementations. The talk presents basic steps of the whole translation and focuses on improvements implemented in the last year, especially:
(a) tectogrammatical LM and Hidden Markov Tree Models,
(b) new translation dictionaries trained on parallel corpus CzEng using Maximum Entropy."
"Treex je víceúčelový open-source framework pro počítačové zpracovávání přirozeného jazyka. Je implementován v programovacím jazyku Perl. Umožňuje rychlý a efektivní vývoj aplikací s využitím široké škály softwarových integrovaných modulů, např. nástroje pro větnou segmentaci, tokenizaci, morfologickou analýzu, tagging, syntaktickou analýzu (parsing na analytickou i tektogramatickou rovinu), rozpoznávání pojmenovaných entit, strojový překlad apod.","Treex is a multi-purpose open-source natural language processing (NLP) framework implemented in Perl programming language. It allows for fast and efficient development of NLP applications by exploiting a wide range of software modules already integrated in Treex, such as tools for sentence segmentation, tokenization, morphological analysis, POS tagging, shallow and deep syntax parsing, named entity recognition, anaphora resolution, tree-to-tree translation, natural language generation, word-level alignment of parallel corpora, and other tasks. One of the most complex applications of Treex is the English-Czech machine translation system TectoMT. Several modules are available also for other languages (German, Russian, Arabic). Where possible, modules are implemented in a language-independent way, so they can be reused in many applications."
"Jazykové modely jsou klíčovou součástí mnoha aplikací jako rozpoznávání mluvené řeči či strojového překladu. Jazykové modely počítají pravděpodobnost řetězce slov jako součin P(w_i|h_i), kde h_i je kontext (historie) slova w_i. Většina jazykových modelů používá jako kontext předchozí slova. Tento článek popisuje dva alternativní přístupy: post-ngramové jazykové modely (které používají jako kontext následující slova) a závislostní jazykové modely (které využívají závislostní strukturu věty). závislostní jazykové modely. V porovnání s baseline trigramovým jazykovým modelem dosáhly oba navrhované přístupy signifikantně nižší perplexity pro všech sedm testovaných jazyků (arabština, katalánština, čeština, angličtina, maďarština, italština, turečtina).","Language models (LMs) are essential components of many applications such as speech recognition or machine translation. LMs factorize the probability of a string of words into a product of P(w_i|h_i), where h_i is the context (history) of word w_i. Most LMs use previous words as the context. The paper presents two alternative approaches: post-ngram LMs (which use following words as context) and dependency LMs (which exploit dependency structure of a sentence and can use e.g. the governing word as context). Dependency LMs could be useful whenever a topology of a dependency tree is available, but its lexical labels are unknown, e.g. in tree-to-tree machine translation. In comparison with baseline interpolated trigram LM both of the approaches achieve significantly lower perplexity for all seven tested languages (Arabic, Catalan, Czech, English, Hungarian, Italian, Turkish)."
"Článek popisuje víceúčelový open-source NLP framework TectoMT, který umožňuje rychlý a efektivní vývoj NLP aplikací. Využívá široké spektrum softwarových modulů, které jsou již integrovány do TectoMT, např. nástroje pro segmentaci textu na věty, tokenizaci, morfologickou analýzu a disambiguaci (tagging), parsing (povrchový i hloubkový), rozpoznávání pojmenovaných entit, rozpoznávání anafory, strojový překlad stromových struktur, generování vět z hloubkových struktur, slovní zarovnávání paralelních korpusů atd.
Jednou z nejkomplexnějších aplikací TectoMT je anglicko-český systém strojového překladu s transferem přes tektogramatickou rovinu. Moduly jsou dostupné i pro další jazyky (němčina, ruština, arabština,...).","In the present paper we describe TectoMT, a multi-purpose open-source NLP framework. It allows for fast and efficient development of NLP applications
 by exploiting a wide range of software modules already integrated in TectoMT, such as tools for
 sentence segmentation, tokenization, morphological analysis, POS tagging, shallow and deep syntax parsing, named entity recognition, anaphora resolution, tree-to-tree translation, natural language generation, word-level alignment of parallel corpora, and other tasks. One of the most complex applications of TectoMT is the English-Czech machine translation system with transfer on deep syntactic (tectogrammatical) layer. Several modules are available also for other languages (German, Russian, Arabic). Where possible, modules are implemented in a language-independent way, so they can be reused in many applications."
"Compost Dutch je nástroj pro morfologické značkování holandštiny založený na taggeru Morče. Je trénován na holandské části korpusu CGN. Výsledný tagger svojí úspěšností překonal dosavadní publikované taggery. Verze 2.0 přináší navíc integrovanou morfologickou analýzu, což usnadňuje použití. Aplikace je spustitelná pod Linuxem a Windows.","Compost Dutch is a tool for POS tagging of Dutch based on Morče tagger. It is trained on Dutch part of CGN corpus. The resulting tagger overcome other previously published taggers. Version 2.0 brings integrated morphological analysis, which makes use of the software easier. Application is executable under Windows and Linux."
"Compost English je nástroj pro morfologické značkování angličtiny založený na taggeru Morče. Je trénován na korpusu WSJ. Výsledný tagger svojí úspěšností dosáhl výsledků doposud publikovaných taggerů. Verze 2.0 přináší navíc integrovanou morfologickou analýzu, což usnadňuje použití. Aplikace je spustitelná pod Linuxem a Windows.","Compost English is a tool for POS tagging of English based on Morče tagger. It is trained on WSJ corpus. The resulting tagger obtained results similar to other previously published taggers. Version 2.0 brings integrated morphological analysis, which makes use of the software easier. Application is executable under Windows and Linux."
Compost Icelandic je nástroj pro morfologické značkování islandštiny založený na taggeru Morče. Je trénován na korpusu IFD. Výsledný tagger svojí úspěšností výrazně překonal dosavadní publikované taggery. Pro použití je však nutné použít předzpracování morfologickou analýzou. Aplikace je spustitelná pod Linuxem a Windows.,"Compost Icelandic is a tool for POS tagging of Icelandic based on Morče tagger. It is trained on IFD corpus. The resulting tagger highly overcome other previously published taggers. However, it is necessary to preprocess data with morphological analysis. Application is executable under Windows and Linux."
Compost Swedish je nástroj pro morfologické značkování švédštiny založený na taggeru Morče. Je trénován korpusu SUC 2.0. Výsledný tagger se svojí úspěšností blíží dosavadním publikovaným taggerům. Jeho výhodou však je snadné použití. Aplikace je spustitelná pod Linuxem a Windows.,Compost Dutch is a tool for POS tagging of Swedish based on Morče tagger. It is trained on corpus SUC 2.0. Results of the tagger are close to previously published taggers. Its advantage is in simple usage. Application is executable under Windows and Linux.
Článek popisuje značkovací experimenty se semi-supervised trénováním coby rozšířením algoritmu průměrovaného perceptronu (Collins02).,"This paper describes POS tagging experiments with semi-supervised training as an extension to the (supervised) averaged perceptron algorithm, first introduced for this task by Collins02. Experiments with an iterative training on  standard-sized supervised (manually annotated) dataset (10^6 tokens) combined with a relatively modest (in the order of 10^8 tokens) unsupervised (plain) data in a bagging-like fashion showed significant improvement of the POS classification task on typologically different languages, yielding better than state-of-the-art results for English and Czech (4.12 % and 4.86 % relative error reduction, respectively; absolute accuracies being 97.44 % and 95.89 %)."
"Příspěvek se zaměřuje na vytváření paralelního česko-anglického korpusu pro
účely strojového překladu vyhledáváním a stahováním paralelních textů z~Internetu. Navrhujeme a vyhodnocujeme několik vlastních metod pro nalezení
kandidátských webů, identifikaci jazyka stránek a především párování získaných
dokumentů.","We examine methods for collecting parallel Czech-English corpora from the web. We propose and evaluate automatic methods for finding source web sites, language identification and most importantly the document alignment of obtained pages."
"Příspěvek je věnován problematice členské negace a způsobům jejího vyjadřování v datech Českého národního korpusu (především SYN2005) a Pražského závislostního korpusu (verze 2.0). Za členskou negaci byla dosud ve většině českých příruček považována taková negace, která neoperuje na predikátu. Autorka na základě analýzy dat obou korpusů a studia české i zahraniční odborné literatury týkající se dané problematiky navrhne nové, primárně sémantické vymezení členské negace v češtině a prozkoumá možnosti zachycování tohoto jevu ve strukturách tektogramatické roviny PDT.","This contribution is focused on constituent negation and ways of its expressing in contemporary Czech, or more precisely in Czech National Corpus (SYN2005) and Prague Dependency Treebank (version 2.0). In most of the Czech linguistic handbooks, constituent negation was treated as such a negation that is not a part of verb. The author offers a new primarily semantic definition of constituent negation in Czech, based on data research and study of relevant literature concerning syntactic negation. Further, the author explores the possibility to express the findings on the tectogrammatical level of PDT."
V tomto článku se zabýváme rozdíly mezi klasickým zarovnáváním slov a zarovnání hloubkových syntaktických struktur. Hloubkovými strukturami rozumíme závislostní stromy obsahující pouze autosémantická slova. Ostatní (funkční) slova jako předložky nebo členy jsou schovány.,"In this paper, we describe differences between a classical word alignment on the surface (word-layer alignment) and an alignment of deep syntactic sentence representations (tectogrammatical alignment). The deep structures we use are dependency trees containing content (autosemantic) words as their nodes. Most of other functional words, such as prepositions, articles, and auxiliary verbs are hidden. We introduce an algorithm which aligns such trees using perceptron-based scoring function. For evaluation purposes, a set of parallel sentences was manually aligned. We show that using statistical word alignment (GIZA++) can improve the tectogrammatical alignment. Surprisingly, we also show that the tectogrammatical alignment can be then used to significantly improve the original
word alignment."
"Pokus o zlepšení kvality frázového překladu (nástroj Moses) tím že word-alignment, na kterém se překladač učí, vylepšíme použitím zarovnání tektogramatických stromů.","In this paper, we describe an experiment whose goal is to improve the quality of machine translation. Phrase-based machine translation, which is the state-of-the-art in the field of statistical machine translation, learns its phrase
tables from large parallel corpora, which have to be aligned on the word level. The most common word-alignment tool is GIZA++. It is very universal and language independent. In this text, we introduce a different approach – the tectogrammatical alignment. It works on content (autosemantic) words only, but on these words
it widely outperforms GIZA++. The GIZA++ word-alignment can be therefore improved using tectogrammatical alignment and if we use this improved alignment for training phrase-based automatic translators, the translation quality also slightly increases."
"Česko-anglický ručně anotovaný paralelní korpus byl vytvořen za účelem testování kvalit česko-anglických automatických zarovnávačů na slova. Obsahuje 2500 paralelních vět, každý pár je anotován nezávisle dvěma anotátory.","Czech-English Manually Aligned Parallel Corpus was developed for testing qualities of Czech-English automatic aligners. It consists of 2500 parallel sentences (books, law, newspapers), each sentence is anotated independently by two annotators."
"V tomto článku popíšeme práci na transformaci ruského treebanku SynTagRus do pražského stylu PDT.
Zatímco v PDT tektogramatická anotace existuje, V treebanku SynTagRus žádná jí podobná není.","In this paper, we report a work in progress on transforming syntactic structures from the SynTagRus corpus into tectogrammatical trees in the Prague Dependency Treebank (PDT) style. SynTagRus (Russian) and PDT (Czech) are both
dependency treebanks sharing lots of common features and facing similar linguistic challenges
due to the close relatedness of the two languages. While in PDT the tectogrammatical representation exists, sentences in SynTagRus are annotated on syntactic level only."
"Článek se věnuje teoretickým i praktickým problémům, které vyvstaly při přípravě anotace mezipropozičních vztahů v PDT 2.0. Na rovině teoretické se článek věnuje problematice jendotlivých rovin v PDT 2.0 a otázce, zda můžeme mezipropoziční vrstvu jazyka považovat za další rovinu ve smyslu koncepce rovin ve FGP. Na rovině praktické se pak věnuje především případům problematického rozsahu diskurzních argumentů (např. nepřekrývání t-stromu a propozice, přímá řeč, parcelace propozice, vsuvky ad.).","The paper focuses on the problems and possibilities of the annotation of interpropositional discourse relations in a dependency corpus of a natural language (Czech) such as PDT 2.0. Apart from the general introduction to the existing PDT 2.0 material and the relevant terminology (proposition, connective, argument, discourse layer etc.) it presents the main areas of problems arising during the IDR annotation that are the consequence of the specific form of the existing (especially tectogrammatical) PDT 2.0 annotation. As the degree of IDR is not an independent language layer but brings new information about the integration of tectogrammatical tree or its parts into its language context, the main emphasis is on recording the IDR on the basis of t-trees annotation. The main areas of problems do therefore touch the relation of a proposition and a tectogrammatical tree, that do not always have to correspond (the point is especially to mark out the argument, discourse parceling, multisentence direct speech and parenthesis) and the possibility of IDR classification. We can thus divide the IDR into syntactic discourse relations and non-syntactic discourse relations that comprise relations expressing the discourse producer`s motivation as well as relations expressing the receiver`s point of view."
"Tento článek popisuje problém rekonstrukce mluvené řeči a představuje seznam nejčastějších chyb mluvčích. Ukazujeme, že pouhé smazaní chyb je nepostačující a je potřeba udělat více komplexní operace nad řetězmi. Dále popisujeme nejlepší metody, které se snažíproblém rekonstrukce řešit a představujeme nové nápady, které budeme v budoucnu implementovat.","This paper describes the speech reconstruction problem and lists the
most frequent speaker errors. We show that deletion of these errors is not sufficient
and more complex string operation should be done. We overview state-of-the-art
methods which try to solve this problem and present new ideas which we would
like implement in the near future."
V článku jsou srovnány dvě metody strojového učení pro určování anafory: konvenční systém založený na klasifikaci a nový systém založený na uspořádání kandidátů pomocí perceptronu.,"In this paper we compare two Machine Learning approaches to the task of pronominal anaphora
resolution: a conventional classification system based on C5.0 decision trees, and a novel perceptron-based ranker. We use coreference links annotated in the Prague Dependency Treebank~2.0 for training and evaluation purposes. The perceptron system achieves f-score 79.43% on recognizing coreference of personal and possessive pronouns, which clearly outperforms the classifier and which is the best result reported on this data set so far."
"Příspěvek se zabývá konstrukcemi s rozpadem tématu a dikta v češtině. Tyto konstrukce jsou realizovány některými třídami sloves mluvení a sloves vyjadřujících duševní procesy. Typickým rysem těchto konstrukcí je realizace participantu sdělení ve dvou valenčních pozicích. V předloženém příspěvku se zabýváme zejména syntaktickými vlastnostmi těchto konstrukcí, při jejich popisu však bereme v úvahu i morfologické a sémantické rysy. Dále si tyto konstrukce zaslouží pozornost zejména z ohledem na koreferenci. Na základě korpusových vyhledávek dokazujeme, že téma představuje antecendent, ke kterému odkazuje/í koreferující výraz/y, který je součástí dikta. U těchto konstrukcí zjišťujeme dva druhy koreference: (i) textovou a (ii) 'obsahovou'. V případě 'obsahové' koreference chybí explicitní anaforická relace a vztah mezi koreferujícím a koreferovaným výrazem/y je založen na nejrůznějších sémantických vztazích. Z těchto důvodů nepovažujeme konstrukce bez rozpadu tématu a dikta a s rozpadem za synonymní.","The present paper deals with Czech constructions with the splitting of the theme and dictum. They are realized by some classes of verbs of communication and verbs that express mental actions. The characteristic feature of these constructions lies in the fact that one of their participants − the participant message − occupies two valency slots. In the present contribution, syntactic properties, especially valency characteristics, of these constructions are of our main interest. However, both morphological and semantic features have to be taken into account within their description. Finally, these constructions deserve close attention with regard to coreference relations. 
On the basis of the corpus evidence, we demonstrate that the theme represents an antecendent to which the coreferring expression(s) that is a part of the dictum refers. In principle, two kinds of coreference occur in the examined constructions: (i) textual and (ii) 'content' coreference. In the latter case, an explicit anaphoric relation is missing, and the relation between the coreferred and the coreferring element(s) is based on various semantic relations. For these reasons, we assume that the constructions with the splitting of the theme and dictum are not synonymous with the constructions without the splitting, due to divergent truth conditions."
"V tomto příspěvku se zabýváme změnami ve valenční struktuře českých sloves z hlediska lexikografické. Zaměřujeme se pouze na syntaktické konstrukce, které se vztahují v zásadě stejné (zobecněné) situaci. Změny ve struktuře valence jsou chápány jako různé mapování mezi jednotlivými účastníky zevšeobecněné situace a valenčními sloty, včetně jejich morfematický realizace. Rozlišujeme dva typy změn ve valenční struktuře, takzvané gramatické diateze a sémantické diateze.

Představujeme základní typologii možných změn ve struktuře valence a navrhujeme způsob reprezentace těchto změn ve valenčním slovníku českých sloves VALLEX.","In this paper, we deal with changes in valency structure of Czech verbs from a lexicographic point of view. We focus only on syntactic constructions that are related in principle to the same (generalized) situation. Changes in valency structure are understood as different mappings between individual participants of a generalized situation and valency slots, including their morphemic realization. We
distinguish two types of changes in valency structure, so-called grammatical diatheses
and semantic diatheses.

We introduce a basic typology of potential changes in valency structure and we propose a method of the representation of these changes in the valency lexicon of Czech verbs VALLEX."
"Představujeme projekt zaměřený na obohacení valenčního slovníku českých sloves o chybějící sémantické informace - sémantické třídy a sémantické role. Pro tento účel jsme využili data z projektu FrameNet. Navrhli jsme způsob, jak překonat problém s jemnějším rozlišením významu ve FrameNet. Tato metoda je založena na relaci 'Inheritance'. Takto bylo zařazeno 6 skupin sloves do ucelenější sémantických tříd a jejich valenčním doplněním byly přiděleny sémantické role. Plánujeme studovat další skupiny sloves, zejména v souvislosti se zvýšením pokrytí sémantické informace ve FrameNetu.","We introduce the project aimed at enhancing the valency lexicon with missing semantic information – semantic classes and semantic roles. For this purpose, we made use of FrameNet data. We proposed a method of overcoming the problem with finer granularity of word sense disambiguation made in FrameNet. This method is based on the relation of 'Inheritance'. As a result, the 6 'supergroups' of verbs were classified into more coherent semantic classes and semantic roles were assigned to their valency complementations. As to future work, we intend to experiment with other groups of verbs and to increase coverage of semantic information following the progress made in FrameNet."
Článek pojednává o textových konektorech a principu jejich anotace plánované v Pražském závislostním korpusu.,"The paper presents a preliminary study on discourse connectives (DC) in Czech. Aiming to build a computerized language corpus capturing discourse relations in Czech, we base our observations on current foreign projects with the same purpose. In this study, first, the different methods of linguistic analysis of the discourse structure and discourse connectives are described, next, the nature and properties of the group of DCs are analyzed and, finally, the procedure of the annotation of discourse connectives in Prague is presented."
Článek referuje o projektu anotace textových vztahů v Pražském závislostním korpusu.,"The paper reports on a developing project concerning manual annotation of discourse relations for Czech. The aim of the project is to design a language corpus capturing Czech language material from the perspective of text structure and coherence, i.e. focusing on the description of inter-sententional relations. The outcome of the project will be a new annotation layer above the existing layers of annotation (morphology, surface syntax and underlying syntax) in the Prague Dependency Treebank. This discourse annotation should function as a unique source for linguistic research in the field of the discourse analysis and for computational experiments in text processing and summarization as well as machine translation."
"Cílem tohoto článku je empiricky testovat předpovědi formulované v rámci Hypotézy Tranzitivity. Jsou zde diskutovány metodologické problémy předchozích přístupů a nabídnuta některá řešení. Pro testování hypotéz byly použity dva korpusy (Pražský mluvený korpus a Pražský závislostní korpus). Výsledky zpochybňují jednak předpokládaný vliv jazykové formy na tranzitivitu a, co je důležitější, pojem Hypotézy tranzitivity obecně.","The  aim  of  the  article  is  to  test  empirically  predictions  formulated  in  the  Transitivity Hypothesis framework. Methodological problems of the original approach are discussed and some solutions  are  offered.  For  the  testing  of  the  hypotheses  two  corpora  of  Czech  were  used  (Prague Spoken Corpus and Prague Dependency Treebank). The results question both the predicted impact of the language form on transitivity and, more importantly, the concept of the Transitivity Hypothesis in general."
AJAX-CAT je ukázka integrace strojového překladu do webového editoru. Pro danou vstupní větu AJAX-CAT ukazuje návrhy překladů jednotlivých frází a též několik variant dokončení překladu celé věty.,"AJAX-CAT demonstrates an integration of machine translation system into a simple web text editor. For a given input sentence, AJAX-CAT presents a table of translation options of source phrases and also provides a suggestion box with output continuations when the user starts typing the translation."
"Představujeme nástroj pro podporu lidského překladu. Ve webovém rozhraní uživatelům systém nabízí nejen překlady jednotlivých úseků vstupní věty, ale též několik variant, jak v načaté věte pokračovat.","A number of tools to support translators (computer-aided translation, CAT)
exist, as there are many systems of machine translation (MT). So far, the
integration of the two system types was little or none. The aim of this paper is
to examine a tighter coupling of MT and CAT.

We introduce our web-based CAT tool implemented using the modern AJAX technology
that
communicates with Moses MT system on the server side
to provide the translator with suggested translations of individual phrases of
the source sentence as well as several options of the complete continuation of
the output sentence. The suggested continuation is based on what has been
already translated and what the user has already written as the output.
Hopefully, the proposed user interface and the MT system at the back end will
accelerate and simplify the process of translation."
Příspěvek studuje vliv příbuznosti jazyků na kvalitu frázového strojového překladu. Kontrastní dvojice jazyků jsou angličtina-ruština a čeština-ruština.,"In this paper we describe an attempt to compare how relatedness of languages
can influence the performance of statistical machine translation (SMT). We
apply the Moses toolkit on the Czech-English-Russian corpus UMC 0.1 in order to
train two translation systems: Russian-Czech and English-Czech. The quality
of the translation is evaluated on an independent test set of 1000 sentences
parallel in all three languages using an automatic metric (BLEU score) as well
as manual judgments. We examine whether the quality of Russian-Czech is better
thanks to the relatedness of the languages and similar characteristics of word
order and morphological richness. Additionally, we present and discuss
the most frequent translation errors for both language pairs."
"UMC003 je vyčištěná sada tokenizovaných vět určená pro evaluaci strojového překladu mezi češtinou, ruštinou a angličtinou. Tato testovací sada je vhodným doplňkem k trénovací sadě UMC 0.1.","UMC003 is a cleaned tokenized development and test set to accompany the training data in UMC 0.1 aimed at Czech-English-Russian machine translation. For more information about the test set, see the README file in the UMC003 package."
Prezentace probihajiciho projektu anotace jmenne koreference a asociacni anafory na PDT se zvlastnim zretelem k lingvistickym problemum vznikajicim pri anotaci.,"This paper describes the scheme of annotation of coreference in PDT. We represent the structure of annotation stages, which consist of grammatical coreference annotation (the antecedent can be calculated from the grammatical rules of  the language), textual pronominal coreference and the extended scheme of textual coreference, which includes noun anaphoric relations and bridging anaphora. We suggest and discuss coreference relations in the extended coreference scheme, examine some complications, which occur by annotation and present our first results."
Prehled anotace koreference a asociacni anafory na tektogramaticke rovine se zvlastnim zretelem k lingvistickym problemum vznikajicim pri anotaci.,"The article describes the annotation of coreference and bridging anaphora on the tectogammatical level of PDT, with special reference to liguistic problems, which occur during the annotation."
Představujeme probíhající projekt anotace rozšířené jmenné koreference a bridging anafory v Pražském závislostním korpusu. Popisujeme anotační schéma s přihlédnutím k jazykové klasifikaci koreferenčních a bridging vztahů a zaměřujeme se rovněž na podrobnosti průběhu anotace z technického hlediska. Představujeme metody usnadnění anotace - pomocí předanotace a několika praktických pomůcek implementovaných v anotačním nástroji. Naše metoda měření mezianotátorské shody je zaměřena na zdokonalení anotačních instrukcí; uvádíme výsledky tří měření této shody.,The present paper outlines an ongoing project of annotation of the extended nominal coreference and the bridging anaphora in the Prague Dependency Treebank. We describe the annotation scheme with respect to the linguistic classification of coreferential and bridging relations and focus also on details of the annotation process from the technical point of view. We present methods of helping the annotators – by a pre-annotation and by several useful features implemented in the annotation tool. Our method of the inter-annotator agreement is focused on the improvement of the annotation guidelines; we present results of three subsequent measurements of the agreement.
"Článek popisuje anotační schéma rozšířené jmenné koreference a bridging anafory v Pražském závislostním korpusu. Porovnáváme náš přístup s již existujícími přístupy ve vztahu k jazyku, pro který je to které schéma použito. Jmenujeme anotační principy a ukazujeme jejich aplikaci na rozsáhlou anotaci českých textů. Dále uvádíme vlastní rozdělení typů koreferenčních a bridging vztahů a věnujeme se některým problematickým otázkám této oblasti. Popisujeme rovněž automatickou předanotaci a několik pomocných vlastností anotačního nástroje, jako je zachovávání koreferenčních řetězců, zvýrazňování kandidátů pro antecedenty apod. Uvádíme řadu statistických údajů získaných na doposud anotované části Pražského závislostního korpusu. Rovněž přinášíme první výsledky měření mezianotátorské shody a objasňujeme nejčastější případy neshody.","The present paper outlines the coding scheme for annotating extended nominal coreference and bridging relations in the Prague Dependency Treebank. We compare our annotation scheme to the existing ones with respect to the language to which the scheme is applied. We identify the annotation principles and demonstrate their application to the large-scale annotation of Czech texts. We further present our classification of coreferential relations and bridging relations types and discuss some problematic aspects in this area. An automatic pre-annotation and some helpful features of the annotation tool, such as maintaining coreferential chain, underlining candidates for antecedents, etc. are presented and discussed. Statistical evaluation is performed on the already annotated part of the Prague Dependency Treebank. We also present the first results of the inter-annotator agreement measurement and explain the most frequent cases of disagreement."
"V posledních letech výzkumu v oblasti vyhledávání informací je
věnována značná pozornost metodám založeným na jazykovém modelování.
I přesto, že tento přístup dovoluje použití libovolného jazykového modelu,
většina publikovaných experimentů byla prováděna s klasickým n-gramovým
modelem (mnohdy pouze s unigramovým modelem). Cílem diplomové práce
je navrhnout, implementovat a vyhodnotit (na českých datech) metodu, která
by pravděpodobnostní model obohatila o použití syntaktické informace získané
automaticky (strojově) z dokumentů i dotazů. V předkládané práci se pokusíme
vhodným způsobem zavést syntaktickou informaci do jazykových modelů a ex-
perimentálně srovnáme navržený přístup s výsledky unigramového a bigramo-
vého povrchového modelu. Kromě využití syntaktické informace se zaměříme
také na vliv vyhlazování, stemmingu, lemmatizace, použití stopwords a me-
tody rozšiřování dotazů – pseudo relevance feedback. Provedeme také detailní
analýzu použitých systémů vyhledávání informace a podrobně popíšeme jejich
vlastnosti.","In the last years, application of language modeling in infor-
mation retrieval has been studied quite extensively. Although language models
of any type can be used with this approach, only traditional n-gram models
based on surface word order have been employed and described in published
experiments (often only unigram language models). The goal of this thesis is
to design, implement, and evaluate (on Czech data) a method which would
extend a language model with syntactic information, automatically obtained
from documents and queries. We attempt to incorporate syntactic information
into language models and experimentally compare this approach with uni-
gram and bigram model based on surface word order. We also empirically
compare methods for smoothing, stemming and lemmatization, eﬀectiveness
of using stopwords and pseudo relevance feedback. We perform a detailed ana-
lysis of these retrieval methods and describe their performance in detail."
"Tento článek se zabývá rozpoznáváním pojmenovaných
entit v českých textech. Popisuje nový korpus s ručně značkovanými entitami ve dvouúrovňovém anotačním schématu. Data byla použita pro trénování rozpoznávače pojmenovaných entit, který je založen na klasifikátoru SVM.","This paper deals with recognition of named entities in Czech texts. We present a recently released corpus of Czech sentences with manually annotated named entities, in which a rich two-level classification scheme was used.  There are around 6000 sentences in the corpus with roughly 33000 marked named entity instances. We use the data for training and evaluating a named entity recognizer based on Support Vector Machine classification technique. The presented  recognizer outperforms the results previously reported for NE recognition in Czech."
"Czech Named Entity Corpus 1.0 je první veřejně přístupný korpus českých vět, v nichž byly ručně vyznačeny a klasifikovány pojmenované entity (nejčastěji se jedná o vlastní jména).","The Czech Named Entity Corpus 1.0 is the first publicly available corpus providing a large body of manually annotated named entities in Czech sentences, including a fine-grained classification."
"Špatné zprávy o dosavadní užitečnosti hloubkového rozboru pro MT, nápady rysů, jimiž by se dal obohatit mělký překlad.","Bad news about the utility of deep syntax in MT so far, ideas on adding more features to shallow MT systems."
"Studie se zabývá vzájemným vztahem mezi lingvistickými teoriemi, daty a aplikacemi. Soustředuje se přitom na jednu konkrétní teorii, teorii Funkčního generativního popisu, jeden konkrétní typ dat, totiž slovesné valenční rámce, a jednu konkrétní aplikaci: strojový překlad z angličtiny do češtiny.","This study explores the mutual relationship between linguistic theories, data
and applications. We focus on one particular theory, Functional Generative
Description (FGD), one particular type of linguistic data, namely valency
dictionaries and one particular application: machine translation (MT) from
English to Czech.

First, we examine methods for automatic extraction of verb valency dictionaries
based on corpus data. We propose an automatic metric for estimating how much
lexicographers' labour was saved and evaluate various frame extraction
techniques using this metric.

Second, we design and implement an MT system with transfer at
various layers of language description, as defined in the framework of FGD. We
primarily focus on the tectogrammatical (deep syntactic) layer.

Third, we leave the framework of FGD and experiment with a rather direct,
phrase-based MT system. Comparing various setups of the system and
specifically treating target-side morphological coherence, we are
able to significantly improve MT quality and out-perform a commercial MT
system within a pre-defined text domain.

The concluding chapter provides a broader perspective on the utility of lexicons
in various applications, highlighting the successful features."
Popularizační seminář pro korespondenční seminář Pralinka na téma strojového překladu.,A quick introduction to problems of machine translation for the participants of Pralinka corespondence series.
Korpus výstupů čtyř systémů strojového překladu s ručně vyznačenými chybami a klasifikací chyb.,A collection of outputs of 4 machine translation systems. Errors in the output are manually flagged and classified.
QuickJudge je minimalistický nástroj pro rychlé a pohodlné ruční hodnocení libovolných řádkově-orientovaných výstupů. Primárně byl vyvinut pro účely hodnocení kvality srovnáním či počítáním chyb ve výstupech jednoho či více systémů strojového překladu.,QuickJudge is a tiny tool to simplify the process of manual judging of string segments (e.g. sentences in machine translation output) of one or more competing systems.
Přednáška pro studenty předmětu Nástroje pro strojový překlad o problematice systémů plně automatického překladu.,A talk for students of the subject Nástroje pro strojový překlad on fully automatic machine translation systems.
"Stručný úvod k automatické bohaté anotaci pomocí TectoMT s cílem vyhýbat se bohatým datovým formátům, jak je to jen možné.",A quick introduction to the automatic rich annotation workflow using TectoMT -- while avoiding rich formats whenever possible.
"Trénovatelný tokenizér je schopen tokenizovat a segmentovat většinu jazyků na základě dodané konfigurace a ukázkových dat. Není určen pro jazyky bez jasně odlišených slov, jako je např. čínština.",Trainable Tokenizer is able to tokenize and segment most languages based on supplied configuration and sample data. The tokenizer is not aimed e.g. for Chinese with no explicit delimitation of words.
Popisujeme dva systémy strojového překladu z angličtiny do češtiny užité při soutěži WMT09.,"We describe two systems for English-to-Czech machine translation that took part
in the WMT09 translation task. One of the systems is a tuned phrase-based system
and the other one is based on a linguistically motivated
analysis-transfer-synthesis approach."
Závěrečná zpráva o hloubkově-syntaktickém transferu pro projekt EuroMatrix.,Final technical report on deep syntactic transfer for the EuroMatrix Project.
Zvláštní vydání časopisu PBML zaměřené na volně šiřitelné nástroje pro strojový překlad. Vydání bylo sestaveno u příležitosti týdenního kurzu MT Marathon 2009.,"A special issue of the PBML journal focussed on open-source tools for machine translation, as presented during MT Marathon 2009."
Popisujeme práce na paralelním česko-anglickém korpusu CzEng pro jeho třetí vydání (verze 0.9). V aktuální verzi korpus obsahuje 8.0 mil. paralelních vět (93 mil. anglických slov a 82 mil. českých slov).,"We describe our ongoing efforts in collecting a Czech-English parallel corpus CzEng.
The paper provides full details on the current
version~0.9 and focuses on its new features: (1) data from new sources were added, most importantly a few hundred electronically available books, technical documentation and also some parallel web pages, (2) the full corpus has been automatically annotated up to the tectogrammatical layer (surface and deep syntactic analysis), (3) sentence segmentation has been refined, and (4) several heuristic filters to improve corpus quality were implemented. In total, we provide a sentence-aligned automatic parallel treebank of 8.0 million sentences, 93 English and  82 Czech words. CzEng~0.9 is freely available for non-commercial research purposes."
CzEng 0.9 je třetí vydání paralelního česko-anglického korpusu. V aktuální verzi korpus obsahuje 8.0 mil. paralelních vět (93 mil. anglických slov a 82 mil. českých slov).,"CzEng 0.9 is the third release of a sentence-parallel Czech-English corpus compiled at the Institute of Formal and Applied Linguistics (ÚFAL) freely available for non-commercial and research purposes.

CzEng 0.9 contains 8.0 million parallel sentences (93 million English and 82 million Czech tokens) from seven different types of sources automatically annotated at surface and deep (a- and t-) layers of syntactic representation."
"Popisujeme naši snahu zlepšit dřívější výsledky strojového překladu z angličtiny do hindštiny. Využíváme dva frázové open-source systémy: Moses a Joshua. Testujeme několik přístupů k morfologickému značkování: od automatických slovních tříd přes segmentaci na kmen a sufix až k POS taggeru. Experimentujeme také s faktorizovanými jazykovými modely. Vyhodnocujeme různé kombinace trénovacích dat a dalších existujících anglicko-hindských jazykových zdrojů. Pokud je nám známo, BLEU skóre, kterého jsme dosáhli, je v současnosti nejlepší publikovaný výsledek na testovacích datech IIIT-TIDES.","We describe our attempt to improve on previous English to Hindi machine translation results, using two open-source phrase-based MT systems: Moses and Joshua. We use several approaches to morphological tagging: from automatic word classes, through stem-suffix segmentation, to a
POS tagger. We also experiment with factored language models. We evaluate various combinations of training data sets and other existing English-Hindi resources. To our knowledge, the BLEU score we obtained is currently the best published result for the IIIT-TIDES dataset."
"Česko-anglických 515 vět, jak byly ručně zarovnány po slovech a použity v publikaci Bojar, Prokopová. LREC 2006. Data zveřejňujeme až v roce 2009.","Czech-English 515 parallel sentences, manually aligned at the word level, as used by Bojar and Prokopová in paper at LREC 2006. We release the data in 2009."
"Jedenáctý rok v řadě je konference CoNLL doprovázena společnou úlohou, jejímž úkolem je podpořit aplikace na zpracování přirozeného jazyka a ohodnotit je za standardních podmínek. V roce 2009 byla úloha zasvěcena spojenému parsingu syntaktických a sémantických závislostí v několika jazycích. Úloha kombinuje zadání z předchozích pěti let v jedinečném závislostním formalizmu podobném úloze z roku 2008. V tomto článku definujeme společnou úlohu, popisujeme, jak byly vytvářeny sady dat a jaké jsou jejich kvantitativní vlastnosti, oznamujeme výsledky a shrnujeme přístupy soutěžících systémů.","For the 11th straight year, the Conference
on Computational Natural Language Learn-
ing has been accompanied by a shared task
whose purpose is to promote natural language
processing applications and evaluate them in
a standard setting. In 2009, the shared task
was dedicated to the joint parsing of syntac-
tic and semantic dependencies in multiple lan-
guages. This shared task combines the shared
tasks of the previous five years under a unique
dependency-based formalism similar to the
2008 task. In this paper, we define the shared
task, describe how the data sets were created
and show their quantitative properties, report
the results and summarize the approaches of
the participating systems."
"Česká testovací (dev i eval) data pro CoNLL 2009 Shared Task. Data jsou vygenerována z PDT 2.0.
LDC2009E35B",Czech testing (development and evaluation) data for CoNLL 2009 Shared Task. The data are generated from PDT 2.0. LDC2009E35B
Česká trénovací data pro CoNLL 2009 Shared Task. Data jsou vygenerována z PDT 2.0. LDC2009E34B,Czech training data for CoNLL Shared Task. The data are generated from PDT 2.0. LDC catalog number: LDC2009E34B
"Česká ukázková data pro CoNLL 2009 Shared Task. Data jsou vygenerována z PDT 2.0.
LDC2009E32B","Czech sample data for CoNLL 2009 Shared Task. The data are generated from PDT 2.0.
LDC2009E32B"
"Projekt rekonstrukce mluvené řeči (pro češtinu a angličtinu) začal na pracovišti UFAL současně s projektem PIRE v roce 2005 a postupně se rozvinul z prvních návrhů k vytvoření software, anotačních manuálů a samotné anotaci dat. PDTSL je součástí korpusů a zdrojů kolem Pražského závislostního korpusu, ke kterému přidává úroveň mluveného jazyka.","The project of speech reconstruction of Czech and English has been started at UFAL together with the PIRE project in 2005, and has gradually grown from ideas to (first) annotation specification, annotation software and actual annotation. It is part of the Prague Dependency Treebank family of annotated corpus resources and tools, to which it adds the spoken language layer(s)."
"Jedná se o data z anglického dialogového korpusu NAP, který vznikl v rámci projektu Companions. Jsou to rozhovory nad fotografiemi. Na tomto korpusu byla prováděna ruční anotace tzv. speech reconstruction, rekonstrukce mluvené řeči.","This release contains the manual speech reconstruction annotation of about 260k tokens of the NAP corpus. The NAP corpus is a corpus of dialogs over personal photograph collections, recorded for the Companions project."
"Na CD se nachází 10 000 manuálně tektogramaticky anotovaných vět z Penn Treebanku, editor a dokumentace.","This CD presents part of the Prague English Dependency Treebank (PEDT). PEDT is the manual tectogrammatical (syntactico-semantic) annotation of texts from the Wall Street Journal - Penn Treebank III. The present CD (PEDT 1.0) comprises approx. 10,000 annotated and checked trees, which is about 20% of the original WSJ-PTB. The following components are included:

    * manually annotated data, integrated valency lexicon Engvallex
    * the valency lexicon Engvallex in printable form (latest revision: January 2009)
    * the ready-to-install package of the tree editor/viewer TREd
    * documentation
    * specification of the annotation format (Prague Markup Language)"
"V článku je navrženo zařazení české 2. osoby zdvořilé (vykání) jako paradigmatické kategorie českého slovesa, protože v některých tvarech vykazuje zvláštní shodu. Klade se otázka, zda v plurálu, kde se formální rozdíl neprojevuje, jde o homonymii nebo o neutralizaci. Na korpusových datech se zkoumají ukazatelé zdvořilostní formy.","The author claims that the Czech polite forms (so-called „vykání“) for addressing the 2nd person should  be undestood as a legitimate part of the Czech conjugation paradigm. If we address a single person in a polite way, some Czech analytical verb forms exhibit „hybrid“ agreement (auxiliaries are in plural, while participle form is in singular). However, the paradigm for singular and plural polite forms is not symmetrical. The question, whether 2nd person plural polite forms are ambiguous (between  the polite meaning and 2nd plural non-polite), or whether the semantic distinction „polite – non-polite“ is neutralized in plural, is open for further discussion."
"Český subjektový infinitiv se probírá jako typ kontrolované struktury. Analyzují se formy a distribuce kontroloru  v řídící predikaci jako žto antecedentu (nevyjádřeného) subjektového infinitivu. V češtině jsou předmětem analýzy tři typy konstrukcí (kromě sloves typu baví ho, zajímá ho jsou to věty s verbonominálním přísudkem substantivníma a djektivním).","The Czech infinitive in the position of subject is analyzed as a type of controlled construction. In three types of constructions (verbs of evaluation of the state, verbonominal predicates with nouns and adjectives)the form and distribution of their respective controller is described."
Korpusová anotace je důležitou součástí lingvistické analýzy a počítačového zpracování jazyka. Tento článek se zabývá problémy spojenými se syntaktickou anotací mluvených textů na pozadí syntaktické anotace ČAKu.,"Corpus annotation plays an important role in linguistic analysis and computa-tional processing of both written and spoken language. Syntactic annotation of spoken texts becomes clearly a topic of considerable interest nowadays, driven by the desire to improve auto-matic speech recognition systems by incorporating syntax in the language models, or to build language under-standing applications. Syntactic anno-tation of both written and spoken texts in the Czech Academic Corpus was created thirty years ago when no other (even annotated) corpus of spoken texts has existed. We will discuss how much relevant and inspiring this annotation is to the current frameworks of spoken text annotation."
"TectoMT je široce modulární nástroj pro zpracování přirozeného jazyka (NLP, natural language processing tool).","TectoMT is a highly modular NLP (Natural Language Processing) software system implemented in Perl programming language under Linux. It is primarily aimed at Machine Translation, making use of the ideas and technology created during the Prague Dependency Treebank project. At the same time, it significantly facilitates and accelerates development of software solutions of many other NLP tasks, especially due to re-usability of the numerous integrated processing modules (called blocks), which are equipped with uniform object-oriented interfaces."
"Rozšiřující modul pro TrEd, který umožní zanalyzovat zadanou českou větu na morfologické, analytické a tektogramatické rovině.","Tred extension that provides a simple TectoMT-based Czech analyzer producing tectogrammatical, analytical and morphological layers for a given Czech sentence."
Článek pojednává o možnosti využití skrytých stromových markovovských modelu ve fázi transferu ve strojovém překladu využívajícím tektogramatickou rovinu.,"We would like to draw attention to Hidden Markov Tree Models (HMTM), which are to our knowledge still unexploited in the field of Computational Linguistics, in spite of highly successful Hidden Markov (Chain) Models. In dependency trees, the independence assumptions made by HMTM correspond to the intuition of linguistic dependency. Therefore we suggest to use HMTM and tree-modified Viterbi algorithm for tasks interpretable as labeling nodes of dependency
trees. In particular, we show that the transfer phase in a Machine Translation system based on tectogrammatical dependency trees can be seen
as a task suitable for HMTM. When using the HMTM approach for the English-Czech translation,
we reach a moderate improvement  over the baseline."
Stručně se připomínají zásady Pražské školy a ukazuje se jejich důležitost pro současné lingvistické bádání.,A brief characterization of the Prague School is presented on the background of the present day development of lingustic theories.
Probírají se nejrůznější aspekty autorovy vědecké dráhy v lingvistice.,Most different aspects of the author`s linguistic carreer are discussed.
"Vztah mezi jádrem jazyka, relativně jednoduše strukturovaným, a jeho složitou periferií lze chápat na základě pojmu příznakovosti. Jádro můžeme vidět v aktuálním členění a v později vyvinuté syntaktické závislosti (valenci).","The distinction between the core of language, patterned in a relatively simple way, and its complex periphery can be expressed in terms of the notion of markedness. If the properties of the language core are to be explained as attributable to general principles, then the core of language may be seen as based on information structure, and syntactic dependency, or valency, might be taken to be a later development."
"Ve stati je shrnut a vysoko hodnocen vědecký přínos jednoho z pionýrů strojového překladu nejen v České republice, Zdeňka Kirschnera, u příležitosti jeho úmrtí.",The scientific contribution of one of the pioneers in the field of machine translation is summarized at the occasion of the scientists' death.
"Několik námětů, které je třeba řešit v budoucím vývoji anotačních schémat pro korpusy textů.","Some issues to be solved in the future development of annotation scenaria
for text corpora."
"Pražská lingvistická škola je jedním ze základních směru evropského strukturalismu, který se vyznačuje vedle strukturního pohledu na jazykový systém také zohledněním komunikativní funkce jazyka. Tyto dva principy jsou ve stati uplatněny na oblast formálního popisu jazyka a na anotování jazykových korpusů na různých rovinách popisu.",Prague School of Linguistics is one of the main schools of linguistic thought distinguished first of all by its structural and functional approach to language system. In the paper these two viewpoints are discussed in their contribution to a formal description of language and to different levels of annotation of linguistic resources.
Jedním ze základních principů přístupu Pražského lingvistického kroužku bylo důsledné rozlišování jazykové formy a funkce. Ve stati se nejprve shrnují klasické pohledy na tuto distinkci a poté se uplatňuje tento pohled na rozbor aktuálního členění větného.,One of the main tenets of the Prague School of Linguistics was a clear distinction to be made between form and function. The paper first refers to the classical statements about this distinction and then discusses this opposition from the viewpoint of topic-focus articulation of the sentence.
"Aktuální členění věty je třeba zachycovat jako jeden ze základních aspektů hloubkové stavby věty, tj. jejího jazykového významu. Jeho primární výrazové prostředky jaou slovosled a větná intonace.","Information structure has to be reflected as a fundamental aspect of the underlying structure of the setence, i.e. of its literal meaning. Its primary means of expression may be seen in the word order and sentence intonantion."
"Tento softwarový balíček poskytuje vizualizaci pro data z CoNLL-2009-ST v TrEdu, konverzní skripty z CoNLL-2009-ST formátu do formátu PML a rozsšíření pro TrEd, umožňující anotaci predikátů a argumentů.","This software package provides visualization of CoNLL-2009-ST data in TrEd, scripts (for Linux and similar systems) for converting from the CoNLL-2009-ST format to the PML format and a TrEd annotation mode for predicate-argument annotation."
"Sada nástrojů pro práci s datovým formátem PML pro reprezentaci lingvistické anotace jazykových dat. Sada zahrnuje validátor, sadu konverzních skriptů z jiných formátů, programy pro management dat, úpravy schématu, knihovny pro Perl, a další nástroje.","A set of tools for working with the PML data format used for capturing linguistic annotations. The toolkit consists of validators, conversion scripts for several other formats, data management tools, schema processing tools, Perl API, and various other tools."
"PML-TQ je systém pro vyhledávání nad lingvisticky anotovanými korpusy závislostních či složkových stromů ve formátu PML. Systém definuje velmi silný dotazovací jazyk. Je implementován pomocí client-server architektury, s použitím SQL databáze na straně serveru a zahrnuje webové a CLI rozhraní a grafické rozhraní zabudované do editoru TrEd. Jako rozsíření TrEdu je dále dostupný čistě klientský vyhledávací systém nad stejným dotazovacím jazykem, umožňující prohledávat lokální soubory.","PML-TQ is a search system for linguistic TreeBanks in PML format. The system defines a powerfull query language, uses a client server architecture (with SQL database backend on the server side) and provides a command-line and a simple web-based search client. The system also includes a graphical client for PML-TQ and client-side PML-TQ search engine, allowing the users to use PML-TQ queries on their local data. The GUI and client-side search engine are distributed separately as extensions to the tree editor TrEd."
"Článek představuje systém pro dotazování nad treebanky. Systém se skládá ze silného dotazovacího jazyka s přímou podporou dotazů napříč anotačními rovinami, z klientského rozhraní s grafickým editorem dotazů a vizualizací výsledků, a ze dvou zaměnitelných dotazovacích nástrojů: velmi výkonného nástroje nad relační databází (vhodného pro statická data) a pomalejšího, ale paralelizovatelného nástroje, který pracuje přímo nad souboru treebanku (vhodného pro ""živá"" data).","This paper presents a system for querying
treebanks. The system consists of a powerful query language with natural support for cross-layer queries, a client interface with a graphical query builder and visualizer of the results, a command-line client interface, and two substitutable query engines: a very efﬁcient engine using a relational database (suitable for large static data), and a slower, but paralel-computing enabled, engine operating on treebank ﬁles
(suitable for “live” data)."
"Tato kniha je věnovaná empirické studii lexikálních asociačních měr a jejich aplikaci v úloze automatické extrakce kolokací. Práce obsahuje vyčerpávající seznam 82 lexikálních asociačních měr ajejich evaluaci na celkem čtyřech referenčních datových množinách: závislostních bigramech z ručně anotovaného Pražského závislostního korpusu, povrchové bigramy ze stejného korpusu, instance prvků předchozí množiny z Českého národního korpusu opatřeného automatickou lemmatizací a morfologickým značkováním a vzdálenostními verbnominálními bigramy z automaticky značko­vaného švédského korpusu Parole. Kolokační kandidáti v referenčních  množinách byli manuálně anotováni jako kolokace nebo nekolokace. Použité evaluační schéma je založeno na měření kvality seřazení kolokačních kandidátů dle jejich pravděpodobnosti tvořit kolokaci. Metody jsou porovnány pomocí precision-recall křivek a hodnot mean average precision, které jsou převzaty  z oboru vyhle­dávání informací. Provedeny byly i testy signifikance výsledků. Dále je zkoumána možnost kombi­nování lexikálních asociačních měr a presentovány výsledky několika kombinačních metod, jejichž použití vedlo k výraznému zlepšení úspěšnosti řešení této úlohy. Dále je v práci navržen algoritmus významně redukující složitost použitých kombinačních modelů bez statisticky významného snížení jejich úspěšnosti.","This publication is devoted to an empirical study of lexical association measures and their application to collocation extraction. It presents a comprehensive inventory of lexical association measures and their evaluation on four reference data sets of collocation candidates: Czech dependency bigrams from the Prague Dependency Treebank, surface bigrams from the same source, instances of the latter from the Czech National Corpus, and Swedish distance verb-noun combinations obtained from the PAROLE corpus. The collocation candidates in the reference data sets were manually annotated and labeled as collocations or non-collocations by expert linguists. The evaluation scheme applied in this work is based on measuring the quality of ranking collocation candidates according to their chance to form collocations. The methods are compared by precision-recall curves, mean average precision scores, and appropriate tests of statistical significance. Further, the study focuses on the possibility of combining lexical association measures and discusses empirical results of several combination methods that significantly improve state of the art in collocation extraction. The work is concluded by a description of a model reduction algorithm that significantly reduces the number of combined measures without any statistically significant difference in performance."
"Důležitou součástí Pražského závislostního korpusu je valenční slovník. Slovník obsahuje 5300 sloves s 8200 valenčními rámci, které jsou propojeny s korpusem. Reprezentace valenčního rámce je plně formalizována. Tento příspěvek je orientován na formální popis forem, kterých nabývají argumenty sloves v různých sekundárních diatezích, jako je  například pasivizace (pasivum opisné a zvratné), rezultativ (sloveso mít, dostat), dispoziční modalita.  Článek detailně  popisuje fungování jednotlivých transformačních pravidel pro příslušné změny forem.","As an important part of the Prague Dependency Treebank project a valency lexicon is being distributed. In this lexicon, more than 5300 verb entries are fully formally represented, with more than 8200 valency frames for verb senses included. Moreover, the valency frames are interlinked with the Prague Dependency Treebank corpus, effectively providing a verb sense distinction and annotation for every occurrence of a verb in the corpus. More than 100,000 verb occurrences are annotated in this way. The valency frame representation is fully formalized. In this contribution, we will concentrate on the formal description of the form of the verb"
Softwarový nástroj zprostředkující formou webového rozhraní editaci a vyhledávání v přepisech audio-visuálních nahrávek dialogů. Vyhledané úseky textu je možné přehrávat a analyzovat pomocí webového prohlížeče.,A software tool allowing editing and searching in the transcripts of audio-visual recordings of dialogues. The dynamic web application provides access for registered users to the digitised archive. Playing and exploring of selected parts is possible in the web browser.
"V knize studujeme anotaci Pražského závislostního korpusu 2.0 a vytváříme seznam požadavků kladených na dotazovací jazyk, který by umožnil vyhledávání a studium všech lingvistických jevů anotovaných v tomto korpusu. Navrhujeme rozšíření dotazovacího jazyka existujícího nástroje Netgraph 1.0 a ukazujeme, že takto rozšířený dotazovací jazyk splňuje definovaný seznam požadavků. Ukazujeme rovněž, jak je pomocí tohoto jazyka možno vyhledávat všechny zásadní lingvistické jevy v korpusu anotované. Navržený dotazovací jazyk byl rovněž implementován – představujeme vyhledávací nástroj a pojednáváme o jeho datovém formátu. Dotazovací jazyk je porovnán s několika dalšími dotazovacími jazyky. Ukazujeme rovněž, do jaké míry jsou vlastnosti tohoto jazyka využívány skutečnými uživateli a co tito uživatelé vyhledávají. Řada dalších informací je k dispozici v přílohách.","In the book, we study the annotation of the Prague Dependency Treebank 2.0 and assemble a list of requirements on a query language that would allow searching for and studying all linguistic phenomena annotated in the treebank. We propose an extension to the query language of the existing search tool Netgraph 1.0 and show that the extended query language satisfies the list of requirements. We also show how all principal linguistic phenomena annotated in the treebank can be searched for with the query language. The proposed query language has also been implemented – we present the search tool as well and talk about the data format for the tool. The query language is compared to several other query languages. We also show to what extent the features of the query language are put to use by the users and what the users really do search for. Much additional information can be found in Appendixes."
"Implementace originálního lingvistického modelu Funkční arabské morfologie, která zahrnuje jak deklarativní definici systému v jazyce Haskell, tak i rozsáhlý arabský morfologický slovník. Publikováno pod licencí GNU GPL.
- první verze online interface
- základní textové a API rozhraní
- základní analýza sekvencí slov","An implementation of the original linguistic model of the Functional Arabic Morphology includes both the declarative definition of the system in Haskell, and an extensive Arabic morphologic dictionary. Published under the GNU GPL license.
- first version of the online interface
- basic text interface and API
- basic analysis of word sequences"
"V článku popisujeme náš systém, se kterým jsme se zúčastnili CoNLL 2009 Shared Task. Systém zahrnuje tři sřetězené komponenty: generativní závislostní syntaktický analyzátor (parser), klasifikátor syntaktických závislostí a sémantický klasifikátor. Výsledky pokusů ukazují, že náš systém dosahuje tzv. labeled macro F1 score (skóre makro-F1 se zohledněním značek) mezi 43,50 % (čínština) a 57,95 % (čeština), s průměrnou hodnotou 51,07 %.","We describe our CoNLL 2009 Shared Task system in the present paper. The system includes three cascaded components: a generative dependency parser, a classifier for syntactic dependency labels and a semantic classifier. The experimental results show that the labeled macro F1 scores of our system on the joint task range from 43.50% (Chinese) to 57.95% (Czech), with an average of 51.07%."
"DZ Interset je prostředek pro konverzi mezi různými sadami značek pro počítačové zpracování přirozených jazyků. Základní myšlenka je podobná strojovému překladu přes interlingvu. V DZ Intersetu je definována sada rysů, které lze zakódovat pomocí jednotlivých sad značek. Sada rysů je co možná nejuniverzálnější. Nemusí zakódovat vše, co je obsaženo v libovolných sadách značek, ale měla by kódovat veškerou informaci, ke které uživatelé mohou chtít přistupovat a/nebo je přenášet z jedné sady značek do druhé.",DZ Interset is a means of converting among various tag sets in natural language processing. The core idea is similar to interlingua-based machine translation. DZ Interset defines a set of features that are encoded by the various tag sets. The set of features should be as universal as possible. It does not need to encode everything that is encoded by any tag set but it should encode all information that people may want to access and/or port from one tag set to another.
"Morfologické značky jsou důležitou součástí anotace většiny korpusů. Bohužel se však v různých korpusech používají různé sady značek, a to i pokud jde o tentýž jazyk. Převody značek z jedné sady do druhé jsou obtížné a jejich implementace je obvykle ušitá na míru konkrétní dvojici sad značek. Zde naproti tomu navrhujeme univerzální přístup, který umožňuje jednou investované úsilí využít při pozdějších převodech do jiných formalismů. Prezentujeme také nepřímé vyhodnocení v kontextu syntaktické analýzy.","Part-of-speech or morphological tags are important means of annotation in a vast number of corpora. However, different sets of tags are used in different corpora, even for the same language. Tagset conversion is difficult, and solutions tend to be tailored to a particular pair of tagsets. We propose a universal approach that makes the conversion tools reusable. We also provide an indirect evaluation in the context of a parsing task."
"DZ Parser je program, který čte předzpracovanou větu v přirozeném jazyce a vrací závislostní strom, který popisuje syntaxi vstupní věty. Předpokládá, že jeho vstup byl tokenizován, morfologicky označkován a uložen ve formátu CSTS Pražského závislostního korpusu. Výstup je v tomtéž formátu. (Poznámka: Nyní jsou přiloženy i nástroje pro konverzi z a do formátu CoNLL shared task.)","DZ parser is a program that reads a pre-processed natural language sentence and returns a dependency tree describing the syntax of the input sentence. It assumes its input has been tokenized, morphologically annotated, morphologically disambiguated, and saved in the CSTS format (Prague Dependency Treebank). The output is in the same format. (Note: Tools for conversion from and to the CoNLL shared task format are now included.)"
"Představujeme náš systém použitý v soutěži ICON 2009 NLP Tools: závislostní syntaktická analýza hindštiny, bengálštiny a telugštiny. Systém se skládá ze tří existujících, volně dostupných závislostních parserů, z nichž o dvou (MST a Malt) je známo, že dokáží generovat špičkové struktury na datech pro jiné jazyky. Zkoumáme různá nastavení jednotlivých parserů, abychom je přizpůsobili zmíněným třem indickým jazykům, a pomocí hlasování z nich vytváříme jeden superparser.","We present our system used for participation in the ICON 2009 NLP Tools Contest: dependency parsing of Hindi, Bangla and Telugu. The system consists of three existing, freely available dependency parsers, two of which (MST and Malt) have been known to produce state-of-the-art structures on data sets for other languages. Various settings of the parsers are explored in order to adjust them for the three Indian languages, and a voting approach is used to combine them into a superparser."
"Morseus implementuje jednoduchou metodu neřízené morfematické segmentace slov v neznámém jazyce. Není k tomu potřeba nic kromě neanotovaného korpusu (nebo seznamu slov) v daném jazyce. Algoritmus identifikuje části slov, které se opakují v řadě slov, a interpretuje je jako kandidáty na morfémy (předpony, kmeny a přípony).","Morseus implements a simple method of unsupervised morpheme segmentation of words in an unknown language. All that is needed is a raw text corpus (or a list of words) in the given language. The algorithm identifies word parts occurring in many words and interprets them as morpheme candidates (prefixes, stems and suffixes)."
"Popisujeme jednoduchou metodu neřízené morfematické segmentace slov v neznámém jazyku. Vše, co potřebujeme, je korpus prostého textu (nebo seznam slov) daného jazyka. Algoritmus identifikuje části slov, které se opakují v mnoha slovech, a interpretuje je jako kandidáty na morfémy (předpony, kmeny a přípony). Hlavní inovací ve srovnání s [1] je nové zpracování předpon. Po odfiltrování falešných hypotéz se seznam morfémů aplikuje na segmentaci vstupních slov. Prezentujeme oficiální výsledky Morpho Challenge 2008 spolu s některými doplňkovými pokusy. Zpracování předpon zlepšilo F-skóre o 5 až 11 bodů pro němčinu, finštinu a turečtinu, ale zhoršilo angličtinu a arabštinu. V závěru rozebíráme chyby s ohledem na zvolenou vyhodnocovací metodu.","We describe a simple method of unsupervised morpheme segmentation of words in an unknown language. All that is needed is a raw text corpus
(or a list of words) in the given language. The algorithm identifies word parts occurring in many words and interprets them as morpheme candidates (prefixes, stems and suffixes). New treatment of prefixes is the main innovation in comparison
to [1]. After filtering out spurious hypotheses, the list of morphemes is applied to segment input words. Official Morpho Challenge 2008 evaluation is given together with some additional experiments. Processing of prefixes improved
the F-score by 5 to 11 points for German, Finnish and Turkish, while it failed to improve English and Arabic. We also analyze and discuss errors with respect to the evaluation method."
"Podáme zprávu o experimentech se strojovým překladem z angličtiny do hindštiny pomocí překladače Moses. Vyhodnotíme vliv přídavných trénovacích dat z jiné domény, jak paralelních, tak jednojazyčných hindských, a experimenty se třemi metodami vylepšení slovosledu: standardní slovosledný model Mosese, pravidlové předzpracování a jazykově nezávislou identifikaci přípon.","We present experiments with a Moses-based English-to-Hindi translation system.
We evaluate the impact of additional out-of-domain training data, both
parallel and Hindi-only, and experiment with three methods for improving word
order: standard Moses reordering model, rule-based pre-processing and
language-independent suffix identification."
"PlayCoref je návrh internetové jazykové hry zaměřené na získávání velkého objemu textu s anotací koreference. Detailně popisujeme rozličné aspekty návrhu hry a vlastnosti, které mají vliv na kvalitu získaných anotací.",PlayCoref is a concept of an on-line language game designed to acquire a substantial amount of text data with the coreference annotation. We describe in detail various aspects of the game design and discuss features that affect the quality of the annotation.
"Předkládáme návrh hry PlayCoref, jejímž cílem je získat velké množství textových dat opatřených anotací koreference.
Přinášíme popis návrhu hry, který sestává ze strategie, instrukcí pro hráče, výběru a přípravy vstupních dat a funkce pro výpočet skóre.","We propose the PlayCoref game, whose purpose is to obtain substantial amount of text data with the coreference annotation.
We provide a description of the game design that covers the strategy, the instructions for the players, the input texts selection and preparation, and the score evaluation."
"Překlady se budou používat výhradně v projektech tzv. automatického neboli strojového překladu mezi češtinou a angličtinou. Budou použity a zveřejněny pouze v elektronické formě, a to navíc způsobem, který umožní tzv. strojové učení. Přeložené texty tedy nebudou sloužit takovým účelům, kdy jde o informační obsah textu, a ani nebudou touto formou (na „papíře“, na internetu v textové podobě atd.) zveřejněny.
Metody strojového učení jsou do jisté míry tolerantní k nepřesnému překladu (koneckonců ani originální text není někdy úplně „hezky“ anglicky), avšak systematické chyby jsou již zavádějící a v textech bychom je měli neradi.","PCEDT is planned to be a corpus of syntactically annotated parallel texts (in English and Czech) intended chiefly for machine translation experiments. The texts for PCEDT were taken from Penn Treebank, which means there are mostly economical articles from the Wall Street Journal. 2312 documents were used in PCEDT (approximately 49,000 sentences) that are manually annotated with constituent trees in Penn Treebank. For the Czech part of PCEDT, the English texts have to be translated into Czech. This book contents the guidelines for translators."
"Článek popisuje některé organizační aspektu budování rozsáhlého korpusu s bohatou lingvistickou anotací, jako příklad slouží PCEDT. Zdůrazňuje nevyhnutelnost rozdělení anotačního postupu do několika fází a představuje systém automatických kontrol korektnosti anotace. Popisuje také několik způsobů měření a evaluace anotace a anotátorů (mezianotátorská shoda, chybovost a výkon).","In this paper, we present some organizational aspects of building of a large corpus with rich linguistic annotation, while Prague Czech-English Dependency Treebank (PCEDT) serves as an example. We stress the necessity to divide the annotation process into several well planed phases. We present a system of automatic checking of the correctness of the annotation and describe several ways to measure and evaluate the annotation and annotators (inter-annotator accord, error rate and performance)."
"Článek představuje system for annotation quality checking, jak byl navržen a jak je využíván při budování české části the Prague Czech-English Dependency Treebank. Nejprve je stručně představen projekt of the Prague Czech-English Dependency Treebank, jeho základní principy, a též anotační proces. V druhé části se pak článek podrobně věnuje jedné z důležitých fází anotačního procesu, totiž způsobu, jakým je průběžně již během anotace automaticky kontrolována správnost anotovaných dat. The system for annotation quality checking je názorně popsán na příkladu několika konkrétních automatických kontrol (které se týkají syntaktických jevů v anotaci). Zhodnocen je přínos tohoto systému nejen pro výslednou kvalitu anotovaných dat, ale také pro design celého korpusu, dopad na anotační pravidla a systém anotace jako takový.","The article presents the system for annotation quality checking, proposed and used during the building of the Czech part of the Prague Czech-English Dependency Treebank. At first, the treebank project is introduced, as well as
its basic principles and annotation process. The second part of the article pursues in detail one of the important phases of the annotation process,
namely how the correctness of the annotated data is automatically and continuously checked during the process. The system of annotation quality
checking is demonstrated on several particular checking procedures concerning syntactical phenomena. We try to evaluate the contribution of the system not only to the quality of the data and annotation, but also to the corpus design,
impact on annotation rules and the annotation process as a whole."
"Redukční závislostní analýza odkazuje na základní schopnost člověka zjednodušit větu. Taková schopnost je základem lidského porozumění přirozenému jazyku. Umožňuje nám získat (ne)závislosti na zýkladě správného zjednodušení věty, jakož i náležité zachycení slovosledných variant vět v jazyce s vysokým stupněm volného slovosledu.

Redukční závislostní analýza se stala důležitou motivací pro nový formální model pro Funkční generativní popis (FGD), původní rámec pro závislost-na popis české, založený na pojmu restartování automatů.

V tomto příspěvku představíme základní rysy FGD a použití závislostní redukční na několika základních jazykových jevech, především na zachycení jazykových závislostí a (ne-)projektivního slovosledu.","Dependency analysis by reduction refers to a basic ability to simplify a sentence. Such ability underlies human understanding
of a natural language. It allows us to obtain (in)dependencies by the correct reductions of  sentences as well as to describe
properly the complex word-order variants of a language with a high degree of ‘free’ word order.

Dependency analysis by reduction became an important motivation for a new formal model for Functional Generative Description
(FGD), an original framework for dependency-based description of Czech, based on the notion of  restarting automata.

In this contribution we introduce the fundamental features of FGD and exemplify the application of analysis by reduction to some basic linguistic phenomena, mainly dependencies and (non-)projective word order."
"Syntaktická analýza přirozeného jazyka je základním předpokladem mnoha aplikačních úkolů. Navrhujeme nový modul mezi morfologickou a syntaktickou analýzu, jehož cílem je stanovení
celkové struktury věty před její kompletní analýzu.

Pracujeme s konceptem segmentů, automaticky snadno zjistitelných a lingvisticky motivovaných jednotkek. Výstup modulu, takzvané ""segmentační schéma"", popisuje vztah mezi segmenty, zejména vztahy koordinace a apozice nebo
vztah podřízenosti.","Syntactic analysis of natural languages is the fundamental requirement of many applied tasks. We propose a new module between morphological and syntactic analysis that aims at determining the
overall structure of a sentence prior to its complete analysis.

We exploit a concept of segments, easily automatically detectable and linguistically motivated units. The output of the module, so-called `segmentation chart', describes the relationship among segments, especially relations of coordination and apposition or
relation of subordination.

In this text we present a framework that enables us to develop and test rules for automatic
identification of segmentation charts. We describe two basic experiments -- an experiment with segmentation patterns obtained
from the Prague Dependency Treebank and an experiment with the segmentation rules applied to plain text. Further, we discuss the
evaluation measures suitable for our task."
"Cílem projektu je představit projekt, ve kterém je přiřazována struktura
českým větám z Pražského závislostní ho korpusu
(PDT) a tak je vytvářena nová rovina syntaktické anotace, rovina syntaktické struktury  věty. Anotace je založena na koncepci segmentů,
lingvisticky motivovaných a snadno automaticky zjistitelných jednotek. Úkolem anotátorů je určit vztahy mezi segmenty, zejména vztahy nadřazenosti a podřízenosti, koordinace, apozice a vsuvky. Potom se identifikují jednotlivé klauze, které tvoří souvětí.

V pilotní fázi anotace bylo zpracováno 2699 vět z PDT.","The goal of the presented project is to assign a structure of clauses to Czech sentences from the Prague Dependency Treebank (PDT) as a new layer of syntactic annotation, a layer of clause
structure. The  annotation is based on the concept of segments, linguistically motivated and easily automatically detectable units. The task of the annotators is to identify relations among
segments, especially relations of super/subordination, coordination, apposition and parenthesis. Then they identify individual clauses forming complex sentences.

In the pilot phase of the annotation, 2,699 sentences from PDT were annotated with respect to their sentence structure."
"Tento příspěvek se zabývá restartovacími automaty,
které tvoří formální rámec pro Funkční generativní popis češtiny. Restartovací automaty pracující současně se čtyřmi rovinami jazykového popisu jsou určeny k tomu, aby prováděly redukční analýzu  českých vět a umožnily tak odvodit závislostní vztahy ve větě z možných pořadí
jednotlivých redukcí. Standardní model restartovacích automatů je zde obohacen o strukturovaný výstup, který umožňuje budovat
tektogramatickou závislostní strukturu odvozenou z redukční analýzy. Restartovací automaty se strukturovaným výstupem
představujeme v tomto příspěvku poprvé.","This paper deals with restarting automata, which are used as a formal framework for modeling the Functional Generative Description of Czech. The proposed model of restarting automaton works simultaneously with four layers of language description; it is intended to carry out reductive analysis of Czech sentences, thus allowing to derive the dependency relations in the sentence of the possible order of reduction. Standard model of restarting automaton is enriched with structured output, which allows us to build tectogrammatical dependency structure derived from the reduction analysis. Restarting automata with structured output are introduced for the first time."
"Tento příspěvek se zabývá restartovacími automaty,
které využíváme jako formální rámec pro Funkční generativní popis češtiny. Navrhovaný model restartovacího automatu pracující současně se
čtyřmi rovinami jazykového popisu je určeny k tomu, aby prováděl redukční analýzu  českých vět a umožnil tak odvodit závislostní vztahy ve větě z možných pořadí jednotlivých redukcí. Standardní model restartovacích automatů je zde obohacen o strukturovaný výstup, který umožňuje budovat
tektogramatickou závislostní strukturu odvozenou z redukční analýzy.","This paper deals with restarting automata,
which we use as a formal framework for modeling the Functional Generative Description of Czech. The proposed model of restarting automaton works simultaneously with four layers of language description; it is intended to carry out reductive analysis of Czech sentences, thus allowing to derive the dependency relations in the sentence of the possible order of reduction. Standard model of restarting automaton is enriched with structured output, which allows to build tectogrammatical dependency structure derived from the reduction analysis."
"Přesný morfologický popis slovních tvarů je prvním předpokladem pro úspěšné automatické zpracování jazykových dat.

Systém kategorií a jejich hodnot, které se k popisu používají, jsou náplní první části práce.

Základním principem je tzv. Zlaté pravidlo morfologie, které říká, že každý slovní tvar by měl být v systému popsán jednoznačně.
Existence variant na úrovni slovních tvarů i celých paradigmat však splnění tohoto pravidla komplikuje.
Koncept variant rozšiřujeme na tzv. mutace, mezi které řadíme i jiné množiny slovních tvarů se stejným popisem (např. víceré tvary osobních zájmen).
Mutace dělíme na globální pro popis na úrovni paradigmat a flektivní pro popis jednotlivých slovních tvarů.
Toto rozdělení nám umožňuje postihnout jejich časté kombinace.
Upouštíme od dělení variant (mutací) podle stylového příznaku jako neobjektivního kritéria.

V kapitole o lemmatizaci zavádíme vícenásobné lemma pro popis variantních lemmat.

Podrobně se zabýváme popisem tzv. složenin, tedy slovních tvarů typu zač, proň, koupilas, koliks.
Pro jejich lemmatizaci rovněž využíváme konceptu vícenásobného lemmatu.
Podle slovních druhů jejich složek je dělíme na několik typů.
Zabýváme se též problémem jejich vyhledávání v jazykových korpusech.

Druhá část práce popisuje systém vzorů pro popis slovních tvarů jednotlivých slovních druhů.
U každého vzoru uvádíme sadu parametrů, které umožní postihnout velkou variabilitu v tvoření konkrétních paradigmat.
Věnujeme se i pravidelnému odvozování příbuzných slov pomocí sufixů.","Detailed morphological description of word forms represents one of the most important conditions of a successful automatic processing of linguistic data.

The system of categories and their values which are used for the description are the subject of the first part of the thesis.

The basic principle, so-called Golden rule of morphology, states that every word form has to be described by the system unambiguously.
The existence of variants of word forms and whole paradigms, however, complicates the accomplishment of this rule.
We introduce so called mutations as an extension of the variants to be able to include other sets of word forms with the same description (for instance multiple word forms of Czech personal pronouns).
We divide mutations into two parts - global ones describing all word forms of a paradigm, and inflectional ones for the description on the word form level.
This division enables us to express their various combinations.
We do not use features of style for the mutation division, for they are subjective.

With a consistent use of the categories called Inflectional Mutation and Global Mutation, the Golden rule of morphology will always be valid.

The concept of multiple lemma is introduced in a chapter dealing with lemmatization. It describes lemma variants.

We give a detailed description of so-called compounds, which incorporate word forms of the type zač, proň, koupilas, koliks.
The concept of multiple lemma is also used for their lemmatization.
According to the word class of their components we divide the compounds into several types.
We also deal with the problem of their searching in language corpora.

The second part of the thesis describes a system of patterns for word description. It is divided according to the part of speech.
Each pattern has a special set of parameters that allow to grasp a large variability in word formation.
We also deal with regular derivations of related words using suffixes."
"Mnoho nedokonavých (avšak ne iterativních) sloves má schopnost spojovat se s některými speciálními předponami a se zvratnou částicí se nebo si, a tím vytváří celé paradigma nových slovních tvarů s poměrně přesně definovaným významem.","Many imperfective Czech verbs (but not iterative ones) is possible to concatenate with certain prefixes and the relative particle se or si, and create the whole paradigm of new wordforms with a relatively strict meaning."
"Tento článek se zabývá lexikálním popisem frekventovaných, nicméně nepříliš kognitivně salientních (zde: sémanticky vyprázdněných) užití významových sloves jako jsou například jít, stát, držet, dát, položit z hlediska srovnání švédštiny s češtinou. Zvláštní pozornost je věnována užití těchto sloves v tzv. verbonominálních nebo analytických predikátech.","This paper aims at a lexical description of frequent, but not enough cognitively salient uses of frequent lexical verbs in Swedish on the background of Czech, with some implications for the lexical description of basic verbs in general. It results in a draft of a production lexicon of Swedish basic verbs for advanced Czech learners of Swedish, with focus on their uses as light verbs."
Tento článek se zabývá možnostmi tektogramatické anotace větných fragmentů v dialogu.,"Being confronted with spontaneous speech, our current annotation scheme requires alterations that would reflect the abundant use of non-sentential fragments with clausal meaning tightly connected to their context, which do not systematically occur in written texts. The purpose of this paper is to list the common patterns of non-sentential fragments and their con-texts and to find a smooth resolution of their semantic annotation."
"Abstrakt
Základní slovesa (basic verbs), tj. frekventovaná významová slovesa, jež zpravidla popisují fyzický pohyb, umístění, stav, nebo děj, procházejí řadou sémantických posunů, díky kterým se používají k vyjádření druhotných, přenesených významů. V
krajních případech se dané sloveso stává pomocným, způsobovým, nebo fázovým slovesem a přestávají pro ně platit kolokační omezení, jež se vztahují na sloveso užité v jeho primárním (tj. doslovném) významu. Tato užití sloves bývají většinou dobře dokumentována v gramatikách i učebnicích, stejně jako kvalitní slovníky podávají
podrobnou informaci o užití těchto sloves v ustálených frazeologických spojeních.
Mezi plně gramatikalizovaným užitím na jedné straně a idiomatickým, frazeologickým užitím na druhé straně však existuje celá škála užití základních sloves v přenesených významech, jejíž zvládnutí je pro nerodilého mluvčího značně obtížné: užití v přeneseném významu, jež mají omezenou kolokabilitu. To jsou především verbonominální konstrukce někdy nazývané analytické predikáty (light verb constructions), ale také užití, která za určitých omezených morfosyntaktických podmínek (např. pouze
v negaci) aktivují abstraktní sémantické rysy u jiných predikátů, např. zesilují význam,
nebo implikují, že daný děj již trvá dlouho, a podobně. Tato druhotná užití významových sloves (ve švédštině) většinou nepůsobí (českým pokročilým studentům švédštiny) potíže při porozumění textu, neboť bývají sémanticky transparentní, avšak tím, že jsou specifická pro konkrétní jazyk a v zásadě neprediktabilní na základě znalosti jiného jazyka, působí problémy při produkci textu. Rodilí mluvčí sami
je většinou nevnímají nebo jejich typické kontexty považují za frazeologismy, a proto
jim ani při výuce cizích studentů nevěnují dostatečnou pozornost.
Předkládaná práce se zaměřuje na švédská základní slovesa z kontrastivního pohledu českého pokročilého studenta švédštiny. Pozorování vybraných slovesných konstrukcí zobecňuje do návrhu struktury elektronického švédsko-českého slovníku zaměřeného na pochopení a osvojení méně zřejmých, ale přesto frekventovaných konstrukcí se
základními slovesy. Slovník je zakotven ve valenční teorii Funkčního Generativního
Popisu, spojené s kolokační analýzou podle sémanticky motivovaných principů Analýzy
Korpusových Vzorců (Corpus Pattern Analysis), jež umožňuje přesnější definici jednotlivých
slovesných užití pomocí jejich typických kolokátů.
Slovník sestává ze dvou vzájemně propojených částí: slovníku sloves SweVallex (vytvořeného na základě českého Vallexu) a slovníku nominálních částí analytických predikátů (Predicate Noun Lexicon). Slovesné kolokáty jednotlivých nominálních komponent jsou roztříděny podle Mel´čukových Lexikálních Funkcí. Kromě toho je u každého analytického predikátu, pokud je to možné, uvedena informace o jeho telicitě, o tom, zda děj je okamžitý, nebo spíše durativní (punctuality), a o tom, jestli jeho subjekt za normálních okolností jedná vědomě a ze své vůle (volitionality). Zvláštní pozornost je věnována morfosyntaktickému chování nominálních komponent ve spojení s jednotlivými slovesnými kolokáty (užití členů, možnosti rozvití).
Studie opouští slovník ve chvíli, kdy je jeho struktura navržena a prověřena na
příkladech. Pro umožnění kvalitní rutinní práce byly připraveny lingvistické zdroje.
Veřejně dostupný švédský korpus PAROLE byl lemmatizován pomocí zvlášť vyvinutého
pravidlového lemmatizátoru a vložen do korpusového rozhraní Bonito, v němž
je zabudován nástroj na automatickou kolokační analýzu – Word Sketch Engine.
Tento nástroj bylo zapotřebí adaptovat na švédštinu, což bylo také předmětem této
dizertační práce. V rámci jiného projektu vzniká paralelní švédsko-český korpus, který má v současné době přibližně 2 miliony tokenů. Ten byl v nejvyšší možné míře využit v kontrastivním pozorování vybraných slovesných konstrukcí. Doplňkově byl využíván také Český národní korpus.","Basic verbs, i.e. very common verbs that typically denote physical movements, locations,
states or actions, undergo various semantic shifts and acquire different secondary
uses. In extreme cases, the distribution of secondary uses grows so general that
they are regarded as auxiliary verbs (go and to be going to), phase verbs (turn, grow),
etc. These uses are usually well-documented by grammars and language textbooks,
and so are idiomatic expressions (phraseologisms) in dictionaries.
There is, however, a grey area in between, which is extremely difficult to learn for
non-native speakers. This consists of secondary uses with limited collocability, in particular
light verb constructions, and secondary meanings that only get activated under
particular morphosyntactic conditions. The basic-verb secondary uses and constructions
are usually semantically transparent, such that they do not pose understanding
problems, but they are generally unpredictable and language-specific, such that they
easily become an issue in non-native text production.
In this thesis, Swedish basic verbs are approached from the contrastive point of
view of an advanced Czech learner of Swedish. A selection of Swedish constructions
with basic verbs is explored. The observations result in a proposal for the structure
of a machine-readable Swedish-Czech lexicon, which focuses on basic verbs and their
constructions. The lexicon is anchored in the valency theory of the Functional Generative
description, coupled with analysis of collocations according to the semantically
motivated principles of Corpus Pattern Analysis, in order to achieve the necessary
level of delicacy to make meaning distinctions correctly.
The lexicon consists of two parts: SweVallex, which is a lexicon of verb frames, and
a Predicate Noun Lexicon, which captures predicate nouns (the nominal components
of light verb constructions). These two parts are interlinked. The verb collocates
of predicate nouns are sorted according to the Mel’čukian Lexical Functions. Features
such as telicity, punctuality, and volitionality are described for each light verb
construction, whenever possible. Special attention is paid to the morphosyntactic
behavior of the respective predicate nouns (determiner use, and modifier insertion).
In order to facilitate the routine of building such a lexicon, the 20-million morphosyntactically
annotated Swedish corpus PAROLE was lemmatized and loaded into the corpus GUI Bonito, which includes the Word Sketch Engine, a tool for automatic collocation analysis. Word Sketch Definitions for Swedish were created and loaded
into the Word Sketch Engine. In addition to the PAROLE corpus, a two-million parallel
Swedish-Czech corpus was used, which has been built within a different project."
Tento článek popisuje aktuální stav ruční tektogramatické anotace korpusu PEDT.,This paper gives an overview of the current state of the Prague English Dependency Treebank project. It is an updated version of a draft text that was released along with a CD presenting the first 25\% of the PDT-like version of the Penn Treebank -- WSJ section (PEDT 1.0).
Článek pojednává o konstrukci a anotaci velkých sémantických sítí zachycujících obsah jazykových sdělení.,"We introduce a large-scale semantic-network annotation effort based on the MutliNet formalism.
Annotation is achieved via a process which incorporates several independent tools including a MultiNet graph editing tool, a semantic concept lexicon, a user-editable knowledge-base for semantic concepts, and a MultiNet parser. We present an evaluation metric for these semantic networks, allowing us to determine the quality of annotations in terms of inter-annotator agreement. We use this metric to report the agreement rates for a pilot annotation effort involving three annotators."
"Článek představuje novou metodu automatické detekce inkonzistentních anotací v korpusu obsahujícím komplexní ruční anotaci. Použitá metoda je založena na algoritmu Apriori. V článku předložíme vyhodnocení této techniky v ručně anotovaném korpusu PDT 2.0, analyzujeme chyby a ukážeme, že 20 z prvních 100 nalezených uzlů obsahovalo anotační chybu.","We present a new method for automated discovery of inconsistencies in a complex manually annotated corpora. The proposed technique is based on Apriori algorithm for mining association rules from datasets. By setting appropriate parameters to the algorithm, we were able to automatically infer highly reliable rules of annotation and subsequently we searched for records for which the inferred rules were violated. We show that the violations found by this simple technique are often caused by an annotation error. We present an evaluation of this technique on a hand-annotated corpus PDT 2.0, present the error analysis and show that in the first 100 detected nodes 20 of them contained an annotation error."
Automatická identifikace předložkových a nepředložkových pádů v současné češtině na základě lingvistických pravidel a rozsáhlých korpusů současné češtiny,Automatic rule-based identification of prepositional and non-prepositional cases in contemporary Czech based on large corpora of contemporary Czech
"Předkládáme naše první experimenty s detekcí a automatickými opravami ručních anotací anglických textů převzatých z Penn Treebanku, na závislostní tektogramatické rovině, jak je definovaná v Pražském závislostním korpusu. Hlavní myšlenkou je, že anotační chyby jsou obvykle důsledkem nekonzistence, tj. stavu kdy jeden jev je na různých místech v korpusu anotován různě.","We present our first experiments with detecting and correcting errors in a manual annotation of English texts, taken from the Penn Treebank, at the dependency-based tectogrammatical layer, as it is defined in the Prague Dependency Treebank. The main idea is that errors in the annotation usually result in an inconsistency, i.e. the state when a phenomenon is annotated in different ways at several places in a corpus. We describe our algorithm for detecting inconsistencies (it got positive feedback from annotators) and we present some statistics on the manually corrected data and results of a tectogrammatical analyzer which uses these data for its operation. The corrections have improved the data just slightly so far, but we outline some ways to more significant improvement.(1)"
"Projekt obsahuje morfologický analyzátor pro quechua, syntetizátor pro angličtinu a slovník quechua-angličtina.","This project provides a morphological analyzer for Quechua, a morphological synthesizer for English, as well as a bilingual Quechua-Spanish dictionary and a reference implementation of a Quechua-to-English MT system for OS X."
Experimentální překladový systém španělština-angličtina pro mobilní telefony.,This project is an experimental MT system (Spanish-to-English) optimized for smartphones.
Kniha zkoumá roli syntaktické analýzy ve strojovém překladu mezi příbuznými jazyky a snaži se najít limity metod mělkého překladu. Zaměřujeme se na baltoslovanské jazyky a hybridní architekturu MT s převážně pravidlovými moduly.,"This book explores the contribution of syntactic analysis to the machine translation (MT) between related languages and it also attempts to explore the limits of shallow MT methods. We focus on one group of languages, the Balto-Slavic language family, and one MT architecture, namely hybrid systems with prevalently rule-based modules."
Práce zkoumá roli syntaktické analýzy ve strojovém překladu mezi příbuznými jazyky a snaži se najít limity metod mělkého překladu. Zaměřujeme se na baltoslovanské jazyky a hybridní architekturu MT s převážně pravidlovými moduly.,"This thesis explores the contribution of syntactic analysis to the machine translation (MT) between related languages and it also attempts to explore the limits of shallow MT methods. We focus on one group of languages, the Balto-Slavic language family, and one MT architecture, namely hybrid systems with prevalently rule-based modules."
"Tento článek popisuje jednoduchou evaluační metriku pro strojový překlad, která se snaží vyřešit známé nedostatky standardně používané metriky BLEU.","This paper describes a simple evaluation
metric for MT which attempts to overcome
the well-known deficits of the standard
BLEU metric from a slightly different angle.
It employs Levenshtein’s edit distance
for establishing alignment between
the MT output and the reference translation
in order to reflect the morphological
properties of highly inflected languages. It
also incorporates a very simple measure
expressing the differences in the word order.
The paper also includes evaluation on
the data from the previous SMT workshop
for several language pairs."
Článek popisuje architekturu systému strojového překladu pro slovanské jazyky.,"This paper describes an architecture of a machine translation system designed
primarily for Slavic languages. The architecture is based upon a shallow transfer
module and a stochastic ranker. The shallow transfer module helps to resolve the
problems, which arise even in the translation of related languages, the stochastic
ranker then chooses the best translation out of a set provided by a shallow
transfer. The results of the evaluation support the claim that both modules newly
introduced into the system result in an improvement of the translation quality."
"V tomto článku popisujeme první etapu budování překladového
systému mezi čestinou a ruštinou, implementovaného v rámci
Česílka. Představujeme nástroje a data použitá v tomto projektu,
jmenovitě česko-ruský slovník a modul syntaktického transferu.
První výsledky Česílka, 1000 testovacích vět byly vyhodnoceny na
základě automaticke metriky BLEU a zároveň i lidského hodnocení.","The present paper is devoted to the ongoing research of the Machine Translation between Czech and Russian implemented in the system Česílko. We will describe the tools and data used in the project, namely the Czech-Russian dictionary and syntactic transfer module. As first results 1000 test sentences were evaluated by automatic metrics BLEU as well as by human evaluation."
Vystoupení shrnulo historii metod použitých při budování komerční aplikace kontroly gramatické správnosti českých textů.,"The talk provided a brief summary of the history of methods applied in the development of a grammar checker for Czech from initial ideas to the implementation as an indistrial application being used in Microsoft Office. The original idea of directly exploiting restarting automata for the error identification and localization in a language with a high degree of word order freedom (Czech) proposed in 1994 responded to a fact that the standard error checking methods using local error patterns were not applicable to such kind of a natural language. The concept of using a restarting automaton naturally allowed to simplify input sentences step by step by preserving an invariant of its correctness/incorrectness. Although the original automaton has transfgormed to a Robust Free-Order Dependency Grammar, it still retained this basic property."
"Článek zdůvodňuje myšlenku, že ačkoli obor automatické analýzy přirozených jazyků byl prakticky ovládnut statistickými metodami, je stále důležité se zabývat syntaktickou analýzou pomocí ručně psaných pravidel. Tato metoda má stále co říci v oblasti teorie formálního popisu přirozených jazyků stejně jako v některých typech aplikací, např. kontrole gramaticky nesprávného vstupu.","The article tries to advocate the fact that although the field of rule-based syntactic analysis of natural languages has recently been practically taken over by data-driven (mostly stochastic) methods. it is still important both for the theory of formal description of natural languages as well as for certain types of applications, especially those dealing with an ill-formed input. The arguments are based upon the experience gained in the process of development a pilot implementation of a grammar checker of Czech. Although the methods described in the paper did not lead directly to a commercial application, they definitely increased the level of understanding of certain complicated linguistic phenomena, namely the phenomenon of grammaticality and non-projectivity of Czech sentences."
"Informace o valenci sloves je podstatná pro mnoho odvětví NLP. Existuje proto již několik valenčních slovníků. V tomto článku představíme dva z nich (VALLEX a PDT-VALLEX), které jsou k disposici v elektronické podobě a které mají společné východisko. Oba mají své přednosti a naším cílem je spojit je v jeden slovník.

Máme k disposici data z korpusu PDT, kterým jsou ručně přiřazeny položky prvního ze slovníků. To nám pomůže provázat oba slovníky přes data využívajíce automatické identifikace (následované ruční prací s problémovými případy). Tímto poloautomatickým spojením dvou slovníků vznikne kvalitní lexikografický zdroj, který by jinak vyžadoval mnohem více lidské práce.

Průměrná úspěšnost namapování rámce z jednoho slovníku výběrem náhodného rámce z druhého je přibližně 60 %.

Článek se také zmiňuje o universálním formátu, ve kterém bude výhodné nová data ukládat odděleně od stávajících.","In this paper we present two valency lexicons (namely VALLEX and PDT-VALLEX). Our aim is to link them together. We can use data annotated by the first lexicon, which helps us to link some entries automatically.
Universal format for stand-off storage of this type of data is also mentioned here."
"Článek popisuje anotaci víceslovných výrazů a víceslovných pojmenovaných entit v Pražském závislostním treebanku. Zahrnuje statistiky týkající se dat a mezianotátorskou shodu. Ukážeme také snadný způsob prohledávání a zobrazení anotací, ačkoli jsou úzce spjaty s hloubkově syntaktickým treebankem.","We describe the annotation of multiword expressions and multiword named entities in the Prague Dependency Treebank. This paper includes some statistics of data and inter-annotator agreement. We also present an easy way to search and view the annotation, even if it is closely connected with deep syntactic treebank."
"Dobře provedené rozlišení smyslu slova (Word Sense Disambiguation, WSD) je důležitým prvním krokem pro další úlohy NLP, jako je strojový překlad.
V tomto článku prezentujeme přístup k WSD v češtině pomocí Průměrovaného perceptronu.
Použili jsme data anotovaná (a do jisté míry opravená) synsety z českého WordNetu. Získali jsme 100 000 výskytů anotovaných slov v celých větách. Jako baseline jsme přiřadili ke každému výskytu jeho nejčastější synset. Zkusili jsme jak nejčastější synset pro dané slovo, tak pro lemma, které bylo výsledkem morfologické analýzy dat.
Pro naše experimenty jsme použili systém Morče, 
For our experiments we used the system Morče, který je založen na skrytých markovovských modelech a průměrovaném perceptronu.
Udělali jsme tři experimenty a překonali baseline ve všech z nich.
Nejprve jsme vzali data tak, jak jsou (s ruční morfologickou anotací) a dosáhli úspěšnosti 94,2% (s baseline 87,9 %). Poté jsme vzali holá vstupní data a přiřadili synsety slovním formám. Výsledek byl 90,7 %, oproti baseline 61,7 %. Nakonec jsme vstup doplnili morfologickým taggerem a dosáhli 94,2 % (při zachování baseline 61,7 %).","Well performed Word Sense Disambiguation is an important first step for other NLP tasks, such as machine translation or information retrieval. In our paper we present an Averaged Perceptron approach to WSD for Czech.
We used data annotated (and to some extend also corrected) by Czech WordNet synsets. We obtained 100,000 occurences of annotated words in whole sentences. As a baseline we assigned the most frequent synset to each occurence. We tried both the most frequent synset for a given word form and for a lemma, as the morphological analysis was done for input data.
For our experiments we used the system Morče, which is based on the Hidden Markov Model and the Averaged Perceptron.
We made three experiments and exceeded baselines in all of them. First we took data as it is (i.e. with manual morphological annotation); we achieved 94.2% (with 87.9% baseline). Then we used a bare input data and assigned synsets to word forms. Our result is 90.7%, compared with 61.7% baseline. Last we enriched the input by a morphological tagger and achieved 94.2% (the baseline remained 61.7%)."
"Disertační práce se zabývá významy kondicionálu v dnešní češtině s cílem začlenit tyto významy do popisu větné sémantiky, tak jak je postulován ve Funkčním generativním popisu. Z široké oblasti modality, kam významy kondicionálu spadají, Funkční generativní popis ovšem dosud věnoval pozornost především významům modálních sloves, při zkoumání funkcí kondicionálu proto budeme vycházet z koncepce Mluvnice češtiny. Na základě korpusového materiálu analyzujeme primární funkci kondicionálu a některé jeho funkce sekundární. Po této analýze navrhneme formální prostředek, díky kterému je možné primární význam kondicionálu zachytit v rámci sémantické anotace. Nastíníme rovněž problémy spojené s reprezentací sekundárních funkcí kondicionálu.","The doctoral thesis deals with functions of the conditional mood in contemporary Czech texts. Two theoretical approaches to modality are described in more detail in Chapters 2 and 3, the approach of Grammar of Czech and that of Functional Generative Description (FGD), respectively. After a brief overview of terminology and corpus data used for the analysis of the conditional (cf. Chapter 4), we focus particularly on the primary function of this mood in Chapter 5. The conditional is primarily used to refer to events (also states etc.) which may be generally characterized as hypothetical. Besides this function, the conditional bears also other, secondary meanings in Czech (cf. Chapter 6). In Chapter 7, we propose a formal means for capturing the primary function of the conditional mood within a deep-syntactic annotation of a sentence. The problems connected with representation of the secondary functions of the conditional are also sketched. Conclutions are included in Chapter 8."
"Kniha se zabývá významy kondicionálu v dnešní češtině s cílem začlenit tyto významy do popisu větné sémantiky, tak jak je postulován ve Funkčním generativním popisu (FGP). Z široké oblasti modality, kam významy kondicionálu spadají, FGP ovšem dosud věnoval pozornost především významům modálních sloves, při zkoumání funkcí kondicionálu proto budeme vycházet z koncepce Mluvnice češtiny. Na základě korpusového materiálu analyzujeme primární funkci kondicionálu a některé jeho funkce sekundární. Po této analýze navrhneme formální prostředek, díky kterému je možné primární význam kondicionálu zachytit v rámci sémantické anotace. Přiblížíme rovněž problémy spojené s reprezentací sekundárních funkcí kondicionálu.","The present book deals with meanings of the conditional mood in contemporary Czech texts in order to include these meanings in the description of sentence semantics as proposed in Functional Generative Description (FGD). Since in FGD main attention has been paid to modal verbs, our analysis of meanings of the conditional is grounded on the detailed conception of modality as presented in Grammar of Czech. The primary and some secondary meanings of the conditional mood are analyzed on the basis of language data from two corpora, namely from the Prague Dependency Treebank 2.0, the annotation scenario of which was based on FGD, and from the SYN2005 corpus. We propose formal means for capturing the primary function of the conditional mood within a deep-syntactic annotation of a sentence. The problems connected with representation of the analyzed secondary functions of the conditional are also sketched."
"Kondicionál je jedním ze slovesných způsobů, v současné češtině plní celou řadu funkcí. V příspěvku se zaměřujeme na primární význam kondicionálu, který spočívá ve vyjadřování hypotetických dějů. Protože tento význam dosud nebyl – přes jeho sémantickou relevanci –zohledňován při popisu větného významu v Pražském závislostním korpusu 2.0 (PDT 2.0), pokusíme se navrhnout nový prostředek, který to umožní.","The conditional form is one of the moods of Czech verbs, and it renders several meanings in contemporary Czech texts (Sect. 2). The present paper focuses on the primary function of this mood, which is to express hypothetical events (Sect. 3). In Section 4, we briefly mention how modality has been treated up to now in PDT 2.0 and some other treebanks and finally in Section 5 we propose a new way how the primary meaning of the conditional mood should be captured in the annotation scheme of the tectogrammatical layer of PDT 2.0."
Článek popisuje proces efektivně využívající manuálních překladů pro konstrukci doménově specifických lexikálních databází.,"Thesauri and controlled vocabularies facilitate access to digital collections by explicitly representing the underlying principles of organization. Translation of such resources into multiple languages is an important component for providing multilingual access. However, the specificity of vocabulary terms in most thesauri precludes fully-automatic translation using general-domain lexical resources. In this paper, we present an efficient process for leveraging human translations to construct domain-specific lexical resources. This process is illustrated on a thesaurus of 56,000 concepts used to catalog a large archive of oral histories. We elicited human translations on a small subset of concepts, induced a probabilistic phrase dictionary from these translations, and used the resulting resource to automatically translate the rest of the thesaurus. Two separate evaluations demonstrate the acceptability of the automatic translations and the cost-effectiveness of our approach."
"Rozšířující modul pro editor TrEd, který umožní otevřít a zobrazit tmt soubory používané v systému TectoMT.",Tree Editor TrEd extension provides ability to open and display *.tmt files used within the Natural Language Processing framework TectoMT.
Článek se zabývá anotací vybraných nezávislostních vztahů v závislostním treebanku.,"The following paper has two aims. First, it introduces a procedure of a manual annotation of selected linguistic phenomena across a large-scale dependency treebank of English. The method was designed to provide higher consistency of annotated data, and so higher credibility of the treebank. Second, the first expert task completed by means of this method is being described – the annotation of rhematizers and discourse connectives and their modifiers, i.e. annotation of some non-dependency relations in a dependency approach."
Článek prezentuje dvě metody omezení komplexity prostoru víceznačných překladových hypotéz v systému strojového překladu s mělkým transferem bez taggeru.,"The article presents two automatic methods that
reduce the complexity of the ambiguous space introduced by the omission of the part of speech
tagger from the architecture of a shallow machine
translation system. The methods were implemented in a fully functional translation system
for related languages. The language pair chosen for the experiments was Slovenian-Serbian
as these languages are highly inflectional with
morphologically ambiguous forms. The empirical evaluations show an improvement over the
original system."
"V tomto příspěvku předkládáme některá pozorování týkající se sémantických charakteristik sloves vyžadujících směrové valenční doplnění. Slovesa byla komparačně studována na materiálu PDT a PCEDT. Více než 500 českých sloves se směrovým doplněním ve valenčním rámci bylo klasifikováno na základě sémantických rysů jejich doplnění typu DIR1, DIR2 nebo DIR3. Výsledky byly porovnány s chováním odpovídajících anglických sloves ve slovníku Engvallex.","We present some of our observations on the semantic characteristics of verbs requiring some kind of directional valency complementation. The verbs have been studied on the Prague Dependency Treebank and Prague Czech-English Dependency Treebank material. More than 500 Czech verbs with a directional specification in the valency frame that appeared in the Prague Dependency Treebank and PDT-VALLEX valency lexicon have been classified according to the semantic features of their complementations represented as DIR1 („from“), DIR2 („through“) or DIR3 („to“) labels. The results have been compared to the behaviour of corresponding English verbs appearing in the EngValLex valency lexicon."
"Příspěvek popisuje současnou fázi projektu spojování dvou existujících elektronických valenčních slovníků v multilingvální valenční slovník. Základním cílem projektu je propojení PDT-Vallexu a Engvallexu, dvou slovníků užívaných při anotacích korpusu PCEDT. Výsledek projektu by měl poskytnout a) slovník překladových slovesných ekvivalentů, b) lingvistické poznatky o jejich valenčních charakteristikách, shodách a rozdílech mezi nimi a c) produkt vhodný k implementaci do experimentů se strojovým překladem.","In my talk I will present an ongoing project focused on building a multilingual valency lexicon. The initial goal of the project is to bring together, refine and interlink two already existing electronic valency dictionaries, PDT-Vallex (valency characteristics of selected Czech verbs) and EngValLex (valency characteristics of selected English verbs). These dictionaries are embedded in a parallel corpus, the so called Prague Czech-English Dependency Treebank. The intended product should provide a) a dictionary of (rough) translational equivalents, b) important linguistic information about relations between valency characteristics of the equivalents (and possibly some more general information about the relation between verbal valency behaviour of the two language systems), and c) another device to be implemented into the proceeding experiments with automated machine translation."
"Příspěvek popisuje probíhající projekt budování dvoujazyčného valenčního slovníku v teoretickém rámci Funkčního generativního přístupu. Tento dvoujazyčný slovník vzniká jako výsledek propojení rámců a jednotlivých prvků rámců ve dvou již existujících valenčních slovnících.

Nejprve představíme oba spojované slovníky, poté vysvětlíme proces spojování rámců a v závěru uvedeme případovou studii, která dokládá, jakým způsobem dvoujazyčný valenční slovník ozřejmuje mezijazykové rozdíly obecně a jak jeho vznik přispívá k rozvíjení valenční teorie.","The paper describes an ongoing project of building a bilingual valency 
lexicon in the framework of Functional Generative Description. The bilingual 
lexicon is designed as a result of interlinking frames and frame elements of 
two already existing valency lexicons. 

First, we give an overall account of the character of the lexicons to be linked,
second, the process of frame linking is explained, and third, a case 
study is presented to exemplify what the information contained in frame 
links tells us about crosslinguistic differences in general and the linguistic 
theory applied."
"Článek se zabývá extrakcí skrytých informací o struktuře souvětí z Pražského závislostního korpusu. Jednotlivé klauze a jejich vzájemné vztahy totiž v tomto korpusu nejsou explicitně oznčkovány a proto bylo nutné vyvinout automatickou metodu, která je schopna transformovat původní anotaci, týkající se téměř výlučně syntaktických rolí jednotlivých slovních forem, do schématu popisujícího vztahy mezi jednotlivými klauzemi ve složených souvětích. Tento úkol byl komplikován jistým stupněm nekonzistencí v původní anotaci právě vzhledem ke klauzím a jejich struktuře. Článek popisuje metodu odvozování informací o klauzích z existující anotace a vyhodnocení úspěšnosti této metody.","The paper concentrates on deriving non-obvious information about clause structure of complex sentences from the Prague Dependency Treebank. Individual clauses and their mutual relationship are not explicitly annotated in the treebank, therefore it was necessary to develop an automatic method transforming the original annotation concentrating on the syntactic role of individual word forms into a scheme describing the relationship between individual clauses. The
task is complicated by a certain degree of inconsistency in original annotation with regard to clauses and their structure. The paper describes the method of deriving clause-related information from the existing annotation and its
evaluation."
"Článek se soustředí na získávání skrytých vztahů ve složených větách Pražského závislostního korpusu. Tento korpus obsahuje informace o vzájemných vztazích mezi slovy a dalšími prvky ve větě (interpunkce apod.), ale explicitně nezachycuje vztahy mezi složitějšími jednotkami (klauzemi). Pro další experimenty s klauzemi a jejich částmi (segmenty), bylo nutné vyvinout automatickou metodu transformující původní anotaci s ohledem na klauze a jejich strukturu.","The paper concentrates on obtaining hidden relationships among individual clauses of complex sentences from the Prague Dependency Treebank. The treebank contains only an information about mutual relationships among individual tokens (words, punctuation marks), not about more complex
units (clauses). For the experiments with clauses and their parts (segments) it was therefore necessary to develop an automatic method transforming the original annotation into a scheme describing the syntactic relationships between
clauses. The task was complicated by a certain degree of inconsistency in original annotation with regard to clauses and their structure. The paper describes the algorithm of deriving
clause-related information from the existing annotation and its evaluation."
"Postavení přísudkového slovesa je jedním z centrálních témat slovosledu ve starší češtině. V reprezentativním korpusu jazykového materiálu analyzuje autorka z kvantitativního hlediska postavení slovesa ve starší češtině obecně, ve specifických syntaktických konstrukcích a ve vybraných dílech. Tato analýza je nejen mimořádně významným přínosem k výzkumu starší češtiny a jeho metodologii, ale současně i exaktní metodologickou základnou pro další výzkum slovosledu v češtině i dalších jazycích. Monografie zároveň přináší podněty a podklady pro další rozvoj české historické stylistiky a slovosledné typologie.",Description of the placement of synthetic forms of verbal predicates in Czech during the period 1500-1620
srovnání paralelních ručních a automatických anotací aktuálního členění českých vět v souvislém textu jako podklad pro automatickou anotaci akutálního členění,comparison of parallel manual and automatic annotations of Topic-Focus Articulation in Czech sentences as a background for automatic annotation of Topic-Focus Articulation
"Tento článek předkládá a srovnává přístupy pro měření podobnosti slov založené na distributivních metodách a WordNet metodách. Článek obsahuje diskuzi o výhodách a nevýhodách obou přístupů při odhadování podobnosti a příbuznosti slov a prezentuje kombinaci obou metod. Každá z našich metod nezávisle dosahuje nejlepších výsledků ve své třídě na datech RG a WordSim353, přičemž jejich kombinace dosahuje nejlepších zatím publikovaných výsledků na obou množinách dat. Na závěr předkládáme metodu pro měření podobnosti napříč jazyky a ukazujeme, že naše metody lze snadno rozšířit na vícejazyčné úkoly pouze s malou ztrátou úspěšnosti.","This paper presents and compares WordNet based
and distributional similarity approaches.
The strengths and weaknesses of each approach
regarding similarity and relatedness
tasks are discussed, and a combination is presented.
Each of our methods independently
provide the best results in their class on the
RG and WordSim353 datasets, and a supervised
combination of them yields the best published
results on all datasets. Finally, we pioneer
cross-lingual similarity, showing that our
methods are easily adapted for a cross-lingual
task with minor losses."
"Článek studuje soulad automatických metrik strojového překladu s ručním hodnocením pro překlad do četštiny. Kromě vyhodnocení několika známých metrik zavádíme vlastní, která dosahuje výborných výsledků.","In the present work we study semi-automatic evaluation techniques of machine
translation (MT) systems. These techniques are based on a comparison of the MT
system's output to human translations of the same text. Various metrics were
proposed in the recent years, ranging from metrics using only a unigram
comparison
to metrics that try to take advantage of additional syntactic or semantic
information. The main goal of this article is to compare these metrics with
respect to their correlation with human judgments for Czech as the target
language and to propose the best ones that can be used for an evaluation of MT
systems translating into Czech language."
"Tato diplomová práce popisuje strojový překlad z angličtiny do češtiny implementovaný v systému TectoMT.
Překlad je založen na transferu přes tektogramatickou rovinu a využívá anotační schéma Pražského závislostního korpusu.

Prvotním cílem práce je zlepšení kvality překladu za pomoci pravidlového přístupu i statistických metod.
Nejprve je popsána ruční anotace překladových chyb ve vzorku 250 vět a následná analýza častých typů chyb a jejich příčin.
Hlavní část textu pak popisuje návrh a provedení úprav, které vedly k vylepšení tří fází překladu: analýzy, transferu a syntézy.
Nejvýraznější inovací je využití stromové modifikace skrytých Markovových řetězců (Hidden Markov Tree Models) ve fázi transferu.
Dosažené zlepšení je kvantitativně vyhodnoceno pomocí metrik BLEU a NIST.","This thesis describes English-Czech Machine Translation as it is implemented in TectoMT system.
The transfer uses deep-syntactic dependency (tectogrammatical) trees and exploits the annotation scheme of Prague Dependency Treebank.

The primary goal of the thesis is to improve the translation quality using both rule-base and statistical methods.
First, we present a manual annotation of translation errors in 250 sentences and subsequent identification of frequent errors, their types and sources.
The main part of the thesis describes the design and implementation of modifications in the three transfer phases: analysis, transfer and synthesis.
The most prominent modification is a novel approach to the transfer phase based on Hidden Markov Tree Models (a tree modification of Hidden Markov Models).
The improvements are evaluated in terms of BLEU and NIST scores."
Článek shrnuje nové výsledky v anglicko-českém strojovém překladu implementovaném v systému TectoMT. Obsahuje analýzu překladových chyb a návrh nového řešení transferu pomocí stromových HMM.,"This paper summarizes our recent results concerning English-Czech
Machine Translation implemented in the TectoMT framework. The system
uses tectogrammatical trees as the transfer medium.
A detailed analysis of errors made by the previous version of the
system (considered as the baseline) is
presented first. Then we describe a number of improvements of the system that
led to better translation quality in terms of BLEU and NIST scores.
The biggest performance gain comes from applying Hidden
Tree Markov Model in the transfer phase, which is a novel technique
in the field of Machine Translation."
Compost Dutch je nástroj pro morfologické značkování holandštiny založený na taggeru Morče. Je trénován na holandské části korpusu CGN. Výsledný tagger svojí úspěšností (97.27 %) překonal dosavadní publikované taggery.,Compost Dutch is a tool for POS tagging of Dutch  based on Morče tagger. It is trained on Dutch part of CGN corpus. The resulting tagger obtained accuracy 97.27 % and thus overcome other previously published taggers.
"V této práci prezentujeme holandský morfologický tagger, který překonal úspěšnost předchozích taggerů. Je založen na průměrovaném perceptronu a natrenován na korpusu CGN (pouze na holandské části). Úspěšnost na náhodně zvolených evaluačních datech dosáhla 97,2 %, což představuje více než 1% redukci chyb oproti předchozímu taggeru (Bosch a kol., 2006).
Přestože nelze určit signifikanci zlepšení úspěšnosti, COMPOST Dutch má několik dalších výhod. Algoritmus je implementován jako samostatný program, který je snadno spustitelný a rychlý (zpracuje okolo 100 tisíc slov za minutu).
COMPOST je volně stažitelný z našeho webu pro výzkumné účely. Funguje jako pod Linuxem, tak pod Windows.","In this work we present a better than state-of-the-art POS tagger developed for Dutch. It is based on Averaged Perceptron algortithm  and trained on CGN corpus (Dutch part only so far). The accuracy on randomly selected eval-test data is 97.2%, which represents a 1% error reduction compared to previous work (Bosch et al., 2006).
Although the improvement of accuracy may not be significant compared, COMPOST Dutch has few more benefits. The algortithm is implemented as a stand-alone program, which is easy to use and quite fast - it can process about 100k words per minute. COMPOST is freely downloadable from our website for research purpose. It works both under Linux and Windows platform."
"Článek je shrnutím PhD disertace Spoustova07 a rozšířením článku SpoustovaEtAl07. Popisuje několik metod značkování, které kombinují ručně psaná pravidla a stochastické taggery.","This article is an extract of the PhD thesis Spoustova07 and it extends the article SpoustovaEtAl07. Several hybrid disambiguation methods are described which combine the strength of hand-written disambiguation rules and statistical taggers. Three different statistical taggers (HMM, Maximum-Entropy and Averaged Perceptron) and a large set of hand-written rules are used in a tagging experiment using Prague 
Dependency Treebank. The results of the hybrid system are better than any other method tried for Czech tagging so far."
Morphium je nástroj zmenšující tagset Penn treebanku na seznam tagů teoreticky použitelných pro dané slovo. Morphium je napsáno v Perlu a je dostupné pod GPL licencí.,"Morphium is a tool which reduces the full Penn Treebank POS tagset to a list of tags theretically plausible for each word. The analyzer still overgenerates a lot, but its precision is much higher than the precision of the full tagset, keeping the same recall.

Morphium is written in Perl and is available under the GPL license."
Compost English je nástroj kombinující morfologický analyzátor Morphium a tagger Morče za užití nové metody semi-supervised trénování. Výsledný tagger má nejlepší výsledky pro angličtinu (97.43 %).,"Compost English is a tool which combines the Morphium morphological analyzer and the Morce tagger using an innovative semi-supervised training method. The resulting tagger gives the best accuracy achieved for English (on standard PTB data set) so far: 97.43 %

Compost English is written in Perl and C and is available for registered users only. However, the default package does not contain the Morce tagger source code, which you can dowload directly from the Morce website."
V tomto článku prezentujeme metodiku použitou pro levnou kontrolu kvality morfologického značkování Pražského závislostního korpusu založenou na vícenasobném ručním přeznačkování s pomocí několika různých taggerů.,In our paper we present a methodology used for low-cost validation of quality of Part-of-Speech annotation of the Prague Dependency Treebank based on multiple re-annotation of data samples carefully selected with the help of several different Part-of Speech taggers.
"Cílem této práce je implementovat a zhodnotit softwarový nástroj pro automatické zarovnávání (alignment) českých a anglických tektogramatických stromů. Úkolem je najít odpovídající si uzly stromů, které reprezentují anglickou větu a její český překlad.","The goal of this thesis is to implement and evaluate a software tool for automatic alignment of Czech and English tectogrammatical trees. The task is to find correspondent nodes between two trees that represent an English sentence and its Czech translation. Great amount of aligned trees acquired from parallel corpora can be used for
training transfer models for machine translation systems. It is also useful for linguists in
studying translation equivalents in two languages. In this thesis there is also described
word alignment annotation process. The manual word alignment was necessary for evaluation of the aligner. The results of our experiments show that shifting the alignment task from the word layer to the tectogrammatical layer both (a) increases the inter-annotator agreement on the task and (b) allows to construct a feature-based algorithm which uses sentence structure and which outperforms the GIZA++ aligner in terms of f-measure on aligned tectogrammatical node pairs. This is probably caused by the fact that tectogrammatical representations of Czech and English sentences are much closer compared to the
distance of their surface shapes."
"Článek je zaměřen na zarovnávání paralelních českých a anglických tektogramatických stromů. Experiment ukazuje, že přesunutí ulohy zarovnávání na tektogramatickou rovinu umožní dosáhnout vyšší mezianotátorské shody.","In this paper, we focus on alignment of Czech and English tectogrammatical dependency trees. The alignment of deep syntactic dependency trees can be used for training transfer models for machine
translation systems based on analysis-transfer-synthesis architecture. The results of our experiments show that shifting the alignment task from the word layer to the tectogrammatical layer both (a) increases the inter-annotator agreement on the task and (b) allows to construct a feature-
based algorithm which uses sentence structure and which outperforms
the GIZA++ aligner in terms of f-measure on aligned tectogrammatical
node pairs."
Článek pojednává o částicích implikujících presupozici jako podstatnou složku větného významu.,The article discusses particles that imply pressupposition as the fundamental part of the meaning of the sentence.
"Tento článek popisuje vyhledávací experimenty týmu z Karlovy Univerzity v Praze na soutěži CLEF 2007 Ad-Hoc. Zaměřili jsme se na monolinguální úlohu a použili nástroj LEMUR pro náš vyhledávač. Naše výsledky ukazují, že pro češtinu lemmatizace signifikantně vylepšuje výsledky vyhledávání a manuální tvorba dotazů je pouze těsně lepší než automatickátvorba dotazů s popisu témet.","In this paper we describe retrieval experiments performed at Charles University in
Prague for participation in the CLEF 2007 Ad-Hoc track. We focused on the Czech
monolingual task and used the LEMUR toolkit as the retrieval system. Our results
demonstrate that for Czech as a highly inflectional language, lemmatization significantly
improves retrieval results and manually created queries are only slightly better
than queries automatically generated from topic specifications."
"Článek přestavuje tři metody strojového učení k automatické analýze jmenných frází. První z nich ji zkoumá jako úlohu seshlukování. Druhá metoda na ni aplikuje rozhodovací stromy a poslední experimentuje s Bell stromem, jakožto vyhledávácí prostor pro vyřešení problému automatické analýzy koreferencí. Znalosti získané z těchto experimentů můžou být prospěšné pro vývoj systému automatické analýzy koreferencí na češtině.","This paper introduces three machine learning approaches to noun phrase
coreference resolution. The first of them gives a view of coreference resolution as a
clustering task. The second one applies a noun phrase coreference system based on
decision tree induction and the last one experiments with using the Bell tree to
represent the search space of the coreference resolution problem. The knowledge
gained from these experiments can be conducive to development of a Czech
coreference resolution system."
"Tento příspěvek přináší analýzu českých sloves mluvení. Popisuje tři sémantické participanty typické pro tato slovesa: mluvčího, příjemce a sdělení. Pozornost je zde věnována zejména participantu sdělení, který bývá často realizován závislou obsahovou klauzí. U sloves mluvení vymezujeme tři typy těchto klauzí: asertivní, interogativní a direktivní. Dále navrhujeme rozdělení skupiny sloves mluvení podle toho, který z typů závislé obsahové klauze k sobě dané sloveso  váže.","This paper provides an analysis of Czech verbs of communication. It describes their three semantic participants 'Speaker', 'Recipient' and 'Message'. Especially, dependent content clauses realizing the participant 'Message' are discussed in great detail. Three types of them are distinguished: assertive, interrogative and directive. A further subdivision of the class of verbs of communication is proposed in accordance with types of dependent content clauses which the verbs of communicatioon bind to themselves."
"V tomto příspěvku představujeme projekt zaměřený na obohacení valenčního slovníku českých sloves o sémantické třídy. Využíváme k tomu FrameNet, sémantický lexikální zdroj. V této fázi byly sémantické informace z FrameNetu mapovány na
dvě skupiny sloves, slovesa komunikace a slovesa výměny. Možnosti tohoto přístupu ukázala mezianotátorská shoda - 85,9% u sloves komunikace a 78,5% u sloves výměny.","We introduce a project aimed at enhancing a valency lexicon of Czech verbs with coherent semantic classes. For this purpose, we
make use of FrameNet, a semantically oriented lexical resource. At the present stage, semantic frames from FrameNet have been mapped to
two groups of verbs with divergent semantic and morphosyntactic properties, verbs of~communication and verbs of exchange. The
feasibility of this task has been proven by the achieved interannotator agreement -- 85.9% for the verbs of communication and 78.5% for the verbs of exchange. As a result of our experiment,
the verbs of communication have been grouped into~nine semantic classes and the verbs of exchange into ten classes, based on upper
level semantic frames from FrameNet."
"V tomto příspěvku představujeme projekt obohacující valenční slovník českých sloves o sémantické role. Pro tento účel využíváme FrameNet. V současné fázi byly mapovány valenční doplnění sloves komunikace a výměny na FE ve Framenetu. Možnosti tohoto přístupu ukázala mezianotátorská shoda - 95,6% u sloves komunikace a 91,2% u sloves výměny. Tímto způsobem jsme získali 37 sémantických rolí pro slovesa komunikace a 34 pro slovesa výměny.","We introduce a project to enhance a valency lexicon of Czech verbs with semantic roles. For this purpose, we make use of FrameNet. At the present stage, frame elements from FrameNet have
been mapped to valency complementations of verbs of communication and verbs of exchange. The feasibility of this task has been proven by the achieved interannotator agreement -- 95.6% for the verbs of communication and 91.2% for the verbs of exchange. As a result, we have obtained 37 semantic roles for the verbs of communication and 34 for the verbs of exchange, based on
frame elements of upper level semantic frames from FrameNet."
"Tato příručka je výstupem z korpusového výzkumu věnovanému vzájemnému vztahu syntakticko-sémantické struktury věty a struktury diskurzu (textu) zpracovanému v diplomové práci Lucie Mladové (Ústav českého jazyka a teorie komunikace FF UK, 2008). Z rozsáhlé problematiky popisu diskurzu v jeho různých aspektech (např. koreferenční vztahy, tematicko-rematická výstavba diskurzu atd.) se zabývá především syntakticky motivovanými vztahy, tj. otázkou, do jaké míry lze ze syntaktického a sémantického popisu věty vyčíst informace o diskurzních vztazích a jakého charakteru tyto informace jsou.","The present manual is a contribution to the widely discussed issue of how the syntactic structure of a sentence and the structure of discourse (text) are related. The syntactic sentence structure along with other language phenomena participates in building a coherent, comprehensible discourse. The author calls the syntactically motivated relations in discourse connective relations. These relations include coordinating relations and some of the subordinating relations within a sentence and, secondly, adjoining of discourse units across the sentence boundary. The explicit means of expressing connective relations are called discourse connectives. It is a group of language expressions that connect or adjoin discourse units while indicating the type of semantic relation between them, i. e. conjunctions, some subjunctions, particles and adverbials, and marginally also some other parts-of-speech. The present thesis describes the semantic category of discourse connectives in Czech on the basis of language data and their syntactic annotation in the Prague Dependency Treebank, and thus aims to contribute to the design of a language corpus annotation scenario capturing the discourse relations in Czech."
"V oblasti zkoumání věty z hlediska jejího aktuálního členění (nebo funkční perspektivy) má česká lingvistika za sebou mnoho práce. Při bádáních zaměřených tímto směrem byla věnována značná pozornost výrazům, které signalizují kategorie aktuálního členění věty, tzv. rematizátorům (jsou to výrazy jako například: jen, zejména, také, hlavně, právě, alespoň atd.).","In this article, we discuss the linguistic properties of the so-called rhematizers and discourse connectives."
"Práce je věnována problematice vzájemného vztahu syntaktické struktury věty a struktury diskurzu (textu). Syntaktická struktura věty se spolu s dalšími jevy podílí na koherenci a tedy srozumitelnosti diskurzu. Syntakticky motivované vztahy v diskurzu nazývá autorka vztahy konektivními. Tyto vztahy zahrnují jednak koordinační a některé závislostní vztahy v rámci věty a jednak připojování či navazování textových jednotek přes hranice věty. Explicitní prostředky vyjádření konektivních vztahů tvoří skupina tzv. diskurzních konektorů, což jsou slova nebo slovní spojení, která spojují či připojují textové jednotky a zároveň vyjadřují druh sémantického vztahu mezi nimi, tj. spojky, některé částicové a adverbiální výrazy a okrajově také další slovní druhy. Práce si klade za cíl popsat skupinu diskurzních konektorů v češtině na základě jazykového materiálu a syntaktické anotace Pražského závislostního korpusu a přispět tak ke vzniku korpusu s anotací diskurzních vztahů.","The present thesis is a contribution to the widely discussed issue of how the syntactic structure of a sentence and the structure of discourse (text) are related. The syntactic sentence structure along with other language phenomena participates in building a coherent, comprehensible discourse. The author calls the syntactically motivated relations in discourse connective relations. These relations include coordinating relations and some of the subordinating relations within a sentence and, secondly, adjoining of discourse units across the sentence boundary. The explicit means of expressing connective relations are called discourse connectives. It is a group of language expressions that connect or adjoin discourse units while indicating the type of semantic relation between them, i. e. conjunctions, some subjunctions, particles and adverbials, and marginally also some other parts-of-speech. The present thesis describes the semantic category of discourse connectives in Czech on the basis of language data and their syntactic annotation in the Prague Dependency Treebank, and thus aims to contribute to the design of a language corpus annotation scenario capturing the discourse relations in Czech."
"Základní představení anotačního systému analýzy diskurzu v Pražském závislostním korpusu, vycházející z jeho tektogramatické roviny a z filadelfského projektu Penn Discourse Treebank","Basic presentation of discourse annotation scenario in Prague Dependency Treebank, based on its tectogrammatical level of analysis and on the Philadelphian project Penn Discourse Treebank"
"V tomto článku stručně shrnujeme hlavní přístupy ke strojovému překladu. Popisujeme principy úspěšného frázového statistického přístupu a ukazujeme některá nedávná vylepšení, která využívají hybridizaci jak směrem k překladu založenému na příkladech, tak k překladu založenému na pravidlech.","In this paper we shortly summarize the main paradigms of machine translation. We describe the principles of successful phrase-based statistical approach and show some recent improvements using hybridization towards both example-based and rule-based directions. We also describe the experiments in this topic English-to-Czech translation that carried out at our department, we comment the weak points and provide for improvement possibilities."
Implementace dolování stromových překladových ekvivalentů ze závislostního paralelního treebanku v jazyce Perl.,A Perl implementation of treelet pair extraction from a parallel dependency treebank.
"V příspěvku podáváme komplexní obraz korpusu DIALOG, a to v časovém sledu: pojednáváme o historii korpusu, jeho současné podobě a výhledech na příští tři roky. V části věnované historii se zabýváme základní motivací, která vedla badatelky a badatele z oddělení stylistiky a lingvistiky textu Ústavu pro jazyk český AV ČR ke sběru a analýze televizních dialogických jazykových projevů; podáváme též přehled o nejdůležitějších publikacích z tohoto období, o hlavních výzkumných tématech a teoretických poznatcích. V části věnované současnosti korpusu se zabýváme obdobím zpracovávání sebraného materiálu do podoby elektronického jazykového korpusu. Podáváme základní charakteristiky korpusu z hlediska lingvistického i počítačově-technického a shrnujeme obsah hlavních publikací z tohoto období. Představujeme také první veřejně přístupnou verzi korpusu, nazvanou DIALOG 0.1, a webové stránky tohoto dílčího korpusu (viz http://ujc.dialogy.cz). V části věnované blízké budoucnosti korpusu DIALOG pojednáváme o cílech grantového projektu Mluvená čeština ve veřejných dialozích: dobudování, zpřístupnění a průzkum korpusu DIALOG (Grantová agentura AV ČR, doba řešení projektu: 2007–2009, identifikační číslo projektu: KJB900610701, řešitel projektu: Petr Kaderka). Představujme možnosti obsažené v technickém řešení projektu, jehož autorem je Nino Peterek, harmonogram zpřístupňování korpusu veřejnosti a lingvistické výzkumy, na nichž aktuálně pracujeme nebo které na nás v blízké budoucnosti čekají.","In this paper, we show a comprehensive picture of DIALOG corpus, in chronological order: the corpus history, its current form and perspectives for the next three years. 
The DIALOG corpus is a prosodically annotated corpus of Czech television debates that has been recorded and annotated at the Czech Language Institute of the Academy of Sciences of the Czech Republic. This project has been carried out in cooperation with the Institute of Formal and Applied Linguistics of Faculty of Mathematics and Physics, Charles University, Prague."
Tento článek se zabývá procesem vývoje foneticky a prozodicky bohatého korpusu mluvené řeči pro jednotkovou syntézu mluvené řeči. Zvláštní pozornost je věnována nahrávání a verifikační fázi procesu. Pro zajištění nejvyšší možné kvality a konzistence nahrávek bylo použito speciální nahrávací zařízení.,"The paper deals with the process of designing a phonetically and prosodically rich speech corpus for unit selection speech synthesis. The attention is given mainly to the recording and verification stage of the process. In order to ensure as high quality and consistency of the recordings as possible, a special recording environment consisting of a recording session management and “pluggable” chain of checking modules was designed and utilised. Other stages, namely text collection (including) both phonetically and prosodically balanced sentence selection and a careful annotation on both orthographic and phonetic level are also mentioned.
Language"
"Doktorská dizertační práce studuje vzájemný vztah mezi lingvistickými teoriemi, daty a aplikacemi. Zaměřujeme se na jednu konkrétní teorii, Funkční generativní popis, jeden konkrétní typ dat, totiž valenční slovníky, a jednu konkrétní aplikaci: strojový překlad z angličtiny do češtiny.","This thesis explores the mutual relationship between linguistic theories, data
and applications. We focus on one particular theory, Functional Generative
Description (FGD), one particular type of linguistic data, namely valency
dictionaries and one particular application: machine translation (MT) from
English to Czech.

First, we examine methods for automatic extraction of verb valency dictionaries
based on corpus data. We propose an automatic metric for estimating how much
lexicographers' labour was saved and evaluate various frame extraction
techniques using this metric.

Second, we design and implement an MT system with transfer at
various layers of language description, as defined in the framework of FGD. We
primarily focus on the tectogrammatical (deep syntactic) layer.

Third, we leave the framework of FGD and experiment with a rather direct,
""phrase-based"" MT system. Comparing various setups of the system and
specifically treating target-side morphological coherence, we are
able to significantly improve MT quality and out-perform a commercial MT
system within a pre-defined text domain.

The concluding chapter provides a broader perspective on the utility of lexicons
in various applications, highlighting the successful features. Finally, we
summarize the contribution of the thesis."
Příspěvek popisuje naše dva systémy v soutěži WMT08: frázový překlad o více faktorech a pravděpodobnostní stromový transfer přes hloubkovou syntax.,"This paper describes our two contributions to WMT08 shared task: factored
phrase-based model using Moses and a probabilistic tree-transfer model at a deep
syntactic
layer."
"Předkládáme experimenty se strojovým překladem z angličtiny do hindštiny založeným na systému Moses (Mojžíš). Vyhodnocujeme vliv dodatečných trénovacích dat z odlišné domény, a to jak paralelních, tak jednojazyčných hindských. Testujeme tři metody pro zlepšení práce se slovosledem: standardní slovosledný model zabudovaný v Mosesu, předzpracování založené na pravidlech a jazykově nezávislou identifikaci přípon.","We present experiments with a Moses-based English-to-Hindi translation system. We evaluate the impact of additional out-of-domain training data, both parallel and Hindi-only, and experiment with three methods for improving word order: standard Moses reordering model, rule-based preprocessing and language-independent suffix identification."
Popisujeme systém automatického překladu z angličtiny do češtiny založený na syntaktickém transferu na rovině hloubkové syntaxe (tzv. tektogramatické rovině). Podrobně je popsán anotační proces pro angličtinu a také vyhodnocena kvalita překladu prototypu celého systému.,We are presenting an overview of an English-to-Czech machine translation system. The system relies on transfer at the tectogrammatical (deep syntactic) layer of the language description. We report on the progress of linguistic annotation of English tectogrammatical layer and also on first end-to-end evaluation of our syntax-based MT system.
Příspěvek stručně popisuje rozdíly mezi závislostními a složkovými stromy včetně jejich vyjadřovací síly a dále uvádí odkazy na některé formalismy stromových gramatik.,The report briefly discusses the differences between constituency and dependency trees including their different expressivity. It also provides references to some tree grammar formalisms.
Experimentální systém strojového překladu převádějící strom na strom.,A release of an experimental tree-to-tree transfer system implemented in Mercury.
Technická zpráva pro projekt EuroMatrix popisující naši implementaci strojového překladu přes syntaktickou reprezentaci (synchronous tree-substituion grammars).,A technical report for the project EuroMatrix describing our implementation of machine translation via a syntactic representation (synchronous tree-substituion grammars).
Článek popisuje nový česko-anglický paralelní korpus CzEng 0.7. Korpus je volně dostupný pro výzkumné a výukové účely.,"This paper describes CzEng 0.7, a new release of Czech-English parallel corpus freely available for research and educational purposes.
We provide basic statistics of the corpus and focus on data produced by a community of volunteers. Anonymous contributors manually
correct the output of a machine translation (MT) system, generating on average 2000 sentences a month, 70% of which are indeed correct
translations. We compare the utility of community-supplied and of professionally translated training data for a baseline English-to-Czech
MT system."
"Česko-rusko-anglický korpus textů, po dvojicích jazyků zarovnán po větách.",Czech-Russian-English parallel corpus with automatic pairwise sentence alignments.
"Tento článek popisuje vznik souboru korpusů v rámci rodiny Pražského závislostního korpusu, které obsahují mluvená data v češtině a v angličtině, a jejich ruční anotaci rekonstrukce mluvené řeši (speech reconstruction).","We present a description of a new resource (Prague Dependency
Treebank of Spoken Language) being created for English and Czech to be used for the task of speech understanding,broad natural language analysis for dialog systems and other speech-related tasks, including speech editing. The resources we have created so far contain audio and a standard transcription of spontaneous speech, but as a novel layer, we add an edited (“reconstructed”) version of the spoken tterances."
"Syntax a sémantika konstrukcí českého akuzativu s infinitivem je předmětem studia této stati, a to v porovnání s jinými slovanskými jazyky. Obligatornost koreference v těchto konstrukcích oproti její fakultativnosti ve vedlejších větách významově blízkých a jistá omezení na pořadí slov jsou chápány jako argumenty pro jejich samostanou hloubkovou reprezentaci.",The constructions „accusativus cum infinitivo“ with the verbs of perception are analyzed in Czech and in other Slavonic languages. The syntactic and semantic features of these Czech constructions and their relation to their respective paraphrases (expressed by subordinated clauses)are studied. The relation of grammatical coreference (obligatory with the AcI and only optional with the analyzed subordinated clauses) are used as arguments for the special position of the  AcI within the underlying structure of the sentence.
"Ve stati se zvažuje místo stupňování adjektiv v popisu jazyka. Zvláštní pozornost se věnuje tzv. ""absolutnímu"" užití komparativu, rozlišuje se lexikalizace, stylizace a porovnávání s průměrem. Podává se kontrastivní pohled na stupňování ve slovenštině a ruštině.","The status of the gradation of adjectives in the description of language is considered. The cases of the ""abolute"" comparative constructions are studied on the corpus data (lexicalization, stylistic effects, comparison with an average). The Czech situation is compared with Slovac and Russian comparative constructions."
"Přestože reflexivní konstrukce jsou ve slavistice často zpracovávány, jednotná metodologická báze popisu chybí. Potíže spočívají v mnohofunkčnosti reflexivního zájmena/částice se/si a časté víceznačnosti. Ve stati se navrhují kritéria pro řazení jednotlivých typů do lexikonu, slovotvorby, morfologie a syntaxe.","The difficulties of the analysis of Slavonic reflexive constructions are caused among other things also by the fact that se/si  constructions in Slavonic languages cross the boundaries between lexicon, word-formation, morphology, and syntax.
The criteria, how to distinguish the class of reflexives tantum, derived reflexives, reciprocals, derived reciprocals, true reflexives and deagentive constructions, are proposed, and the difficuilties with the analysis of real data  The Czech and Russian reflexives are compared only briefly."
"Český akademický korpus 2.0 (ČAK 2.0) sestává z 650 tisíc slovních forem z rozličných novinových článků, časopisů a přepisů rozhlasových či televizních pořadů ze 70. a 80. let dvacátého století, ručně anotovaných na morfologické a analytické rovině.","The Czech Academic Corpus version 2.0 (CAC 2.0) consists of 650,000 words from various 1970s and 1980s newspapers, magazines and radio and television broadcast transcripts manually annotated for morphology and syntax."
"Průvodce ČAK 2.0 je, podobně jako v případě ČAK 1.0, průvodce CD-ROM. Obsah průvodce je koncipován tak, že čtenář nemusí být předem seznámen s průvodcem ČAK 1.0, a přesto se  o projektu dozví vše potřebné. Pokud ho budou zajímat podrobnosti historie projektu Českého akademického korpusu a podrobnosti přípravy první verze, může si samozřejmě průvodce ČAK 1.0 otevřít. Čtenář, který je s průvodcem ČAK 1.0 seznámen, se bude v předkládaném průvodci orientovat velmi snadno, protože jsme se v něm přidrželi stejného členění kapitol do třech tematických celků.

První celek, kapitola 2, podává základní charakteristiku Českého akademického korpusu 2.0, popisuje strukturu anotací v něm obsažených a dokumentuje dílčí kroky spojené se syntaktickými anotacemi.

Druhý celek, kapitoly 3 až 6, se věnuje samotnému CD-ROM, tj. jeho datové komponentě, nástrojům, bonusům a tutoriálům. 

Kapitoly 8 a 9 jakožto třetí celek věnují pozornost personálnímu a finančnímu zabezpečení projektu.","The CAC 2.0 Guide is a guide to the CD-ROM, just like the previous CAC 1.0 Guide. The contents of the Guide provide all the necessary information about the project; however the user does not need to be familiar with the CAC 1.0 Guide. The CAC 1.0 Guide can be referred to for the details of the CAC project’s history and its preparation details. Nevertheless, if you are already familiar with the CAC 1.0 Guide, navigating it will be easy, as we have maintained its chapters’ organisation into three main units.

The first unit, Chapter 2, describes the main characteristics of the Czech Academic Corpus 2.0, the structure of its annotations and the documentation of the partial steps of the syntactical annotations.

The second unit, Chapters 3 through 6, contain the CD-ROM information and the documentation of the data component, tools, bonus material and tutorials. 

Chapters 8 and 9 form the third unit of the Guide. They cover the personal and financial aspects of the project."
Tree Aligner je experimentální systém pro získání slovníku převádějícího mezi sebou závislostní struktury částí vět. Toto je implementace v Javě.,Tree Aligner is an experimental implementation to extract treelet-to-treelet translation dictionary from a parallel treebank. This is the Java version.
"TectoMT je modulární softwarový systém pro vývoj aplikací pro zpracování přirozeného jazyka. Tento průvodce popisu architekturu systému, včetně aplikačního rozhraní pro práci se strukturovanými lingvistickými daty.","TectoMT is a highly modular software system for developing NLP applications. This guide gives a detailed overview of the system's architecture, including the API description."
Představujeme nový systém strojového překladu z angličtiny do češtiny spojující lingvisticky motivované vrstvy jazykového popisu (jak jsou definovány v anotačním schématu Pražského závislostního korpusu) s prvky statistických metod počítačového zpracování jazyka.,We present a new English to Czech machine translation system combining linguistically motivated layers of language description (as deﬁned in the Prague Dependency Treebank annotation scenario) with statistical NLP approaches.
Rozbírají se hlavní metodologické zásady Pražské lingvistické školy.,The main methodological insights of the Prague School are analyzed. It is shown that the ideas are still valid.
Probírají se pojmy jako spisovnost a standard a ukazuje se užitečnost toho druhého i nevhodnost prvního.,"Concepts such as correctness, literary norm, or standard are examined; the last term is to be preferred."
Probírají se lexikální jednotky týkající se Velikonoc z hledsika jejich původu i slovotvorných aspektů.,Lexical items concerning Easter are characterized as for different aspects of their origin and structure.
"Rozbor některých lingvistických hypotéz, které je možné ověřovat nad anotovaným textovým korpusem.","The building up and annotation of text corpora (both written and spoken) has become one of the urgent topics in present-day linguistics; the creation of the Czech National Corpus and the morphologically and syntactically annotated Prague Dependency Treebank documents that the Prague Linguistic School has not only kept contact with the recent trends of linguistic studies in the world, but in some aspects, it even sets an example. In the present contribution, several linguistic phenomena are selected to illustrate how a systematically designed and carefully implemented deep-level annotation of a large corpus of Czech texts may serve to verify linguistic theory. The theory underlying the annotation is that of Functional Generative Description (FGD) designed by Petr Sgall in the early 1960s as an original alternative to Chomskyan transformational grammar and developed since then by a group of Praguian theoretical and computational linguists at Charles University."
"Úvodní přednáška na semináři k výročí PLK, v němž jsou shrnuty hlavní příspěvky členů této lingvistické školy.","Introductory talk at a workshop marking the anniversary of the Prague Linguistics Circle, where the main contributions of the members of this linguistic school are summarized."
"V pozvané přednášce byly analyzovány vztahy mezi teoretickou, počítačovou a korpusovou lingvistikou a vzájemného podílu každého z těchto odvětví; obecné závěry byly podloženy rozborem některých jazykových jevů spjatých především s komunikativní funkcí jazyka a bylo ukázáno, jak se v jazykové formě odráží dichotomie „o čem se mluví“ a „co se o tom říká“.","In view of the relationships between theoretical, computational and corpus linguistics, their mutual contributions are discussed and illustrated on the issue of the aspect of language related to the information structure of the sentence, distinguishing ”what we are talking about” and ”what we are saying about it”."
"Cílem příspěvku je vyhodnotit, které aspekty struktury diskurzu v textech mohou být odhaleny a zároveň objasněny. Analýza je provedena na větách z Pražského závislostního korpusu, které jsou anotovány na podkladové rovině, včetně anotace aktuálního členění a koreference.","The aim of the contribution is to document, on the example of the annotation of sentences on an underlying syntactic layer including Topic-Focus Articulation and enriched by an establishment of basic coreference links in the Prague Dependency Treebank, which aspects of the discourse structure can be discovered and elucidated."
Při anotování Pražského závislostního korpusu se přechází od věty k textu a tedy i k anotaci koreferenčních vztahů.,In the annotation of text corpora it is essential to pass over from the annotation of sentence structure to an annotation of discourse relations.
"PML-TQ je systém pro vyhledávání nad lingvisticky anotovanými korpusy závislostních či složkových stromů ve formátu PML. Systém definuje velmi silný dotazovací jazyk. Je implementován pomocí client-server architektury, s použitím SQL databáze  na straně serveru a zahrnuje webové a CLI rozhraní a grafické rozhraní zabudované do editoru TrEd. Jako rozsíření TrEdu je dále dostupný čistě klientský vyhledávací systém nad stejným dotazovacím jazykem, umožňující prohledávat lokální soubory.","PML-TQ is a search system for linguistic TreeBanks in PML format. The system defines a powerfull query language, uses a client server architecture (with SQL database backend on the server side) and provides a command-line and a simple web-based search client. The system also includes a graphical client for PML-TQ and client-side PML-TQ search engine, allowing the users to use PML-TQ queries on their local data. The GUI and client-side search engine are distributed separately as extensions to the tree editor TrEd."
"V tomto článku představujeme aktuální vývoj již zavedeného pracovního prostředí pro syntakticky anotované korpusy, sestávajícího z abstraktního datového formátu založeného na XML, plně přizpůsobitelného editoru stromových struktur, nástroje automatizované zpracování anotovaných dat s podporou výpočtu na počítačovém clusteru a prototyp relačního vyhledávácího systému s grafickým uživatelským rozhraním zabudovaným do editoru stromů.","This paper presents recent advances in
an established treebank annotation framework comprising of an abstract XML-based data format, fully customizable editor of tree-based annotations, a toolkit for all kinds of automated data processing with support for cluster computing, and
a work-in-progress database-driven search
engine with a graphical user interface built
into the tree editor."
Tento článek popisuje nasši účast v evaluační kampani MWE 2008 zaměřené na automatickou extrakci kolokací.,This paper describes our participation in the MWE 2008 evaluation campaign focused on ranking MWE candidates. Our ranking system employed 55 association measures combined by standard statistical-classification methods modified to provide scores for ranking. Our results were crossvalidated and compared by Mean Average Precision. In most of the experiments we observed significant performance improvement achieved by methods combining multiple association measures.
Frekvenční charakteristiky českých kolokačních kandidátů extrahovaných z Pražského závislostního korpusu jako závislostní bigramy.,Frequency characteristics of Czech collocation candidates extracted as dependecy bigrams from the Prague Dependency Treebank.
Frekvenční charakteristiky českých kolokačních kandidátů extrahovaných z Českéno národního korpusu jako povrchové bigramy.,Frequency characteristics of Czech collocation candidates extracted as surface bigrams from the Czech National Corpus.
Frekvenční charakteristiky českých kolokačních kandidátů extrahovaných z Pražského závislostního korpusu jako povrchové bigramy.,Frequency characteristics of Czech collocation candidates extracted as surface bigrams from the Prague Dependency Treebank.
Disertace se zabývá studiem lexikálních asociačních měr aplikovaných v úloze automatické extrakce kolokací.,A PhD dissertation studying lexical association measures and their application for collocation extraction.
Referenční množina kolokačních kandidátů extrahovaných z Pražského závislostního korpusu jako závislostní bigramy a anotovaných jako kolokace nebo nekolokace.,A reference set of collocation candidates extracted as dependency bigrams from the Prague Dependency Treebank and annotated as collocational or non-collocational.
Referenční množina kolokačních kandidátů extrahovaných z Českého národního korpusu jako povrchové bigramy a anotovaných jako kolokace nebo nekolokace.,A reference set of collocation candidates extracted as surface bigrams from the Czech National Corpus and annotated as collocational or non-collocational.
Referenční množina kolokačních kandidátů extrahovaných z Pražského závislostního korpusu jako povrchové bigramy a anotovaných jako kolokace nebo nekolokace.,A reference set of collocation candidates extracted as surface bigrams from the Prague Depedency Treebank and annotated as collocational or non-collocational.
Popis tří referenčních datových množin použitých v rámci evaluační kampaně MWE 2008 zaměřené na extrakci kolokací.,"We introduce three reference data sets provided for the MWE 2008 evaluation campaign focused on ranking MWE candidates. The data sets comprise bigrams extracted from the Prague Dependency Treebank and the Czech National Corpus. The extracted bigrams are
annotated as collocational and non-collocational and provided with corpus frequency information."
Přehled výsledků Cross-Language Speech Retrieval Track organizované v rámci evaluační kampaně CLEF 2007.,"The CLEF-2007 Cross-Language Speech Retrieval (CL-SR) track included two tasks: to identify topically coherent segments of English interviews in a known-boundary condition, and to identify time stamps marking the beginning of topically relevant passages in Czech interviews in an unknown-boundary condition. Six teams participated in the English evaluation, performing both monolingual and cross-language searches of ASR transcripts, automatically generated metadata, and manually generated metadata. Four teams participated in the Czech evaluation, performing monolingual searches of automatic speech recognition transcripts."
"Důležitou součástí Pražského závislostního korpusu je valenční slovník. Slovník obsahuje 5300 sloves s 8200 valenčními rámci, které jsou propojeny s korpusem. Reprezentace valenčního rámce je plně formalizována. Tento příspěvek je orientován na formální popis forem, kterých nabývají argumenty sloves v různých sekundárních diatezích, jako je například pasivizace (pasivum opisné a zvratné), rezultativ (sloveso mít, dostat), dispoziční modalita. Článek detailně popisuje fungování jednotlivých transformačních pravidel pro příslušné změny forem.","As an important part of the Prague Dependency Treebank project a valency lexicon is being distributed. In this lexicon, more than 5300 verb entries are fully formally represented, with more than 8200 valency frames for verb senses included. Moreover, the valency frames are interlinked with the Prague Dependency Treebank corpus, effectively providing a verb sense distinction and annotation for every occurrence of a verb in the corpus. More than 100,000 verb occurrences are annotated in this way. The valency frame representation is fully formalized. In this contribution, we will concentrate on the formal description of the form of the verb"
Webový portál umožňující editaci a vyhledávání v přepisech audio-visuálních nahrávek dialogů.,A web portal allowing editing and searching in the transcripts of audio-visual recordings of dialogues. The dynamic web application provides access for registered users to the digitised archive. Playing selected parts is possible in the web browser.
"Na řadě příkladů představujeme dotazovací jazyk Netgraphu - plně grafického 
nástroje pro vyhledávání v Pražském závislostním korpusu 2.0. Abychom 
ukázali, že dotazovací jazyk je pro tento korpus vhodný, studujeme anotační 
manuál nejsložitější - tektogramatické - roviny korpusu a dokládáme, že 
pomocí tohoto jazyka je možno vyhledávat lingvistické jevy anotované na této 
rovině.","On many examples we present a query language of Netgraph - a fully graphical tool for searching in the Prague Dependency Treebank 2.0. To demonstrate that the query language fits the treebank well, we study an annotation manual for the most complex layer of the treebank - the tectogrammatical layer - and show that linguistic phenomena annotated on the layer can be searched for using the query language."
"Vyhledávání v lingvisticky anotovaných korpusech je důležitý úkol, vyžadující pokročilý nástroj. Netgraph byl navržen tak, aby vyhledávání bylo co nejpohodlnější, s minimem požadavků na uživatele. Ačkoliv byl vyvinut především pro Pražský závislostní korpus 2.0, může být použit také na jiné korpusy, a to jak závislostní, tak složkové, poté co je korpus převeden do vhodného formátu. V článku představujeme dotazovací jazyk Netgraphu a na mnoha příkladech ukazujeme, jak může být použit k vyhledávání běžných lingvistických jevů.","Searching in a linguistically annotated treebank is a principal task that requires a sophisticated tool. Netgraph has been designed to perform the searching with maximum comfort and minimum requirements on its users. Although it has been developed primarily for the Prague Dependency Treebank 2.0, it can be used with other treebanks too, both dependency and constituent-structure types, as long as the treebank is transformed to a suitable format.
In this paper, we present Netgraph query language and on many examples show how it can be used to search for frequent linguistic phenomena."
"Netgraph je aplikace typu klient-server pro vyhledávání v lingvisticky anotovaných korpusech, vyvinutá primárně pro vyhledávání v Pražském závislostním korpusu 2.0. Nicméně, Netgraph lze použít s dalšími korpusy, pokud jsou převedeny do formátu FS.
Tato zřejmě konečná verze Netgraphu je vyvrcholením dlouholetého vývoje a její pomocí lze vyhledávat a studovat všechny jevy anotované v PDT 2.0 s použitím jednoduchého a intuitivního graficky orientovaného dotazovacího jazyka.","Netgraph is a client-server application for searching in linguistically annotated treebanks, developed primarily for searching in the Prague Dependency Treebank 2.0. Nevertheless, Netgraph can work with other corpora too, as long as they are converted to FS format.
This supposedly last version of Netgraph concludes years of development and allows searching and studying all phenomena annotated in PDT 2.0 using a simple and intuitive, graphically oriented query language."
"V článku studujeme anotaci Pražského závislostního korpusu 2.0 a sestavujeme seznam požadavků na dotazovací jazyk, který by umožnil vyhledávat a studovat všechny lingvistické jevy anotované v tomto korpusu. Navrhujeme rozšíření dotazovacího jazyka existujícího nástroje Netgraph 1.0 a ukazujeme, že tento rozšířený dotazovací jazyk splňuje všechny jmenované požadavky.","In the article, we study the annotation of the Prague Dependency Treebank 2.0 and assemble a list of requirements on a query language that would allow searching for and studying all linguistic phenomena annotated in the treebank. We propose an extension to the query language of the existing search tool Netgraph 1.0 and show that the extended query language satisfies the list of requirements."
"Lingvisticky anotované korpusy hrají zásadní roli v moderní počítačové lingvistice. Čím složitějšími se korpusy stávají, tím pokročilejší nástroje jsou potřeba pro jejich používání, zejména pro vyhledávání v těchto datech.
Zabýváme se lingvistickými jevy anotovanými v Pražském závislostním korpusu 2.0 a vytváříme seznam požadavků, které tyto jevy staví pro vyhledávací nástroj, obzvláště pro jeho dotazovací jazyk.","Linguistically annotated treebanks play an essential part in the modern computational linguistics. The more complex the treebanks become, the more sophisticated tools are required for using them, namely for searching in the data. We study linguistic phenomena annotated in the Prague Dependency Treebank 2.0 and create a list of requirements these phenomena set on a search tool, especially on its query language."
"Dotazovací jazyk Netgraphu je dotazovací systém pro lingvisticky anotované korpusy, který se snaží být dostatečně silný pro lingvistické potřeby, ale zároveň chce být tak jednoduchý, aby nevyžadoval programátorské či matematické dovednosti od svých uživatelů. Poskytujeme úvod do tohoto systému a ukazujeme na příkladech, jak vyhledávat některé časté lingvistické jevy. Nabízíme rovněž srovníní dotazovací síly Netgraphu a TGrepu - tradičního a dobře známého dotazovacího systému pro strukturované korpusy.",Netgraph query language is a query system for linguistically annotated treebanks that aims to be sufficiently powerful for linguistic needs and yet simple enough for not requiring any programming or mathematical skill from its users. We provide an introduction to the system along with a set of examples how to search for some frequent linguistic phenomena. We also offer a comparison to the querying power of TGrep – a traditional and well known treebank query system.
"Představujeme Netgraph - snadno použitelný nástroj pro vyhledávání v lingvisticky anotovaných korpusech. Na několika příkladech z Pražského závislostního korpusu ukazujeme vlastnosti vyhledávacího jazyka a ukazujeme rovněž, jak vyhledávat některé běžné lingvistické jevy.",We present Netgraph – an easy to use tool for searching in linguistically annotated treebanks. On several examples from the Prague Dependency Treebank we introduce the features of the searching language and show how to search for some frequent linguistic phenomena.
"ElixirFM je vysokoúrovňová implementace Funkční arabské morfologie zdokumentovaná na http://elixir-fm.wiki.sourceforge.net/. Jádro ElixirFM je napsáno v Haskellu, zatímco rozhraní v Perlu podporuje údržbu slovníku a další interakce.","ElixirFM is a high-level implementation of Functional Arabic Morphology documented at http://elixir-fm.wiki.sourceforge.net/. The core of ElixirFM is written in Haskell, while interfaces in Perl support lexicon editing and other interactions."
Pražský arabský závislostní korpus (PADT) sestává z rozpracovaných víceúrovňových lingvistických anotací moderní psané arabštiny. Druhem obsažených morfologických a syntaktických informací se PADT zřetelně odlišuje od Penn Arabic Treebanku (PATB).,"Prague Arabic Dependency Treebank (PADT) consists of refined multi-level linguistic annotations over the language of Modern Written
Arabic. The kind of morphological and syntactic information comprised in PADT differs considerably from that of the Penn Arabic
Treebank (PATB). This paper overviews the character of PADT and its motivations, and reports on converting and enhancing the PATB
data in order to be included into PADT. The merged, rule-checked and revised annotations, which amount to over one million words, as
well as the open-source computational tools developed in the project are considered for publication this year."
"Morfologické značky jsou důležitou součástí anotace většiny korpusů. Bohužel se však v různých korpusech používají různé sady značek, a to i pokud jde o tentýž jazyk. Převody značek z jedné sady do druhé jsou obtížné a jejich implementace je obvykle ušitá na míru konkrétní dvojici sad značek. Zde naproti tomu navrhujeme univerzální přístup, který umožňuje jednou investované úsilí využít při pozdějších převodech do jiných formalismů. Prezentujeme také nepřímé vyhodnocení v kontextu syntaktické analýzy.","Part-of-speech or morphological tags are important means of annotation in a vast number of corpora. However, different sets of tags are used in different corpora, even for the same language. Tagset conversion is difficult, and solutions tend to be tailored to a particular pair of tagsets. We propose a universal approach that makes the conversion tools reusable. We also provide an indirect evaluation in the context of a parsing task."
"Tento článek popisuje jednoduchou metodu neřízené morfologické analýzy neznámého jazyka. Potřeba je pouze prostý textový korpus daného jazyka. Algoritmus se dívá na slova, rozpozná opakovaně se vyskytující kmeny a přípony a sestaví pravděpodobné morfologické vzory. Článek také popisuje způsob, jak byla tato metoda využita při řešení úlohy Morpho Challenge 2007, a prezentuje výsledky Morpho Challenge. Přestože tato práce byla původně studentským projektem bez návaznosti na obdobný výzkum ve světě, k našemu překvapení tento jednoduchý přístup překonal několik dalších algoritmů v podsoutěži segmentace slov. Věříme, že v metodě je dostatečný prostor pro zlepšení, který může výsledky dále zlepšit. V článku jsou rozebrány chyby a navržena budoucí rozšíření.","This paper describes a rather simplistic method of unsupervised morphological analysis of words in an unknown language. All what is needed is a raw text corpus in the given language. The algorithm looks at words, identifies repeatedly occurring stems and suffixes, and constructs probable morphological paradigms. The paper also describes how this method has been applied to solve the Morpho Challenge 2007 task, and gives the Morpho Challenge results. Although the present work was originally a student project without any connection or even knowledge of related work, its simple approach outperformed, to our surprise, several others in most morpheme segmentation subcompetitions. We believe that there is enough room for improvements that can put the results even higher. Errors are discussed in the paper; together with suggested adjustments in future research."
"Popisujeme jednoduchou metodu neřízené morfematické segmentace slov v neznámém jazyce. K tomu potřebujeme pouze korpus prostého textu (nebo seznam slov) v daném jazyce. Algoritmus rozpozná části slov, které se vyskytují v mnoha slovech, a interpretuje je jako kandidáty na morfémy (předpony, kmeny a přípony). Hlavní novinkou oproti Zeman (2007) je nové zpracování předpon. Po odfiltrování scestných hypotéz se seznam morfémů použije k segmentaci slov na vstupu. Uvádíme oficiální vyhodnocení Morpho Challenge 2008 a také dodatečné pokusy, které jsme vyhodnotili neoficiálně. Součástí práce je detailní rozbor chyb s ohledem na použitou vyhodnocovací metodu.","We describe a simple method of unsupervised morpheme segmentation of words in an unknown language. All what is needed is a raw text corpus (or a list of words) in the given language. The algorithm identifies word parts occurring in many words and interprets them as morpheme candidates (prefixes, stems and suffixes). New treatment of prefixes is the main innovation over Zeman (2007). After filtering out spurious hypotheses, the list of morphemes is applied to segment input words. Official Morpho Challenge 2008 evaluation is given along with some additional experiments evaluated unofficially. We also analyze and discuss errors with respect to the evaluation method."
"Článek popisuje metodu adaptace parseru na nový jazyk. Předpokládá se, že pro cílový jazyk je k dispozici mnohem méně lingvistických zdrojů než pro zdrojový jazyk. Postup byl kvůli dostupnosti testovacích dat testován na dvou evropských jazycích; je však snadno aplikovatelný na libovolné dva příbuzné jazyky, včetně některých indoárijských. V rámci našich pokusů jsme dokázali snížit chybovost o 34 %.","The present paper describes an approach to adapting a parser to a new language. Presumably the target language is much poorer in linguistic resources than the source language. The technique has been tested on two European languages due to test data availability; however, it is easily applicable to any pair of related languages, including some of the Indic language group. Within our experimental setting, we were able to reduce the error rate by 34 %."
"Představujeme systém STYX, který je navržen jako elektronická civčebnice českého tvarosloví a české syntaxe.
Téměř 12 000 cvičebnicových příkladů je vybráno z Pražského závislostního korpusu, nejrozsáhlejšího anotovaného korpusu češtiny. Cvičebnice nabízí komplexní zpracování věty z pohledu morfologických a syntaktických jevů, které pokrývají učební látku středních škol a vyšších tříd základních škol.
Využití anotovaných korpusů mimo jejich ""domácí prostředí"", např. v hodinách českého jazyka, je originální napříč bohatou škálou jazyků, pro které anotované korpusy existují.","We present the STYX system, which is designed as an electronic corpus-based exercise book of Czech morphology and syntax with sentences directly selected from the Prague Dependency Treebank, the largest annotated corpus of the Czech language. The exercise book offers complex sentence processing with respect to both morphologigal and syntactic phenomena, i. e. the exercises allow studens of basic and secondary schools to practice classifying parts of speech and particular morphological categories of words and in the parsing of sentences and classifying the syntactic functions of words. The corpus-based exercise book presents a novel usage of annotated corpora outside their original context."
"Významy adverbiálních určení (času, místa, způsobu apod.) jsou v syntaktických příručkách propracovány do různé hloubky, s větší či menší přesností vymezení jejich jednotlivých významů. Určeny jsou intuitivně na základě omezeného množství příkladů. I pro tektogramatickou anotaci Pražského závislostního korpusu byl nejprve empiricky stanoven soubor významů adverbiálních určení – označovaných jako funktory. Podle navrženého souboru funktorů pak byla anotována data. V současné době probíhá vyhodnocování této anotace: oanotovaná data poskytují velké množství příkladů, na jejichž základě jsou významy funktorů precizněji definovány a jemněji tříděny na tzv. subfunktory. Výsledkem bude na korpusovém materiálu založený, ucelený popis významů a podvýznamů adverbiálních určení. V tomto příspěvku představíme funktory a subfunktory pro prostorová adverbiální určení.","The article will briefly introduce the Prague Dependency Treebank. In this treebank written Czech sentences are annotated on three layers: morphological layer (morphological categories), analytical layer (surface structure) and the tectogrammatical layer (deep structure). We focus on how sentences are represented on the tectogrammatical layer. Main aim of this article is to suggest a detailed specification of meanings of spatial modifications for annotation on this layer. This detailed specification of meanings of modifications represents necessary information for the translation from one language to another."
"Dokument obsahuje pravidla pro manuální anotaci, kterou je třeba provést při budování
závislostního korpusu mluveného jazyka. Tato anotace spočívá v tzv. rekonstrukci
standardizovaného textu z mluvené řeči, tj. původní segmenty mluvené řeči, mnohdy velmi
vzdálené gramaticky správným větám, se zde popsaným způsobem převádí do takové
„standardizované” podoby, na kterou již je možné uplatnit další anotační pravidla (přidávající
zejména informaci o syntaktické struktuře věty).
Anotační manuál je určen anotátorům Pražského závislostního korpusu mluvené češtiny, ale
lze jej chápat jako obecný návod pro podobně pojatou anotaci kteréhokoli jazyka.",This document is primarily meant to serve as a manual for human annotators of spoken data of The Prague Dependency Treebank of Spoken Czech (PDTSC).
"Příspěvek shrnuje dosavadní poznatky získané při budování Pražského závislostního
korpusu mluvené češtiny (Prague Dependency Treebank of Spoken Czech; dále PDTSC)
v Ústavu formální a aplikované lingvistiky MFF UK. PDTSC bude prvním korpusem
mluvené řeči, který nabídne i syntakticko-sémantickou anotaci promluv. Východiskem
projektu PDTSC je syntakticko-sémantická anotace korpusu psaných textů, která již byla
zpracována v projektu Pražského závislostního korpusu 2.0 (dále PDT).",PDTSC aims to be the first spoken corpus including the syntactic annotation of speech. This corpus is based on the annotation of written language (PDT).
Příspěvek v Kronice Slova a slovesnosti k jubileu prof. Jarmily Panevové.,Contribution in Chronicle of Slovo a slovesnost in honour of prof. Jarmila Panevova.
"V~tomto textu shrnujeme výsledky dosažené při vytváření lexikální databáze českých sloves. Práce se soustřeďuje na tři základní okruhy. Prvním okruhem je formální zachycení valenčních vlastností českých sloves ve valenčním slovníku. Je zde představena logická stavba bohatě strukturovaných slovníkových dat. Druhým okruhem,
kterému se práce věnuje, jsou nové teoretické aspekty, které přináší zpracování rozsáhlého jazykového materiálu -- je to především koncept kvazivalenčních doplnění a adekvátní zpracování
slovesných alternací. Třetí okruh tvoří
problematika formálního modelování přirozeného jazyka. Je zde představen nový formální model závislostní syntaxe založený na originálním konceptu restartovacích automatů.","The present work summarizes the results of building a lexical database of Czech verbs. It concentrates on three essential topics. The first of them is the formal representation of valency properties of Czech verbs in the valency lexicon. The logical organization of richly structured lexicon data is presented here. The second topic concerns new theoretical aspects that result from the extensive processing of language material, namely the concept of quasi-valency complementation and adequate processing of verb alternations. The third topic addresses questions of formal modeling of a natural language. A new formal model of dependency syntax based on a novel concept of restarting automata is introduced here."
"Valence, tedy ""počet a povaha míst (argumentů), které na sebe sloveso (-) váže"" (Encyklopedický slovník češtiny, Karlík a kol., 2002), patří k jazykovým jevům, které vzbuzují zájem lingvistů, ale i odborníků zabývajících se automatickým zpracováním přirozených jazyků. Dobrá znalost valence je nezbytná pro každého, kdo pracuje s jazykem - pro učitele, redaktory, novináře, studenty. Valence zároveň hraje klíčovou roli při mnoha úlohách automatického zpracování přirozeného jazyka, jakými jsou např. strojový překlad či vyhledávání informací. Valenční slovník českých sloves VALLEX poskytuje informace o valenční struktuře českých sloves v jejich jednotlivých významech, které charakterizuje pomocí glos a příkladů. Pro jednotlivá valenční doplnění uvádí jejich možná morfematická vyjádření. Tyto základní údaje jsou doplněny o některé další charakteristiky, jako je možnost recipročního užití či syntakticko-sémantická třída slovesa.","Valency, that is ""the number and character of places (arguments), which a verb (...) ties to itself"" (Encyclopaedic Dictionary of Czech, Karlík et al., 2002), belongs among the linguistic phenomena, which interest linguists as well as experts concerned with automatic processing of natural languages. A good knowledge of valency is necessary for anybody who works with languages - teachers, editors, journalists, students. Valency also plays an important role in many tasks of automatic processing of natural languages, such as machine translation or information search. VALLEX, the valency dictionary of Czech verbs, provides information about the valency structure of Czech verbs with their individual meanings, which are characterised by notes and examples. It also presents possible morphematic forms for individual valency complements. These elementary data are complemented with some other characteristics, such as the possibility of their reciprocal use or the syntactic-semantic verb class."
"Syntaktická analýza vět přirozeného jazyka, základní předpoklad mnoha aplikovaných úkolů, je složitá úloha, a to zejména pro jazyky s volným slovosledem. Přirozeným krokem, který snižuje
složitost vstupních vět, může být vytvoření modulu, ve kterém se určí struktura souvětí ještě před úplnou syntaktickou analýzou. Navrhujeme využít pojem segmentů, snadno automaticky rozpoznatelných úseků vět. Určujeme `segmentační
schémata' popisující vzájemné vztahy mezi segmenty -- zejména souřadná a apoziční spojení, podřadná spojení, případně vsuvky.

V tomto článku představujeme vývojový rámec, který umožňuje vyvíjet a testovat pravidla pro automatické určování segmentačních schémat. Popisujeme dva základní experimenty -- experiment se získáváním segmentačních schémat ze stromů Pražského závislostního korpusu a experiment se segmentačními pravidly aplikovanými na prostý text. Dále navrhujeme míry pro vyhodnocování úspěšnosti segmentačních pravidel.","Syntactic analysis of natural language sentences, the basic requirement of many applied tasks, is a complex task, especially for languages with free word order. Natural solution, which reduces
complexity of the input sentences, can be a module in which they determined the structure of sentences before full synyactic analysis. We propose to use the concept of segments, easily recognizable sections sentences automatically. We introduce `segmentation schemata' that describe the relationship between the segments - in particular, super/subordination, coordination and aposition, and parenthesis.

In this article we present framework that allows to develop and test rules for automatically determining the segmentation schemes. We describe two basic experiments - experiment to obtain the segmentation patterns from trees from Prague Dependency Treebank amd segmentation experiment with the rules applied to plain text. Furthermore, we propose measures for evaluating  segmentation rules."
"Příspěvek prezentuje základní formální pojmy, které umožňují formalizovat redukční analýzu pro Funkční generativní popis češtiny. Ilustruje metodu redukční analýzy a její aplikaci na zpracování závislostí a slovosledu v jazyce s volným slovosledem. Zavádí 4-úrovňový redukční systém založený na pojmu jednoduchých restartovacích automatů. Tento nový rámec umožňuje formálně definovat charakteristickou  relaci, a tedy zachytit synonymie a víceznačnost v studovaném jazyce.","The paper presents the basic formal notions that allow for formalizing the notion of analysis by reduction for Functional Generative Description, FGD. We have outlined and exemplified the method of analysis by reduction and its application in processing dependencies and word order in a language with a high degree of free word order. Based on this experience, we have introduced the 4-level reduction system for FGD based on the notion of simple restarting automata. This new formal frame allows us to define formally the characteristic relation for FGD, which renders synonymy and ambiguity in the studied language."
"V tomto příssěvku se soustředíme na česká slovesa mluvení s imperativními rysy, která k sobě vážou valenční doplnění se sémantickou rolí informace. Toto může být morfematicky vyjádřeno jako závislá obsahová klauze. Dané klauze bývají prototypicky uvozeny spojkou aby. Spojka aby však může být za určitých podmínek nahrazena spojkou že. Tyto podmínky jsou pak předmětem naší analýzy založené na korpusovém materiálu. Korpusový materiál ukazuje, že daná slovesa vykazují tendenci vázat k sobě závislé obsahové klauze buď s modalitou nutnosti, nebo možnosti.","This paper focuses on Czech verbs of communication with imperative features. One of their valency complementation corresponding to the participant 'Message' is morphematically realized as dependent content clause prototypically introduced by the conjunction 'aby' which may be replaced by the conjunction 'že' on certain conditions. We analyzed these conditions on the basis of corpus evidence. We conclude that this class of verbs of communication prefer either the modality of necessity, or possibility. On the other hand, the corpus material does not prove that these verbs are associated only with single modal meaning distinguished within the mentioned categories."
"V tomto příspěvku popisujeme pokus o přiřazení sémantických informací z FrameNetu lexikálním jednotkám z VALLEXu, valenčního slovníku českých sloves. Popisujeme experiment s přiřazením sémantických rámců lexikálním jednotkám sloves mluvení. Další část experimentu spočívá v provázání valenčních doplnění daných sloves s elementy sémantických rámců Z FrameNetu. Mezianotátorská shoda týkající se přiřazení sémantických rámců dosáhla téměř 69%. Shody 84.6%  dosáhli anotátoři při přiřazení jednotlivých elementů sémantických rámců valenčním doplněním. Na závěr navrhujeme při obohacení VALLEXu o chybějící sémantické informace z FrameNetu využít sémantického vztahu dědičnosti.","In this paper, we report on our attempt at assigning semantic
information from FrameNet to lexical units in VALLEX, a valency
lexicon of Czech verbs. We focus on the class of communication
verbs. We experiment with assigning FrameNet semantic frames to
lexical units for communication verbs. The second task consists in linking
their valency complementations with FrameNet frame elements. The
exact pairwise inter-annotator agreement reaches almost 69% on
the semantic frames and 84.6% on the frame elements. We propose
enhancing VALLEX with missing semantic information from FrameNet
based on exploitation of the semantic relation 'Inheritance'."
"Zavádíme ""Zlaté pravidlo morfologie"", které vyžaduje odlišný morfologický popis každého slovního tvaru. V současných morfologických systémech češtiny toto pravidlo nebývá splněno, především kvůli nekonzistentnímu popisu různých typů morfologických a ortografických variant. Definujeme dvě hlavní typy variant - globální a flektivní.","The paper presents „Golden Rule of Morphology” that requires different morphological tags for different wordforms. This requirement is not fulfilled in recent morphological systems of Czech, mainly due to inconsistent treatment of different types of morphological and orthographic variants. We define two major types of variants, namely inflectional variants, that concern only some combinations of morphological categories, and global variants that affect all wordforms of a given lemma. We propose how to tag the variants in order that they belonged to the same lemma, but were still distinguishable."
Prezentujeme nástroj Affisix pro automatické rozpoznávání předpon. Na základě rozsáhlého seznamu slov určujeme řetězce - kandidáty na předpony. V nástroji jsou implementovány dvě metody - metoda entropie a metoda čtverců.,"In the paper, we present a software tool Affisix for automatic recognition of prefixes. On the basis of an extensive list of words in a language, it determines the segments - candidates for prefixes. There are two methods implemented for the recognition - the entropy method and the  squares method. We briefly describe the methods, propose their improvements and present
the results of experiments with Czech."
"Nový systém morfologie, který zde prezentujeme, vychází ze současného pražského systému. Kromě nové implementace stávajícího slovníku pomocí konečného automatu přidává algoritmy na rozpoznání neznámých tvarů. V současné fázi je to především využití seznamu předpon, které lidé připojují bez větších omezení ke slovům a činí je tak pro automatické metody nerozpoznatelnými. Stačí předponu rozpoznat, odtrhnout a analyzovat zbylý řetězec. Výsledky této analýzy lze pak jednoduše aplikovat na původní tvar s předponou. K rozpoznání neznámých vlastních jmen používáme heuristiku. V příspěvku stručně popíšeme stávající pražský systém a použitý zárodek guessru.",New system of automatic morphology of Czech is based on the existing Prague system. New features are mainly recognition of OOV prefixed words and a heuristics about foreign names.
"Zabýváme se dvěma typy asymetrie mezi slovními tvary a jejich (morfologickými) charakteristikami, totiž (morfologickými) variantami a homonymy. Zavádíme tzv. vícenásobné lemma.","We discuss two types of asymmetry between wordforms and their (morphological) characteristics, namely (morphological) variants
and homographs. We introduce a concept of multiple lemma that allows for unique identification of wordform variants as well as
`morphologically-based' identification of homographic lexemes. The deeper insight into these concepts allows further refining of morphological dictionaries and subsequently better performance of any NLP tasks."
Tento příspěvek se zabývá lexikografickým zachycením různých typů reflexívních sloves ve velkých německých jednojazyčných slovnících.,This contribution addresses various types of reflexivity in Germans verbs and their lexicographical description in current large monolingual dictionaries.
Tento článek popisuje manuální anotaci rekonstrukce mluvené řeči na dialogovém korpusu NAP. Korpus NAP obsahuje rozhovory anglických mluvčích nad alby fotografií. Anotace vzniká v rámci projektu Companions.,"This paper presents the ongoing manual speech reconstruction annotation of the NAP corpus, which is a corpus of recorded conversations between pairs of people above family photographs, relating it to a more complex annotation scheme of the Prague Dependency Treebank family. The result of this effort will be a resource that will contain, on top of the audio recording of the dialog and its usual transcription, an edited and fully grammatical “reconstructed” dialog. The format and alignment with the original audio and transcription on one side and a similar alignment (linking) to a deep analysis of the natural language sentences uttered in the dialog on the other side will be such that the resource can serve as a training and testing material for machine learning experiments in both intelligent editing as well as in dialog language understanding. The resource will be used in the Companions project, but it will be publicly available outside of the project as well."
"Tento příspěvek ilustruje, jak se tektogramatický popis dá použít jako měřítko porovnávání dvou nepříbuzných jazyků - zde češtiny a angličtiny.","The present paper is aimed to illustrate how the description of underlying structures carried out in annotating Czech texts may be used as a basis for comparison with a more or less parallel description of English. Specific attention is given to several points in which there are differences between the two languages that concern not only their surface or outer form, but (possibly) also their underlying structures."
"Tento příspěvek ilustruje, jak je možné využít tektogramatickou reprezentaci jako měřítko porovnávání dvou nepříbuzných jazyků - zde češtiny a angličtiny.",This contribution illustrates how the description of underlying structures carried out in annotating Czech texts may be used as a basis for comparison with a more or less parallel description of English.
"Tato publikace je návodem pro anotátory, jak anotovat rovinu rekonstrukce anglické mluvené řeči. Anotace zvaná Rekonstrukce mluvené řeči je prováděna na českém a anglickém korpusu a má dále sloužit pro uplatnění metod strojového učení na přirozený jazyk. Anotace obsahuje původní doslovný přepis nahrávek a také editovanou verzi, která vyhovuje standardům psaného textu. Obě verze představují oddělené roviny, které jsou navzájem propojeny na úrovni akustických segmentů, vět editovaného textu a jednotlivých slov.","This is an annotation manual of English speech reconstruction. Speech reconstruction has been carried out at the Prague Dependency Treebank of Spoken Language, which consists of a Czech and an English, to be used for the task of speech understanding, broad natural language analysis for dialog systems and other speech-related tasks, including speech editing. The resources we have created so far contain audio and a standard transcription of spontaneous speech, but as a novel layer, we add an edited (“reconstructed”) version of the spoken utterances."
Příspěvek popisuje korpusové metody pro zjišťování změn v užívání slov. Metody byly použity na dvou stomilionových korpusech češtiny ze dvou po sobě jdoucích období.,"The paper presents a corpus-based method for obtaining ranked wordlists that can
characterise lexical usage changes. The method is evaluated on two 100-million
representatively balanced corpora of contemporary written Czech that cover two consecutive
time periods. Despite similar overall design of the corpora, lexical frequencies have to be first
normalised in order to achieve comparability. Furthermore, dispersion information is used to
reduce the number of domain-specific items, as their frequencies highly depend on inclusion
of particular texts into the corpus. Statistical significance measures are finally used for
evaluation of frequency differences between individual items in both corpora.
It is demonstrated that the method ranks the resulting wordlists appropriately and several
limitations of the approach are also discussed. Influence of corpora composition cannot be
completely obliterated and comparability of the corpora is shown to play a key role.
Therefore, although highly-ranked items are often found to be related to changes of
language usage, their relevance should be cautiously interpreted. In addition to several
general language words, the real examples of lexical variation are found to be limited
mostly to temporary topics of public discourse or items reflecting recent technological
development, thus sketching an overall picture of lifestyle changes."
"Pražský závislostní korpus (PDT) je cenným zdrojem lingvistických informací anotovaných na několika rovinách. Anotační roviny pokrývají škálu od mělkých po hloubkové a měly by obsahovat veškerou lingvistickou informaci o textu. Je tedy přirozené rozšířit je o sémantickou rovinu, která by sloužila jako báze znalostí pro úlohy jako je zodpovídání dotazů, extrakce informací atd.","The Prague Dependency Treebank (PDT) is a valuable resource
of linguistic information annotated on several layers. These
layers range from shallow to deep and they should contain all
the linguistic information about the text. The natural extension
is to add a semantic layer suitable as a knowledge base
for tasks like question answering, information extraction etc.
In this thesis I set up criteria for this representation, explore
the possible formalisms for this task and discuss their properties.
One of them, Multilayered Extended Semantic Networks
(MultiNet), is chosen for further investigation. Its properties
are described and an annotation process set up. I discuss some
practical modifications of MultiNet for the purpose of manual
annotation. MultiNet elements are compared to the elements
of the deep linguistic layer of PDT. The tools and problems of
the annotation process are presented and initial annotation data
evaluated."
"Pražský závislostní korpus (PDT) je cenným zdrojem lingvistických informací anotovaných na několika rovinách. Anotační roviny pokrývají škálu od mělkých po hloubkové a měly by obsahovat veškerou lingvistickou informaci o textu. Je tedy přirozené rozšířit je o sémantickou rovinu, která by sloužila jako báze znalostí pro úlohy jako je zodpovídání dotazů, extrakce informací atd.","The Prague Dependency Treebank (PDT) is a valuable resource
of linguistic information annotated on several layers. These
layers range from shallow to deep and they should contain all
the linguistic information about the text. The natural extension
is to add a semantic layer suitable as a knowledge base
for tasks like question answering, information extraction etc.
In this thesis I set up criteria for this representation, explore
the possible formalisms for this task and discuss their properties.
One of them, Multilayered Extended Semantic Networks
(MultiNet), is chosen for further investigation. Its properties
are described and an annotation process set up. I discuss some
practical modifications of MultiNet for the purpose of manual
annotation. MultiNet elements are compared to the elements
of the deep linguistic layer of PDT. The tools and problems of
the annotation process are presented and initial annotation data
evaluated."
Prezentujeme vyhodnocení anotace mezivětné koreference v kontextu ručně vytvořených sémantických sítí.,"We present an evaluation of inter-sentential coreference annotation in the context of manually created semantic networks. The semantic
networks are constructed independently be each annotator and require an entity mapping priori to evaluating the coreference. We
introduce a model used for mapping the semantic entities as well as an algorithm used for our evaluation task. Finally, we report the raw
statistics for inter-annotator agreement and describe the inherent difficulty in evaluating coreference in semantic networks."
"Zcela přepracovaná verze systému STYX 2007:
- vylepšena pravidla filtrování vět
- vylepšeny transformace syntaktických stromů do školské podoby
- úpravy uživatelského rozhraní
- opravy chyb 

Systém STYX je elektronickou cvičebnicí češtiny postavenou nad daty Pražského závislostního korpusu. Skládá se z konzolové aplikace určené k filtrování vět (FilterSentences), administračního programu sloužícího k sestavování cvičení (Charon) a vlastní cvičebnice nazvané Styx.","Complete rewrite of the STYX 2008 system:
- improved rules for sentence filtering
- improved transformations of syntactic trees to the school form
- rewritten user interface
- bugfixes

STYX is an electronic exercise book of Czech based on data of the Prague Dependency Treebank. It consists of a console application used to filter unsuitable sentences (FilterSentences), an administrative application for creating exercises (Charon) and the exercise book itself, Styx."
"Cílem naší práce je představit elektronickou cvičebnici českého jazyka o celkovém objemu 12 tisíc vět k procvičování ve dvou oblastech: tvarosloví (určování slovních druhů a jejich morfologických kategorií) a větný rozbor (určování větných členů a vztahů mezi nimi). Uživatelům je k dispozici pro všechny věty i klíč k řešení. Cvičebnice je sestavena z výběru vět, které obsahuje akademický Pražský závislostní korpus.",We introduce an electronic exercise book of Czech that consists of 12 thousand sentences to practice morphology and syntax. The correct answers are available to the users as well. The sentences in the exercise book represent a selection from the Prague Dependency Treebank.
"Victoria je nástroj pro anotování textu na webových stránkách pomocí webového prohlížeče. Stránka je automaticky stažena ze zadaného URL, analyzována a anotátor může vybrat kategorii pro každý blok textu.",Victoria is a tool for web-page anotation using a web browser. Web page is downloaded and analzyed. Annotator can simply select a category for every text block.
"V tomto článku prezentujeme kompletní řešení pro automatické čištění HTML stránek, jehož cílem je použití webových dat pro vytvoření korpusu textů pro zpracování přirozeného jazyka nebo pro lingvistiku. Používáme algoritmus sekvenčního značkování Conditional Random Fields. Každému bloku textu analyzované webové stránky je přiřazena sada rysů extrahovaná z textu a HTML struktury stránky. Blokům jsou pak automaticky přiřazeny značky, které říkají, zda má být blok zachován, nebo odstraněn. Naše řešení je založeno na nástroji z CLEANEVAL 2007.","In this paper we present a complete solution for automatic cleaning of arbitrary HTML pages with a goal of using web data as a corpus in the area of natural language processing and computational linguistics. We employ a sequence-labeling approach based on Conditional Random Fields (CRF). Every block of text in analyzed web page is assigned a set of features extracted from the textual content and HTML structure of the page. The blocks are automatically labeled either as content segments containing main web page content, which
should be preserved, or as noisy segments not suitable for further linguistic processing, which should be eliminated. Our solution is based on the tool introduced at the CLEANEVAL 2007 shared task workshop. In this paper, we present new CRF features, a handy annotation tool, and new evaluation metrics. Evaluation itself is performed on a random sample of web pages automatically downloaded from the Czech web domain."
Článek představuje velké textové korpusy Českého národního korpusu a jejich morfologické značkování a lemmatizaci. Popisuje metody značkování a jejich úspěšnost ve třech velkých korpusech ČNK.,The paper presents large textual corpora of the Czech National Corpus and their morphological tagging and lemmatization. It describes the methods used for morphological tagging and their precision in three large corpora of ČNK.
Článek představuje experimentální systém strojového překladu pro mobilní zařízení a jeho hlavní komponentu - distribuovanou databázi pro pravidla lexikálního transferu.,The paper presents an experimental machine translation system for mobile devices and its main component — a distributed database which is used in the module of lexical transfer. The database contains data shared among multiple devices and provides their automatic synchronization.
Článek se věnuje popisu situace české (moravské) národnostní menšiny v pruském Slezsku.,The article describes the situation of the Czech (Moravian) minority in the Prussian part of Silesia.
Článek se věnuje popisu situace slovinsé národnostní menšiny v rakouských Korutanech z historického hlediska.,The article describes the situation of the Slovenian minority in Carianthia in Austria from the historical point of view.
Reimplementace interpretu Q-systémů v C++. Rozšíření o pojmenované proměnné a eliminaci duplicitních hran.,A reimplementation of the Q-systems interpreter in C++. Allows for named variables and elimination of multiple equal edges.
Článek popisuje formalismus pro mělký parsing pro překlad mezi příbuznými jazyky. Formalismus umožňuje psát pravidla pro částečnou disambiguaci vstupních vět. Stochastický ranker vybírá nejvhodnější překlad v závislosti na jazykovém modelu cílového jazyka.,This paper describes a shallow parsing formalism aiming at machine translation between closely related languages. The formalism allows to write grammar rules helping to (partially) disambiguate chunks in input sentences. The chunks are then translatred into the target language without any deep syntactic or semantic processing. A stochastic ranker then selects the best translation according to the target language model. The results obtained for Czech and Slovak are presented.
"Článek zavádí hybridní přístup ke strojovému překladu mezi příbuznými jazyky. Zmiňuje předchozí experimenty pro skandinávské, slovanské, turkické a románské jazyky a popisuje novou metodu, kombinaci mělkého parseru a stochastického rankeru.","The paper introduces a hybrid approach to a very specific field in machine translation — the translation of closely related languages. It mentions previous experiments performed for closely related Scandinavian, Slavic, Turkic and Romanic languages and describes a novel method, a combination of a simple shallow parser of the source language (Czech) combined with a stochastic ranker of (parts of) sentences in the target language (Slovak, Russian). The ranker exploits a simple stochastic model of the target language and its main task is to choose the best translation among those provided by the system. The last section of the paper presents results indicating better translation quality compared to the existing MT system for Czech and Slovak and compares them top the results obtained by the translation from Czech to Russian using the same system."
Reimplementace systému Česílko. Jedná se o verzi s mělkým parsingem a stochastickým rankerem.,A reimplementation of the system Česílko. This version contains a shallow parser and a stochastic ranker.
Tento článek představuje hybridní přístup k překladu blízce příbuzných jazyků.,The paper presents a hybrid approach to MT between related languages.
Článek popisuje vylepšení architektury systému Apertium pro pár portugalština-španělština.,"The paper gives an overview of the shallow-transfer MT system Apertium, describes an experiment with the language pair Portuguese-Spanish and suggests a modification of the system architecture which leads to higher translation quality. Finally, consequences of the architecture improvement for the design of language resources for shallow-transfer based systems are discussed."
Článek popisuje použití částečného parsingu v systému strojového překladu pro slovanské jazyky.,The paper describes the use of partial parsing in an MT system for Slavic languages.
"Tento článek popisuje výsledky, které byly dosaženy v mezinárodním výzkumném projektu LT4eL z pohledu jednoho jazyka zpracovávaného v projektu - češtiny. Cílem projektu je využití jazykových technologií pro rozšíření funkcionality open source systém pro e-learning ILIAS. Nová funkcionalita je založena na stávajícíh a nově vytvořených nástrojích pro všechny zapojené jazyky. Článek podrobně popisuje problémy implementace extraktoru klíčových slov a slovníkových definic z textu pro češtinu.","This paper describes the efforts undertaken in an international research project LT4eL from the perspective of one of the participating languages, Czech. The project aims at exploiting language technologies for adding new functionalities to an open source Learning Management System ILIAS. The new functionalities are based both on existing and newly developed tools for all languages involved. The paper describes in detail the issues of the implementation of a keyword extractor and a glossary candidate detector for Czech."
V tomto příspěvku se zaměříme na využití technologií zpracování přirozeného jazyka k vylepšení současných systémů pro výuku (e-learning). Zaměříme se na vyhledávání definic a klíčových slov a technologii sémantického vyhledávání.,In this paper we present recent advances in using language technology to improve current learning management systems. We focus on definitions and keyword search as well as semantic search technology.
"V článku pojednáme o probíhajícím projektu poloautomatické anotace víceslovných výrazů. V prvém plánu jde o doplňování dodatečné informace k datům PDT 2.0, v dlouhodobějším pohledu by mělo jít o součást přiblížení tektogramatické vrstvy PDT k tomu, jak byla tektogramatická analýza ve Funkčním generativním popisu (FGP) navržena. Vysvětlíme, jakou roli v našem pojetí hraje ruční anotace a co je možno provést automaticky.","In this article we want to demonstrate that
annotation of multiword expressions in the
Prague Dependency Treebank is a well deﬁned task and that it is useful as well as feasible.
We argue that some automatic pre-annotation is possible and it does not damage the results."
"V tomto článku chceme ukázat, že anotace víceslovných výrazů Pražského závislostního korpusu je dobře definovaný úkol, že je potřebný a proveditelný, a že můžeme dosáhnout dobré mezianotátorské shody.
Ukážeme způsob, jak měřit shodu pro tento druh anotace. Dále tvrdíme, že určitá automatická předanotace je možná a nepoškozuje výsledky.","In this article we want to demonstrate that annotation of multiword expressions in the Prague Dependency Treebank is a well defined task, that it is useful as well as feasible, and that we can achieve good consistency of such annotations in terms of inter-annotator agreement. We show a way to measure agreement for this type of annotation. We also argue that some automatic pre-annotation is possible and it does not damage the results."
"Příspěvek se zabývá otázkou, zda zájmena uvozující obsahové věty klasifikovat jako tázací nebo vztažná. V české lingvistické literatuře lze najít oba přístupy, záleží přitom na tom, jak jsou v jednotlivých příručkách tyto dvě zájmenné podskupiny definovány. V příspěvku se přikláníme ke klasifikaci zájmen uvozujících obsahové věty jako zájmen tázacích. Výhody, které tento přístup podle našeho názoru přináší, se pokoušíme objasnit.","In the contribution, the problem how pronouns introducing content clauses are classified in Czech linguistic literature is discussed. The classification of these pronouns depends on how interrogative and relative pronouns are defined in the given approaches. Basically, two different types of approaches are described. Firstly, relative pronouns are defined broadly as only attaching a dependent clause to its governing one; pronouns introducing content clauses belong then to this subgroup of pronouns. In this connection, interrogative pronouns occur only in direct questions. In approaches of the second type, which we subscribe to, the constitutive feature of relative pronouns is their relation to an element of the governing clause. The main characteristic of interrogative pronouns is the reference to an unknown person/object – pronouns introducing both questions and content clauses are interpreted as interrogatives; this classification is advantageous for several reasons, which we try to indicate."
"Ačkoli jsou vlastní jména nedílnou součástí textů, a tedy i textových korpusů, byla jim (přinejmenším) v české korpusové lingvistice dosud věnována jen okrajová pozornost. V příspěvku představíme, jak jsou vlastní jména popsána v dostupných korpusech češtiny. Ukážeme, že dosavadní způsob zachycení je nedostatečný, a pokusíme se proto navrhnout nový způsob jejich reprezentace. V Pražském závislostním korpusu 2.0 (PDT 2.0) by reprezentace vlastních jmen měla být součástí popisu větné sémantiky, pro tyto účely je nutné stávající anotační schéma adaptovat.","Although proper nouns are an inseparable part of natural language texts and thus of text corpora, (at least) Czech corpus linguistics has been paying little attention to this area. We demonstrate that Czech corpora can be certainly used as a rich source for study of proper nouns. Firstly, we introduce how proper nouns are handled in present Czech corpora: e.g., in the Prague Dependency Treebank 2.0 a very simple annotation of proper nouns is involved in the morphological annotation whereas the syntactic annotation scheme of this corpus does not take proper nouns into consideration. We list several reasons why we consider such annotations to be insufficient and unsuitable. As for the position of the annotation of proper nouns within a multi-layered annotation scheme, we arrive at the conclusion that proper nouns could be annotated at a (deep) syntactic layer. Therefore, the annotation schemes have to be adapted for this purpose."
"Recenze se zabývá sborníkem Language in its multifarious aspects, v němž jsou shromážděny články prof. Petra Sgalla týkající se obecných a teoretických témat, syntaxe, aktuálnho členění, otázkám významu a obsahu, typologie jazyků a rysům psané a mluvené češtiny.","The book ""Language in its multifarious aspects"" is reviewed, which involves Petr Sgall's articles on general and theoretical issues, syntax, topic-focus articulation, relation between meaning and content, typology of languages, and spoken and written Czech."
"Valenční slovník zachycuje slovesa, jejich vazby, povinná a volná doplnění. Valenční slovník moderní spisovné arabštiny je budován s pomocí příkladů z Pražského arabského závislostního korpusu.","A valency dictionary presents verbs, their valency, obligatory and free modifiers. The valency dictionary of the Modern Standard Arabic language has been built using examples from the Prague Arabic Dependency Treebank."
"Článek porovnává architekturu dvou morfo-syntaktických generátorů vět, generujících český a anglický výstup. Popisujeme vstupní struktury: závislostní stromy z Funkčního generativního popisu P.Sgalla a také vlastní systém generování vět v jazycích, které jsou typologicky velmí odlišné . Výkon obou generátorů je nakonec měřen pomocí BLEU skóre.","We present a work in progress on a pair of morpho-
syntactic realizers sharing the same architecture. We provide
description of input tree structures, describe our procedural
approach on two typologically different languages and finally
present preliminary evaluation results conducted on manually
annotated treebank."
"Článek představuje projekt Pražského závislostního korpusu: jeho teoretické pozadí, rozdělení na roviny, anotační schémata a nástroje používané k anotaci. Udává také několik přikladů práce s treebankem.","The article presents the project of Prague Dependency Treebank 2.0: its theoretical background, division into layers, annotation schemata and tools used in annotation process. It gives several examples how the treebank could be used."
"Pražský závislostní korpus (PDT 2.0) obsahuje velké množství českých textů doplněných rozsáhlou a provázanou morfologickou (2 milióny slovních jednotek), syntaktickou (1,5 miliónu slovních jednotek) a sémantickou (0,8 miliónu slovních jednotek) anotací; na sémantické rovině jsou navíc anotovány aktuální členění věty a koreferenční vztahy.
PDT 2.0 vychází z dlouhodobé pražské lingvistické tradice, upravené pro současné potřeby výzkumu v oblasti komputační lingvistiky. Samotný korpus využívá nejnovější anotační technologie.","The Prague Dependency Treebank 2.0 (PDT 2.0) contains a large amount of Czech texts with complex and interlinked morphological (2 million words), syntactic (1.5 MW) and complex semantic annotation (0.8 MW); in addition, certain properties of sentence information structure and coreference relations are annotated at the semantic level. PDT 2.0 is based on the long-standing Praguian linguistic tradition, adapted for the current Computational Linguistics research needs. The corpus itself uses the latest annotation technology. 
Besides the large corpus of Czech, a corpus of Czech-English parallel resources (The Prague Czech-English Dependency Treebank) is being developed. English sentences from the Wall Street Journal and their translations into Czech are being annotated in the same way as in PDT 2.0. This corpus is suitable for experiments in machine translation, with a special emphasis on dependency-based (structural) translation.
In the report, the basic annotation scheme is represented, with special reference to complex semantic (tectogrammatical) level. The system of syntactic functors and valency lexicon VALLEX are also discussed."
"Článek prověřuje tři metody intonační stylizace v češtině: sekvenci intonačních přízvuků, sekvenci hraničních tónů a sekvenci kontur. Účinnost těchto metod byla porovnána pomocí neuronové sítě, která předpovídala křivku F0 z každého ze tří uvedených vstupů, s následným percepčním vyhodnocením. Výsledky ukázaly, že českou intonaci se lze naučit přibližně se stejnou úspěšností ve všech třech případech. To hovoří ve prospěch rehabilitace kontur, jakožto tradičního popisu české intonace, stejně jako užití hraničních tónů, jakožto alternativního lokálního pohledu.","This paper examines three methods of intonational
stylization in the Czech language: a sequence of pitch accents, a sequence of boundary tones, and a sequence of contours. The efficiency of these methods was compared by means of a neural network which predicted the f0 curve from each of the three types of input, with subsequent perceptual assessment. The results show that Czech intonation can be learned with about the same success rate in all three situations. This speaks in favour of a rehabilitation of contours as a traditional means of describing Czech intonation, as well as the use of boundary tones as another possible local approach."
Syntéza emotivního mluveného projevu je stále výzvou. Centrálním tématem výzkumu je jak začlenit do syntézy mluvené řeči emotivní projevy. \v tomto článku popisujeme dve konkatenativní syntézové systémy a navrhujeme nové přístupy.,"The synthesis of emotional speech is still an open
question. The principal issue is how to introduce expressivity without compromising the naturalness of the synthetic speech provided by the state-of-the-art technology. In this paper two
concatenative synthesis systems are described and some approaches to address this topic are proposed. For example,considering the intrinsic expressivity of certain speech acts, by
exploiting the correlation between affective states and
communicative functions, has proven an effective solution. This
implies a different approach in the design of the speech
databases as well as in the labelling and selection of the
“expressive” units. In fact, beyond phonetic and prosodic
criteria, linguistic and pragmatic aspects should also be
considered. The management of units of different type (neutral
vs expressive) is also an important issue."
"Victor je nástroj pro čištění webových stránek.
Používá algoritmus sekvenčního značkování Conditional Random Fields. Každému bloku textu analyzované webové stránky je přiřazena sada rysů, která je extrahovaná z textu a HTML struktury stránky. Blokům jsou pak automaticky přiřazeny značky, které říkají, zda má být blok zachován, nebo odstraněn.","Victor is a tool for cleaning web pages. It employs a sequence-labeling approach based on Conditional Random Fields (CRF). Every block of text in the analyzed web page is assigned a set of features extracted from the textual content and HTML structure of the page. Text blocks are automatically labeled either as content segments containing main web page content, which should be preserved, or as noisy segments not suitable for further linguistic processing, which should be eliminated."
"Příspěvek představuje přípravný výzkum v oblasti slovesné valence a argumentové struktury. V souvislosti s právě budovaným vícejazyčným valenčním slovníkem si klademe otázku, zdali má být struktura hesel spíše jednoduchá a nestrukturovaná, či zda může být výhodné vybudovat ji hierarchicky a zachytit tak vztahy mezi jednotkami na více úrovních, včetně vztahů v rámci každého jazyka zvlášť.","The paper presents a preliminary research in the area of verbal valency and argument structure theory. With the perspective of building a multilingual archive of valency characteristics of verbs, the question is raised whether the structure of such a linguistic resource should be straight and simple, or to some extent hierarchical and capturing more relation types, including those among individual frames within a single language."
úvodní článek k časopiseckému číslu zaměřenému na aktuální členění a výstavbu diskursu,introductory article on journal number concerning the topic-focus articulation and discourse
"Role přísudkových sloves, rematizovaných skupin a příslovečných určení v aktuálním členění v českých větách","The role of predicate verbs, focalized groups and adverbials in topic-focus articulation in Czech sentences - problematic points"
Slovosledné postavení příklonky se/so v aktivních a pasivních konstrukcích,Word order position of the clitic se/so in active and passive constructions
Článek pojednává o nejednoznačnosti aktuálního členění výpovědi v básnické tvorbě Otokara Březiny.,The article discusses ambiguity of the topic-focus articulation in the poetry of Otokar Březina.
Popis česko-anglicko-ruského korpusu (po dvojicích paralelní) pro strojový překlad.,The description of a pairwise parallel English-Czech-Russian corpus for machine translation.
Compost Czech je program kombinující morfologickou analýzu z PDT 2.0 a tagger Morče s novým semi-supervised trénováním. Výsledný tagger má na češtině nejlepší úspěšnost: 96 %,Compost Czech is a tool which combines the PDT 2.0 morphological analyzer and the Morce tagger using an innovative semi-supervised training method. The resulting tagger gives the best accuracy achieved for Czech (on standard PDT 2.0 data set) so far: 96 %
"Tématem této práce jsou metody pro morfologické značkování (tagging) češtiny, zejména pak nejnovější experimenty s kombinováním pravidlových a statistických metod.","The thesis consists of three parts, which are all related to a rule-based morphological disambiguation project."
"Článek popisuje několik disambiguačních metod, které kombinují ručně psaná pravidla a stochastické taggery (Feature-based, HMM, průměrovaný perceptron).","Several hybrid disambiguation methods are described which
combine the strength of hand-written disambiguation rules
and statistical taggers. Three different statistical (HMM,
Maximum-Entropy and Averaged Perceptron) taggers are used in
a tagging experiment using Prague Dependency Treebank.
The results of the hybrid systems are better than any other method
tried for Czech tagging so far."
Článek popisuje konverzi slovníku povrchové valence českých sloves do valenčního slovníku deverbativních adjektiv.,"This paper describes conversion of a surface valency lexicon of Czech verbs
to a surface valency lexicon of adjectives that can be derived from these
verbs and that use their (possibly modified) valency frames."
"Článek popisuje rozšíření pravidlového disambiguačního systému, které umožňuje využít disambiguační pravidla pro popvrchovou syntaktickou analýzu.","The present paper describes an extension to a rule-based morphological
disambiguation system, which makes the disambiguation rules
usable for shallow parsing. The whole system
(both the morphological disambiguation and the syntactic
extension) is under development, but it already gives some
promising results. Several methods of using the rules to
improve the performance of statistical parsers are discussed."
"Tento článek popisuje vyhledávací experimenty týmu z Karlovy Univerzity v Praze na soutěži CLEF 2007 Ad-Hoc. Zaměřili jsme se na monolinguální úlohu a použili nástroj LEMUR pro náš vyhledávač. Naše výsledky ukazují, že pro češtinu lemmatizace signifikantně vylepšuje výsledky vyhledávání a manuální tvorba dotazů je pouze těsně lepší než automatickátvorba dotazů s popisu témet.","In this paper we describe retrieval experiments performed at Charles University in
Prague for participation in the CLEF 2007 Ad-Hoc track. We focused on the Czech
monolingual task and used the LEMUR toolkit as the retrieval system. Our results
demonstrate that for Czech as a highly inflectional language, lemmatization significantly
improves retrieval results and manually created queries are only slightly better
than queries automatically generated from topic specifications."
Tento článek popisuje experimenty s vyhledáváním v mluvené řeči týmu z Karlovy Univerzity provedené v rámci evaluační kampaně CLEF 2007.,"This paper describes a system built at Charles University in Prague for participation
in the CLEF 2007 Cross-Language Speech Retrieval track. We focused only on monolingual
searching the Czech collection and used the LEMUR toolkit as the retrieval
system. We employed own morphological tagger and lemmatized the collection before
indexing to deal with the rich morphology in Czech which significantly improved our
results."
V článku je prezentován algoritmus pro rozpoznávání anaforických vztahů v českém textu. Vyhodnocení je provedeno s pomocí dat Pražského závislostního korpusu.,"In this paper, we present a rule-based approach to resolution of anaphora links, as annotated in the Prague Dependency Treebank 2.0. The
created system consists of handwritten rules developed and tested using the Treebank data, which contain more than 45,000 coreference
links in almost 50,000 manually annotated Czech sentences. The F-measure of our system is 74.2%."
Článek opakuje specifické rysy předponových sloves v češtině a přístupy k jejich zachycení ve valenčním slovníku. Shrnujeme prostředky a funkce slovesné prefixace. Ukazujeme pravidelný vztah mezi základními a odvozenými slovesy s ohledem na jejich syntaktické a sémantické vlastnosti.,The paper reviews the specific features of prefixed verbs in Czech and approaches to their capture in a valency lexicon. We summarise means and functions of verbal prefixation. We illustrate a regular relation between base verbs and derived verbs as to their syntactic and semantic properties.
"V článku je prezentován nový algoritmus pro analýzu vět v přirozeném jazyce, který vede k vyšší úspěšnosti při zpracování koordinačních konstrukcí.",We present an algorithm for parsing with detection of intra-clausal coordinations. The algorithm is based on machine learning techniques and helps to decompose a large parsing problem into several smaller ones. Its performance was tested on Slovene Dependency Treebank. Used together with the maximum spanning tree parsing algorithm it improved parsing accuracy.
Popis experimentů s frázovým statistickým překladem z angličtiny do češtiny s cílem zlepšit tvaroslovnou koherenci výstupu.,"This paper describes experiments with English-to-Czech phrase-based machine
translation. Additional annotation of input and output tokens (multiple factors)
is used to explicitly model morphology.
We vary the translation scenario (the setup of multiple factors) and the amount
of information in the morphological tags.
Experimental
results demonstrate significant improvement of translation quality in terms of
BLEU."
Webová ukázka několika konfigurací systému strojového překladu mezi angličtinou a češtinou.,An interactive demonstration of English-Czech machine translation in a simple web interface.
Experimentální systém strojového překladu s převodem stromu na strom.,A release of an experimental MT system with tree-to-tree transfer.
Návrh matematického modelu pro převod věty přirozeného jazyka reprezentované jako závislostní strom na závislostní strom v cílové řeči.,A proposed mathematical model mapping dependency analyses of source sentences in one language to dependency structures representing the sentence in another language.
Česko-anglický paralelní korpus určený pro experimenty se strojovým překladem.,Czech-English parallel corpus for Machine Translation experiments.
Článek popisuje systém automatického překladu z angličtiny do češtiny založený na syntaktickém transferu na rovině hloubkové syntaxe (tzv. tektogramatické rovině). Podrobně je popsán anotační proces pro angličtinu a také vyhodnocena kvalita překladu prototypu celého systému.,"We present an overview of an English-to-Czech machine translation sys-
tem. The system relies on transfer at the tectogrammatical (deep syntactic)
layer of the language description. We report on the progress of linguistic
annotation of English tectogrammatical layer and also on first end-to-end
evaluation of our syntax-based MT system."
Navrhujeme formát překladových slovníků vhodný pro strojový překlad. Formát je úsporný a zobecňuje položky slovníku zavedením pravidel pro morfologické generování.,"We are proposing a format for translation dictionaries suitable for
machine translation. The dictionary format is concise and generalizes phrases by
introducing rules for morphological generation instead of using simple phrase to
phrase mapping.

We describe a simple way how to automatically construct our compact entries from
a machine-readable dictionary originally intended for human users using parallel
corpora. We further describe how to expand the compact dictionary entries to
phrase table dictionary that
can be used further on by machine translation systems (until the systems will
support morphological generation from a translation dictionary natively).
We performed manual annotation of a small set of entries to analyze problems of
this approach."
"V posledních dvou nebo třech desetiletích se v počítačové lingvistice aplikují statistické metody, a to nejen v oblasti automatického rozpoznávání řeči, ale i v ostatních jazykových oblastech. V pozvané přednášce se autoři zabývají argumenty pro i proti uplatnění těchto metod a argumentují ve prospěch  hybridní metodologie","In the recent twenty or thirty years, a great interest in computational linguistics is paid to the application of statistical methods. Starting with the domain of speech recognition, this trend has become quite obvious also in the analysis of other linguistic domains. In the invited paper, the authors analyze the pros and cons for these methods, in relation to rule-based approaches and argue for a hybrid methodology."
"První část testovací části soutěžních dat pro CoNNL 2007 Shared Task pro Arabštinu, obsahující Arabskou anotaci na syntaktické a sémantické rovině. .",Part one of the evaluation subset of the Arabic data set for the CoNLL 2007 Shared Task. The core of the task is to predict syntactic and semantic dependencies and their labeling.
"Druhá část testovacích soutěžních dat pro CoNNL 2007 Shared Task pro Arabštinu, obsahující Arabskou anotaci na syntaktické a sémantické rovině.",Part two of the evaluation subset of the Arabic data set for the CoNLL 2007 Shared Task. The core of the task is to predict syntactic and semantic dependencies and their labeling.
"Soutěžní data pro CoNNL 2007 Shared Task pro Arabštinu, obsahující Arabskou anotaci na syntaktické a sémantické rovině. Toto je trénovací část.",An Arabic data set for the CoNLL 2007 Shared Task. The core of the task is to predict syntactic and semantic dependencies and their labeling. This is the training set.
"V tomto článku prezentujeme výsledky základních experimentů pro automatické extrahování definic (pro automatické generování glosářů) z nestrukturovaného (případně jen málo strukturovaného) textu v bulharštině, češtině a polštině. Extrakce je prováděna pomocí regulárních gramatik, které jsou použity na dokumenty v jednotném XML formátu. Výsledky nejsou uspokojivé a ukazujeme, že příčina je ve vnitřní složitosti tohoto úkolu, k čemuž nás opravňuje nízká mezianotátorská shoda. Dále navrhujeme zpracování pomocí hlubší lingvistické analýzy a klasifikačních metod strojového učení.","This paper presents the results of the preliminary experiments in the automatic extraction of definitions (for semi-automatic glossary construction) from usually unstructured or only weakly structured e-learning texts in Bulgarian, Czech and Polish. The extraction is performed by regular grammars over XML-encoded morphosyntactically-annotated documents. The results are less than satisfying and we claim that the reason for that is the intrinsic difficulty of the task, as measured by the low interannotator agreement, which calls for more sophisticated deeper linguistic processing, as well as for the use of machine learning classification techniques."
"Stupňování adjektiv je pomezní oblastí mezi morfologií a slovotvorbou. Komparativ je spojen s obligatorní valenční pozicí srovnání, které je na povrchu často vypuštěno. Zkoumají se podmínky jeho vypuštění a analyzují se konstrukce s ""absolutním"" komparativem.","The position of gradation (degrees of comparison) of adjectives between morphology and word-formation is discussed as well as the determination of the semantic and syntactic characteristics of comparatives of adjectives (CMPR). The form of a comparative is connected with an obligatory valency slot filled by the modification of comparison (CPR); however, this valency member is very often missing on the surface. The reasons of the absence of this member are analyzed. The examples usually described as an “absolute” usage of CMPR are described and classified."
Stať je rozšířením autorčina přístupu k popisu recipročních konstrukcí z r. 1999. Je třeba rozlišovat inherentní lexikální reciprocitu a reciprocitu syntaktickou (obecněji přijatelnou). Možnou účast jednotlivých valenčních pozic na reciprokalizaci je třeba vyznačit ve valenčním rámci slovníkového hesla.,"A continuation and modification of our approach (given in Panevová (1999)is presented. The necessity to distinguish an inherent lexical reciprocity, as a part of a lexical meaning, is and syntactical reciprocity is argued. The relation of symmetry between emancipated participants is, in general, present only with syntactical reciprocal constructions.The possible participation of the respective valency slot in the process of reciprocalization has to be marked in the valency frame of the verb."
"V tomto příspěvku navázujeme na tři příspěvky ke zkoumání recipročních vztahů v češtině (Panevová, 1999, Panevová, v tisku, Panevová, Mikulová, v tisku) a rozšířit je jak o několik úvah, které vyplynuly z diskusí o těchto příspěvcích, tak o další doklady z elektronických korpusů ilustrujících tyto problémy (budeme používat ČNK ve verzi SYN2005, dále PDT ve verzi 2.0 a Internet).","We think that the topic of Czech reciprocals has not yet been exhausted. We have proposed several issues open for further studies, e. g. distribution of the optional lexical means, their position in word order, behavior of si-reflexives etc. Recalling our ontological considerations on vagueness in syntactical reciprocal relations (see Panevová, in press, Section 4, as well as Chrakovskij, op.c. ), our insight into the corpus material confirms for the whole domain of reciprocity, that there are many vague and ambiguous constructions, interpretation of which strongly depends on inferences provided by the speech participants with the knowledge of the broader context or situation."
"Stať rozvíjí přístup nastíněny v Panevová (1999). Rozlišuje se inherentní lexikální reciprocita od reciprocity syntaktické. Lexikální třídy sloves, na něž lze aplikovat operaci reciprokalizace, jsou uvedeny v odd. 3.1-3.3. Explicitní lexikální prostředky pro reciprocitu se analyzují v odd. 5 -8.",We present a follow-up and modification of the approach to the description of reciprocal constructions in Panevová (1999).Inherent lexical reciprocity is distinguished from reciprocal constructions which are syntactic. The syntactic operation of reciprocalization could be applied to the verbs from three classes proposed in Sections 3.1 – 3.3.The specific formal expressions used in Czech reciprocal constructions are analyzed in Sections 5-8.
"Průvodce Českým akademickým korpusem verze 1.0 je průvodce CD-ROM. Objektem prohlídky je morfologicky ručně anotovaný korpus češtiny o celkovém objemu 660 tisíc slov a nástroje pro jeho prohlížení a úpravu spolu s nástroji pro zpracování textů z pohledu tvarosloví neboli morfologie. Průvodce dokumentuje historii korpusu, podněty k vytvoření jeho první verze a detaily jeho počítačové reprezentace. Zároveň poskytuje stručné návody k užívání nabízených nástrojů.","The guide to the Czech Academic Corpus version 1.0 is a roadmap to the CD-ROM. Within the context of the CD-ROM you will find the manually morphologically annotated corpus of Czech consisting of nearly 660,000 words along with tools for viewing and modifying them. The tools treating texts from the standpoint of morphology are available as well. The guide provides the users with the fundamental characteristics of the academic corpus, presenting the evolution of the corpus together with the motivation of the current edition. In addition, the brief guidelines to the tools offered are included."
Český akademický korpus verze 1.0 je morfologicky ručně anotovaným korpusem češtiny o objemu 660 tisíc slov.,"The Czech Academic Corpus version 1.0 is a corpus with a manual annotation of morphology of the Czech language consisting of approximately 660,000 words."
Přehled výsledků Cross-Language Speech Retrieval Track organizované v rámci evaluační kampaně CLEF 2006.,"The CLEF-2006 Cross-Language Speech Retrieval (CL-SR) track included two tasks: to identify topically coherent segments of English interviews in a known-boundary condition, and to identify time stamps marking the beginning of topically relevant passages in Czech interviews in an unknown-boundary condition. Five teams participated in the English evaluation, performing both monolingual and cross-language searches of ASR transcripts, automatically generated metadata, and manually generated metadata. Results indicate that the 2006 evaluation topics are more challenging than those
used in 2005, but that cross-language searching continued to pose no unusual challenges when compared with collections of character-coded text. Three teams participated in the Czech evaluation, but no team achieved results comparable to those obtained with English interviews. The reasons for this outcome are not yet clear."
"Závislostní analýza přirozeného jazyka získává na důležitosti díky své aplikovatelnosti v mnoha úlohách NLP. Mnohé ze vznikajících závislostních struktur jsou neprojektivní, vzniká tedy potřeba umět je podrobně popsat, zejména pro potřeby přístupů využívajících strojové učení, jako je např. parsing. Pomocí dat z dvanácti přirozených jazyků vyhodnocujeme několik omezení a měr na neprojektivních strukturách. Využíváme přitom přístupu založeného na vlastnostech jednotlivých hran oproti vlastnostem celých závislostních stromů. Ve svém vyhodnocení uvádíme dosud neprezentované míry neprojektivity, které v sobě zahrnují hladiny uzlů v závislostních stromech. Empirické výsledky podporují výsledky teoretické a prokazují, že přístup založený na vlastnostech hran využívající hladin uzlů poskytuje přesné a silné prostředky pro zachycení neprojektivních struktur v přirozených jazycích.","Dependency analysis of natural language has gained importance for its applicability in tasks of NLP. Non-projective structures are common in dependency analysis, therefore we need fine-grained means of describing them, especially for the purposes of machine-learning oriented approaches like parsing. We present an evaluation on twelve languages which explores several constraints and measures on non-projective structures. We pursue an edge-based approach concentrating on properties of individual edges as opposed to properties of whole trees. In our evaluation, we include previously unreported measures taking into account levels of nodes in dependency trees. Our empirical results corroborate theoretical results and show that an edge-based approach using levels of nodes provides an accurate and at the same time expressive means for capturing non-projective structures in natural language."
"Dizertace zkoumá projektivitu a neprojektivitu v závislostních stromech. Uvádíme původní výsledky, z nichž nejdůležitější jsou: nová definice projektivity, zavedení takzvaných úrovňových typů neprojektivních hran, pojem projektivizace, vztahy mezi úrovňovými typy neprojektivních hran a planaritou (slabou projektivitou) a dobrou zahnízděností (v obou případech se jedná o podmínky na uspořádání na závislostních stromech slabší než projektivita), a příslušné algoritmy včetně jejich složitosti. Ve druhé části zkoumáme neprojektivní struktury v téměř dvaceti závislostních korpusech různých přirozených jazyků s využitím prostředků představených v první části.","The thesis studies projectivity and non-projectivity in dependency trees. We present new mathematical results, the main ones being: a novel definition of projectivity, introduction of so-called level types of non-projective edges, the notion of projectivization, relationships between level types of non-projective edges and planarity (weak projectivity) and well-nestedness (which are both weaker conditions on the ordering of nodes in dependency trees than projectivity), and relevant algorithms together with their complexity analyses. In the second part of the thesis, we present an extensive evaluation of non-projective syntactic structures from about twenty natural language corpora using the formal means derived in the first part."
"Závislostní analýza přirozeného jazyka se neobejde bez neprojektivních struktur. O podmínce dobré zahnízděnosti bylo nedávno prokázáno, že dobře zachycuje empirická jazyková data. Ukazujeme, jak ji lze přeformulovat pomocí vlastností neprojektivních hran, a dále jejich vztah k úrovňovým typům neprojektivních hran; odvozujeme také jednoduchý kvadratický algoritmus pro ověřování dobré zahnízděnosti.",Dependency analysis of natural language gives rise to non-projective structures.  The constraint of well-nestedness on dependency trees has been recently shown to give a good fit with empirical linguistic data. We present a reformulation of this constraint using properties of non-projective edges and show its formal relationship to level types of non-projective edges; we also derive a simple $\BigO(n^2)$ algorithm for checking well-nestedness.
Sada nástrojů implementovaných v Perlu pro konverzi valenčních slovníků z anotačního formátu do HTML a PDF.,A set of perl scripts for converting valency lexicons from the annotation format into HTML and PDF presentation formats.
"Valenční slovník českých sloves (VALLEX 2.0) shromažďuje lingvisticky zpracovaná data a jejich dokumentaci. Poskytuje informace o valenční struktuře sloves v jejich jednotlivých významech, počtu a možných morfologické formy jejich doplnění a
další syntaktické informace, spolu s poznámkami a příklady. Primárním cílem textu je stručně popsat datovou strukturu slovníku.","The Valency Lexicon of Czech Verbs (VALLEX 2.0) is a collection of linguistically
annotated data and documentation. It provides information on the valency structure of verbs in
their particular meanings / senses, possible morphological forms of their complementations and
additional syntactic information, accompanied with glosses and examples. The primary goal of
the following text is to briefly describe the content of VALLEX~2.0 data from a structural
point of view."
Při anotování velkého korpusu je velmi užitečné všímat si i slovesné valence.,"In annotating a large corpus, it is highly useful to present an analysis of verb valency."
Vzhledem k různosti názorů v lingvistice je v ní vždycky nezbytné hledání konsenzu.,"Since there are different views in linguistics, it is useful to look for consense."
Anotace korpusu je chápána jako důležitý prostředek pro testování lingvistické teorie. Na základě systematického anotování korpusu je možné ověřovat teoretické lingvstické hypotézy.,Corpus annotation is not a self-contained task but one of its important application is a testing of linguistic theories. A systematic annotation of corpus makes it possible to test linguistic hypotehses.
"The function-form viewpoint (means and ends, and the regard to the communicative function) is applied to the analysis of the information structure of the sentence, distinguishing between the semantically relevant topic-focus articulation and its means of expression (morphological, syntactic, prosodical).","Článek se věnuje analýze informační struktury věty z hlediska vztahu mezi funkcí a formou: rozlišujeme zde mezi sémanticky relevantním aktuálním členěním věty a prostředky jeho vyjádření (které mohou patřit do plánu morfologického, syntaktického a prozodického)."
Přehled životních osudů  vědeckých výsledků především z oblasti komputační a teoretické lingvistiky.,A critical survey of research achievements with special regard to computational and theoretical linguistics.
Rozbor frunkčního přístupu Pražské lingvistické školy jako jednoho z významných myšlenkových proudů strukturalismu.,Analysis of the approach of the Prague Linguistic School as one of the important trends of structuralist thinking.
Potřebnost anotace korpusu na podkladové rovině je dokumentována na rozboru několika jazykových jevů.,Arguments are given for an underlying syntactic annotation of sentences of large text corpora.
Postavení aktuálního členění věty v teoretickém popisu jazyka na základě závislostních vztahů; relevance aktuálního členění pro význam věty,Topic-Focus Articulation in a formal description of language based on dependency grammar; relevance of TFA for the meaning of the sentence.
"Porozumění přirozenému jazyku se chápe jako jeden z důležitých komponentlů systémů umělé inteligence. 
Ptáme se, kam až teoretická i komputační lingvistika ve svém příspěvku k umělé inteligenci došla a kudy podle našeho mínění i zkušeností vede k tomuto cíli cesta. 
Ilusrujeme na projektech a výsledcích pražské skupiny počítačové lingvistiky na MFF UK, a to ve třech oblastech: (i) příprava jazykových zdrojů, (ii) využití těchto zdrojů pro některé aplikace a (iii) na příkladu jednoho integrovaného projektu týkajícího se rozpoznávání mluveného jazyka a vyhledávání informací ve velmi velkých mluvených souborech.",Natural language understanding is considered to be one of the urging issues of systems of artificial intelligence.
V anotacich Pražského závislostního korpusu se při anotaci aktuálního členění bere v úvahu i rozlišení kontrastivního členu základu výpovědi.,The claim of the paper is that the Topic/Focus structure of the sentence does not involve only a bipartioon of the sentence structure but that in the topic part of the sentence a special status should be given to a contrastive element.
"Práce se zabývá studiem podmodelů modelů Peanovy aritmetiky a jejích fragmentů. Klíčovou úlohu v této práci hraje pojem diagonální nerozlišitelnosti, pomocí nějž se studují tři okruhům otázek: zobecnění nekonečné Ramseyovy věty na diagonální nerozlišitelnost, vlastnosti a rozložení specifických řezů modelů aritmetiky a zkoumání vlastností Stoneova prostoru algebry definovatelných množin spočetného modelu Peanovy aritmetiky užitím nestandardních metod (vnoření do velkého modelu).","In this thesis, we study a range of questions concerning submodels of models of Peano arithmetic (PA) or its fragments. Our study focuses on three different areas that share a common central topic, namely diagonally  indiscernible elements.
    In the ﬁrst part, we explore a diagonal version of the Inﬁnite Ramsey Theorem provable in PA and partially provable in fragments of PA. We provide a detailed level-by-level analysis of the principle in terms of the arithmetical hierarchy and the corresponding fragments of the schemes of induction and collection. Then we derive a theorem characterizing Σn -elementary initial segments of a given model that satisfy (fragments of) PA as cuts on certain systems of diagonal indiscernibles.
    In the second part, we study initial segments with some speciﬁc properties, and especially their distribution in a given countable model M |= PA.
We provide a theorem that gathers general topological consequences of the method of indicators. We then extend the theorem with further results about some prominent families of Σn -elementary initial segments (among others,
those satisfying PA or IΣn+k , and those isomorphic to M). For example, by applying the results from the ﬁrst part, we prove that every interval that contains an Σn -elementary initial segment satisfying IΣn+k (or PA) contains
a closed subset of such initial segments that is order-isomorphic to the Cantor set. We conclude by proving some strict inclusions between the topological closures of the studied families.
    In the last part, we study the properties of the Stone space of the algebra of deﬁnable subsets of a given countable model M |= PA. We present
the topic from a non-standard viewpoint, situating the countable base model M into some ℵ1 -saturated elementary extension C, under which ultraﬁlters from the Stone space appear as sets of 1-indiscernible elements, called monads. Our main tool here is the Rudin-Keisler (RK) pre-order on monads. We investigate monads of diagonally indiscernible elements and diagonal partition properties on monads. Among other results, we prove that RK-minimal monads (which correspond to selective ultraﬁlters), p-monads (which corre-
spond to p-points), and regular monads, in this order, are properties of strictly
decreasing strengths. Furthermore, we show that the counter-examples (e.g. p-points that are not RK-minimal) form dense subsets in the the corresponding subspaces of the Stone space."
"MEd je anotační nástroj, v němž lze vytvářet a upravovat lineárně strukturované anotace textu nebo akustických dat. Tento nástroj podporuje několik vrstev anotací, které mohou být vzájemně propojeny odkazy. MEd lze použít také pro jiné účely, jako je zarovnání paralelních korpusů na bázi slov. MEd je hlavním nástrojem pro anotaci projektu Pražský závislostní korpus mluvené řeči (PDTSL). Nativním formátem tohoto nástroje je PML - Prague Markup Language.","MEd is an annotation tool in which linearly-structured annotations of text or audio data can be created and edited. The tool supports multiple stacked layers of annotations that can be interconnected by links. MEd can also be used for other purposes, such as word-to-word alignment of parallel corpora. 
MEd is the main annotation tool for the project Prague Dependency Treebank of Spoken Language (PDTSL). The native format of the tool is PML - the Prague Markup Language."
Testovací kolekce použita pro evaluaci systémů pro ad-hoc vyhledávní informací v rámci CLEF 2007.,A test collection employed for evaluation of the information retrieval systems at the Ad-Hoc track at CLEF 2007.
Testovací kolekce použita pro evaluaci systémů pro vyhledávní v mluvené řeči v rámci CLEF 2007,The test collection employed for evaluation of the speech retrieval systems at Cross-language Speech Retrieval track at CLEF 2007.
Přehled výsledků Cross-Language Speech Retrieval Track organizované v rámci evaluační kampaně CLEF 2007.,"The CLEF-2007 Cross-Language Speech Retrieval (CL-SR) track included two tasks: to identify topically coherent segments of English interviews in a known-boundary condition, and to identify time stamps marking the beginning of topically relevant passages in Czech interviews in an unknown-boundary condition. Six teams participated in the English evaluation, performing both monolingual and cross-language searches of ASR transcripts, automatically generated metadata, and manually generated metadata. Four teams participated in the Czech evaluation, performing monolingual searches of automatic speech recognition transcripts."
"Vyhodnocení jazykovědné soutěže, přehled vybraných úkolů z jazykovědy a slohu.","Evaluation of the linguistic contest, overview of selected tasks in linguistics and essays."
Tento článek popisuje návrh první rozsáhlé české testovací kolekce pro vyhledávání informací v mluvené řeči.,"This paper describes the design of the first large-scale IR test collection built for the Czech language. This collection also happens to be very challenging, as it is based on a continuous text stream from automatic transcription of spontaneous speech and thus lacks clearly defined document
boundaries. All aspects of the collection building are presented, together with some initial experiments."
Obsahuje valenční slovník pro všechna slovesa a některá substantiva a adjektiva z PDT 2.0 v XML formátu.,Contains valency lexicon for all verbs and some nouns and adjectives from PDT 2.0 in XML format.
"Článek popisuje budování a automatické zpracování audio-visuálního korpusu DIALOG. Korpus DIALOG je prosodicky anotovaný korpus českých televizních diskusí nahrávaných a anotovaných v Ústavu pro jazyk český Akademie věd České republiky. 
V současnosti obsahuje více jak 400 VHS 240min kazet a 375 přepsaných pořadů. Popisovaný digitalisační proces a automatický alignment umožnily vznik uživatelsky přívětivého výzkumného prostředí podporujícího zkoumání prosodie češtiny, její analýzu a modelování. Tento projekt je řešen ve spolupráci s Ústavem formální a aplikované lingvistiky, MFF UK. První veřejně dostupná verze korpusu DIALOG obsahuje 10 revidovaných hodinových pořadů a je přístupná na adrese http://ujc.dialogy.cz.","This article describes the development and automatic processing of the audio-visual DIALOG corpus. The DIALOG corpus is a prosodically annotated corpus of Czech television debates that has been recorded and annotated at the Czech Language Institute of the Academy of Sciences of the Czech Republic.
It has recently grown to more than 400 VHS 4-hour tapes and 375 transcribed TV debates. The described digitisation process and automatic alignment enable an easily accessible and user-friendly research environment, supporting the exploration of Czech prosody and its analysis and modelling. This project has been carried out in cooperation with the Institute of Formal and Applied Linguistics of Faculty of Mathematics and Physics, Charles University, Prague. Currently the first version of the DIALOG corpus is available to the public (version 0.1, http://ujc.dialogy.cz). It includes 10 selected and revised hour-long talk shows."
"Cílem navrhovaného dema by bylo předvést technologii stojící za Pražským arabským závislostním korpusem (Hajič et al., 2004), projektem jazykové anotace, který lze aplikovat v mnoha oblastech počítačového zpracování přirozeného jazyka.","The proposed demo would aim to present the technology behind the Prague Arabic Dependency Treebank (Hajič et al., 2004), a project of linguistic annotation having application in many areas of Natural Language Processing."
"Implementace originálního lingvistického modelu Funkční arabské morfologie, která zahrnuje jak deklarativní definici systému v jazyce Haskell, tak i rozsáhlý arabský morfologický slovník. Publikováno pod licencí GNU GPL.","An implementation of the original linguistic model of the Functional Arabic Morphology includes both the declarative definition of the system in Haskell, and an extensive Arabic morphologic dictionary. Published under the GNU GPL license."
"Implementace původního lingvistického modelu Funkční arabské morfologie zahrnuje jak deklarativní definici systému v Haskellu, tak rozsáhlý arabský morfologický slovník. Šířeno pod licencí GNU GPL.","An implementation of the original linguistic model of the Functional Arabic Morphology includes both the declarative definition of the system in Haskell, and an extensive Arabic morphologic dictionary. Published under the GNU GPL license."
"Funkční arabská morfologie je formulace arabského flexivního systému, která se snaží najít fungující rozhraní mezi morfologií a syntaxí. ElixirFM je její vysokoúrovňová implementace, která využívá a rozšiřuje funkční morfologickou knihovnu pro Haskell.","Functional Arabic Morphology is a formulation of the Arabic inflectional system seeking
the working interface between morphology and syntax. ElixirFM is its high-level implementation
that reuses and extends the Functional Morphology library for Haskell.
Inflection and derivation are modeled in terms of paradigms, grammatical categories,
lexemes and word classes. The computation of analysis or generation is conceptually
distinguished from the general-purpose linguistic model.
The lexicon of ElixirFM is designed with respect to abstraction, yet is no more complicated
than printed dictionaries. It is derived from the open-source Buckwalter lexicon
and is enhanced with information sourcing from the syntactic annotations of the Prague
Arabic Dependency Treebank.
MorphoTrees is the idea of building effective and intuitive hierarchies over the information
provided by computational morphological systems. MorphoTrees are implemented
for Arabic as an extension to the TrEd annotation environment based on Perl.
Encode Arabic libraries for Haskell and Perl serve for processing the non-trivial and
multi-purpose ArabTEX notation that encodes Arabic orthographies and phonetic transcriptions
in parallel."
Toto je shrnutí autorovy doktorské disertační práce obhájené 17. září 2007 na Matematicko-fyzikální fakultě Univerzity Karlovy v Praze. Výsledků v disertaci prezentovaných bylo dosaženo během autorova doktorského studia matematické lingvistiky v letech 2001-2007. Celá disertace je dostupná přes http://sourceforge.net/projects/elixir-fm/.,"This is a summary of the author's PhD dissertation defended on September 17, 2007 at the Faculty of Mathematics and Physics, Charles University in Prague. The results comprised in the thesis were obtained within the author's doctoral studies in Mathematical Linguistics during the years 2001-2007. The complete dissertation is available via http://sourceforge.net/projects/elixir-fm/."
"Pražský arabský závislostní korpus, nedávno vydaný ve své první verzi, je jednak kolekcí anotací arabských textů na více rovinách, jednak balíčkem softwarových nástrojů vytvořených pro použití v počítačovém zpracování přirozeného jazyka.","Prague Arabic Dependency Treebank, recently published in its first version, is both a collection of multi-level linguistic annotations of Arabic texts, and a suite of unique software implementations designed for general use in Natural Language Processing."
Prostředí a Perlová knihovna pro konverzi mezi různými sadami značek.,A framework and Perl library for converting between various tag sets.
"Tento článek popisuje jednoduchou metodu neřízené morfologické analýzy neznámého jazyka. Potřeba je pouze prostý textový korpus daného jazyka. Algoritmus se dívá na slova, rozpozná opakovaně se vyskytující kmeny a přípony a sestaví pravděpodobné morfologické vzory. Článek také popisuje způsob, jak byla tato metoda využita při řešení úlohy Morpho Challenge 2007, a prezentuje výsledky Morpho Challenge. Přestože tato práce byla původně studentským projektem bez návaznosti na obdobný výzkum ve světě, k našemu překvapení tento jednoduchý přístup překonal několik dalších algoritmů v podsoutěži segmentace slov. Věříme, že v metodě je dostatečný prostor pro zlepšení, který může výsledky dále zlepšit. V článku jsou rozebrány chyby a navržena budoucí rozšíření.","This paper describes a rather simplistic method of unsupervised morphological analysis of words in an unknown language. All what is needed is a raw text corpus in the given language. The algorithm looks at words, identifies repeatedly occurring stems and suffixes, and constructs probable morphological paradigms. The paper also describes how this method has been applied to solve the Morpho Challenge 2007 task, and gives the Morpho Challenge results. Although the present work was originally a student project without any connection or even knowledge of related work, its simple approach outperformed, to our surprise, several others in most morpheme segmentation subcompetitions. We believe that there is enough room for improvements that can put the results even higher. Errors are discussed in the paper; together with suggested adjustments in future research."
"Lexical Annotation Workbench (LAW) je integrované prostředí pro morfologickou anotaci. Podporuje jednoduchou anotaci, porovnávání různých anotací téhož textu, hledání určitého slova, značky, atd.","Lexical Annotation Workbench (LAW) is an integrated environment for morphological annotation. It supports simple morphological annotation, comparison of different annotations of the same text, searching for particular word, tag etc."
Laudatio k sedmdesátýmpátým narozeninám profesora Fredericka Jelinka.,Laudation for Professor Frederick Jelinek on the occasion of his 75th birthday.
"Představujeme systém STYX, který je navržen jako elektronická civčebnice českého tvarosloví a české syntaxe. 

Téměř 12 000 cvičebnicových příkladů je vybráno z Pražského závislostního korpusu, nejrozsáhlejšího anotovaného korpusu češtiny. Cvičebnice nabízí komplexní zpracování věty z pohledu morfologických a syntaktických jevů, které pokrývají učební látku středních škol a vyšších tříd základních škol.","We present the STYX system, which is designed as an electronic corpus-based exercise book of Czech with exercises directly selected from the Prague Dependency Treebank, the largest annotated corpus of Czech. The exercise book offers a complex sentence processing with respect to morphological and syntactic phenomena, i. e. the exercises give practice in classifying parts of speech and particular morphological categories of words and in parsing a sentence and classifying syntactic functions of words. The exercise book covers a subject matter the students of secondary schools should master."
"Příručka je zkrácenou verzí rozsáhlého manuálu: Anotace na tektogramatické rovině Pražského závislostného
korpusu. Anotátorská příručka. (viz Prague Dependency Treebank 2.0, CDROM, doc/manuals/cz/t-layer/), který
obsahuje podrobný a úplný popis reprezentace věty na tektogramatické rovině (přesné, podrobné a úplné informace
je třeba vždy čerpat z „velkého“ manuálu).","This reference book is a shortened version of an extensive manual called Annotation on the tectogrammatical level
in the Prague Dependency Treebank. Annotation manual. (see Prague Dependency Treebank 2.0, CDROM,
doc/manuals/en/t-layer/), which contains the complete and detailed description of sentence representation at the
tectogrammatical level (it is necessary to consult the “big” manual for exact, detailed and complete information)."
Poukazuje se na souvislost slovesné předpony a valenčních vlastností slovesa. Polysémické vlastnosti předpon souvisejí úzce s valencí slovesa.,The interdependance between verbal prefixes and valency frames with the verbs of motion is studied.
"VALLEX 2.5 poskytuje informaci o valenční struktuře sloves v jejich specifických významech. VALLEX je úzce spjat s Pražským závislostním korpusem, který také využívá Funkčního generativního popisu jako podkladovou teorii. Ve VALLEXu 2.5 je obsaženo zhruba 2.730 lexémů obsahujících dohromady kolem 6.460 lexikálních jednotek (""významů"").","The Valency Lexicon of Czech Verbs, Version 2.5 (VALLEX 2.5), is a collection of linguistically annotated data and documentation, resulting from an attempt at formal description of valency frames of Czech verbs. VALLEX 2.5 has been developed at the Institute of Formal and Applied Linguistics, Faculty of Mathematics and Physics, Charles University, Prague. VALLEX 2.5 is a successor of VALLEX 1.0, extended in both theoretical and quantitative aspects. VALLEX 2.5 provides information on the valency structure (combinatorial potential) of verbs in their particular senses. VALLEX is closely related to the Prague Dependency Treebank project: both of them use Functional Generative Description (FGD), being developed by Petr Sgall and his collaborators since the 1960s, as the background theory. In VALLEX 2.5, there are roughly 2,730 lexeme entries containing together around 6,460 lexical units (""senses""). Note that VALLEX 2.5 - according to FGD, but unlike traditional dictionaries and also unlike VALLEX 1.0 - treats a pair of perfective and imperfective aspectual counterparts as a single lexeme (if perfective and imperfective verbs would be counted separately, the size of VALLEX 2.5 would virtually grow to 4,250 verb entries). To ensure high quality of the data, all VALLEX entries have been created manually, using several previously existing lexicons as well as corpus evidence from the Czech National Corpus."
"Funkční generativní popis je závislostní popis češtiny, který se vyvýjí od šedesátých let minulého století. Původně byl implementován jako generativní postup, ale později jsme se zabývali jeho deklarativní reprezentací. Tohoto článek se týká základů redukčního systému, který dovoluje zachycovat složitější vztahy než jsou povrchová syntaktické vztahy ve větě, protože poskytuje nejen možnost kontroly správnosti povrchové analýzy věty, ale i její hloubkové reprezentace. Takový redukční systém umožňuje formálně definovat analýzu a syntézu věty.","Functional Generative Description is a dependency based descriptive system, which has been in
development since the 1960s. It was
originally implemented as a  generative procedure, but lately we have been interested in a declarative representation. The object
of the present paper concerns the foundations of a reduction system, which is more complex than a reduction system for a (shallow) syntactic analyzer, since it provides not only the
possibility of checking the well-formedness of the (surface) analysis of a sentence, but its underlying  representation as well. Such a reduction system makes it possible to define formally the analysis as well as the  synthesis of a sentence."
"V tomto článku prezentujeme anotační schéma, které zachycuje obecné časové vztahy mezi událostmi vyjádřené v diskurzu.",In this paper we present an annotation scheme that captures general temporal relations between events expressed in a discourse.
"V tomto článku prezentujeme funkční přístup k zachycení informace, kterou v diskurzu pokrývají různé časové výrazy.","In this paper we present a functional approach to capture the information conveyed by various time expressions within a discourse. The
approach is motivated by annotation scheme that captures general temporal relations between events expressed in a discourse. A parser
for Czech as well as an inference engine that makes it possible to compare functional compositions is implemented."
Práce se zabývá automatickou desambiguací slovesných valenčních rámců na českých datech. Hlavním přínosem je stanovení nejužitečnějších rysů pro zjednoznačnění valenčních rámců.,"This work deals with automatic disambiguation of verb valency frames on Czech data. Main contribution lies in determining of the most useful features for valency frame disambiguation. We experimented with diverse types of features, including morphological, syntax-based, idiomatic, animacy andWordNet-based. The considered features were classiffed using decision trees, rule-based learning and Naive Bayes classiffer. On a set of 7 778 sentences we achieved accuracy of 79.86% against baseline 68.27% obtained by assigning the most frequent frame."
V tomto příspěvku se zabýváme Funkčním generativním popisem češtiny (FGP) na pozadí formální teorie překladů a formální teorie jazyků. Klademe důraz na propojení formálních modelů s jejich jazykovou (lingvistickou) náplní. Jednou z formálních podob FGP byla kompozice překladů pomocí pěti překladových gramatik. Zavedeme zde rozlišovací sílu takových systémů. Dále představíme nový formální model založený na překladových restartovacích automatech.,"This paper describes the Functional Generative Description Czech (FGP) upon the background of formal theory  of translation for formal languages. Emphasis is placed on linking formal models of language (linguistic) descriptions. One of the forms of formal model fo FGP was a composition of five translation grammars. Here we introduce the generative power of such systems. Furthermore, we introduce a new formal model based on the translation restarting automata."
"Příspěvek popisuje typologii chyb objevujících se v morfologicky anotovaných korpusech. Typy jsou demonstrovány na příkladech z českého korpusu SYN2000. Tři hlavní typy chyb jsou: původní chyby pocházející z originálních textů, kódovací chyby a anotační chyby.","The article proposes a typology of errors that occur in morphologically annotated corpora, demonstrated on the example of the Czech National Corpus, its version SYN2000. It is morphologically annotated corpus with 3 attributes: word form, lemma and morphological tag. Word forms come from original texts acquired from various providers, the other two are added by corpus builders during the annotation. 
It explains the process of morphological annotation, its three phases – morphological analysis, guesser and disambiguation. It describes types of errors that can occur during the individual phases and why. And it discusses possibilities of their removal.
There are three main categories of errors: original errors coming from original texts, coding errors that come from possible recoding of various texts into one common format, and annotation errors due to faults in morphological dictionary and imperfections in the disambiguation – the statistical as well as rule-based. 
All types of corpus defects are documented by examples from the corpus SYN2000."
"Článek pozoruje švédské sloveso ""hålla på"", běžně používané v pseudokoordinaci s významovým slovesem jako pomocné sloveso průběhového času u dějových sloves. V některých kontextech, zejména v kombinaci s negací, sloveso ""hålla på"" překvapivě dodává slovesu, s kterým je v koordinaci, významový rys konstantnosti daného děje. Korpusové konkordance prokazují tendenci rozšíření tohoto významového rysu na kontexty bez negace, což znamená, že se pomocná konstrukce ""hålla på och"" stává polysémním. Tento zajímavý významový posun je dáván do souvislosti s Hopperovou ideou gramatikalizace a s obecným mechanismem sémantického posunu, jenž popsali Heine, Claudi a Hünnemeyer (1991) a nazvali jej ""context-induced reinterpretation"".","This paper observes the Swedish auxiliary verb ""hålla på"", commonly used as a progressivity marker in pseudocoordination with a process verb. In some contexts, especially in combination with negation, ""hålla på"" gives the process denoted by the lexical verb a flavour of constancy. The corpus evidence proves that this semantic feature is spreading onto non-negated contexts, too, which implies that the auxiliary construction ""hålla på och"" is becoming polysemous. This interesting semantic shift is related to Hopper's (1987) idea of grammaticalization regarded as ""movement towards structure"" as well as to the concept of ""context-induced reinterpretation"" as one type of semantic shifting described by Heine, Claudi and Hünnemeyer (1991)."
"MMI_clustering je sada nástrojů příkazové řádky, kterým se provádí Mercer maximální vzájemnou výměnu informací na základě shlukování-technika. Hlavní program shlukování přichází s podpůrné nástroje pro třídu-založené text výsledek transformace a vizualizace. Dohromady tyto formuláře useful gadget pro jazykové modelování, studium sémantických tříd, nebo dokonce rozbor konkrétních autorů 'sdružení. Balíček obsahuje program počítačové zařazení stromu (roste ho dychtivě cestu z listů (to je slovo) na jeho root), program pro dělení tohoto stromu na dané úrovni, abychom mohli získat předem stanovený počet slovních druhů a nakonec je visualizer / transformátor kreslení stromů (ASCII art-based) a pomocí třídy transformovat vstupní text do textu, kde by každé slovo označí své třídě například (výstupní formát je velmi konfigurovatelný).","MMI_clustering is a set of command line tools implementing Mercer's maximum mutual information-based clustering technique. Main clustering program comes with subsidiary tools for class-based text transformations and result visualization. Together these form useful gadget for language modeling, study of semantic classes, or even analysis of authors' specific associations. The package contains program computing classification tree (growing it in an eager way from leafs (that is words) to its root), program for cutting this tree at a given level so we could obtain predetermined number of word classes and finally there is a visualizer/transformer drawing trees (ASCII-art based) and using classes to transform input text into a text where each word would be annotated with its class for example (the output format is quite configurable)."
Prezentujeme demonstraci anotačního nástroje pro anotování textů do formalismu sémantických sítí zvaného MultiNet. Nástroj je založen na grafickém uživatelském rozhraní Java Swing a umožňuje anotátorům editovat uzly a relace v síti a také vazby mezi uzly v síti a uzly předchozí anotační roviny. Data zpracovaná nástrojem v této prezentaci pocházejí z anglické verze Wall Street Journalu.,"We present a demonstration of an annotation tool designed to annotate texts into a semantic network formalism called MultiNet. The tool is based on a Java Swing GUI and allows the annotators to edit
nodes and relations in the network, as well as links between the nodes in the network and the nodes from the previous layer of annotation. The data processed by the tool in this presentation are from the English version of the Wall Street Journal."
"Tento abstrakt popisuje projekt, jehož cílem je ruční anotace obsahu výpovědí v přirozeném jazyce v paralelních textových korpusech. Používáme formalismus zvaný MultiNet - Vícevrstvou rozšířenou sémantickou síť. Anotace by měla být zahrnuta jako nová anotační rovina do Pražského závislostního korpusu.",This abstract describes a project aiming at manual annotation of the content of natural language utterances in a parallel text corpora. The formalism used in this project is MultiNet – Multilayered Extended Semantic Network. The annotation should be incorporated into the Prague Dependency Treebank as a new annotation layer.
"Článek se zabývá možnostmi modifikace souboru rysů, který je použit v závislostní parseru založeném na hledání maximální kostry grafu.",In this paper we present the results of our experiments with modifications of the feature set used in the Czech mutation of the Maximum Spanning Tree parser. First we show how new feature templates improve the parsing accuracy and second we decrease the dimensionality of the feature space to make the parsing process more effective without sacrificing accuracy.
"Systém STYX je elektronickou cvičebnicí češtiny postavenou nad daty Pražského závislostního korpusu. Skládá se z konzolové aplikace určené k filtrování vět (FilterSentences), administračního programu sloužícího k sestavování cvičení (Charon) a vlastní cvičebnice nazvané Styx.","STYX is an electronic exercise book of Czech based on data of the Prague Dependency Treebank. It consists of a console application used to filter unsuitable sentences (FilterSentences), an administrative application for creating exercises (Charon) and the exercise book itself, Styx."
"V článku popisujeme námi vyvinutý systém, který jsme použili při veřejné úloze vícejazyčného parsingu CoNLL 2007. Systém tvoří tři komponenty: parser založený na hledání k nejlepších orientovaných koster, značkovač pro závislostní stromy a reranker, který přeuspořádává k nejlepších označkovaných stromů. Představujeme dva způsoby trénování parseru založeného na orientovaných kostrách: podmíněné trénování založené na stromové normalizaci a na grafové normalizaci. Přeuspořádávací model pro stromy dovoluje explicitně modelovat globální syntaktické jevy; rysy používané rerankerem zahrnují rysy popisující neprojektivní hrany. Analyzujeme chyby v parsingu našeho systému a navrhujeme možné změny použitých modelů, které by mohly přispět k jeho zlepšení.","We present our system used in the CoNLL 2007 shared task on multilingual parsing. The system is composed of three components: a k-best maximum spanning tree (MST) parser, a tree labeler, and a reranker that orders the k-best labeled trees. We present two techniques for training the MST parser: tree-normalized and graph-normalized
conditional training. The tree-based
reranking model allows us to explicitly model global syntactic phenomena. We describe the reranker features which include non-projective edge attributes. We provide an analysis of the errors made by our system and suggest changes to the models and features that might rectify the current system."
"Klasifikace na základě Fisherovy lineární diskriminační analýzy (FLDA) je složitou úlohou v případě, že počet proměnných je o mnoho vyšší než počet daných instancí objektů. Původní FLDA je potřeba pečlivě modifikovat i s ohledem na fakt, že ve vysokých dimenzích hrají důležitou roli implementační otázky jako např. redukce pamětových nákladů. Článek probere různé metody pro high dimension/ small sample size problem a vybere metodu, která je v určitém smyslu nejblíže klasickému regulárnímu postupu. Článek se dále zabývá implementací vybrané metody a to rovněž s ohledem na její vylepšení vzhledem k výpočetním a paměťovým nákladům a vzhledem k numerické stabilitě. Vylepšení je dosaženo kombinací několika známých i zcela nových implementačních strategií. Provedené experimenty prokazují kvalitativně lepší hodnoty celkových numerických nákladů i chyby klasifikace u výsledného algoritmu než u ostatních metod.","Classification based on Fisher's linear discriminant analysis (FLDA) is challenging when the number of variables largely exceeds the number of given samples. The original FLDA needs to be carefully modified and with high dimensionality implementation issues like reduction of storage costs are of crucial importance. Methods are reviewed for the high dimension/small sample size problem and the one closest, in some sense, to the classical regular approach is chosen. The implementation of this method with regard to computational and storage costs and numerical stability is improved. This is achieved through combining a variety of known and new implementation strategies. Experiments demonstrate the superiority, with respect to both overall costs and classification rates, of the resulting algorithm compared with other methods."
"Tento článek představuje metody, jimiž byly označkovány tři velké textové korpusy (SYN2000, SYN2005 a SYN2006PUB). Postup značkování má několik fází: tokenizaci a segmentaci, morfologickou analýzu a dizambiguaci. Při značkování korpusů byly použity jak stochastické, tak pravidlové metody. V závěru článku je představena podrobná evaluace značkovacích metod a kvality značkování ve jmenovaných korpusech.","This paper presents the methods by which three large textual corpora (SYN2000, SYN2005 and SYN2006PUB) of the Czech National Corpus have been tagged and lemmatised. The process proceeded in several phases: tokenization and segmentation, morphological analysis and disambiguation. Statistical taggers as well as a rule-based method of disambiguation have been used in the process. SYN2000 has been tagged by a single feature-based tagger, SYN2005 and SYN2006PUB have been tagged by two different combinations of statistical and rule-based methods. In SYN2006PUB, the number of errors has been further reduced with some simple replacement algorithms. At the end of this paper, an evaluation of the different methods is presented: the method used for corpus SYN2006PUB shows approximatively twice less errors in tagging than in the older tagging of corpus SYN2000."
"Popisujeme pokusy s automatickým anotováním anglických textů z Penn Treebanku na závislostní tektogramatické rovině, jak ji definuje Pražský závislostní korpus. Navržený analyzátor je založen na metodách strojového učení a v nejdůležitějších atributech dosahuje vyšší úspěšnosti než nástroj založený na ručně psaných pravidlech, používaný pro částečnou tektogramatickou anotaci angličtiny dosud.","We present experiments with automatic annotation of English texts, taken from the Penn Treebank, at the dependency-based tectogrammatical layer, as it is defined in the Prague Dependency Treebank. The proposed analyzer, which is based on machine-learning techniques, outperforms a tool based on hand-written rules, which is used for partial tectogrammatical annotation of English now, in the most important characteristics of tectogrammatical annotation. Moreover, both tools were combined and their combination gives the best results."
Článek popisuje nejnovější vývojové tendence jablunkovského dialektu na pomezí Moravy a Slezska.,The paper describes current development tendencies in the dialect of the region of Jablunkov in the borderland between Moravia and Silesia.
Článek popisuje teorii podspecifikovanosti v kontextu slovanských jazyků. Speciálním zkoumaným případem je mizení klitik.,The paper sketches a theory of underspecification in the context of Slavic languages. A special case being investigated is the omission of clitics.
"Pravidlový hloubkový transfer pro systém strojového překladu Česílko, založeného na zjednodušené analýze vstupního jazyka.","Rule-based deep transfer for the Machine Translation system Česílko, which is based on simplified source language analysis."
Softwarový systém pro správu bibliografických údajů. Systém je implementován v jazyce Java a běží v servletovém kontejneru.,A software system for administration of bibliographic data. The system is implemented in Java and runs in a servlet container.
"Tento článek se v první části věnuje experimentálnímu systému strojového překladu Česílko, zvláště funkčnímu popisu jeho jednotlivých modulů, jejich implementace a jimi používaných datových struktur, ve druhé části pak popisuje některé rozdíly mezi obecně velmi podobnými baltoslovanskými jazyky z lingvistického hlediska, konkrétně v systému příčestí a kategorii určitosti s možnostmi jejího vyjádření na povrchové rovině, a naznačuje možnosti formálního zachycení těchto rozdílů.",The paper describes the MT system Česílko and linguistic differences between Balto-Slavic languages.
"Článek popisuje metodu zpracování souvětí založenou na identifikaci segmentů, snadno zjistitelný a lingvisticky motivované jednotek, které mohou poskytnout základ pro další zpracování souvětí. Metoda byla vyvinuta pro český jazyk jako zastupupce jazyků
s vysokým stupněm volného slovosledu. V článku jsou zavedeny důležité pojmy, je zde popsáno
segmentační schéma - datová struktura používana pro popis vzájemného vztahu mezi
jednotlivými segmenty a oddělovači. Obsahuje základní soubor pravidel, která lze užít pro
segmentace souboru českých vět.","The paper describes a method of dividing complex sentences into segments, easily detectable and
linguistically motivated units, which may provide a basis for further processing of complex
sentences. The method has been developed for Czech as a language representing languages with
relatively high degree of word-order freedom. The paper introduces important terms, describes a
segmentation chart, the data structure used for the description of mutual relationship between
individual segments and separators. It contains a simple set of rules applied for the
segmentation of a small set of Czech sentences. The issues of segment annotation based on
existing corpus are also mentioned."
"Představujeme tři poměrně odlišné přístupy k popisu slovního významu ve třech slovnících. Zabýváme se výhodami a nevýhodami zvolených přístupů. Se všemi slovníky jsme provedli experimenty (včetně strojového učení a ruční anotaci), které jsou stručně popsány. Na závěr tyto slovníky porovnáváme.","In this paper we present three quite different approaches to
word senses description in three particular lexicons.
The advantages and disadvantages of these approaches are mentioned.
We have done some practical experiments with all of them.
These experiments--including machine learning and manual annotation--are
briefly described. At the end, we conclude by comparing those three lexicons."
"Příspěvek se zabývá zpracováním pojmenovaných entit v českých textech. Představíme dvouúrovňovou klasifikaci pojmenovaných entit, která byla použita při ruční anotaci 2000 vět. V tomto materiálu bylo identifikováno více než 11000 pojmenovaných entit. S použitím těchto dat jsme metodami strojového učení vyvinuli softwarový systém, který automaticky rozpoznává a klasifikuje pojmenované entity v českých textech.","This paper deals with the treatment of Named Entities (NEs) in Czech. We introduce a two-level NE classification. We have used this
classification for manual annotation of two thousand sentences, gaining more than 11,000 NE instances. Employing the annotated data and
Machine-Learning techniques (namely the top-down induction of decision trees), we have developed and evaluated a software system aimed at automatic detection and classification of NEs in Czech texts."
"Tato technická zpráva shrnuje výsledky práce na tématu pojmenovaných entit v Ústavu formální a aplikované lingvistiky Matematicko-fyzikální fakulty Univerzity Karlovy v Praze v letech 2005 a 2006. Obsahuje rešerši zahraničních
přístupů k tomuto tématu, vlastní návrh klasifikace pojmenovaných entit v češtině, popis ruční anotace pojmenovaných entit na vzorcích z Českého národního korpusu, základní kvantitativní vlastnosti anotovaných dat a výsledky prvních experimentů s automatickým rozpoznáváním pojmenovaných entit v českých
textech.",The technical report deals with classification and automatic regocnition of named entities in Czech texts.
"Příspěvek popisuje volně šiřitelný soubor nástrojů pro strojový překlad, jehož nové rysy zahrnují podporu pro lingvisticky motivované informace, překlad tzv. confusion networks a úsporné datové formáty pro překladové a jazykové modely.","We describe an open-source toolkit for statistical
machine translation whose novel
contributions are (a) support for linguistically
motivated factors, (b) confusion network
decoding, and (c) efficient data formats
for translation models and language
models. In addition to the SMT decoder,
the toolkit also includes a wide variety of
tools for training, tuning and applying the
system to many translation tasks."
"Článek popisuje vývoj systému generujícího gramatické věty v českém jazyce ze vstupního syntakticko-sémantického závislostního stromu.

Zabýváme se dvěma lingvistickými teoriemi a implikacemi pro generování ze struktur, které popisují: (1) Funkční generativní popis P. Sgalla, který byl použit také pro anotaci Pražského závislostního treebanku a (2) Meaning-Text Theory.

Na závěr je výstup prototypu generátoru vyhodnocen.","We report work in progress on a complex system generating
Czech sentences expressing the meaning of input syntactic-semantic structures.
Such component is usually referred to as a realizer in the domain of Natural Language Generation.

Existing realizers usually take advantage of a background linguistic theory.
We introduce the Functional Generative Description, a framework of our choice conceived in 1960's by Petr Sgall.
This language theory lays out foundations of the formalism
in which our input syntactic-semantic structures are specified.
The structure definition was further elaborated and refined during the
annotation of the Prague Dependency Treebank,
now available in its second version.

A section of the paper is devoted to description of another theoretical
framework suitable for the task of
Natural Language Generation -- the Meaning-Text Theory.

We explore state-of-the-art realizers deployed in real life applications, describe common architecture of 
a generation system and highlight the strengths and weaknesses of our approach.
Finally, preliminary output of our surface realizer is compared against a
baseline solution."
V článku je navržen komplexní systém pro generování českých vět z jejich podkladové tektogramatické reprezentace.,"We propose a complex rule-based system for generating Czech sentences out of tectogrammatical trees, as introduced in Functional Generative Description (FGD) and implemented in the Prague Dependency Treebank 2.0 (PDT 2.0). Linguistically relevant phenomena including valency, diathesis, condensation, agreement, word order, punctuation and vocalization have been studied and implemented in Perl using software tools shipped with PDT 2.0. Parallels between generation from the tectogrammatical layer in FGD and deep syntactic representation in Meaning-Text Theory are also briefly sketched."
"Tento dokument zkoumá vlastnosti populární varianta ROC - detekce chyb trade-off plot (DET).
Zejména čerpáme soubor podmínek pro základní rozdělení pravděpodobnosti
vyrábět lineární DET pozemků v zobecněné nastavení. Ukazujeme, že lineární DETs na normální odchýlit stupnice
nejsou vyráběná výhradně
normální distribuce se však, že běžné distribuce, hrají jedinečnou roli v prahu
chování, jak se pohybuje podél trati DET. Zajímavé spojení mezi lineárními a DETs
Kullback-Leibler divergence je také předmětem diskuse.","This paper investigates the properties of a popular ROC variant - the Detection Error Trade-Off plot (DET).
In particular, we derive a set of conditions on the underlying probability distributions
to produce linear DET plots in a generalized setting. We show that the linear DETs on a normal deviate scale
are not exclusively produced by
normal distributions, however, that normal distributions do play an unique role in the threshold
behavior as one moves along the DET line. An interesting connection between linear DETs and
the Kullback-Leibler divergence is also discussed."
"Článek popisuje datový přístup k modelování všech tří základních prozodických vlastností - základního hlasivkového tónu, intenzity a trvání.","This paper describes data-driven modelling of all three basic prosodic features - fundamental frequency, intensity and segmental duration - in the Czech text-to-speech system ARTIC. The fundamental frequency is generated by a model based on concatenation of automatically acquired intonational patterns. Intensity of synthesised speech is modelled by experimentally created rules which are in conformity with phonetics studies. Phoneme duration modelling has not been previously solved in ARTIC and this paper presents the first solution to this problem using a CART-based approach."
"Tento článek popisuje účast Karlovy univerzity v soutěži Cleaneval 2007, společném úkolu a soutěži automatických systémů pro čištění webových stránek s cílem připravit data pro jazykový korpus z oplasti zpracování přirozeného jazyka. Tento úkol jsme pojali jako proces značkování sekvence jednotek, náš experimentální systém je založený na algoritmu Conditional Random Fields a používá rysy extrahované z textu a HTML struktury stránky. Nálepky přiřazené každému textovému bloku potom rozlišují, jestli se jedná o užitečnou část textu, která má být zachována, nebo o část, která se má z dalšího zpracování vyřadit.","This paper describes the participation of the Charles University in Cleaneval 2007, the shared task and competitive evaluation of automatic systems for cleaning arbitrary web pages with the goal of preparing web data for use as a corpus in the area of computational linguistics and natural language processing. We try to solve this task as a sequence-labeling problem and our experimental system is based on Conditional Random Fields exploiting a set of features extracted from textual content and HTML structure of analyzed web pages for each block of text. Labels assigned to these blocks then discriminate between different types of content blocks containing useful material that should be preserved in the document and noisy blocks of no linguistics interest that should be eliminated."
"V této práci jsou zkoumány možnosti zachycování konstrukcí s koordinací tzv. nestejných kategorií. Za nestejné kategorie jsou ve zvoleném teoretickém rámci, funkčním generativním popisu, považovány nestejné sémantické hodnoty jednotlivých uzlů v syntaktickém stromě, tzv. funktory. Autorka navrhuje omezující pravidla, která podchycují podmínky gramatičnosti koordinace nestejných kategorií. Tato pravidla jsou založena na vztahu konjunktů k argumentové struktuře jejich řídícího slovesa. Podstatou těchto pravidel je fakt, že koordinace argumentové a adjunkční pozice generuje za všech okolností negramatické struktury. Na základě těchto pravidel se navrhuje, které případy je možno zachycovat jako koordinaci členskou a které jako koordinaci na úrovni slovesa. V souvislosti s cíli práce se autorka pokouší také o vlastní třídění koordinačních konstrukcí na základě valenčních charakteristik koordinovaných pozic. Práce si klade za cíl vyvrátit vžitý názor, že není možné definovat pravidla pro tvoření gramatických typů koordinace nestejných kategorií.","In this work, theoretical aspects of a descriptive approach to the coordination of unlike categories are studied. According to the theory the author adopts, the so called Functional Generative Description, the different semantic values of coordinated nodes in a dependency tree (called functors) are referred to as unlike categories. The author offers constraints (of a kind) for generating coordinative structures with unlike categories. These constraints are based on the relation between a functor and its dominating verb with respect to the valency structure of the verb. The core of the theory is the fact that a coordination of an argument position and an adjunct position is forbidden as a rule. Considering the proposed constraints, a decision is made, which of the possible structures are to be represented as direct phrasal coordinations and which of them as coordinations on the level of the dominating verb. With respect to the aims of the work, the author submits her own proposal for categorisation of coordinative constructions according to the valency properties of the coordinated positions.  The work aspires to uproot the established opinion that basically there are no syntactic rules for the coordination of unlike categories."
"Toto je první verze valenčního slovníku anglických sloves EngVallex, který vznikl částečně automatickou konverzí slovníku PropBank. Stejně jako PropBank, i EngVallex je propojen s anotací nad korpusem textu z Wall Street Journalu.","This is the first version of EngVallex, a valency lexicon of English verbs, which arose partly by a semi-automatic conversion of the PropBank lexicon. Like PropBank, the lexicon is interlinked with the annotated data of the Wall Street Journal corpus."
Příspěvek se zabývá rozdíly mezi hloubkovými syntaktickými strukturami češtiny a angličtiny. Upozorňujeme na některé jevy potenciálně problematické pro automatické zarovnávání uzlů.,Our paper comments on the divergences of the deep syntactic layers of Czech and Eglish. We point out several phenomena potentially problematic for syntactic alignment.
"Recenzovaná kniha je sborníkem konference Connectives as Discourse Landmarks 2005. Její studie se věnují jednak diskurzním konektorům z hlediska lexikologie a syntaxe, jednak také pragmatickým aspektům užití konektorů.","The peer-reviewed book is the proceedings of the  conference ""Connectives as Discourse Landmarks 2005"". Its contributions focus on discourse connectives in terms of lexicology and syntax, as well as pragmatic aspects of the use of connectives."
"Předpokládáme, že rozdělení věty na téma a réma (o čem se vypovídá co) lze vyvodit automaticky z hodnot kontextové zapojenosti, připsaných každému uzlu v závislostním stromě reprezentujícím hloubkovou strukturu věty. Pro ověření této hypotézy byly provedeny kontrolní ruční paralelní anotace. Článek informuje o principech a předběžných výsledcích těchto kontrolních anotací.","We suppose that the bipartition of the sentence into its Topic and Focus (""aboutness"") can be automatically derived from the values of contextual boundness assigned to each node of the dependency tree representing the underlying structure of the sentence. For the testing of this hypothesis, control manual parallel annotations have been carried out. The principles of the control annotations are described and preliminary results are reported on."
V tomto článku jsou popsány některé nástroje a přístupy ke strojovému překladu z češtiny do ruštiny.,This paper deals with some aspects of MT between Czech and Russian.
"Článek se zabývá hledáním vhodného formalismu pro popis prozodie pro účely strojového učení. Cílovou aplikací je modul generující prozodii pro syntézu řeči z textu. Tento modul se naučí prozodické značky (parametry nebo symboly) z rozsáhlého korpusu. Formalismus, který hledáme, by měl být obecný, percepčně relevantní, obnovitelný, automaticky získatelný, objektivní a naučitelný. Popsali a porovnali jsme hlavní formalismy pro popis F0, jmenovitě Fujisakiho model, ToBI, Intsint, Tilt tzv. “Glissando threshold”. Nejvhodnější metoda popisu F0 pro úlohu strojového učení je “Glissando threshold” s přidaným zjednodušením.","We need to find the most suitable prosody formalism for the task of machine learning. The
target application is a prosody generative module for text-to-speech synthesis. This module will learn prosody marks (parameters or symbols) from large corpora. Formalism we are looking for should be general, perceptually relevant, restorable, automatically obtained, objective and learnable. Main formalisms for the pitch description are briefly described and compared, namely Fujisaki model, ToBI, Intsint, Tilt and “Glissando threshold” adaptation. The most suitable method of pitch description for the task of machine learning is “Glissando threshold” adaptation with an additional simplification."
Český morfologický tagger založený na Průměrovaném perceptronu. Obsahuje sadu nástrojů pro experimenty s různými sadami rysů a trénování na různých datech.,Czech morphological tagger based on Averaged Perceptron. The package contains set of tools for experiments with feature sets and training on various data.
Litomyšlská rodina Sgallů prošla holokaustem se ztrátou většiny členů.,The family Sgall from Litomyšl went through Shoa loosing the majority of its members.
"Článek navrhuje metodu přípravy a pořízení řečového korpusu pro úlohu syntézy řeči z textu s dynamickým výběrem jednotek řízenou pomocí symbolické prozodie. Soustředí se na algoritmus výběru foneticky a prozodicky bohatých vět. Foneticky přepsané věty jsou obohaceny o symbolický popis na hrubé prozodické úrovni s respektováním typu prozodému, ve kterém se fony objevují. Výsledný algoritmus pak vybírá věty s ohledem na fonetická i prozodická kritéria. Abychom též pokryli i supravětné prozodické jevy, náhodně jsme vybrali odstavce a nahráli je. Nový řečový korpus se může využít k syntéze řeči s dynamickým výběrem jednotek a také k trénování datově orientovaného prozodického parseru.","This paper proposes a way of preparing and recording a speech corpus for unit selection text-to-speech speech synthesis driven by symbolic prosody. The research is focused on a phonetically and prosodically rich sentence selection algorithm. Symbolic description on a deep prosody level is used to enrich the phonetic representation of sentences (by respecting the prosodeme types phones appear in). The resulting algorithm then selects sentences with respect to both phonetic and prosodic criteria. To cover supra-sentential prosody phenomena, paragraphs were selected at random and recorded as well. The new speech corpus can be utilised in unit selection speech synthesis and also for training a data-driven prosodic parser."
Experimenty s frázovým strojovým překladem a zamyšlení nad užitečností podrobných lingvistických analýz.,Experiments with phrase-based MT and a discussion on the utility of linguistic analyses.
"V článku je popsán nový anglicko-český paralelní korpus CzEng 0.5, který obsahuje v obou jazycích přibližně 20 miliónů tokenů.","We introduce CzEng 0.5, a new Czech-English sentence-aligned parallel corpus consisting of around 20 million
tokens in either language. The corpus is available on the Internet and can be used under the terms of license
agreement for non-commercial educational and research purposes. Besides the description of the corpus, also
preliminary results concerning statistical machine translation experiments based on CzEng 0.5 are presented."
Příspěvek popisuje experiment s česko-anglickým slovním zarovnáním. Na pěti stech párech ručně zarovnaných vět studujeme nejčetnější důvody neshody a srovnáváme ruční zarovnání s několika variantami automatického postupu.,"We describe an experiment with Czech-English word alignment. Half a thousand
sentences were manually annotated by two annotators in parallel and the most
frequent reasons for disagreement are described. We evaluate the accuracy of
GIZA++ alignment toolkit on the data and identify that lemmatization of the
Czech part can reduce alignment error to a half. Furthermore we document that
about 38% of tokens difficult for GIZA++ were difficult for humans already."
Článek popisuje experimenty s česko-anglickým strojovým frázovým překladem a vyhodnocuje několik technik zlepšujících kvalitu překladu (měřenou pomocí automatické metriky BLEU).,"We describe experiments with Czech-to-English phrase-based machine translation. Several techniques for improving translation quality (in terms of well-established measure BLEU) are evaluated. In total, we are able to achieve BLEU of 0.36 to 0.41 on the examined corpus of Wall Street Journal texts, outperforming all other systems evaluated on this language pair."
"Článek / kapitola popisuje jednotlivé úrovně anotace Pražského závislostního korpusu a vztahy mezi nimi, zejméne mazi sémantickou a syntaktickou rovinou anotace.","Complex Corpus Annotation: The Prague Dependency Treebank. The article - chapter describes the layers of annotation in the Prague Dependency Treebank, and the relations among them."
"Kapitola pojednává o komplexní anotaci jazykových korpusů na úrovni morfologické, povrchově syntaktické a tektogramatické. Za příklad slouží Pražský závislostní korpus.","The chapter discusses complex annotation of language corpora on the layers of morphology, surface syntax and tectogrammatics. The Prague Dependency Treebank serves as an example."
"Kapitola pojednává o syntakticky anotovaných korpusech (treebancích) a principech návrhu sad morfologických a syntaktických značek, které se při anotaci takových korpusů využívají.",The chapter discusses syntactically annotated corpora (treebanks) and the design principles of sets of morphological and syntactic tags that are used for annotation of such corpora.
"Závislostní korpus anotovaný na rovině morfologické (2 miliony slov), syntaktické (1,5 milionu slov) a sémantické (0,8 milionu slov), obsahující navíc doplňující informace o informační struktuře věty a koreference. Distribuováno organizací Linguistic Data Consortium.","Dependency corpus annotated at morphological, syntactic, and deep syntactic levels, with additional attributes describing information structure, coreferences and many other grammatical values. It is distributed by the Linguistic Data Consortium."
"Technická zpráva shrnuje dosavadní poznatky získané při budování Pražského závislostního korpusu mluvené
češtiny (Prague Dependency Treebank of Spoken Czech; PDTSC) v Ústavu formální a aplikované lingvistiky MFF
UK Praha. PDTSC bude prvním korpusem mluvené řeči, který bude obsahovat anotace významu promluv. Výzkum
ukázal, že před vlastní hloubkovou analýzou mluvené řeči je nezbytné transkribované segmenty mluvené řeči
nejprve standardizovaným způsobem převést na gramaticky správné věty, tj. provést tzv. rekonstrukci
standardizovaného textu z mluvené řeči.","Unprepared spontaneous speech breaks many rules by which written texts are constituted. The speakers, for instance, often get the syntax wrong; they mispronounce or confuse lexical units, and their use of ellipsis as well as of deictic words and connectives is abundant, compared to standard written texts. The only way out seems to lead through machine learning: to process enough data for the machine to learn how to tell apart noise from relevant structures and how to restore the commonest types of ellipses to be able to analyze the spoken data with the tools already available. To build such data means smoothing the speech transcription to meet the usual written-text standards by re-chunking and re-building the original segments into grammatical sentences with acceptable word order, proper morphosyntactic relations between words, and appropriate wording, while preserving links to the original transcription."
"První nástroj na kontrolu gramatické správnosti českých vět, který je integrální součástí balíku kancelářských programů Office 2007. Nástroj pročítá text a zelenou barvou podtrhává konstrukce, které jsou gramaticky nesprávné.","The first tool checking the grammatical correctness of Czech sentences, which constitutes an integral part of the Microsoft Office 2007 software package. The tool reads the text and umderlines in green those strings, which are grammatically incorrect."
"První poznámka se vztahuje ke konstrukcím, kde jde o distributivitu, a k prostředkům, jak se na ně anaforicky odkazuje. Druhá se týká konstrukcí s předložkou mezi + Instr. a jejich významu v recipročních konstrukcích (plurálový participant reciproční konstrukce musí mít víc než 2 členy).","The first remark concerns the relation between distributive reading and anaforic expressions coreferred. The second remark is related to the meaning of the Czech preposition mezi in reciprocal constructions, where the plural of the noun after mezi means more than two."
"Ve stati se posuzuje valence některých vyhraněných českých adjektiv. Zvažuje se na základě korpusového materiálu, zda lze oddělit jejich užití v absolutním významu (pyšný člověk, věrný přítel) od užití s obsazenou valenční pozicí (otec pyšný na dceru, své nevěstě věrný snoubenec).","The valency of some typical Czech adjectives is studied. The possibility to distinguish their ""absolute"" usage from the usage with filled valency position is considered."
"Laudatio k sedmdesátým narozeninám profesorky Evy Hajičové. Laudatio bylo předneso v rámci setkání Pražského lingvistického kroužku, během kterého pronesla jubilantka přednášku.",Laudation for Professor Eva Hajičová on the occasion of her 70th birthday. The laudation was presented at the meeting of the Prague Linguistic Circle during which the honored person gave a lacture.
"Čas a šťastná náhoda si spolu velmi dobře rozumějí, většinou. Uvedou nás do situací, do kterých bychom se dostali za předpokladu opravdu „vychytralé“ intuice, většinou. Představíme jednu takovou situaci, která nese reálnou podobu a reálné jméno – Český akademický korpus. Zmínili jsme čas – proto jej představíme na pozadí této veličiny. 
Vrátíme se o dvacet let zpátky do doby, kdy vznikl. Připomeneme dobu před deseti lety, kdy otevřel nové možnosti aplikace stochastických metod v počítačovém zpracování češtiny. Popíšeme jeho současnou příbuznost s Pražským závislostním korpusem.","The Czech Academic Corpus was created during the 1970s and 1980s at the Czech Language Institute under the supervision of Marie Těšitelová. The main motivation to build it (a total of 540 thousand word tokens) was to obtain the quantitative characteristics of contemporary Czech. 
The corpus is structurally annotated on two levels - the morphological level and the syntactical-analytical level. The original stochastic experiment in morphological tagging of Czech were performed using the corpus at the beginning of the 1990s. Given this, the corpus-based processing of Czech was launched. At the end of 1990s, work on the Prague Dependency Treebank had started (independently from the corpus) and its first edition was published in 2001. In considering future released versions of the treebank, we have decided to convert the corpus into the treebank-like format. This article focuses on the twenty-year history of the Czech Academic Corpus. Special attention is devoted to thus far unpublished fats about the corpus annotation. The conversion steps resulting in the first version of the Czech Academic Corpus are described in detail."
Přehled výsledků Cross-Language Speech Retrieval Track organizované v rámci evaluační kampaně CLEF 2006.,"The CLEF-2006 Cross-Language Speech Retrieval (CL-SR) track included two tasks: to identify topically coherent segments of English interviews in a known-boundary condition, and to identify time stamps marking the beginning of topically relevant passages in Czech interviews in an unknown-boundary condition.  Five teams participated in the English evaluation, performing both monolingual and cross-language searches of speech recognition transcripts, automatically generated metadata, and manually generated metadata.  Results indicate that the 2006 English evaluation topics are more challenging than those used in 2005, but that cross-language searching continued to pose no unusual challenges when compared with monolingual searches of the same collection.  Three teams participated in the monolingual Czech evaluation using a new evaluation measure based on differences between system-suggested and ground truth replay start times, with results that were broadly comparable those observed for English."
"Základní forma mluvené češtiny se užívá v Čechách, zatímco na většině Moravy je situace jiná.","Spoken Czech in its unmarked form is used in Bohemia, whereas the situation in most of Moravia is different."
Svým rodičům vděčím za první vhled do komplexnosti mluvené češtiny.,My parents gave me a good start for seeing the intricaces of spoken Czech.
"Vybrané spisy Petra Sgalla, Matematicko-fyzikállní fakulta Univerzity Karlovy Praha","Selected linguistic writings of Petr Sgall, Faculty of Mathematics and Physics, Charles Univeristy, Prague."
Hyperkorekce podléhá jazykovému vývoji a je k ní třeba věnovat náležitou pozornost při popisu jazykového usu.,Hypercorrection underlies language development and has to be taken into account in discussions on the current language situation.
Místo jasné hranice je třeba vidět široké přechodné pásmo mezi „spisovnou“ a běžně mluvenou češtinou.,"Instead of such a boundary, it is necessary to see a large transition zone between standard (written) Czech and the everyday speech."
Recenzovaná kniha usiluje o charakterizaci metod Pražské školy z různých aspektů pohledu.,The reviewed book attempts at a characterization of the methods of the Prague School.
"Jádro jazykového systému lze vidět ve valenci jednotlivých slov, což je spojující prvek mezi slovní zásobou a mluvnicí.","The core of language can be seen in the valency of individual words, which is the connecting link between lexicon and grammar."
"Zatímco standardní (ne vždy „spisovná“) čeština je typická pro psaný projev, je pro mluvenou češtinu charakteristická především obecná čeština.","While written Czech typically corresponds to the standard norm, in spoken usage primarily Common Czech is used."
Stručný přehled přínosu Petra Sgall ke světové i české lingvistice při příležitosti jeho osmdesátin.,"A brief article summarizing the scientific contribution of Profesor Petr
Sgall to the broad field of lingusitic."
"Kritický rozbor problémů, s nimiž se setkává závislostní popis jazyka.",A critical analysis of issues and problems of dependency description of language.
Rozbor případů tzv. přerušených syntaktických vztahů mezi členy téhož rozvitého větného členu.,A corpus based analysis of long distance dependencies in the representation of Czech sentences.
Podmínkou pro automatický překlad je úplné porozumění danému textu.,An adequate translation is possible only under the condition of  full understanding of the text.
Tradice Pražské lingvstické školy a její pokračování v oblasti exaktního popisu jazyka.,"Prague linguistic tradition and its reflection in the formal description of language. Functionalism, dependency syntax, syntactico-semantic structure of the sentence."
"Při příležitosti udělení odměny za celoživotní dílo v počítačové lingvistice autorka   vyčlenila a rozebrala některé výsledky klasické lingstiky, které podstatně přispěly k rozvoji moderní a počítačové lingvistiky.","At the occasion of the Life Achievements Award presented to the author of the paper, the awardee singled out and analyzed several contributions of (classical) linguistics to modern  methods in linguistics and to computational lingusitics."
Diskuse o některýh specifických otázkách vztahu překladu a různých stupňů porozuměni překládaému textu.,Specific issues concerning the relation of translation and the degree of understanding necessary for translation is discussed.
"Syntaktická anotace korpusů se nesmí zastavit na povrchové rovině, ale je třeba zachytit i podkladové syntaktické  vztahy.",Arguments are given for an underlying syntactic annotation of sentences of large text corpora.
Anotování korpusu je  důležitým materiálem pro ověřování či modifikaci lingvistické teorie.,Linguistics is an empirical science and as such it works with hypotheses. Annotation of corpora offers an important way how to test these hypotheses.
Analýza nejdůležitější lingvistických studií Petra Sgalla při příležitosti uveřejnění jeho Vybraných spisů.,A detailed analysis of the most important writings of Petr Sgall at the occasion of the publication opf his Selected Writings.
Stručný přehled a zhodnocení životního díla významného českého lingvisty Petra Sgalla.,"A brief summary of the professional life and publications of Professor
Petr Sgall."
Rozbor životního přínosu profesora Petra Sgalla pro českou lingvistiku.,Life-long contribution of Professor Petr Sgall to the Czech linguistic thinking.
Využití jazykových korpusů pro testování lingvistických teorií (na příkladu PZK).,The use of annotated corpora for testing linguistics hypotheses (on the example of PDT).
Kritický rozbor vědeckého přínosu členů Pražské školy v průběhu její osmdesátileté existence.,A critical survey of the scientific contribution of the members of the Prague Linguistic Circle in the course of its eighty-years of existence.
"Dynamický přístup ke struktuře diskurzu je charakterizován zapojením pojmu ´stupeň aktivovanosti´ objektů, které jsou přístupny v zásobníku sdílených znalostí, jenž mluvčí i posluchač sdílejí.

Představujeme první verzi algoritmu pro přiřazení stupně aktivovanosti objektům. Algoritmus vychází ze struktury pro reprezentaci větného ohniska a základu. Rovněž představíme graifckou vizualizaci výstupu algoritmu.","A dynamic approach to discourse structure is characterized using
the notion of degrees of salience of items in the stock of
knowledge the speaker assumes s/he shares with the hearer. A
preliminary algorithm of salience assignment (based primarily on
the appearance of the nodes of the dependency tree representing
the underlying structure of the sentence to topic or focus) has
been implemented and a visualization of its results has been
produced in order to make the implications of proposed discourse
analysis more perspicuous."
Příspěvek do diskuse o postaveni obecné a spisovné češtiny z hlediska korpusové lingvistiky.,A contribution to the ongoing discussion on standard and common Czech.
"V tomto příspěvku je představen obecný datový formát zaoložený na XML, tzv. PML (Prague Markup Language), který byl speciálně navržen pro potřeby bohaté vícevrstvé lingvistické anotace a vč. anotačních slovníků. PML je hlavní datový formát pro připravované vydání Pražského závislostního korpusu 2.0. Nejprve prezentujeme základní pojmy a myšlenky formátu, pak popisujeme, jak je PML aplikováno na PZK, a na závěr předkládáme návrhy pro další vylepšení.","In this paper we introduce a generic XML-based data format called PML (Prague Markup Language), which was speciﬁcally designed for the needs of representing rich multi-layered linguistic annotation and other data sources such as annotation dictionaries. PML is the main data format for the upcoming release of version 2.0 of the PDT (Prague Dependency Treebank). We ﬁrst present the fundamental concepts and ideas behind the format, then describe how the annotation of PDT is represented in PML, and ﬁnally outline our plans for further improvement."
Testovací kolekce použita pro evaluaci systémů pro vyhledávní v mluvené řeči v rámci Cross-language Speech Retrieval track v rámci CLEF 2006.,A test collection employed for evaluation of the speech retrieval systems at Cross-language Speech Retrieval track at CLEF 2006.
"Představujeme možnost kombinování lexikálních asociačních měr a přínášíme empirické výsledky metod z automatické extrakce kolokací. V první části se nalézá podrobný přehled asociačních měr a jejich výsledků na manuálně anotových datech, která byla evaluována pomocí grafů presision-recall a hodnot mean average precision. Ve druhé části popisujeme nekolik klasifikačních metod vhodných ke kombinování asociačních měr, poté následuje jejich evaluace a porovnání s jednotlivými individuálními měrami. Dále představujeme algoritmus pro výběr rysů, který podstatně snižuje počet kombinovaných měr, a to s minimálním snížením celkového výkonu.","We introduce the possibility of combining lexical association measures and present empirical results of several methods employed in automatic collocation extraction. First, we present a comprehensive summary overview of association measures and their performance on manually annotated data evaluated by precision-recall graphs and mean average precision. Second, we describe several classification methods for combining association measures, followed by their evaluation and comparison with individual measures. Finally, we propose a feature selection algorithm significantly reducing the number of combined measures with only a small performance degradation."
"Popisujeme, jak přistupujeme k valenci v rámci anotování PZK. Zaměřujeme se zejména na valenci sloves a na specifické problémy spojené s touto problematikou.",We present a description of how we dealt with the valency of verbs during the annotation of the PDT and the way the verbal part of the valency dictionary was built. We focus on some specific problems related to verbal valency (as well as some other verbal complementations) from the point of view of the PDT.
"Příspěvek představuje PZK a anotaci na třech lingvistických úrovních: morfologické, analytické a tektogramatické. Soustřeďuje se zejména na hloubkově syntaktickou rovinu a anotaci elips.","The presentation will briefly introduce the PDT that aims at complex linguistic annotation of naturally occurring sentences. Written Czech sentences are annotated on three layers: morphological layer (lemmas, tags, morphological categories), analytical layer (surface structure, dependencies, analytical functions) and the tectogrammatical layer. In our contribution we focus mainly on how sentences are represented on the tectogrammatical layer. Demonstration of this layer will be part of the presentation."
Tato stať je shrnutím disertační práce Valence deverbativních substantiv v češtině úspěšně obhájené v říjnu 2006. Obsahuje vlastní výsledky získané během autorčina doktorského studia na MFF UK v Praze v letech 1999–2006.,"The present paper is an overview of Doctoral Thesis Valence deverbativních substantiv v češtině successfully defended in October 2006, containing results obtained by the author during her doctoral study at the Faculty of Mathematics and Physics of the Charles University (MFF UK) in Prague from 1999 until 2006."
"Předkládaná práce popisuje kroky směřující k modelování prosodie češtiny. Po charakteristice a rozboru současných prosodických teorií a aplikací představuji ústřední bod této práce, popis vývoje snadno přístupného a uživatelsky přívětivého výzkumného prostředí Dialogy.Org, které podporuje zkoumání české prosodie, její analýzu i modelování.","This work describes steps towards prosody models of spoken Czech language.
After a characterisation and discussion of recent prosody definitions and of area of prosody applications, I present the central point of the work, development of an easy-accessible and user-friendly research environment Dialogy.Org, supporting exploration of Czech prosody and its automatic analysis and modelling."
"Netgraph je snadno ovladatelný a intuitivní nástroj vyvinutý pro vyhledávání v Pražském závislostním korpusu, je ho ale možno použít i pro korpusy jiné. Je platformově nezávislý, založený na architektuře klient-server a pracuje v prostředí internetu.","Netgraph is an easy to use and intuitive tool developed for searching in the Prague Dependency Treebank; it can be used for other corpora as well. It is platform-independent, based on the client-server architecture and works in the internet environment."
"Představujeme Netgraph - nástroj pro vyhledávání v lingvisticky anotovaných treebancích. Pracuje v prostředí internetu, je víceuživatelský a založený na principu klient-server.
Netgraph má grafické hardwarově nezávislé uživatelsky přítulné rozhraní. Dotazovací systém je velice intuitivní, snadný k naučení, pochopení a použití, nicméně dokáže provádět pokročilá vyhledávání.
Ukážeme, jak může být Netgraph použit pro tak komplexní anotační schémata jako je Pražský závislostní korpus 2.0 se vztahem mezi uzly jednotlivých rovin jiného typu než 1:1. Zmíníme rovněž hlavní vlastnosti dvou dalších vyhledávacích nástrojů, které jsou pro tento treebank k dispozici.","We present Netgraph - a tool for searching in linguistically annotated treebanks. It works in the Internet environment, on multi-user and client-server basis.
Netgraph has a graphically oriented hardware independent user-friendly interface. The query system is very intuitive, easy to learn, understand and use, nevertheless it can perform advanced searches.
We show how Netgraph can be used for such complex annotation schemes as the Prague Dependency Treebank 2.0 with its non-1:1 relation among nodes on different layers. We also mention main properties of two other searching tools available for this treebank."
"Implementace pro kódování arabštiny v jazycích Haskell a Perl. Podpora po ArabTeX, Buckwalter, UTF a další kódování. Interpretovatelné notace generující originální ortografii a/nebo fonetickou transkripci.","Implementations for encodings of Arabic, in Haskell and Perl. Support for ArabTeX, Buckwalter, UTF and other encodings. Interpretable notations generating original orthography and/or phonetic transcriptions."
"Příspěvek pojednává o anotačních detailech Pražského arabského závislostního korpusu, morfologicky a povrchově syntakticky anotovaného korpusu arabských novinových textů.","The contribution discusses several annotation details of the Prague Arabic Dependency Treebank, a morphologically and surface-syntactically annotated corpus of Modern Standard Arabic newswire texts."
"Hlavním cílem příspěvku je ověřit možnost navýšení objemu Pražského závislostního korpusu o data obsažená v Českém akademickém korpusu.

Pražský závislostní korpus je komplexně anotován na třech rovinách, které zachycují moforlogické a syntaktické (povrchové i hloubkové) vlastnosti českých vět. Charakteristiky zachycené v anotacích Českého akademického korpusu odrážejí zejména vztahy mezi jednotkami vět. 

Integrace ČAK do PDT implikuje kompatibilitu obou datových bank -- kompatibilita na rovině morofologické již byla zajištěna.

Ve věci syntaktické kompatibility se v příspěvku ptáme, je-li automatická konverze syntaktických anotací Českého akademického korpusu efektivnější než přímá aplikace statistického parseru.","The aim of the present paper is to investigate a possibility to enlarge the data in the Prague Dependency Treebank by the data included in the Czech Academic Corpus. The Prague Dependency Treebank annotation is based on a complex three-layer scenario capturing the morphemic and syntactic properties (both of the surface and of the underlying, tectogrammatical structures) of Czech sentences. The characteristics included in the Czech Academic Corpus reflect basic (mostly intra-clausal) relations between sentence elements. The integration of the Czech Academic Corpus material into the Prague Dependency Treebank implies, of course, the necessity to make the two sets of annotated data compatible. This has already been done as for the morphemic layer. The question the paper poses and attempts to answer is whether an automatic transition of the syntactic Czech Academic Corpus data into the Prague Dependency Treebank format is more effective than a direct annotation of the same texts by a statistical parser."
"Technická zpráva je dokumentací k Pražskému závislostnímu korpusu verze 2.0 (PDT 2.0). Obsahuje podrobný komplexní popis dosavadních pravidel anotování českých vět na tektogramatické rovině, a to především po stránce lingvistické, ale i po stránce technické. Anotovaná data neodráží vždy přesně popisovaný stav pravidel anotace, proto je v technické zprávě zahrnut i co nejpřesnější popis anotovaných tektogramatických stromů v korpusu PDT 2.0.","This technical document provides detailed documentation of the Prague Dependency Treebank, version 2.0 (PDT 2.0). It includes a detailed complex description of the rules that have been used so far for the annotation of Czech sentences on the tectogrammatical layer both in linguistic and technical respect. The annotated data do not always reflect the described state of the rules precisely, therefore the technical document includes also a detailed description of the tectogrammatical trees that are annotated in PDT 2.0."
"Technická zpráva je stručným popisem reprezentace věty na tektogramatické rovině Pražského závislostního korpusu verze 2.0 (PDT 2.0). Je určena uživatelům PDT, kteří se chtějí rychle zorientovat v námi použité reprezentaci.",Technical report presents a short description of sentence representation at the tectogrammatical level in the Prague Dependecy Treebank 2.0 (PDT 2.0). It is aimed at those PDT users that look for a quick introduction into the used representation.
"Technická zpráva je stručným popisem reprezentace věty na tektogramatické rovině Pražského závislostního korpusu verze 2.0 (PDT 2.0). Je určena uživatelům PDT, kteří se chtějí rychle zorientovat v námi použité reprezentaci.",Technical report presents a short description of sentence representation     at the tectogrammatical level in the Prague Dependecy Treebank 2.0(PDT 2.0). It is aimed at those PDT users that look for a quick introduction into the used representation.
Ve stati jsou uvedeny základní rysy valenčního přístupu užívaného ve Funkčním generativním popisu a aplikovaného ve valenčním slovníku VALLEX. Z hlediska teoretického je rámec rozšířen o tzv. kvazivalenční doplnění. Podává se jejich charakteristika vzhledem k participantům a volným doplněním.,The main features of the approach to the description of valency in the FGD and applied in the valency dictionary VALLEX are described. The quasivalency modifications are introduced and characterized with regard to their position between inner participants and free modifications.
"Valenční slovník českých sloves VALLEX 2.0, založený na valenční teorii převzaté z funkčního generativního popisu. VALLEX zachycuje chování frekventovaných českých sloves (počet a typ doplnění a jejich merfematickou realizaci).","Valency Lexicon of Czech Verbs VALLEX 2.0, based on valency theory adopted from Functional Generative Description. VALLEX describes valency characteristics of frequent Czech verbs (number and type of complementations ant their morphemic realization)."
"Valenční slovník českých sloves, obsahující přibližně 2730 záznamů o lexémech pokrývajících cca. 6460 lexikálních jednotek (významů). Slovník je volně k dispozici pro účely výzkumu.

V ramci ČR bylo nejvíce licencí vyžádáno z pracovišt Filozofické fakulty UK, Fakulty informatiky MU a Ústavu pro jazyk český AV, z desítek licencí pro zahraniční instituce pak lze uvést např. The Ohio State University, Saarland University, Zagreb University.","The Valency Lexicon of Czech Verbs, Version 2.0 (VALLEX 2.0) is a collection of linguistically annotated data and documentation, resulting from an attempt at formal description of valency frames of Czech verbs. VALLEX 2.0 has been developed at the Institute of Formal and Applied Linguistics, Faculty of Mathematics and Physics, Charles University, Prague. VALLEX 2.0 is successor of VALLEX 1.0, extended in both theoretical and quantitative aspects."
V tomto příspěvku představujeme alternační model valenčního slovníku VALLEX. Alternace popisují pravidelné změny ve valenční struktuře sloves. Charakterizujeme a exemplifikujeme ‘syntaktické‘ a ‚sémantické‘ alternace a jejich dopad na valenční strukturu sloves.,"The main objective of this paper is to introduce an alternation-based model of valency lexicon of Czech verbs VALLEX. Alternations describe regular changes in valency structure of verbs – they are seen as transformations taking one lexical unit and return a modified lexical unit as a result. We characterize and exemplify ‘syntactically-based’ and ‘semantically-based’ alternations and their effects on verb argument structure. The alternation-based model allows to distinguish a minimal form of lexicon, which provides compact characterization of valency structure of Czech verbs, and an expanded form of lexicon useful for some applications."
"V tomto příspěvku navrhujeme nový formální rámec pro FGD založený na restartovacích automatech. Tento přístup zrcadlí tzv. redukční analýzu, metodu implicitně využívanou lingvisty - tato analýza umožňuje odhalit závislostní vztahy ve větě na základě jejího postupného zjednodušování.","We propose a new formal frame for FGD based on restarting automata. This new approach mirrors straightforwardly the so-called analysis by reduction, an implicit method used for linguistic research - analysis by reduction allows to obtain dependencies from the correct reductions of Czech sentences as well as to describe properly
the complex word-order variants of free a word order language."
"Zájmena a další zájmenná slova vytvářejí neproduktivní, uzavřené skupiny, v jejichž rámci lze (alespoň do jisté míry) identifikovat pravidelné slovotvorné a významové vztahy. V první části příspěvku je představena reprezentace českých zájmenných slov v rámci tektogramatické anotace Pražského závislostního korpusu (PDT 2.0). V druhé částí příspěvku se obdobným způsobem pokoušíme popsat anglická a německá zájmenná slova s cílem nastínit, že zájmenné systémy různých jazyků sdílejí celou řadu vlastností.","Pronouns and other pronominal words are unproductive, closed classes with (at least to a certain extent) transparent derivational relations not only in Czech, but also in other languages. In the first part of our contribution, we introduce the representation of Czech pronominal words at the underlying syntactic layer (so called tectogrammatical layer, t-layer) of the Prague Dependency Treebank version 2.0, the annotation scenario of which was built on the theoretical basis of the Praguian Functional Generative Description. In the second part, we try to apply this representation to English and German pronominals in order to illustrate some of the common (universal) properties of the pronominal systems."
"V příspěvku je popsána práce na systému gramatémů, což jsou nejčastěji sémantické protějšky morfologických kategorií (substantivního čísla, slovesného času apod.). Gramatémy byly navrženy v rámci Funkčního generativního popisu a dále rozpracovány při víceúrovňové anotaci Pražského závislostního korpusu (PDT 2.0). Představena je také typologie tektogramatických uzlů, která je využívána jako formální prostředek pro rozlišení, které gramatémy danému uzlu náležejí a které nikoli.","In this paper we report our work on the system of grammatemes (mostly semantically-oriented counterparts of morphological categories such as number, degree of comparison, or tense), the concept of which was introduced in Functional Generative Description, and has been recently further elaborated in the layered annotation scenario of the Prague Dependency Treebank 2.0. We present also a hierarchical typology of tectogrammatical nodes, which is used as a formal means for ensuring presence or absence of respective grammatemes."
"Předkládáme anotační schéma, které zachycuje obecné časové vztahy mezi ději vyjádřenými v diskurzu. Jeho cílem je přirozeně rozšířit existující rovinu tektogramatické anotace Pražského závislostního korpusu. Představuje tak
krok k zachycení obsahu diskurzu. Existence korpusu anotovaného pomocí předkládaného schématu umožní trénování a testování algoritmů automatické extrakce časových vztahů, což přispěje k řešení mnoha úkolů ve zpracování přirozeného jazyka jako je získávání znalostí a strojový překlad. Celkem bylo zatím anotováno 233 vět českého překladu Wall Street Journalu (část Penn Treebanku). Překládáme informaci o statistickém rozdělení jednotlivých typů časových vztahů založenou na těchto prvních anotovaných datech a uvádíme též výsledek algoritmu pro automatické určování časových vztahů založeném na využití informace poskytované gramatikou.","In this paper we present an annotation scheme that captures general temporal relations between events expressed in a discourse. The proposed scheme aims to naturally extend the existing tectogrammatic annotation of the Prague Dependency Treebank and represents a step
towards capturing the cognitive (ontological) content of a discourse. The existence of such an annotation will allow the training and testing of algorithms for automatic extraction of temporal relations which, in turn, contributes to various NLP tasks such as information retrieval and machine translation. 233 sentences of Czech translations of the Wall Street Journal (Penn Treebank) have been annotated so far. We also present statistics on the distribution of respective temporal relations based on this
preliminary annotation data as well as the performance of a grammar-based algorithm."
"Předkládáme formalismus určený k vyhledávání a případnému nahrazování podstromů v ohodnocených stromech. Zvláštní pozornost je věnována zpracování jazykových korpusů. Je-li interpret použit v nahrazovacím módu, zpracovává přepisovací pravidla obsahující levou a pravou stranu. Levá strana určuje vyhledávací formulí les podstromů, které mají být nalezeny. Pravá strana pak obsahuje odpovídající substituce. Ve vyhledávacím módu je přítomna pouze levá strana. Formalismus je plně implementován. Výkon  implementovaného nástroje umožňuje zpracovat i rozsáhlé korpusy v přijatelném čase. Hlavním přínosem předkládané práce je dotazovací síla vyhledávací formule, elegantní a intuitivní podoba
pravidel (a jejich reverzibilita) a výkon implementovaného nástroje.","e presents a formalism capable of searching and
optionally replacing forests of subtrees within labelled trees. In particular, the formalism is developed to process linguistic treebanks. When used as a substitution tool, the interpreter
processes rewrite rules consisting of left and right side. The left side specifies a forest of subtrees to be searched for within a tree by imposing a set of constraints encoded as a query
formula. The right side contains the respective substitutions for these subtrees. In the search mode only the left side is present. The formalism is fully implemented. The performance of the
implemented tool allows to process even large linguistic corpora in acceptable time. The main contribution of the presented work consists of the expressiveness of the query formula, in the
elegant and intuitive way the rules are written (and their easy reversibility), and in the performance of the implemented tool."
"Tento příspěvek má za cíl představit návrh automatického generování valenčích rámců českých sloves, které dosud nejsou obsaženy ve valenčním slovníku VALLEX. V tomto návrhu využíváme syntakticko-sémantické klasifikace sloves. Popisujeme první krok v automatickém rozpoznávání valenčních rámců sloves mluvení a automatickém přiřazení valenčních rámců těmto slovesům. Představená metoda je vyhodnocena oproti dvěma verzím VALLEXu a FrameNetu 1.2. Pro účely generování valenčních rámců navrhujeme novou metriku založenou na konceptu vzdálenosti rámců.","We aim at a procedure of automatic generation of valency
frames for verbs not covered in VALLEX, a lexicon of Czech verbs.We ex-
ploit the classification of verbs into syntactico-semantic classes. This arti-
cle describes our first step to automatically identify verbs of communica-
tion and to assign the prototypical frame to them. The method of identi-
fication is evaluated against two versions of VALLEX and FrameNet 1.2.
For the purpose of frame generation, a new metric based on the notion
of frame edit distance is outlined."
Článek se zabývá automatickou desambiguací slovesných valenčních rámců na českých datech. Hlavním přínosem je stanovení nejužitečnějších rysů pro zjednoznačnění valenčních rámců.,"This paper deals with automatic disambiguation of verb valency frames on Czech data. Main contribution lies in determining of the most useful features for valency frame disambiguation. We experimented with diverse types of features, including morphological, syntax-based, idiomatic, animacy andWordNet-based. The considered features were classiffed using decision trees, rule-based learning and Naive Bayes classiffer.
On a set of 7 778 sentences we achieved accuracy of 79.86% against baseline 68.27% obtained by assigning the most frequent frame."
Mnoho současných systémů pro zpracování přirozeného jazyka potřebuje informaci o slovesné valenci. Tento článek popisuje převod již existujícího valenčního slovníku angličtiny do struktury FGP.,"Many recent NLP applications, including machine translation and information retrieval, could benefit from semantic analysis of language data on the sentence level. This paper presents a method for automatic disambiguation of verb valency frames on Czech data. For each verb occurrence, we extracted features describing its local context. We experimented with diverse types of features, including
morphological, syntax-based, idiomatic, animacy and WordNet-based features. The main contribution of the paper lies in determining which ones are most useful for the disambiguation task. The considered features were classified using decision trees, rule-based learning and a Naive Bayes classifier. We evaluated the methods using 10-fold cross-validation on VALEVAL, a manually annotated corpus of frame annotations containing 7,778 sentences. Syntax-based features have shown to be the most effective. When we used the full set of features, we achieved an accuracy of 80.55% against the baseline 67.87% obtained by assigning the most frequent frame."
"V tomto článku srovnáváme automatické metody zjednoznačnění slovesných významů. Konkrétně zkoumáme naivní bayesovský klasifikátor, rozhodovací stromy a metodu založenou na pravidlech. Navrhujeme různé druhy rysů (morfologických, syntaktických, idiomatických a založených na WordNetu). Vyhodnocujeme metody i jednotlivé druhy rysů na dvou podstatně odlišných českých korpusech, VALEVALu a Pražském závislostním korpusu.","In this paper we compare automatic methods for disambiguation of verb senses, in particular we investigate Naive Bayes classifier, decision trees, and a rule-based method. Different types of features are proposed, including morphological, syntax-based, idiomatic, animacy, and WordNet-based features. We evaluate the methods together with individual feature types on two essentially different Czech corpora, VALEVAL and the Prague Dependency Treebank. The best performing methods and features are discussed."
Systémy zpracování přirozených jazyků vyžadují informaci o slovesné valenci. Článek popisuje výrobu valenčního slovníku angličtiny EngVallex na základě již existujícího slovníku PropBank.,"This paper presents the English valency
lexicon EngValLex, built within the Functional
Generative Description framework.
The form of the lexicon, as well as the
process of its semi-automatic creation is
described. The lexicon describes valency
for verbs and also includes links to other
lexical sources, namely PropBank. Basic
statistics about the lexicon are given.
The lexicon will be later used for annotation
of the Wall Street Journal section
of the Penn Treebank in Praguian formalisms."
"Manuální anotace paralelního esko-anglického korpusu na úrovni slov. Pouili jsme existující pokyny pro anglitinu a francouztinu (Melamed 1998) a rozíili jsme je, aby pokrývaly pípady systematicky se objevující v naem korpusu. Popisujeme hlavní pípady rozíení a uvádíme píklady. Vyhodnotili jsme jak intra-, tak inter-anotatorskou shodu s velmi dobrými hodnotami Kappa výrazn nad 0,9 a shodou 95% pro intra-anotatorskou shodu a 93% pro inter-anotatorskou.","We report on our experience with manual alignment of Czech and English parallel corpus text. We applied existing guidelines for
English and French (Melamed 1998) and augmented them to cover systematically occurring cases in our corpus. We describe the main
extensions covered in our guidelines and provide examples. We evaluated both intra- and inter-annotator agreement and obtained very
good results of Kappa well above 0.9 and agreement of 95% and 93%, respectively."
"Menší chyby v článku tří autorů lze opravit, aniž by se opouštělo přesvědčení, že pojem spisovnosti zastarává.","Several minor mistakes in the paper by the three authors may be revised without changing the conviction that the concept of ""literary"" language is getting obsolete."
V článku jsou popsány dvě řešení syntaktické analýzy českých vět. Vyhodnocení je provedeno s pomocí dat Pražského závislostního korpusu.,"In this paper we describe in detail two
dependency parsing techniques developed
and evaluated using the Prague Dependency Treebank~2.0.  Then we
propose two approaches for combining various existing parsers in order
to obtain better accuracy. The highest parsing accuracy reported in
this paper is 85.84~\%, which represents 1.86~\% improvement compared
to the best single state-of-the-art parser. To our knowledge, no better result
 achieved on the same data has been published yet."
"Článek popisuje první vydání Slovinského závislostního korpusu, který v současnosti obsahuje přibližně 2000 vět. Anotační postup je převzat z Pražského závislostní korpusu.","The paper presents the initial release of the Slovene Dependency Treebank, currently containing 2000 sentences or 30.000 words. Our approach to annotation is based on the Prague Dependency Treebank, which serves as an excellent model due to the similarity of the languages, the existence of a detailed annotation guide and an annotation editor. The initial treebank contains a portion of the MULTEXT-East parallel word-level annotated corpus, namely the first part of the Slovene twas first parsed automatically, to arrive at the initial analytic level dependency trees. These were then hand corrected using the treeranslation 
of Orwell’s “1984”. This corpus  editor TrEd; simultaneously, the Czech annotation manual was modified for Slovene. The current version is available in XML/TEI, as well as derived formats, and has been used in a comparative evaluation using the MALT parser, and as one of the languages present in  the CoNLL-X shared task on dependency parsing. The paper also discusses further work, in the first instance the composition of the corpus to be annotated next."
"Na příkladu Frekvenčního slovníku češtiny ukážeme a vysvětlíme některé nové obecné principy, které poskytují lepší výsledky pro praktické použití frekvenčních slovníků. Jde především o použití průměrné redukované frekvence místo frekvence prosté.","On the example of the recent edition of the Frequency Dictionary of Czech we describe and explain some new general principles that should be followed for getting better results for practical uses of frequency dictionaries. It is mainly adopting average reduced frequency instead of absolute frequency for ordering items. The formula for calculation of the average reduced frequencyis presented in the contribution together with a brief explanation, including examples clarifying the difference between the measures. Then, the Frequency Dictionary of Czech and its parts are described."
"EngValLex je valenční slovník anglických sloves používaných v korpusu Penn Treebank, který jsme získali poloautomatickou konverzí již existujícího valenčního slovníku PropBank-Lexicon do formátu použitelného pro tektogramatickou anotaci podle Funkčního generativního popisu. Tento článek se věnuje automatické konverzi dat a lingvistické problematice jejich následné manuální korektury.","EngValLex is the name of an FGD-compliant valency lexicon of English verbs, built from the PropBank-Lexicon and following the structure of Vallex, the FGD-based lexicon of Czech verbs. EngValLex is interlinked with the PropBank-Lexicon, thus preserving the original links between the PropBank-Lexicon and the PropBank-Corpus. Therefore it is also supposed to be part of corpus annotation. This paper describes the automatic conversion of the PropBank-Lexicon into Pre-EngValLex, as well as the progress of its subsequent manual refinement (EngValLex). At the start, the Propbank-arguments were automatically re-labeled with functors (semantic labels of FGD) and the PropBank-rolesets were split into the respective example sentences, which became FGD-valency frames of Pre-EngValLex. Human annotators check and correct the labels and make the preliminary valency frames FGD-compliant. The most essential theoretical difference between the original and EngValLex is the syntactic alternations used by the PropBank-Lexicon, not yet employed within the Czech framework. The alternation-based approach substantially affects the conception of the frame, making in very different from the one applied within the FGD-framework. Preserving the valuable alternation information required special linguistic rules for keeping, altering and re-merging the automatically generated preliminary valency frames."
"Technická zpráva je předběžným stručným popisem reprezentace anglické věty na tektogramatické rovině Pražského anglického závislostního korpusu verze. Je určena uživatelům PEDT, kteří se chtějí rychle zorientovat v námi použité reprezentaci.",Technical report presents a preliminary short description of English sentence representation at the tectogrammatical level in the Prague English Dependecy Treebank. It is aimed at those PEDT users that look for a quick introduction into the used representation.
"Složenými predikáty (SP) rozumíme zejména konstrukce složené z významově vyprázdněného slovesa a nějakého abstraktního substantiva (často označujícího děj nebo stav). Toto substantivum může být jak deverbativní (např. učinit rozhodnutí, provést údržbu), tak nedeverbativní (např. dát pohlavek). Zmíněný typ predikátů je občas označován také za predikáty verbonominální, příp. analytické. V rámci anotací PDT volíme pro tyto predikáty název „složené predikáty“, a to z toho důvodu, že termín analytický je vyhrazen pro tzv. analytickou rovinu PDT a atributy s ní spojené, termín verbonominální pak zpravidla používáme pro označení jednoho z podtypů složených predikátů, a to predikátů tvořených sponovým slovesem být. V anglickém textu používáme pro označení všech typů složených predikátů termín complex predicates; pro složené predikáty, které nejsou tvořeny sponovým slovesem být, pak volíme obecně užívaný termín support verb constructions. V tomto příspěvku se věnujeme složeným predikátům bez sponového slovesa být.","Support Verb Constructions (SVCs) are combinations of a noun denoting an event or a state and a lexical verb. From the semantic point of view, the noun seems to be a part of a complex predicate rather than the object (or subject) of the verb, whatever the surface syntax may suggest. The meaning is concentrated in the noun component, whereas the semantic content of the verb is reduced or generalized.
	In this article we deal with the question of how to treat SVCs in the Prague Dependency Treebank (PDT subsequently). In the second section we briefly describe what PDT is, what linguistic theory it is based on and what questions regarding the SVCs arose during the annotation. In the third section we explain how SVCs have been identified and inventoried in PDT. We also give a brief survey of how SVCs have been treated within other linguistic frameworks and, based on this knowledge, what conclusions were drawn for PDT. Of course, this survey does not claim to be exhaustive. The fourth section focuses on the semantic aspects of SVCs. The last section describes how the FGD-based valency theory has been implemented in the case of SVCs to provide both a consistent and a linguistically justified annotation in PDT."
Tento článek popisuje extrakci verbonominálních kolokací do švédského valenčního slovníku.,This article presents a method of collocation extraction for a proposed Swedish valency lexicon.
"LEMPAS je pravidlový lematizátor pro švédský morfosyntakticky tagovaný korpus PAROLE. Vznikl jako jako provizorium při přípravě PAROLE pro kolokační analýzu prováděnou nástrojem Sketch Engine. Přesto dává poměrně uspokojivé výsledky v lematizaci substantiv, sloves a částečně i adjektiv, jak jsme zjistili jeho testováním na ručně lematizovaném korpusu SUC.","LEMPAS, the lemmatizer for the Swedish corpus PAROLE, came into existence as a by-product of running the Sketch Engine (Kilgarriff et al., 2004) on Swedish, since many of the desirable features of the Sketch Engine, such as building word sketches, are only available for lemmatized corpora. We did not have access to any Swedish lexical sources and the time allowed for the lemmatization was very limited. Consequently, the lemmatizer had no great design ambitions.  Initially, we were only attempting to bring related forms together under a prelemma, using general rules, and avoiding explicit lists where possible. When the initial rules gave surprisingly good lemmatizations of nouns, verbs and adjectives, we decided to transform the pre-lemmas into real lemmas. The improved lemmatizer made a very good impression. We have tested the program on the manually lemmatized Stockholm-Umeå Corpus (SUC), and have analyzed the results."
"Zde, já
předložit některé poznámky týkající se provádění nyní klasické metody
Údaje shlukování, tzv. maximální vzájemné výměny informací clusteru. Bylo to
zaveden v [\ markcite ((\ it Mercer et al.)) 1992] v souvislosti s jazykem
modelování. Původní článek obsahuje některé podněty k jeho provádění.
Ty jsou prováděny v detailu tady, spolu s některými novými triky. Výsledky
z test na 110M slov dlouho Český národní korpus je stručně
pak popsány. Také jsou identifikovány některé problémy z původní přístup
a jejich možné příčiny se navrhuje.","Herein, I
present some notes concerning implementation of now classical method of
data clustering, called Maximum Mutual Information Clustering. It was
introduced in [\markcite{{\it Mercer et al.}, 1992}] in context of language
modeling. The original article contained some cues concerning its implementation.
These are carried out in detail here, together with some new tricks. Results
of the test run on 110M words long Czech National Corpus are briefly
described then. Also, some problems of the original approach are identified
and their possible cause is suggested."
"Prezentujeme srovnání dvou formalismů pro reprezentaci výpovědí v přirozeném jazyce, totiž hloubkově syntaktickou tektogramatickou rovinu Funkčního generativního popisu (FGD) a sémantický formalismus MultiNet. Probíráme možnou pozici MultiNetu v rámci FGD a prezentujeme předběžné zobrazení reprezentačních prostředků těchto dvou formalismů.","We present a comparison of two formalisms
for representing natural language
utterances, namely deep syntactical Tectogrammatical
Layer of Functional Generative
Description (FGD) and a semantic
formalism, MultiNet. We discuss the
possible position of MultiNet in the FGD
framework and present a preliminary mapping
of representational means of these
two formalisms."
"Nedávno vydaný Pražský závislostní korpus 2.0 (PDT 2.0) je největším korpusem anotovaným na tektogramatické rovině (""rovině jazykového významu"") popsané ve Sgall et al. (2004) a obsahuje asi 0,8 miliónu slov (viz Hajič (2004)). Doufáme, že tato rovina anotace je již natolik blízko významu výpovědí v korpusu obsažených, že umožní automatickou transformaci textů do báze znalostí použitelné pro extrakci informací, zodpovídání dotazů, sumarizaci atd.","Recently, the Prague Dependency Treebank 2.0 (PDT 2.0) has emerged as the largest text corpora annotated on the level of tectogrammatical
representation (""linguistic meaning"") described in Sgall et al. (2004) and containing about 0.8 milion words (see Hajic (2004)).
We hope that this level of annotation is so close to the meaning of the utterances contained in the corpora that it should enable us to automatically
transform texts contained in the corpora to the form of knowledge base, usable for information extraction, question answering,
summarization, etc. We can use Multilayered Extended Semantic Networks (MultiNet) described in Helbig (2006) as the target formalism.
In this paper we discuss the suitability of such approach and some of the main issues that will arise in the process."
"Představujeme systém elektronické cvičebnice české morfologie a syntaxe. Jednotlivá cvičení jsou
vybrána přímo z Pražského závislostního korpusu. Chceme takto seznámit žáky s důležitým akademickým
produktem. Pochopitelně neočekáváme, že studenti si budou procvičovat gramatiku s takovým nadšením,
s jakým surfují po webu, povídají si s kamarády nebo si píší blog. Na druhou stranu věříme, že
elektronická cvičebnice může přinést zábavnější formu procvičování.

Poskytujeme dva typy cvičení: morfologická a syntaktická, tedy cvičení v určování slovních druhů a
jejich morfologických kategorií a v rozboru věty a určování větných členů. Vzhledem k rozdílům mezi
akademickým a školským přístupem nemohou být data Pražského závislostního korpusu použita přímo.
Některé věty musejí být zcela vynechány, na jiné je potřeba aplikovat řadu transformací a tím je
převést z původní reprezentace do podoby, na niž jsou žáci zvyklí.","We present a system designed as an electronic corpus-based exercise book of Czech morphology and
syntax with the exercises directly selected from the Prague Dependency Treebank. In this way we want
to make schoolchildren familiar with such an important academic product. Obviously, we do not
expect that the schoolchildren (will) do grammar practicing so enthusiastically as they surf the
web, chat with friends or write a web log. However, we believe that an electronic exercise book can
make practicing more fun.

Two kinds of exercises are provided, morphological and syntactic, i. e. the exercises give practice
in classifying parts of speech and morphological categories of words and in parsing a sentence and
classifying syntactic functions of words. The Prague Dependency Treebank data cannot be used
directly though, because of the differences between the academic approach and the approach taught in
schools. Some of the sentences have to be completely discarded and several transformations have to
be applied to the others in order to convert the original representation to the form the
schoolchildren are familiar with."
"Pražský závislostní korpus (PDT) patří mezi nejvýznamnější
jazykové korpusy na světě. Cílem této práce je představit softwarový
systém, který nad daty PDT tvoří cvičebnici českého jazyka. Procvičování
probíhá ve dvou oblastech: tvarosloví (určování slovních druhů a jejich
morfologických kategorií) a větný rozbor (určování větných členů a
závislostí mezi nimi). Vzhledem k odlišnostem mezi akademickými rozbory
vět a rozbory tak, jak jsou vyučovány ve školách, však nelze data
PDT použít zcela přímočaře. Mnoho vět je potřeba z dat úplně vyřadit,
na ostatních je nutné provést množství transformací, které převedou
původní reprezentaci do tvaru, na který jsou žáci zvyklí ze školy.","Prague Dependency Treebank (PDT) is one of the top
language corpora in the world. The aim of this work is to introduce
a software system that builds an exercise book of Czech
using the data of PDT. Two kinds of exercises are provided: morphology
(selecting correct parts of speech and their morphological categories)
and sentence parsing (selecting analytical functions and dependencies
between them). The PDT data cannot be used directly though, because
of the differences between the academic approach in sentence parsing
and the approach that is used in schools. Some of the sentences have
to be discarded completely, several transformations have to be applied
to the others in order to convert the original representation to the
form to which the students are used to from school."
"Pražský závislostní korpus (PDT) patří mezi nejvýznamnější jazykové korpusy na světě. Cílem naší
práce je představit softwarový systém, který nad daty PDT vytvoří elektronickou cvičebnici českého
jazyka. Procvičování probíhá ve dvou oblastech: tvarosloví (určování slovních druhů a jejich
morfologických kategorií) a větný rozbor (určování větných členů a závislostí mezi nimi). Vzhledem k
odlišnostem mezi akademickými rozbory vět a rozbory tak, jak jsou vyučovány ve školách, však nelze
data PDT použít zcela přímočaře. Mnoho vět je potřeba z dat úplně vyřadit, na ostatních je nutné
provést množství transformací, které převedou původní reprezentaci do tvaru, na nějž jsou žáci
zvyklí ze školy.","Prague Dependency Treebank (PDT) is one of the most important language corpora in the world. The aim
of our work is to introduce a software system which builds an exercise book of Czech language upon
the PDT data. Two kinds of exercises are provided, morphological (classifying parts of speech and
morphological categories of words) and syntactic (parsing a sentence and classifying syntactic
functions of words). Due to the differences between the academic approach and the school approach
to the parsing of sentences, the PDT data cannot be used directly. Many sentences have to be
discarded completely, several transformations need to be applied to the others in order to convert
them to a form the students are familiar with."
Webové stránky přináší unikátní příležitost vytvořit velkou a kvalitní kolekci textů s malým úsilím. V tomto článku popisujeme nutné podmínky pro vytvoření dobrého korpusu textů a přinášíme program program pro jeho vytvoření z webových stránek. Jako pilotní studii jsme vytvořili slovinský korpus o velikosti přesahující miliardu slov.,"The World Wide Web offers a unique possibility to create very large and high quality text collections with low manual work necessary. In this paper, we describe requirements for usable linguistic corpus and we present a routine for building such corpus from the web pages. Several important issues that must be resolved for successful processing are discussed. As a pilot study, we create a billion-token Slovenian corpus based solely on the contents of web pages."
"Ve zpracování přirozeného jazyka se při studiu kolokačního jevu používají tzv. asociační míry, které jsou často původně definovány v oborech jako statistika, teorie informace nebo komputační lingvistiky. Zde přestavujeme procesy výroby, evaluace a vizualizace asociačních měr, které se dají prakticky využít. Zároveň navrhujeme způsob, jak míry kombinovat za účelem zlepšení výsledků.","In natural language processing task  you can use so called association measures while studying collocation event. Those measures are often defined in branches as statistics, information theory and computational linguistics. Here we are presenting the processes of preparation, evaluation and visualisation of association measures that can be used in practical experiments. Moreover, we are proposing the way how to combine individual measures in order to result improvements."
"V tomto příspěvku je naším cílem optimalizovat implementování Fisherovy lineární diskriminační analýzy (FLDA), která je základní klasifikační metodou pro úlohu s malým vzorkem pozorovaných objektů. Mezi metodami řešícími tento problém představujeme metodu, která je v jistém smyslu nejblíž původnímu klasickému regulárnímu přístupu a jejíž implementace zlepšuje komputační a pamětové nároky a numerickou stabilitu.","Here we aim at optimizing the implementation of Fisher’s Linear Discriminant Analysis (FLDA) - based classification for the small sample size problem. Among methods for this problem it considers the one closest, in some sense, to the classical regular approach and improves its implementation with regards to computational and storage costs and numerical stability."
"Čeština (jako ostatní slovanské jazyky) je dobře známa svou morfologickou bohatostí. Zpracování textu (např. strojový překlad, syntaktická analýza) obvykle vyžaduje jednoznačný výběr gramatických kategorií (tzv. morfologické značky) pro každé slovo v textu. Morfologické značkování sestává ze dvou částí - přiřazení všech možných značek každému slovu v textu a volbu správné značky v daném kontextu. Projekt Morče řeší druhou část, obvykle zvanou disambiguace.
Byla použita statistická metoda založená na kombinaci skrytého Markovova modelu a průměrovaného perceptronu. Autor provedl mnoho experimentů porovnávajících různá nastavení parametrů algoritmu, aby dosáhl nejlepší možné úspěšnosti.
Výsledná úspěšnost Morčete na datech z PDT 2.0 byla 95,431 % (březen 2006), což je na češtině zatím nejlepší dosažený výsledek samostatného taggeru.","Czech (like other Slavic languages) is well known for its complex morphology. Text processing (e.g., automatic translation, syntactic analysis...) usually requires unambiguous selection of grammatical categories (so called morphological tag) for every word in a text. Morphological tagging consists of two parts – assigning all possible tags to every word in a text and selecting the right tag in a given context. Project Morče attempts to solve the second part, usually called disambiguation. Using a statistical method based on the combination of a Hidden Markov Model and the AveragedAveraged Perceptron algorithm, a number of experiments have been made exploring different parameter settings of the algorithm in order to obtain the best success rate possible. Final accuracy of Morče on data from PDT 2.0 was 95.431% (results of March 2006). So far, it is the best result for a standalone tagger."
"Tato práce předkládá nástroje pro analýzu na analytické a tektogramatické rovině, které jsou základem Pražského závislostního korpusu.

Nástroje pro analytickou anotaci sestávají ze dvou parserů a nástroje přiřazujícího tzv. analytické funkce. Ačkoli úspěšnost parserů je daleko za úspěšností nejlepších parserů, oba mohou být chápány jako určitý přínos k parsingu, neboť jsou založeny na nových metodách. Nástroj přiřazující analytické funkce dělá o 15 % chyb méně než nástroj, který se k tomuto účelu používal dosud.

Nástroj vyvinutý pro tektogramatickou anotaci je jediný, který tuto úlohu nyní zvládá v takové šíři. Ačkoli jiné, specializované nástroje možná řeší některé její podúlohy lépe, pro češtinu dělá můj nástroj o 29 %, resp. 47 % méně chyb než kombinace existujících nástrojů určujících tektogramatickou strukturu, resp. hloubkové funktory, což je obojí jádrem tektogramatické roviny.

Předkládané nástroje jsou navrženy tak, aby je bylo možno použít i pro jiné jazyky.","The thesis presents tools for analysis at analytical and tectogrammatical layers that the Prague Dependency Treebank is based on.

The tools for analytical annotation consist of two parsers and a tool for assigning syntactic tags. Although the performance of the parsers is far below that of the state-of-the-art parsers, they both can be considered a certain contribution to parsing, since the methods they are based on are novel. The tool for assigning syntactic tags makes 15% less errors than a tool used for this purpose previously.

The tool developed for tectogrammatical annotation is the only one that can currently perform this task in such a breadth. Although other, specialized tools may have a better performance of some of its particular subtasks, my tool makes 29% and 47% less errors for the Czech language than the combination of existing tools for annotating the tectogrammatical structure and deep functors, respectively, which are the core of the tectogrammatical layer.

The proposed tools are designed the way they can be used for other languages as well."
"Nástroj používající trénovací data pro vytvoření svého jazykového modelu přidává anotaci na tektogramatické rovině (tak, jak je definována v Pražském závislostním korpusu) k textům v češtině anotovaným na morfologické a analytické rovině.","The tool, using training data for creation of its language model, adds annotation at the tectogrammatical layer (as it is defined in the Prague Dependency Treebank) to Czech text annotated at morphological and analytical layers."
"Tento článek představuje dvě metody závislostní syntaktické analýzy pomocí pravidel automaticky odvozených z trénovacích dat. Úspěšnost takto získaných analyzátorů na češtině je zřetelně pozadu za nejlepšími známými parsery, avšak článek přináší novou metodu odvozování pravidel a novátorským způsobem aplikuje transformační učení na syntaktickou analýzu. Navíc parsery využívají vlastnosti češtiny jen ve velmi omezené míře, takže mohou být snadno nasazeny na jiný jazyk. Článek také představuje metodu přiřazení takzvaných analytických funkcí, která vykazuje lepší výsledky než metody používané dosud.","This paper introduces two methods of dependency parsing by means of rules automatically inferred from training data. For Czech the accuracy of the proposed parsers is considerably behind that of the state-of-the-art parsers, but the paper brings a new method of inference of rules and applies transformation-based learning to parsing in a novel way. Moreover, the parsers use properties of Czech language in a very limited way and thus can easily be used for parsing another language. The paper also introduces a method of assigning so called analytical functions
that outperforms that currently used."
"Existuje několik nástrojů, které podporují ruční anotaci dat na tektogramatické rovině, jak ji definuje Pražský závislostní korpus. S pomocí transformačního strojového učení jsme vyvinuli nový nástroj, který zlepšuje dosavadní výsledky preanotace tektogramatických struktur o 29 % (měřeno jako relativní snížení chybovosti) a hloubkových funktorů (tj. sémantických funkcí) o 47 %.","There are several tools that support manual annotation of data at the Tectogrammatical Layer as it is defined in the Prague Dependency Treebank. Using transformation-based learning, we have developed a tool which outperforms the combination of existing tools for pre-annotation of the tectogrammatical structure by 29%
(measured as a relative error reduction) and for the deep functor (i.e., the semantic function) by 47%. Moreover, using machine-learning technique makes our tool almost independent of the language being processed. This paper gives details
of the algorithm and the tool."
"Článek popisuje situaci polské národnostní menšiny na Těšínsku, historický vývoj dialektu a jeho současný stav.","The paper describes the language situation of the Polish minority in Teshen Silesia, its history and development up to the present day."
Článek navrhuje míru pro měření podobnosti jazyků založenou na strukturní podobnosti povrchových závislostních stromů.,"This paper outlines a measure of language similarity based on structural similarity of surface syntactic dependency trees. Unlike the more tradi- tional string-based measures, this measure tries to reflect deeper correspondences among languages. The development of this measure has been inspired by the experience from MT of syntactically similar languages. This experience shows that the lexical similarity is less important than syntactic similarity. This claim is supported by a number of examples illustrating the problems which may arise when a measure of language similarity relies too much on a simple similarity of texts in different languages."
Článek popisuje architekturu systému strojového překladu pro slovanské jazyky.,"This paper describes an architecture of a machine translation system designed primarily for Slavic languages. The architecture is based upon a shallow transfer module and a stochastic ranker. The shallow transfer module helps to resolve the problems, which arise even in the translation of related languages, the stochastic ranker then chooses the best translation out of a set provided by a shallow transfer. The results of the evaluation support the claim that both modules newly introduced into the system result in an improvement of the translation quality."
"Příspěvek zavádí pojem (větného) segmentu, jednotky, která je lingvisticky motivovaná a přitom snadno automaticky rozpoznatelná.
Rozpoznání segmentů umožňuje určovat segmentační strukturu věty (reprezentovanou segmentačním schématem), na jejímž základě lze
vymezit jednotlivé klauze souvětí a jejich vzájemný vztah, a tím i syntaktickou strukturu souvětí. Metoda segmentace je navržena
pro automatické zpracování češtiny, jazyka s relativně velmi volným slovosledem.

V příspěvku je dále popsána sada jednoduchých pravidel, která je využita pro budování segmentačních schémat. Výsledky segmentace
jsou  vyhodnoceny  vzhledem k malému ručně anotovanému korpusu českých vět.","On segmentation of Czech sentences. The paper introduces a concept of segments, linguistically motivated and easily detectable language units. These segments may be subsequently combined into clauses and thus provide a structure of a complex sentence with regard to the mutual relationship of individual clauses. The method has been developed for Czech as a language representing languages with relatively high degree of word-order freedom. 

The paper introduces important terms and describes a segmentation chart. It also contains a simple set of rules applied for the
segmentation of a small set of Czech sentences. The segmentation results are evaluated against
a small hand-annotated corpus of Czech complex sentences."
"Článek popisuje metodu zpracování souvětí založenou na identifikaci segmentů.
Metoda byla vyvinuta pro český jazyk, který je charakteristický volností slovosledu. Příspěvek zavádí důležité pojmy a popisuje
datovou struktury používanou pro popis vzájemného vztahu mezi jednotlivými segmenty. Obsahuje také základní soubor pravidel pro
segmentaci a vyhodnocení na malém souboru českých vět.","The paper describes a method of dividing complex sentences into segments, easily detectable and
linguistically motivated units that may be subsequently combined into clauses and thus provide
a structure of a complex sentence with regard to the mutual relationship of individual clauses.
The method has been developed for Czech as a language representing languages with relatively
high degree of word-order freedom. The paper introduces important terms, describes a
segmentation chart, the data structure used for the description of mutual relationship between
individual segments and separators. It also contains a simple set of rules applied for the
segmentation of a small set of Czech sentences. The segmentation results are evaluated against
a small hand-annotated corpus of Czech complex sentences."
"Tato práce se zabývá desambiguací významu substantiv a adjektiv.
 Významy rozlišuje dvojím způsobem, na základě synsetů z Českého WordNetu
 a podle valenčních rámců zachycených v
PDT-VALLEXU.
 Tím vznikají dvě oddělené úlohy, spočívající v přiřazování synsetů/rámců
 víceznačným lemmatům.
 Řešíme je metodou strojového učení, konkrétně využíváme rozhodovací stromy.
 K disposici máme korpus PDT s bohatou anotací na více jazykových rovinách
 obsahující i valenční rámce a dále část PDT s ruční anotací pomocí ČWN.
 V první části práce se zabýváme spojením obou korpusů, neboť jsou v různých
 formátech.
 Ve druhé části s použitím syntaktických závislostí věty a morfologických
 informací přiřazujeme synsety z ČWN.
 Dosahujeme úspěšnosti 91,4% (proti 90,0% baseline) pro substantiva a 93,9%
 (proti 93,2%) pro adjektiva.
 To představuje opravení 13,7% (resp.
 10,0%) chyb vůči baseline.
 Krátce tuto metodu aplikujeme také na t-rovinu, kde je však patrný nedostatek
 dat.
 Ve třetí části přiřazujeme valenční rámce substantivům na základě informací
 z hloubkové roviny významu.
 Dosahujeme úspěšnosti 86,9% proti 84,9% baseline.
 Na závěr porovnáváme oba použité slovníky.","This thesis deals with word sense disambiguation of nouns and
 adjectives.
 We make use of the two approaches to distinguish word senses: the first
 method is derived from synsets from the Czech WordNet, the second one uses
 valency frames from the PDT-VALLEX dictionary.
 This means we have the two separate tasks, the goal of which is to assign
 appropriate senses (synsets/frames) to ambiguous lemmas.
 We are employing machine learning methods, the most notable of which are
 the decision trees.
 For this purpose we are using two types of data, namely the PDT corpus
 with rich annotations on several language layers, and also the part of
 the PDT manually annotated using the CWN.
 In the first part we are trying to merge both corpora, since they are stored
 in the different formats.
 In the second part we are using syntactic and morphologic features to assign
 CWN synsets.
 We reach 91,4% accuracy (compared to 90,0% baseline) for nouns and 93,9%
 (compared to 93,2%) for adjectives.
 In other words this means that we can correct 13,7% (10,0% respectively)
 of errors made by the baseline.
 This method is applied on the t-layer, where lack of data is obvious.
 In the third part we are assigning valency frames to nouns using information
 from deep syntactic layer.
 The accuracy gained by us has grown to 86,9% compared to 84,9% baseline.
 At the very end, we compare the both dictionaries obtained."
"Tento článek popisuje zkušenost s lexikálně-sémantickou anotací Pražského závislostního korpusu (Prague Dependency Treebank, PDT). Jako slovník jsme používali Český WordNet (ČWN) a anotovali jsme každé slovo vyskytující se v ČWN. Na základě chybové analýzy jsme anotační slovník upravili a následně přeanotovali vybraná lemmata. Předkládáme výsledky anotací a zlepšení dosažená díky opravám.","This paper presents our experience with the lexico-semantic annotation of
the Prague Dependency Treebank (PDT). We have used the Czech WordNet (CWN)
as an annotation lexicon (repository of lexical meanings) and we annotate each word
which is included in the CWN. Based on the error analysis we have performed some
experiments with modiﬁcation of the annotation lexicon (CWN) and consequent re-
annotation of occurrences of selected lemmas. We present the results of the annotations
and improvements achieved by our corrections."
"Přípěvek představuje formální lingvistický systém pro anotaci zájmenných slov, který byl vyvinut a implementován v rámci tektogramatické roviny Pražského závislostního korpusu (PDT 2.0). Z hlediska vytváření anotovaných korpusů a jejich užívání se ukazuje jako užitečné, pokud jsou pravidelnosti, které lze uvnitř určité podskupiny zájmenných slov sledovat, explicitně popsány. Při takovém postupu jsou významové rysy, které jednotlivá zájmenná slova sdílejí, z těchto slov extrahovány a zachyceny hodnotou atributů. V příspěvku je sada atributů navržených pro tyto účely podrobně popsána.","In this paper, we present a formal linguistic system for the annotation of proforms which has been developed and implemented in the framework of the tectogrammatical layer of the Prague Dependency Treebank 2.0. The main motivation of our approach is the following: if there is a semantically relevant regularity within a certain subset of pro-forms, then it is more useful – at least from the viewpoint of treebank users interested in natural language semantics, in conversions into logical forms etc. – if such information is available in the treebank in an explicit, machine-tractable form. In this case, the semantic features originally present in the word form (given its context) are extracted and stored as values of inner parameters of tectogrammatical nodes corresponding to the given word form."
Publikace Miroslava Červenky mají základní význam pro teorii verše a pro literarni vědu obecně.,Miroslav Červenka’s publications are of great importance for the theory of verse and for Czech literary science in general.
Tento článek popisuje efektivní postup využívající strukturální podobnosti a znovuvyužitelných manuálních překladů pro překlad rozsáhlých ontologií.,"This paper presents a process for leveraging structural relationships and reusable
phrases when translating large-scale ontologies. Digital libraries are becoming more and
more prevalent. An important step in providing universal access to such material is to provide
multi-lingual access to the underlying principles of organization via ontologies,
thesauri, and controlled vocabularies. Machine translation of these resources requires high
accuracy and a deep vocabulary. Human input is often required, but full manual translation
can be slow and expensive. We report on a cost-effective approach to ontology translation.
We describe our technique of prioritization, our process of collecting aligned translations
and generating a new lexicon, and the resulting improvement to translation system output.
Our preliminary evaluation indicates that this technique provides significant cost savings
for human-assisted translation. The process we developed can be applied to ontologies in
other domains and is easily incorporated into other translation systems."
Tento článek popisuje efektivní postup využívající manuálních překladů pro konstrukci doménově specifických lexikálních zdrojů.,"Thesauri and ontologies provide important
value in facilitating access to digital
archives by representing underlying principles
of organization. Translation of
such resources into multiple languages is
an important component for providing
multilingual access. However, the specificity
of vocabulary terms in most ontologies
precludes fully-automated machine
translation using general-domain
lexical resources. In this paper, we present
an efficient process for leveraging
human translations when constructing
domain-specific lexical resources. We
evaluate the effectiveness of this process
by producing a probabilistic phrase dictionary
and translating a thesaurus of
56,000 concepts used to catalogue a large
archive of oral histories. Our experiments
demonstrate a cost-effective technique
for accurate machine translation of
large ontologies."
"Závěrečná zpráva z workshopu JHU. Popisuje implementaci a experimenty s frázovým systémem Moses, který podporuje dodatečnou anotaci vstupu i výstupu pomocí tzv. faktorů.",The final report of JHU workshop. The report describes the implementation and experiments with a phrase-based MT system Moses.
V tomto článku je popsán nový pravidlový přístup k úloze generování přirozeného textu ze vstupní reprezentace v podobě tektogramatických stromů.,"In this paper we deal with a new rule-based approach to the~Natural
Language Generation problem. The presented system synthesizes Czech
sentences from Czech tectogrammatical trees supplied by the Prague
Dependency Treebank~2.0 (PDT~2.0). Linguistically relevant phenomena including
valency, diathesis, condensation, agreement, word order, punctuation
and vocalization have been studied and implemented in Perl using
software tools shipped with PDT~2.0. BLEU score metric is used for the
evaluation of the generated sentences."
"Článek popisuje různé metody a nástroje používané k poanotačním opravám dat PDT 2.0. Anotační proces treebanku byl komplikován několika faktory, například rozdělením dat na několik rovin, které si odpovídají. Pravidla pro anotaci se navíc během anotačního procesu měnila a vyvíjela. Některé části dat byly navíc anotovány odděleně a paralelně, takže se později musely s daty slévat. Dalším zdrojem chyb byl převod ze starého anotačního formátu do nového, kromě všudypřítomné lidské chybovosti. Kontrolní procedury zajišťující integritu a korektnost dat jsou dále klasifikovány z různých hledisek, např. podle jejich lingvistické relevance a role v kontrolním procesu. V poslední části článku jsou metody porovnány a ohodnoceny.","Various methods and tools used for the post-annotation checking of Prague Dependency Treebank 2.0 data are being described in this article. The annotation process of the treebank was complicated by several factors: for example, the corpus was divided into several layers that must reflect each other. Moreover, the annotation rules changed and evolved during the annotation. In addition, some parts of the data were annotated separately and in parallel and had to be merged with the data later. The conversion of the data from an old format to a new one was another source of possible problems besides  omnipresent human inadvertence. The checking procedures used to ensure data integrity and correctness are classified according to several aspects, e.g. their linguistic relevance and their role in the checking process, and prominent examples are given. In the last part of the article, the methods are compared and scored."
"Článek popisuje metody a nástroje používané k poanotačním opravám dat PDT 2.0. Anotační proces byl komplikován několika faktory, například rozdělením treebanku na několik rovin, které si musejí odpovídat. Anotační pravidla se v průběhu anotace měnila a vyvíjela, části dat byly anotovány odděleně a paralelně, takže se musely slévat dohromady. Dalším zdrojem problémů byl převod ze starého datového formátu do nového. Kontrolní procedury jsou klasifikovány podle různých faktorů, např. jejich lingvistické relevance či role v kontrolním procesu, a jsou představeny některé příklady. V závěru článku jsou metody číselně porovnány.","This paper describes methods and tools used for the post-annotation
checking of Prague Dependency Treebank~2.0 data. The annotation
process was complicated by many factors: for example, the corpus is
divided into several layers that must reflect each other; the
annotation rules changed and evolved during the annotation process;
some parts of the data were annotated separately and in parallel and
had to be merged with the data later. The conversion of the data
from the old format to a new one was another source of possible
problems besides omnipresent human inadvertence. The checking
procedures are classified according to several aspects, e.g. their
linguistic relevance and their role in the checking process, and
prominent examples are given. In the last part of the paper, the
methods are compared and scored."
"Práce popisuje nejrůznější metody a nástroje používané při anotaci a poanotačních opravách dat Pražského závislostního korpusu 2.0. Anotační proces byl komplikován několika faktory: například rozdělením treebanku na několik rovin, které si odpovídají. Anotační pravidla se navíc měnila a vyvíjela v průběhu anotačního procesu. Některé části dat byly navíc anotovány odděleně a paralelně, takže se s daty později slévaly. Vedle nevyhnutelné lidské chybovosti byl dalším potenciálním zdrojem problémů převod dat ze starého formátu do nového

V první kapitole je představeno teoretické pozadí PDT. Jsou popsány rozdíly mezi teoretickými předpoklady a jejich realizací v treebanku a různé vlastnosti anotačních schémat a datových formátů.

Druhá kapitola popisuje nástroje používané k anotaci a poanotačním opravám. Zvláštní pozornost je věnována koordinačním a apozičním konstrukcím, porovnává se několik možných přístupů a uvádějí se funkce, které byly k jejich zachycení použity.

Třetí kapitola popisuje poanotační kontroly, které zaručovaly integritu a korektnost dat. Procedury jsou klasifikovány podle různých kritérií a uvedeno je mnoho lingvisticky motivovaných příkladů. V poslední části kapitoly se studuje dopad kontrolních procedur na počet změn v datech, procedury se porovnávají a zkoumá se jejich přínos.","This work describes various methods and tools used during the
annotation and post-annotation checking of Prague Dependency
Treebank 2.0 data. The annotation process of the treebank was
complicated by several factors: for example, the corpus was divided
into several layers that must reflect each other. Moreover, the
annotation rules changed and evolved during the annotation. In
addition, some parts of the data were being annotated separately and
in parallel and had to be merged with the data later. Conversion of
the data from an old format to a new one was another source of
possible problems besides omnipresent human inadvertence.

In the first chapter, the theoretical background of the Prague
Dependency Treebank is given. Differences between theoretical
assumptions and their realization in the treebank are described
together with various aspects of annotation schemata and data format.

The second chapter describes the tools used for annotation and during
the post-annotation checking. Special attention is paid to
coordination- and apposition-like constructions: several possible
approaches are compared and functions for resolving complex structures
(encoded according to the used approach) are presented.

The third chapter expounds the post-annotation checking procedures
used to ensure data integrity and correctness. The procedures are
classified by several criteria and many linguistically inspired
examples are given. In the last part of the chapter, the impact of the
checking procedures is measured by counting the number of changes in
the data, the procedures are compared and their contribution and
usefulness is discussed."
V nedávné době jsme představili náš nový datový model prozodie pro systémy převodu textu na řeč. Tento model je založen na parametrizaci textu používající generativní prozodickou gramatiku a na metodách automatické analýzy řečových korpusů. Model byl úspěšně testován a kladně hodnocen při syntéze češtiny. V předkládaném článku jsou prezentovány první výsledky jeho aplikace na syntézu němčiny.,We have recently introduced our new data-driven prosody model for text-to-speech synthesis. The model is based on text parametrisation using a generative prosodic grammar and on automatic speech corpora analysis methods. The model has been successfully tested for Czech language with highly assessed naturalness of resulting speech. The current stage of the model development involves the first experiments with its application to German synthesis. The results of these experiments are presented in the paper.
"Analýza umístění přísudkového slovesa v různých jazykových žánrech, a to v závislosti na aktuálním členění a dalších jazykových jevech.","Analysis of the location of the predicate verb in different language genres, depending on the information structure and other linguistic phenomena."
"Netypické slovosledné uspořádání kontextově nezapojeného aktora, adresáta a patientu v češtině.","Non-typical word order of contextually non-bound actor, addresee and patient in Czech."
"Příspěvek popisuje probíhající práce na česko-anglickém slovníku pro strojový
překlad. Slovník vychází z dostupných strojově čitelných slovníků, kombinací
ručních a automatických metod jsou doplňovány informace nutné pro nasazení
slovníku v automatickém systému. Jedná se zejména o morfologická omezení nutná
pro uplatnění hesel, popis syntaktické struktury hesel a překladové ekvivalenty
slovesných rámců.",The paper describes ongoing work on our Czech-English translation dictionary aimed at machine translation.
Popisujeme metodu extrakce překladových slovesných rámců (paralelních valenčních rámců) z paralelního závislostního korpusu.,"We describe a method for extracting translation verb frames (parallel
subcategorization frames) from a parallel dependency treebank. The extracted
frames constitute an important part of machine translation dictionary for a
structural machine translation system. We evaluate our method independently,
using
a manually annotated test dataset, and conclude that the bottleneck of the method
lies in quality of automatic word alignment of the training data."
Projekt Enti má za cíl vytvořit nástroj pro navrhování umělých agentů podobných lidem. Hlavní komponenty tohoto nástroje jsou virtuální prostředí pro agenty a programovací jazyk E pro popis chování agentů. Příspěvek popisuje první verzi tohoto nástroje.,"The Project ENTs aims at providing a universal high-level tool for
prototyping human-like artificial agents. The main features of this tool are a
virtual test-bed environment and E language, which enables description of
human-like agents’ behaviours using various techniques, in particular reactiveThe Project ENTs aims at providing a universal high-level tool for
prototyping human-like artificial agents. The main features of this tool are a
virtual test-bed environment and E language, which enables description of
human-like agents’ behaviours using various techniques, in particular reactive
planning and BDI-architecture. In this paper, we present first generation of this
tool together with an example agent—an artificial gardener that acts in a virtual
family house. We then briefly discuss applicability of this tool and introduce
some requirements for its second generation.
planning and BDI-architecture. In this paper, we present first generation of this
tool together with an example agent—an artificial gardener that acts in a virtual
family house. We then briefly discuss applicability of this tool and introduce
some requirements for its second generation."
Souhrn experimentu s ruční anotací příkladů sloves hesly slovníku VALLEX pro změření mezianotátorské shody a kontrolu kvality slovníkových hesel.,An experiment with manual annotation of verb examples using entries in the lexicon VALLEX aimed at an estimate of inter-annotator agreement and the quality of VALLEX entries.
Popis pokusu o recyklaci částí systému strojového překladu z češtiny do ruštiny v nového systému do angličtiny.,This paper describes an attempt to recycle parts of the Czech-to-Russian machine translation system (MT) in the new Czech-to-English MT system. The paper describes the overall architecture of the new system and the details of the modules which have been added. A special attention is paid to the problem of named entity recognition and to the method of automatic acquisition of lexico-syntactic information for the bilingual dictionary of the system.
Článek popisuje pokus o recyklaci systému strojového překladu z češtiny do ruštiny.,This paper describes an attempt to recycle parts of the Czech-to-Russian machine translation system (MT) in the new Czech-to-English MT system. The paper describes the overall architecture of the new system and the details of the modules which have been added. A special attention is paid to the problem of named entity recognition and to the method of automatic acquisition of lexico-syntactic information for the bilingual dictionary of the system.
Popis pokusů o revitalizaci staršího systému strojového překladu.,A summary of attempts at revitalizing an older implementation of an MT system.
Oblast morfologického zjednoznačňování arabštiny zaznamenala v poslední době výrazné úspěchy. Díky nim se Penn Arabic Treebank etabluje jako standard pro vývoj a vyhodnocování systémů pro automatické zpracování arabské morfologie a Buckwalterův arabský morfologický analyzátor se stává nejrespektovanějším lexikálním zdrojem svého druhu.,"The field of morphological disambiguation of Arabic has recently witnessed significant achievements. Through them, the Penn Arabic Treebank is being confirmed as a standard for development and evaluation of systems for automatic morphological processing of Arabic, and the Buckwalter Arabic Morphological Analyzer is becoming the most respected lexical resource of its kind."
"Tento software ke stažení poskytuje první dostupnou kontrolu české gramatiky pro sadu Microsoft Office 2003. Kontrola české gramatiky analyzuje text a zeleně podtrhává úseky, které nemusejí být gramaticky správně.","This downloadable software provides the first publicly available grammar checker for Czech for the  Microsoft Office 2003. The grammar checker analyzes the text and underlines in green the strings, which may not be grammatically correct."
Článek popisuje metodu klasifikace a rozpoznávání morfologických kolokací. Problémy jsou popsány pomocí příkladů v litevštině.,The paper describes a method of classification and recognition of morphological collocations. The problems are explained by means of Lithuanian examples.
"Ve stati se porovnávají dva přístupy k popisu valence: Přístup autorek Valenčního slovníku slovenských sloves je charakterizován jako více lexikologicky a sémanticky orientovaný, zatímco přístup Funkčního generativního popisu je pokládán za syntakticky založený. Hledání hranic a operačních kritérií je nezbytné pro oba přístupy.","Two approaches to the description of verbal valency are compared. The former (the approach of the authors of the Valency dictionary of Slovac verbs) is considered as more lexicologically and semantically based, the latter (valency theory in the Functional Generative Description)  is considered as more syntactically based. The necessity of providing  clear boundaries between the phenomena constituting the sentence nucleus and the other phenomena belonging to the sentence periphery s is stressed."
"Děti používají  počítač ke psaní, kreslení, hraní her, listování v encyklopediích, skládání hudby - proč by jej nemohli používat k procvičování větných rozborů a určování rodu, čísla, pádu, ...?

Představujeme systém STYX, který je navržen jako elektronická cvičebnice českého tvarosloví a české syntaxe. Příklady jsou vybrány z Pražského závislostního korpusu.","The schoolchildren can use a computer to write, to draw, to play games, to page encyclopedia, to 
compose music - why they could not use it to parse a sentence, to determine gender, number, case, …? 

We are presenting a system ""Styx"" that is designed 
to be an exercise book of Czech morphology and syntax with the exercises directly selected from 
PDT."
"Tento článek představuje Prague Czech-English Dependency Treebank (PCEDT), nový zdroj dat pro experimenty se strojovým překladem využívajícím větnou strukturu. Popisujeme popis tvorby základních částí -- paralelního syntakticky anotovaného korpusu a překladových slovníků. Část Penn Treebanku byla přeložena do češtiny, anotace české části byla vytvořena utomatickými nástroji, anotace anglické části byla automaticky převedena z formalismu Penn Treebanku do formalismu Pražského závislostního korpusu. Podmnožina paralelních dat byla anotována ručně. První experimenty s česko-anglickým strojovým  překladem proběhly. Tento datový zdoj byl vytvořen na Karlově Universitě v Praze a jeho vydání v Linguistic Data Consortium je plánováno na rok 2004.","This paper introduces the Prague Czech-English Dependency Treebank
(PCEDT), a new Czech-English parallel resource suitable for
experiments in structural machine translation. We describe the process
of building the core parts of the resources -- a bilingual
syntactically annotated corpus and translation dictionaries. A part of
the Penn Treebank has been translated into Czech, the dependency
annotation of the Czech translation has been done automatically from
plain text. The annotation of Penn Treebank has been tranformed into
dependency annotation scheme. A subset of corresponding Czech and
English sentences has been annotated by humans. First experiments in
Czech-English machine translation using these data have already been
carried out. The resources being created at Charles University in
Prague are scheduled for release as Linguistic Data Consortium data
collection in 2004."
"V práci se zabýváme projektivitou a algoritmy pro projektivizaci a nalezení neprojektivních hran v úplně uspořádaných kořenových stromech (takové stromy se používají v syntaktické analýze přirozeného jazyka, kde se pro ně užívá název závislostní stromy). Definujeme kanonickou projektivizaci úplně uspořádaného kořenového stromu (zachovávající stromovou strukturu a pro všechny vnitřní vrcholy relativní uspořádání těchto vrcholů a jejich dětí) a dokazujeme její jednoznačnost; uvádíme také zobecnění tohoto výsledku. Dále se zabýváme vlastnostmi neprojektivních hran, které jsou podstatné pro nově představené algoritmy: První algoritmus pro vstupní strom vrací jeho projektivizaci, druhý algoritmus ve vstupním stromu nalezne neprojektivní hrany dvou ze tří zavedených typů (ukazujeme také, jak je možné výstup algoritmu využít k nalezení všech neprojektivních hran). Dokazujeme, že algoritmy jsou optimální: jejich časová složitost je O(n).","The paper discusses the notion of projectivity and algorithms for projectivizing and detecting non-projective edges in totally ordered rooted trees (such trees are used in dependency syntax analysis of natural language, where they are called dependency trees). We define the canonical projectivization of a totally ordered rooted tree (preserving the tree structure and the relative ordering for all inner nodes and their immediate dependents) and show its uniqueness; we also give a generalization of this result. We then discuss some properties of non-projective edges relevant for the newly presented algorithms:The first algorithm computes the projectivization of the input tree, the second algorithm detects non-projective edges of certain types in the input tree (we also give a hint on finding all non-projective edges using its output). Both algorithms can be used for checking projectivity. We prove that the algorithms are optimal: they have time complexities O(n)."
"V práci se zabýváme projektivitou a algoritmy pro projektivizaci a nalezení neprojektivních hran v úplně uspořádaných kořenových stromech (takové stromy se používají v syntaktické analýze přirozeného jazyka, kde se pro ně užívá název závislostní stromy). Definujeme kanonickou projektivizaci úplně uspořádaného kořenového stromu (zachovávající stromovou strukturu a pro všechny vnitřní vrcholy relativní uspořádání těchto vrcholů a jejich dětí) a dokazujeme její jednoznačnost; uvádíme také zobecnění tohoto výsledku. Dále se zabýváme vlastnostmi neprojektivních hran, které jsou podstatné pro nově představené algoritmy: První algoritmus pro vstupní strom vrací jeho projektivizaci, druhý algoritmus ve vstupním stromu nalezne neprojektivní hrany dvou ze tří zavedených typů (ukazujeme také, jak je možné výstup algoritmu využít k nalezení všech neprojektivních hran). Dokazujeme, že algoritmy jsou optimální: jejich časová složitost je O(n).","The paper discusses the notion of projectivity and algorithms for projectivizing and detecting non-projective edges in totally ordered rooted trees (such trees are used in dependency syntax analysis of natural language, where they are called dependency trees). We define the canonical projectivization of a totally ordered rooted tree (preserving the tree structure and the relative ordering for all inner nodes and their immediate dependents) and show its uniqueness; we also give a generalization of this result. We then discuss some properties of non-projective edges relevant for the newly presented algorithms:The first algorithm computes the projectivization of the input tree, the second algorithm detects non-projective edges of certain types in the input tree (we also give a hint on finding all non-projective edges using its output). Both algorithms can be used for checking projectivity. We prove that the algorithms are optimal: they have time complexities O(n)."
"V příspěvku se hodnotí vývoj strojového překladu od jeho začátků přes novější systémy až po současný stav, v němž převažují metody statistické založené na paralelních korpusech.",The development of machine translation systems is discussed. The rule-based systems of machine translation used since 60-ies last century and the statisticaly based systems used nowadays are compared. The existence of paralel corpora is a useful tool for the developmnet of such systems.
"Pražský česko-anglický závislostní korpus (Prague Czech-English Dependency Treebank, PCEDT) je syntakticky anotovaný česko-anglický paralelní korpus. Jedná se o Penn Treebank, který byl přeložen do češtiny a jeho anotace automaticky transformována do závislostní anotace. Závislostní anotace češtiny byla provedena plně automaticky. Malá množina paralelních vět byla anotována ručně. Na tomto korpusu byly provedeny první pokusy se strojovým překladem z češtiny do angličtiny. Jazykové zdroje byly vytvořeny na Univerzitě Karlově v Praze a publikovány prostřednictvím  Linguistic Data Consortium v roce 2004.","The Prague Czech-English Dependency Treebank (PCEDT) is a syntactically annotated Czech-English parallel corpus. The Penn Treebank has been translated to Czech, and its annotation automatically transformed into dependency annotation scheme. The dependency annotation of Czech is done from plain text by automatic procedures. A small subset of corresponding Czech and English sentences has been annotated by humans. First experiments in Czech-English machine translation using these data have already been carried out. The resources have been created at Charles University in Prague and released by Linguistic Data Consortium in 2004."
Funční generativní popis (FGP) je stratifikační závislostní přístup k popisu přirozeného jazyka. V tomto článku uvádíme některé jeho vlastnosti společné s teorií Smysl-Text.,"Functional Generative Description (FGD) is a stratificational dependency-based approach to natural language description, which has been developed by Petr Sgall and his collaborators in Prague since 1960's. Although FGD bears surprisingly many resemblances with the Meaning-Text Theory, to our knowledge there is no reasonably detailed comparative study available so far. In this paper, we try to point out at least the basic obvious parallels (and also differences),
which - in our opinion - remain generally unknown."
"V práci je představen valenční slovník českých sloves VALLEX. V první části je uveden přehled literatury související s valenčními slovníky. V druhé části je podrobně popsána struktura navrženého slovníku, softwarové nástroje pro jeho vytváření a jeho základní kvantitativní vlastnosti.","Valency is a property of language units reflecting their combinatorial potential in language utterances. The availability of the information about valency is supposed to be crucial in various Natural Language Processing tasks. In general, valency of language units cannot be automatically predicted, and therefore it has to be stored in a lexicon. The primary goal of the presented work is to create a both human- and machine-readable lexicon capturing valency of the most frequent Czech verbs. For this purpose, valency theory developed within Functional Generative Description (FGD) is used as the theoretical framework. The thesis consists of three major parts. The first part contains a survey of literature and language resources related to valency in Czech and other languages. Basic properties of as many as eighteen different language resources are mentioned in this part. In the second part, we gather the dispersed linguistic knowledge necessary for building valency lexicons. We demonstrate that if manifestations of valency are to be studied in detail, it is necessary to distinguish two levels of valency. We introduce a new terminology for describing such manifestations in dependency trees; special attention is paid to coordination structures. We also preliminarily propose the alternation-based lexicon model, which is novel in the context of FGD and the main goal of which is to reduce the lexicon redundancy. The third part of the thesis deals with the newly created valency lexicon of the most frequent Czech verbs. The lexicon is called VALLEX and its latest version contains around 1600 verb lexemes (corresponding to roughly 1800 morphological
lemmas); valency frames of around 4400 lexical units (corresponding to the individual senses of the lexemes) are stored in the lexicon. The main software components of the dictionary production system developed for VALLEX are outlined, and selected quantitative properties of the current version of the lexicon are discussed."
"Popisujeme, jak přistupujeme k valenci v rámci anotování PZK. Zaměřujeme se zejména na valenci sloves a na specifické problémy spojené s touto problematikou.",We present a description of how we dealt with the valency of verbs during the annotation of the PDT and the way the verbal part of the valency dictionary was built. We focus on some specific problems related to verbal valency (as well as some other verbal complementations) from the point of view of the PDT.
"Činnost Pražského lingvistického kroužku byla zastavena v komunistickém období, ale v r. 1989-90 byla plně obnovena.","The activity of the Prague Linguistic Circle was stopped in the Communist years, but it was possible to resume it in 1989-90."
"Jubilea se dožívá Eva Hajičová, vynikající lingvistka, které česká věda vděčí za podstatný přínos.",Eva Hajičová has achieved an anniversary after bringing a major contribution to the Czech linguistics.
Autoři popisují jazykovou situaci ve velké části západní Afriky a její vývoj.,The authors describe the language situation of and development in a large part of West Africa.
"Dizertace je zaměřena na problematiku modelování dokumentů, podobnosti dokumentů, témat dokumentů a souvisejících věcí. Nejprve analyzujeme, jaký druh informací může být z dokumentů extrahován s použitím automatických method lingvistické analýzy. Dále je dizertace zaměřena na explicitní identifikaci témat textů v modelech dokumentů. Specifická témata se hledají jako podgrafy v grafy celé kolekce textových dokumentů.","In the thesis we focus mainly on the area of document models, document
similarity and topics, and related things.
We first analyze what information can be extracted from natural
language texts using automatic linguistic processing. Then we try to
directly and explicitly capture the topics of the texts in the
document models for this information seems to be of critical
importance. We view a text collection as a graph and try to discover
topics in the text collection as a specific subgraphs.
We also developed some model data that capture the human understanding
about document similarity and topics. The data is used for tests and
for learning parameters."
"Kniha pokrývá nové technologie z oblasti zpracování přirozeného jazyka. Zaměřuje se na vyhledánání informací, automatickou extrakci informací z textu a klasifikaci textů podle tématu.","This book covers the emerging technologies of document retrieval, information extraction, and text categorization in a way which highlights commonalities in terms of both general principles and practical issues."
"Recenze monografie, v níž autor prezentuje svůj návrh na reprezentaci
informatické struktury věty na základě triadických struktur.","A review of a monograph the author of which presents its proposalw to
represent the information structure of the sentence based on triadic
structures."
Přínos anotovaných jazykových korpusů pro lingvistické studium aktuálního členění.,Annotated corpora are discussed from the viewpoint of their contribution to linguistic theories.
Proces překladu je nahlížen z hlediska porozumění; je navržen možný přístup k reprezentaci významu textu.,The process of translation is viewed from the point of view of understanding and a representation of meaning is argued for.
"Rozbor jazykových problémů, které je třeba řešit pro automatické porozumění textů v přirozeném jazyce.",An analysis of several linguistic issues that must be taken into account in any automatic natural language understanding system.
Vztah mezi mluveným a psaných jazykem z hlediska jazykové víceznačnosti.,"Language is characterized by several types of asymmetries, one of the most important is the case of homonymy, which can be found both in spoken and in written languge."
"Počítačové ověření algoritmu pro určení základu a ohniska výpovědi na
základě primárniho příznaku kontextoveho zapojeni.","A computational implementation of the algorithm for determination of topic
and focus on the basis of the primary marker of contextual boundness."
Postavení aktuálního členění věty v popisu hloubkové (podkladové)struktury jazyka.,"The status of the representation of topic/focu articulation in the overall
underlying representation of the structure of the sentence."
"Technická zpráva popisuje design nového datového formátu založeného na XML, který má zajistit lepší  interoperabilitu a nahradit rozličné starší datové formáty používané v různých oblastech            korpusové lingvistiky se strukturovanou anotací.
Zpráva představuje první verzi formátu pod názvem Prague Markup Language (PML) a to včetně aktuální verze technické specifikace.","In the first part of this technical report we describe our approach to design
        a new data format, based on XML (Extensible Markup Language)
            and aimed to provide a better and unifying alternative to
            various legacy data formats used in various areas of
            corpus linguistics and specifically in the field of
            structured annotation.
            We introduce the first version of the format, called Prague
            Markup Language (PML). This version has already been employed as
            the main data format for the upcoming Prague Dependency
            Treebank 2.0 (PDT).
Finally we outline our ideas and proposals for further improvement of
            PML, based on our current experience with using and
            processing data in PML format in the PDT 2.0 project.
       
            The second part of the technical report contains the state-of-the-art
            specification of PML."
"Leonard Talmy shrnuje jeho práci v oblasti sémantiky (kterou ztotožňuje s kognitivní lingvistika) v posledních 30 let. Ačkoli se to může zdát zbytečné, když používá atribut 'kognitivní' v souvislosti s 'sémantiky' zdůraznit zájem o pojmové struktury, neboť se tvoří v lidském myšlení a také jeho fenomenologický přístup. Ke knize Kognitivní sémantika se skládá ze dvou svazků. Objemu v rámci přezkumu myšlenku obecného pojmu-struktury systémů v jazyce a jejich vztahy k jiným systémům vnímání je předložit, načež analyzuje tři takové systémy jsou poskytovány. Objem je rozdělen do čtyř částí: Základy Koncepční Strukturování v jazyce, Configurational struktura, pozornost, síly a jejich příčin.","Leonard Talmy sums up his work in the field of semantics (which he identifies with cognitive linguistics) in the last 30 years. Though it may seem redundant, he uses the attribute 'cognitive' in connection with 'semantics' to emphasize the concern for the conceptual structures as they are formed in a person's mind and also his phenomenological approach. The book Toward a Cognitive Semantics consists of two volumes. In the volume under review the idea of general concept-structuring systems in language and of their relationships to other perception systems is put forward, whereupon the analyzes of three such systems are provided. The volume is divided into four parts: Foundations of Conceptual Structuring in Language, Configurational Structure, Attention, Force and Causation."
Empirická studie popisující současný stav výzkumu metod pro extrakci kolokací.,"This paper presents a status quo of an
ongoing research study of collocations –
an essential linguistic phenomenon having
a wide spectrum of applications in
the field of natural language processing.
The core of the work is an empirical evaluation
of a comprehensive list of automatic
collocation extraction methods using
precision-recall measures and a proposal
of a new approach integrating multiple
basic methods and statistical classification.
We demonstrate that combining
multiple independent techniques leads to
a significant performance improvement in
comparisonwith individual basic methods."
Hlavní problém jazykového modelování v češtině je enormní velikost slovníku způsobená velkým množstvím různých slovních tvarů odvozených z jednoho slova (lemmatu).,Main problem of language modeling encountered in Czech is enormous vocabulary growth caused by great number of different word forms derived from one word (lemma).
"Článek popisuje vytváření LVCSR systému pro rozpoznávání spontánní promluvy českých, ruských a slovenských svědků holokaustu v projektu MALACH. Ruční transkripce byly použity jako hlavní zdroj pro jazykové modelování a normalizovány s použitím standardního slovníku, což přineslo 2-3% snížení chybovosti. Následná interpolace s tématicky podobnými větami automaticky vybranými z obecného korpusu přinesla další zlepšení o 3%.","This paper describes the building of LVCSR systems for recognition of spontaneous speech of Czech, Russian, and Slovak witnesses of the Holocaust in the MALACH project. Manual transcripts as one of the main sources for language modeling were automatically „normalized” using standardized lexicon, which brought about 2 to 3% reduction of the word error rate. The subsequent interpolation of such LMs with models built from an additional collection (consisting of topically selected sentences from general text corpora) resulted into an additional improvement of performance of up to 3%."
"Disertace se zabývá problematikou valence deverbativních substantiv v češtině. Úvodní oddíly jsou věnovány přehledu zahraničních i českých přístupů k otázkám valence substantiv a shrnutí dosavadních poznatků týkajících se některých vybraných problémů v oblasti valence českých deverbativních substantiv (zejména vztahu mezi povrchovým vyjádřením valenčních doplnění deverbativních substantiv a formou odpovídajících valenčních doplnění u příslušného základového slovesa). Vlastní výsledky zkoumání jsou představeny jednak v podobě detailních studií věnovaných syntakticky nebo sémanticky uceleným skupinám deverbativních substantiv (zejména substantiv s dativní valencí), jednak v podobě teoretických závěrů vyplývajících z prozkoumaného jazykového materiálu. Jazykový materiál byl čerpán ze dvou českých elektronických korpusů, Českého národního korpusu a Pražského závislostního korpusu. Jako teoretický rámec pro popis valenčních vlastností zkoumaných substantiv byl zvolen funkční generativní popis.","The present Doctoral Thesis deals with valency properties of deverbal nouns in Czech. After an overview of Czech and foreign approaches to the valency of nouns and a summary of current knowledge concerning some special issues of valency of Czech deverbal nouns, we present results consisting of our analysis of syntactically and semantically compact groups of deverbal nouns as well as theoretical conclusions following from the examined language material. We have focused our attention on Czech deverbal nouns that can be modified by a participant expressed by prepositionless dative. Such nouns were searched for in two Czech electronic corpora, Czech National Corpus (CNC) and Prague Dependency Treebank (PDT). The obtained occurrences were manually sorted and analysed and their valency behaviour is described within the theoretical framework of the Functional Generative Description (FGD)."
"Sborník anotací vyšel už při konferenci v roce 2005. Kniha s úplnými články vyšla až o 2 roky později: GRAMATIKA A KORPUS, GRAMAR & CORPORA 2005, editoři František Štícha a Josef Šimandl, ISBN 80-86496-32-5, 304 stran, 31 textů, vydavatel Ústav pro jazyk český.

Tento příspěvek se zaměřuje na porovnání valenčního chování dvou skupin deverbativních substantiv odvozených od sloves s dativní valencí, a to substantiv dávání a substantiv mluvení.","The book of abstracts was published at the conference in 2005. A book with full papers was published 2 years later: GRAMATIKA A KORPUS, GRAMAR & CORPORA 2005, editors František Štícha and Josef Šimandl, ISBN 80-86496-32-5, 304 pages, 31 texts, publisher Ústav pro jazyk český (Institute of the Czech Language).

Studying valency properties of nouns derived from verbs that can also be modified by a valency complementation expressed by prepositionless dative, we focused on two distinct semantic classes, i.e. nouns of giving and nouns of saying."
Učení založené na paměti (memory-based learning) patří k tzv. líným (lazy) metodám generalizace. Trénovací data jsou pouze zapamatována a během testování se mezi nimi hledají co nejpodobnější příklady. Tuto metodu používáme k disambiguaci morfologického značkování češtiny a ukazujeme první výsledky.,"The memory-based learning belongs to so-called lazy methods of generalization. The training data are only stored in the memory and during the testing, the most similar examples are retrieved. We use this method for the morphological disambiguation of Czech and show the first results."
"Pražský závislostní korpus patří k nejvyspělejším jazykově anotovaným korpusům světa. Je anotován na třech rovinách jazykové abstrakce - morfologické, analytické a tektogramatické. K jeho prohledávání vytváříme uživatelsky přítulný nástroj Netgraph, který nabízí intuitivní ovládání a především intuitivní dotazovací jazyk, spolu s přehledným zobrazením výsledku dotazů.","The Prague Dependency Treebank belongs to the most advanced linguistically annotated corpora in the world. It is annotated on three layers of abstraction: morphological, analytical and tectogrammatical. For searching in the corpus, we develop a user-friendly tool called Netgraph. It offers an intuitive interface and most of all, an intuitive query language, along with a comprehensive depicting of the results."
Syntaktický analyzátor morfologicky označkovaného českého textu v CSTS formátu Pražského závislostního korpusu.,Syntactic parser of morphologically tagged Czech text in the CSTS format of the Prague Dependency Treebank.
"Tento dokument zkoumá možnosti zlepšení výsledků analýzy kombinací výstupů několika parsery. Pro některé ex-stanu, jsme přenášeli myšlenky Hender-syn a Brill (1999), do světa závislosti struktur. Lišíme se od nich v kontextu zkoumání vlastností hlouběji. Všechny naše experimenty byly kon-odváděny na českém, ale metoda je lan-guage-nezávislé. Byli jsme dokázali výrazně zlepšit po pars-ing nejlepší výsledek pro dané nastavení, známé doposud. Navíc naše experimenty ukazují, že i parsery hluboko pod stavem může přispět k celkovému zlepšení.","This paper explores the possibilities of improving parsing results by combining outputs of several parsers. To some ex-tent, we are porting the ideas of Hender-son and Brill (1999) to the world of dependency structures. We differ from them in exploring context features more deeply. All our experiments were con-ducted on Czech but the method is lan-guage-independent. We were able to significantly improve over the best pars-ing result for the given setting, known so far. Moreover, our experiments show that even parsers far below the state of the art can contribute to the total improvement."
"Dokument popisuje anotace Pražského závislostního korpusu na morfologické rovině. Vedle přehledu morfologických značek přináší také informace o značkách připojených k lemmatům. Na řadě příkladů rozebírá sporné situace, kde není na první pohled jasné, jakou značku zvolit.",The document describes annotation of the Prague Dependency Treebank on the morphological layer. Besides an overview of the morphological tags it also brings information about the tags attached to lemmas. It gives many examples to analyze difficult situations where it is not obvious what tag to use.
"Rozpoznávání souvislé řeči s rozsáhlým slovníkem flexivních jazyků jako čeština, ruština nebo srbochorvatšitna je silně negativně ovlivněno vysokým výskytem neznámých slov. V tomto článku řešíme problém výběru slovníku, jazykového modelování a prořezávání pro flexivní jazyky.","Large vocabulary continuous speech
recognition of inflective languages, such
as Czech, Russian or Serbo-Croatian, is
heavily deteriorated by excessive out of
vocabulary rate. In this paper, we tackle
the problem of vocabulary selection, language
modeling and pruning for inflective
languages. We show that by explicit
reduction of out of vocabulary rate we
can achieve significant improvements
in recognition accuracy while almost
preserving the model size. Reported
results are on Czech speech corpora."
"Závislostní syntaktickou analýzu (parsing) formalizujeme jako hledání maximální kostry v orientovaném grafu. Při této reprezentaci lze použít Eisnerův (1996) algoritmus pro prohledání všech projektivních stromů v čase O(n3). Překvapivě lze tuto reprezentaci přirozeně rozšířit na neprojektivní analýzu pomocí algoritmu Chu-Liu-Edmonds (1965, 1967). Výsledný algoritmus má složitost O(n2).","We formalize weighted dependency parsing as searching for maximum spanning trees (MSTs) in directed graphs. Using this representation, the parsing algorithm of Eisner (1996) is sufficient for searching over all projective trees in O(n3) time. More surprisingly, the representation is extended naturally to non-projective parsing using Chu-Liu-Edmonds (1965, 1967) MST algorithm, yielding an O(n2) parsing algorithm."
"Tento článek prezentuje metodu kořenových stromů a její využití pro závislostní parsing češtiny včetně souhrnu experimentů, které přibližují chybovost, popřípadě úspěšnost takto získaných závislostních stromů.","The paper presents rooted trees and their usage for dependency parsing of Czech, including a summary of experiments that demonstrate the error/success rate of the resulting dependency trees."
"Tato technická zpráva je dokumentací k Pražskému závislostnímu korpusu verze 2.0 (PDT 2.0). Obsahuje
podrobný komplexní popis dosavadních pravidel anotování českých vět na tektogramatické rovině,
a to především po stránce lingvistické, ale i po stránce technické. Anotovaná data neodráží vždy přesně
popisovaný stav pravidel anotace, proto je v technické zprávě zahrnut i co nejpřesnější popis anotovaných
tektogramatických stromů v korpusu PDT 2.0.","This technical document provides detailed documentation of the Prague Dependency Treebank, version
2.0 (PDT 2.0). It includes a detailed complex description of the rules that have been used so far for
the annotation of Czech sentences on the tectogrammatical layer both in linguistic and technical respect.
The annotated data do not always reflect the described state of the rules precisely, therefore the technical
document includes also a detailed description of the tectogrammatical trees that are annotated in
PDT 2.0."
"V tomto textu chceme čtenáře seznámit s možností formálního zavedení podkladové reprezentace
přirozeného jazyka, tedy s reprezentací, která zachycuje jazykový význam. Vycházíme přitom
z Funkčního generativního popisu, což je stratifikační, závislostně orientovaný popis češtiny. Přibližujeme zde přístupnou formou hlavní myšlenky článku Vl. Petkeviče A New Formal Specification of Underlying
Structures, který vyšel v časopise Theoretical Linguistics, vol. 21, No.1 v roce 1995.","In this article a new formal model of underlying representation of natural language is provided. As a background, Functional Generative Description of Czech is used. We aim at clear and comprehensive introduction of main ideas published by Vl. Petkevič in the article A New Formal Specification of Underlying Structures, Theoretical Linguistics, vol. 21, No.1, 1995."
"VALLEX je slovník sloves zaměřený na popis syntaktické informace užitečné pro NLP. Slovník obsahuje asi 2500 ručně anotovaných českých sloves s více než 6000 valenční rámce (léto 2005). V tomto příspěvku je představen VALLEX a popsán experiment, kde byl pomocí jednotlivých rámcům VALLEXu anotován korpus 10.000 instancí 100 českých sloves - mezianotátorská shody činila 75%. Část dat byla použita pro WSD, tedy pro automatické přiřazování významu, ve kterém jsme dosáhli úspěšnosti 78,5%.","VALLEX is a linguistically annotated lexicon aiming at a~description of syntactic
information which is supposed to be useful for NLP. The lexicon contains roughly 2500 manually annotated Czech verbs with over 6000 valency frames (summer 2005). In this paper we introduce VALLEX and describe an experiment where VALLEX frames were assigned to 10,000 corpus
instances of 100 Czech verbs -- the pairwise inter-annotator agreement reaches 75%.
The part of the data where three human annotators agreed were used for an automatic word sense disambiguation task, in which we achieved the precision of 78.5%."
Tento příspěvek vysvětluje principy závislostní redukční analýzy a její vztah závislostem a závislostním stromům. Závislostní redukční analýzu dokládá českými příklady charakteristickými slovoslednou volností. příspěvek shrnuje základní prvky metody závislostní syntaxe. Tato metoda slouží jako základ pro ověřování (a vysvětlení) přiměřenosti formální a výpočetních modelů z těchto metod.,"This paper explains the principles of dependency analysis by reduction and its correspondence to the notions of dependency and dependency tree. The explanation is illustrated by examples from
Czech, a language with a relatively high degree of word-order freedom. The paper sums up the basic features of methods of dependency syntax. The method serves as a basis for the verification (and explanation) of the adequacy of formal and
computational models of those methods."
V článku je popsáno anotační schéma koreference v Pražském závislostním korpusu. Dále je popsán a vyhodnocen nový systém na vyhledávání antecedentů osobních zájmen.,"The aim of this paper is two-fold. First, we want to present a part of the annotation scheme of the Prague Dependency Treebank 2.0 related to the annotation of coreference on the tectogrammatical layer of sentence representation (more than 45,000 textual and grammatical coreference links in almost 50,000 manually annotated Czech sentences). Second, we report a new pronoun resolution system developed and tested using the treebank data, the success rate of which is 60.4 %."
"Pražský závislostní korpus je využit k testování hypotéz o diskurzních vztazích, především v oblastio anafor.","A dependency based annotated corpus of Czech is used for testing several hypotheses
concerning topic/focus of the sentence."
"V příspěvku představujeme systém gramatémů, který byl koncipován ve Funkčním generativním popisu a dále rozpracován při anotaci Pražského závislostního korpusu 2.0 (PDT 2.0).","In the contribution, the work on the system of grammatemes (mostly semantically-oriented counterparts of morphological categories such as number, degree of comparison, or tense) is presented, The concept of grammatemes was introduced in Functional Generative Description, and is now further elaborated in the context of Prague Dependency Treebank 2.0."
"V příspěvku je představen systém gramatémů, který byl koncipován ve Funkčním generativním popisu a rozpracován při anotaci Pražského závislostního korpusu 2.0 (PDT 2.0). Gramatémy jsou nejčastěji významové protějšky morfologických kategorií, např. kategorie čísla nebo času.","In this paper we report our work on the system of grammatemes (mostly semantically-oriented counterparts of morphological categories such as number, degree of comparison, or tense), the concept of which was introduced in Functional Generative Description, and is now further elaborated in the context of Prague Dependency Treebank 2.0. We present also a new hierarchical typology of tectogrammatical nodes."
"Morfologické značkování je důležitý problém v oblasti počítačové lingvistiky, protože na něm staví další významné úlohy jako syntaktická analýza a strojový překlad. V současnosti se tento problém nejčastěji řeší statisticky. Další slibnou metodou jsou umělé neuronové sítě (ANN). V článku prezentujeme výsledky aplikace známé zpětné propagace (BP) na několik druhů experimentů.","Morphological tagging is an important problem in the area of computational linguistics as it underlies other crucial tasks such as syntactic parsing and machine translation. Nowadays, the problem is being most commonly solved by a statistical approach. Artificial neural networks (ANN) represent another promising approach to this kind of problems for which the exact algorithmic solution is unknown or not efficient enough. In this paper we present the results obtained by application of the well-known backpropagation (BP) neural network in several types of experiments. We have focused on the Czech morphology, because its morphological system is very rich and no experiments concerning application of artificial neural networks have been carried out for this language. First, we have verified on a set of preliminary experiments that the neural network is capable of capturing the Czech morphology, which, secondly, served also for determination of appropriate network and context parameters. Thirdly, we have used neural networks for a voting experiment. The aim of the voting experiment was to select the correct tag (if present) from the outputs of two statistical taggers, the Markov model tagger and the Featurebased tagger. In this experiment, BP showed higher tagging precision (93,56%) than any of the input statistical methods (92,74%, 92,58%) and exceeded even the currently best available statistical result (93,47%). BP has proved to be a worthy post-processing tool that is able to perform implicit evaluation on complementary aspects of different statistical approaches."
"Morfologické značkování je důležitý problém v oblasti počítačové lingvistiky, protože je předstupněm pro další zásadní úlohy jako syntaktickou analýzu a strojový překlad. V současné době je nejčastěji řešen statistickými metodami. Jiný slibný přístup k tomuto druhu problémů, pro které není známo nebo není dostatečně efektivní exaktní algoritmické řešení, představují umělé neuronové sítě (ANN). V tomto článku prezentujeme výsledky aplikace neuronových sítí s ""backpropagation"" (BP) na pokusy několika druhů.","Morphological tagging is an important problem in the area of computational linguistics as it underlies other crucial tasks such as syntactic parsing and machine translation. Nowadays, the problem is being most commonly solved by a statistical approach. Artificial neural networks (ANN) represent another promising approach to this kind of problems for which the exact algorithmic solution is unknown or not efficient enough. In this paper we present the results obtained by application of the well-known backpropagation (BP) neural network in several types of experiments. We have focused on the Czech morphology, because its morphological system is very rich and no experiments concerning application of artificial neural networks have been carried out for this language. First, we have verified on a set of preliminary experiments that the neural network is capable of capturing the Czech morphology, which, secondly, served also for determination of appropriate network and context parameters. Thirdly, we have used neural networks for a voting experiment. The aim of the voting experiment was to select the correct tag (if present) from the outputs of two statistical taggers, the Markov model tagger and the Feature-based tagger. In this experiment, BP showed higher tagging precision (93.56%) than any of the input statistical methods (92.74%, 92.58%) and exceeded even the currently best available statistical result (93.47%). BP has proved to be a worthy post-processing tool that is able to perform implicit evaluation on complementary aspects of different statistical approaches."
"Tento příspěvek představuje různé přístupy k sémantické klasifikaci sloves. Vychází z Funkčního generativního popisu, který představuje teoretický rámec valenčního slovníku VALLEX, a pokouší se formulovat základní kritéria pro vymezení syntakticko-sémantických tříd sloves. Tento přístup je demonstrován na příkladech některých slovesných tříd, jako jsou slovesa mluvení, myšlení, vnímání nebo výměny.","In the contribution, different approaches to verb classification are characterized. We briefly describe valency theory of Functional Generative Description that provides the theoretical background for valency lexicon VALLEX. The basic criteria for classifying verbs from the valency lexicon VALLEX are formulated. Some illustrative instances of delimitation of classes such as communication, mental action, perception, exchange and providing are introduced in this paper."
"Článek pojednává o metodách, kterými lze automaticky přiřazovat sémantické rámce pomocí syntakticko-sémantického rozhraní v lexikálních funkčních gramatikách.",The article discusses methods that can be used to automatically assign semantic frames using the Syntax-Semantics Interface in Lexical Functional Grammars.
"Pojem spisovnosti zastarává, je třeba nahradit ho ne tak ostře ohraničeným chápáním češtiny standardní.","The concept of ""literary"" language is getting obsolete, it should be changed into that of standard language, lacking clear boundary lines."
"Zavádíme nový typ restartovacích automatů, abychom získali prostředek umožňující klasifikaci jevů
souvisejících s valencí a slovosledem u přirozených jazyků. Studujeme dva základní typy omezení výpočtů:
j-roztržitost interpretujeme jako míru nesouvislosti valencí (redukcí) a j-volnost jako míru volnosti slovosledu.",We introduce a new type of restarting automaton as a means for classification phenomena related to valency and word order in natural languages. Two basic types of constraints are studied: j-abstractedness as a measure for discontinuity of valences and j-freedom as a measure for free word order.
"Průměrná redukovaná frekvence je číslo, které slouží k seřazení slov podle běžnosti. Na rozdíl od prosté frekvence bere v úvahu rozložení slov v korpusu, a tím se vypořádává s problémem výskytu slov ve shlucích.",Average reduced frequency is a value that should be used instead of pure frequency for ranking words according to their commonness. It takes into account not only number of occurrences but also the word distribution within the whole corpus.
"V příspěvku je popsán experiment s automatickým překladačem Česílko, který překládá mezi blízkými jazyky, konkrétně češtinou a slovenštinou. Experiment byl proveden na české a slovenské verzi Orwellova románu 1984.","The contribution will describe an experiment with the automatic translational tool Česílko that was designed for translation between very close languages, namely Czech and Slovak. We had at our disposal the Czech version of the Orwell's novel 1984, morphologically annotated, and the Slovak version without the annotation. We automatically translated the Czech version into Slovak and compared the result with the automatic morphological annotation of the Slovak version. We evaluated the experiment using manually annotated part of the Slovak version.

During the experiment we had to deal with different non-consistent morphological tagsets used for the annotation of different input data.
Conversions among them made the hardest problems of the whole work. The contribution will concentrate on overcoming inconsistent tagsets, as the problem is quite common."
"Tento článek popisuje návrh švédského valenčního slovníku, jehož mikrostruktura (struktura slovníkového hesla) by byla obohacena o informaci o telicitě a způsobu slovesného děje.",This article presents a proposed Swedish valency lexicon. The lexicon microstructure contains additional event-structure information.
"Tento příspěvek se zabývá podstatnými jmény, které figurují v jmenných částech tzv. analytických predikátů.",This contribution addresses nouns in light verb constructions and their lexicographical description for NLP purposes.
"Druhý základní problém s touto knihou je, že pro většinu z ka -
ters Cachia draws on texts which appeared before 1970. vat Cachia čerpá z textů, které se objevily před rokem 1970. Modern Arab literature Moderní arabské literatuře
develops fast, and this is particularly true of the last twenty-five years. rychle vyvíjí, a to platí především za posledních dvacet pět roků. Some char- Některé char -
acteristics which he apparently sees as still valid have now been modified. acteristics kterou zřejmě považuje za stále platné již byly upraveny. As far as Co se týče
'Islamic inspiration' is concerned, Sufism has formed a point of reference for two 'Islámský inspirace' se obává, Súfismus vytvořila referenční bod pro dva
leading Egyptian writers of the post-Mahfuz generation. přední egyptský spisovatelé post-Mahfuz generace.","The second fundamental difficulty with this book is that for most of the chapters
Cachia draws on texts which appeared before 1970. Modern Arab literature
develops fast, and this is particularly true of the last twenty-five years. Some characteristics
which he apparently sees as still valid have now been modified. As far as
'Islamic inspiration' is concerned, Sufism has formed a point of reference for two
leading Egyptian writers of the post-Mahfuz generation."
Předvádíme korektivní model pro získávání neprojektivních závislostních struktur ze stromů generovaných nejlepšími dostupnými parsery založenými na složkách.,We present a corrective model for recovering non-projective dependency structures from trees generated by state-of-the-art constituency-based parsers.
V příspěvku popisujeme automatické rozpoznání derivačních předpon českých slov. Metoda spočívá v použití dvou statistických měr - Entropie a Ekonomického principu. Experimenty byly prováděny se seznamem téměř 170 tisíc lemmat z Českého národního korpusu.,"This paper describes the application of a method for the automatic, unsupervised recognition of derivational prefixes of Czech words. The technique combines two statistical measures - Entropy and the Economy Principle. The data were taken from the
list of almost 170 000 lemmas of the Czech National Corpus."
Článek popisuje konverzi slovníku povrchové valence českých sloves na slovník povrchové valence deverbativních adjektiv. Po manuální přípravě dat je celá konverze plně automatická a veškeré změny ve zdrojovém slovníku se automaticky odrazí ve slovníku cílovém.,"This paper describes conversion of a surface valency lexicon of Czech verbs
to a surface valency lexicon of adjectives that can be derived from these
verbs and that use their (possibly modified) valency frames. After
preparing the necessary data by hand, the conversion can be fully automatic
and every change of the source lexicon can be automatically reflected in
the destination lexicon. We have successfully converted the verb valency
lexicon Brief with about 15,000 verbs to a valency lexicon of about
27,000 deverbal adjectives. The paper also describes some interesting
peculiarities in the process of creating passive adjectives and their
valency frames."
Článek popisuje spolupráci čtyř evropských univerzit zaměřenou na popularizaci evropských magisterských studií v oblasti jazykových a komunikačních technologií. Tato spolupráce byla formálně posvěcena v rámci programu Erasmus Mundus jako Zvláštní podpůrná akce v roce 2004. Konsorcium se také zaměřuje na vytvoření pevného základu púro společný magosterský program v oblasti jazykových technologií a informatiky.,This paper describes the cooperation of four European Universities aiming at attracting more students to European mas-ter studies in Language and Communica-tion Technologies. The cooperation has been formally approved within the frame-work of the new European program “Erasmus Mundus” as a Specific Support Action in 2004. The consortium also aims at creating a sound basis for a joint master program in the field of language technol-ogy and computer science.
"Cílem předložené práce je vytvořit metody pro automatické přiřazování morfologických vzorů českým slovům. Nejprve je provedena analýza problému, ve které jsou zdůrazněny některé podproblémy, se kterými se musíme vypořádat. Poté jsou navrženy čtyři různé algoritmy pro výběr z možných vzorů, pracující na základě analýzy slova a jeho kontextu. Dále jsme navrhli algoritmus pro rozdělení množiny slov na třídy ekvivalence podle společného lemmatu. Pro odhad optimálních parametrů jednotlivých metod jsme použili různé zdroje dat, na kterých jsme provedli přes 250 testů s různými hodnotami parametrů. Součástí
práce je popis použitých algoritmů a jejich implementace v programovacích jazycích Perl a C++.","Aim of the presented work is to explore possibility of automatic morphological paradigms assignment for the Czech words. Theoretical part of our work consists of the problem analysis with emphasized issues we have to deal with. We present four different algorithms for morphological paradigm assignment, using both word form analysis and contextual information processing. Word forms are partitioned into equivalence classes according to their lemma, using another algorithm. We performed more than 250 tests on the various corpus data with the purpose of estimating best method parameters. Presented algorithms are thoroughly described and implemented."
"Statistické rozhodovací pravidla mohou být využita v genetice, přesněji v odvětví microarray, za účelem klasifikace proteinů do několika několika tříd, a to podle informací shrnutých v několika naměřených proměnných.

Příspěvěk pojednává o použití metody Fisherovy lineární diskriminační analýzy na reálná data o 268 proteinech klasifikovaných použitím 400 proměnných do 42 tříd. Takovýto klasifikační problém je typický v microarray, kde počet proměnných překračuje počet pozorovaných objektů (tzv. p>>n problém). Data byla již dříve studována; souhrn všech výsledků lze nalézt na http://www.dkfz.de/biostatistics/protein/DEF.html. Byly použity lineární i neliární metody, nejnižší chybovost bylo dosaženo pomocí Support Vector Machines.

Bude přestavena implementace Fisherovy (lineární) discriminační analýzy, která může v chybovosti konkurovat i nelineárním metodám. Bude přiloženo i porovnání této nové implementace s klasickou implementací funkcí lda() ve výpočetním prostředí R (http://www.r-project.org).","Statistical decision rules can be used in genetics, more accurately in microarray, to classify proteins into several classes according information taken from other measured variables.

The contribution concerns on using Fisher linear discriminant analysis on a real data consisting of 268 proteins classified according 400 variables into 42 classes. The classification task of such a case is typical for microarray where number of variables is higher than number of observed objects (also known as  p>>n problem). The data was investigated several times earlier; the project web page of these studies as well as with other results is http://www.dkfz.de/biostatistics/protein/DEF.html. A lot of linear and nonlinear methods was used, the lowest error was reached with nonlinear method called Support Vector Machines.

It will be shown that with a good implementation of Fisher discriminants the linear method can beat nonlinear ones. A small comparison with classical implementation by lda() function in R (http://www.r-project.org) will be shown as well."
"Statistická metada Fisherovy lineární diskrimianční analýzy slouží je jedna z nejoblíbenějších a nejstarších klasifikačních metod. Byla původně definována ve 30. letech 20. století pomocí rovnic. Později numericky přeformulována jako úloha řešení vlastních čísel a vlastních vektorů symetrické pozitivně semi-definitní matice.
Zde přestavujeme některé méně známé aspekty impelementace, které mohou výrazně urychlit výpočty a zlepšit výsledné hodnoty.","The Fisher linear discriminat analysis is one of the most used and the oldest of the classification methods. Originally, it was defined at the thirties of the twentieth century by the equations. Later, it was numerically refolmulated as the eigen-decomposition task of the symmetric positive semi-definitive matrix. We are presenting some less known aspects of the implementation that can significantly speed-up calculations and improve output values."
"V příspěvku zkoumáme numerické aspekty klasifikace při použití různých implementací Fisherovy lineární diskriminační analýzy (FLDA). FLDA je založena na maximalizačním kritériu poměru mezitřídního a vnitrotřídního rozptylu daných proměnných. Maximalizační problém je často řešen jeho redukcí na obecný symetrický problém vlastních čísel a vektorů definovaný pomocí mezitřídní a vnitrotřídní kovarianční matice. Tyto matice jsou ovšem singulární, pokud počet proměnných překročí počet objektů pozorovaných při trénování. Následkem čehož se efektivní numerické řešení problému vlastních čísel a vektorů stává významným [1], v historii bylo použito již několik technik, jak se singularitou matic v FLDA zacházet [2]. V těchto kamparativních studiích jsou ovšem na úkor klasifikačního výkonu zanedbávány numerické aspekty jako výpočetní a pamětové nároky. Zaměříme se na vztah mezi implementací a výkonem metody FLDA. Přidáme porovnání několika populárních implementací, včetně detailů o numerické stabilitě, pamětových a komputačních nákladech a odhadů komputačních chyb. Dále předkládáme numerické výsledky vzniklé aplikací vybraných metod na data z klasifikace proteinů [3], rozdíly v klasifikačním výkonu je udivující. Implementace založena na Moore-Penrosově pseudoinverzi svým výkonem převyšuje všechny ostatní strategie, včetně metody Support Vector Machines, která je obecně považováná za nejúčinnější pro tato data. Závěrem zmiňujeme důsledky tohoto pozorování, možná rozšíření na další úlohy a přehled relevantního softwaru.
Reference:
[1] Z. Bai, J. Demmel, J. Dongarra, A. Ruhe and H. van der Vorst (eds.) (2000): Templates for the solution of Algebraic Eigenvalue Problems: A Practical Guide. Philadelphia, SIAM
[2] Y.-Q. Cheng,  Y.-M. Zhuang and  J.-Y. Yang (1992): Optimal Fisher discriminant analysis using the rank decomposition. Pattern recognition, vol. 25, 101--111
[3] L. Edler  and J. Grassmann  (1999): Protein fold prediction is a new field for statistical classification and regression. In Seillier-Moiseiwitsch F(Ed): Statistics in Molecular Biology and Genetics. IMS Lecture Notes Monograph Series 33, 288--313","In this contribution we investigate numerical aspects of classification using various implementations of Fisher's linear discriminant analysis (FLDA). FLDA is based on maximizing the ratio of between-group variance to within-group variance of given variables. The maximization problem is frequently solved by reducing it to the symmetric generalized eigenproblem defined by the between-group and the within-group covariance matrices. Unfortunately, these matrices are singular in classification tasks where the number of given variables exceeds the number of objects for training. Consequently, efficient numerical solution of the eigenproblem becomes a challenging problem (see, e.g. [1]) and several techniques to handle the singularity have been proposed in the literature about FLDA (see, e.g. [2]). In comparative studies of these techniques, however, assessment of classification performance more or less discards numerical aspects such as computational or storage costs.
We focus on the relation between implementation and performance of FLDA. We give a comparison of a number of popular FLDA implementations including detailed information about their numerical stability, storage costs, computational costs and estimation of computational error. Moreover, we provide numerical examples by applying the discussed methods to a particular protein classification problem (see, e.g. [3]). The differences of classification performance are striking. An implementation based on reduction to a classical eigenproblem via Moore-Penrose pseudeoinverses outperforms all other strategies, including the Support Vector Machines approach that is generally considered the most powerful for the given data. We discuss some consequences of this observation and possible extension to other types of problems and conclude with a brief overview of relevant software.
References:
[1] Z. Bai, J. Demmel, J. Dongarra, A. Ruhe and H. van der Vorst (eds.) (2000): Templates for the solution of Algebraic Eigenvalue Problems: A Practical Guide. Philadelphia, SIAM
[2] Y.-Q. Cheng,  Y.-M. Zhuang and  J.-Y. Yang (1992): Optimal Fisher discriminant analysis using the rank decomposition. Pattern recognition, vol. 25, 101--111
[3] L. Edler  and J. Grassmann  (1999): Protein fold prediction is a new field for statistical classification and regression. In Seillier-Moiseiwitsch F(Ed): Statistics in Molecular Biology and Genetics. IMS Lecture Notes Monograph Series 33, 288--313"
"Tato práce navazuje na implementačně-výzkumný projekt Morče, jehož cílem bylo vytvoření co nejlepšího morfologického taggeru češtiny, založeného na skrytém Markovově modelu s průměrovaným perceptronem. Úspěšnost algoritmu závisí především na zvolené sadě rysů popisujících kontext, na jehož základě se značky vybírají. Práce stručně popisuje zvolený algoritmus a jeho implementaci. Její stěžejní část spočívá ve velké řadě provedených experimentů, které v rámci daných možností důkladně mapují možné sady rysů, jejich úspěšnosti a vztahy mezi nimi. Pro tento účel jsou definována pravidla, podle kterých se verze porovnávají. Využívá se pětinásobná crossvalidace a pro zjištění statistické významnosti výsledků je aplikován t-test. Při zahájení práce byla dána k dispozici nová data pro češtinu, takže veškeré experimenty se již prováděly nad daty z PDT 2.0. Vedlejším výsledkem práce je i statisticky významné zvýšení úspěšnosti taggeru, nicméně nejlepší tagger zřejmě překonán nebyl. Kromě ručního vývoje verzí byl projekt také upraven pro automatický vývoj, který byl v menším rozsahu proveden a popsán.","This work continues in implementational and experimental project Morče, which aimed to create the best possible morphological Czech tagger based on hidden Markov model with averaged perceptron. Successfulness  of algorithm depends mainly on a selected set of features describing a context, which determines choice of a tag. The work describes briefly the algorithm and its implementation. Main part of the work consists of a lot of experiments which explore possible feature sets, their successfulness and their relationships. Few clear rules are defined for comparison of versions. Fivefold crossvalidation with t-test is used for verification of statistical significance. After the work was started, new Czech data became available, so all experiments used data from PDT 2.0. Side effect of this work was statistical significant improvement of successfulness. However, the best Czech tagger was obviously not overwhelmed. Some modifications were made in order to perform automatic version development. It was executed in small extent and also described."
"Článek prezentuje systém strojového překladu z češtiny do dolnolužické srbštiny, menšinového jazyka používaného v Německu v okolí Chotěbuze. Popisujeme architekturu systému a zaměřujeme se na morfologickou disambiguaci, částečný syntaktický parser a transfer.","The paper presents a machine translation system from Czech to Lower Sorbian, a minority language spoken in a region around Cottbus in Germany. This West Slavonic language, which is spoken by less than 20,000 people, is very archaic, it, has supine, dual and some other grammatical forms, which disappeared in most Slavonic languages. The paper describes the architecture of the system and focuses on morphological disambiguation, partial syntactic parser and lexical and structural transfer. First evaluation results on a small set of sentences are also presented."
"Přehled zejména syntaktických jevů, jejichž užívání v humanistické češtině bylo podpořeno vzorem klasické latiny.",Overview of syntactic phenomena in Humanistic Czech usage of which was supported by the ideal and language example of Classic Latin.
Slovosledné postavení jednoslovného slovesného přísudku ve vybraných typických syntaktických konstrukcích.,Word order position of one-word verbal predicate in specific syntactic constructions.
"Předsuny kvalifikačních, kvantifikačních a negačních výrazů na počátek věty a jejich vztah k aktuálnímu členění (kontrast, réma).","The initial position of qualifying, quantifying and negative expressions in a sentence and their relation to the functional perspective of the sentence (contrast, rheme)."
"Cílem tohoto článku je prezentovat počáteční výsledky adaptace SProUTu, vícejazyčné platformy pro počítačové zpracování přirozeného jazyka, pro polštinu. Článek popisuje některé problémy způsobené integrací Morfeusze, externího morfologického analyzátoru polštiny, a různá řešení problému neexistujících rozsáhlých polských zeměpisných slovníků.","The aim of this article is to present the initial results of adapting SProUT, a multi-lingual Natural Language Processing platform developed at DFKI, Germany, to the processing of Polish. The article describes some of the problems posed by the integration of Morfeusz, an external morphological analyzer for Polish, and various solutions to the problem of the lack of extensive gazetteers for Polish. The main sections of the article report on some initial experiments in applying this adapted system to the Information Extraction task of identifying various classes of Named Entities in financial and medical texts, perhaps the first such Information Extraction effort for Polish."
Článek popisuje pokus o implementaci závislostní gramatiky pro četšinu ve formalismu Extensible Dependency Grammar (XDG) založeném na omezujících podmínkách.,"This article describes an attempt to implement a constraint-based dependency
grammar for Czech, a language with rich morphology and free word order, in the
formalism Extensible Dependency Grammar (XDG). The grammar rules are
automatically inferred from the Prague Dependency Treebank (PDT) and constrain
dependency relations, modification frames and word order, including
non-projectivity. Although these simple constraints are adequate from the
linguistic point of view, their combination is still too weak and allows an
exponential number of solutions for a sentence of n words."
"# Obsahuje 37 původních článků napsaných vůdčími osobnostmi oboru.
# Zabývá se ústředními otázkami sdílenými zájemci o obor.","# Contains 37 original articles written by leaders in the field.
# Addresses the central concerns shared by those interested in the subject.
# Major sections focus on the experience of particular disciplines in applying computational methods to research problems; the basic principles of humanities computing; specific applications and methods; and production, dissemination and archiving.
# Accompanied by a website featuring supplementary materials, standard readings in the field and essays to be included in future editions of the Companion."
"Článek popisuje anotaci korpusu mluvené češtiny - nahrávek z archívu Shoa VHF a problémy s tím spojené, např. kvalitu těchto nahrávek z akustckého hlediska.","The paper describes the problems adn solutions to the annotation of the Czech recordings in the Shoa VHF collection, e.g. the problems related to the acoustic quality etc."
"V článku probíráme některé problémy spojené s podmínkou projektivity v závislostním popisu jazyka (viz Sgall, Hajičová a Panevová (1986), Hajičová, Partee a Sgall (1998)) se zvláštním zřetelem na anotační schéma Pražského závislostního korpusu (PDT, viz Hajič (1998)).","In the present paper we discuss some issues connected with the condition of projectivity in a dependency based
description of language (see Sgall, Hajičová, and Panevová (1986), Hajičová, Partee, and Sgall (1998)), with a
special regard to the annotation scheme of the Prague Dependency Treebank (PDT, see Hajič (1998)). After a short
Introduction (Section 1), the condition of projectivity is discussed in more detail in Section 2, presenting its formal
definition and formulating an algorithm for testing this condition on a subtree (Section 2.1); the introduction of
the condition of projectivity in a formal description of language is briefly substantiated in Section 2.2. and some
problematic cases are discussed in Section 2.3. In Section 3, a preliminary classification into three main groups
and several subgroups of Czech non-projective constructions on the analytical level is presented (Section 3.1),
with illustrations of each subgroup in Section 3.2. A discussion of (surface) non-projectivities viewed from the
perspectives of the underlying (tectogrammatical) structures is given in Section 4; the classification outlined in
Section 4.1 reflects the types of deviations from projectivity caused by topic-focus articulation (TFA). In Section
4.2 we examine the motivation and factors of non-projective constructions. The treatment of non-projective
constructions in the annotation scenario of PDT is presented in Section 5. In the Conclusion (Section 6) we summarize
the results and outline some directions for further research in this domain. The present contribution is an
enlarged and slightly modified version of the paper Veselá, Havelka, and Hajičová (2004)."
"Finite State Morphology. Vydal CSLI Publications, Stanford, Kalifornie, 2003 (CSLI Studies in Computational Linguistics, xviii+510 pp a CD-ROM, ISBN 1-57586-434-7)","Finite State Morphology. CSLI Publications, Stanford, California, 2003 (CSLI Studies in Computational Linguistics, xviii+510 pp and CD-ROM, ISBN 1-57586-434-7)"
"Datově-orientovaná syntaktická analýza je název pro originální statistický přístup k syntaktické analýze, který se učí výskyty jednotlivých podstromů.",Data-oriented parsing is a name for a novel statistical approach to syntactic parsing that learns occurrences of subtrees.
Cílem této technické zprávy je popsat neprojektivní konstrukce v Pražském závislostním korpusu.,The goal of this technical report is to describe non-projective constructions in the Prague Dependency Treebank.
"Tato disertační práce popisuje statistický parser (syntaktický analyzátor) češtiny. Krok za krokem v ní analyzujeme vývoj parseru a přínos jednotlivých jeho částí. Parser je postaven na metodě přímého statistického modelování závislostí mezi slovy, která je originální i při srovnání se zahraničními pracemi. Přestože se nepodařilo tímto způsobem získat nejúčinnější možný nástroj pro syntaktickou analýzu češtiny a existují české adaptace původně anglických parserů, které si vedou lépe, ukážeme, že díky odlišnému přístupu dělá náš parser chyby jiného druhu a lze tedy jeho kombinací s lepšími parsery dosáhnout výsledku, kterého žádný z nich není sám o sobě schopen.","This thesis presents a statistical parser of Czech. We analyze step by step its evolution and the merit of its various parts. The parser is based on the original approach of dependency bigram modeling. Although there are other parsers that have been originally developed for English and their adaptations for Czech perform better than ours, we demonstrate that our parser makes different errors and thus it can help the better parsers to become even better."
"Článek popisuje počítačovou aplikaci vyvinutou týmem autorů na Univerzitě Karlově v Praze, jejímž cílem je podpořit víceaspektové zpracování příkladů kulturního dědictví v inteligentním prostředí informačních technologií.","The article presents a description of a computer application, developed by a team of authors at the Charles University in Prague, meant to support a multiaspect processing of examples of the cultural heritage in the intelligent environment of the information technologies. Provided is a possibility for the application to be used when describing and analyzing medieval manuscripts, experimented in the project of the Faculty of Mathematics and Physics Annotation corpora of Text (ACT, see http://prometheus.ms.mff.cuni.cz/act). The system is a linguistically-independent product for lexical and corpora processing of written texts. It has been created with the purpose to process large corpora with linguistic annotation, which mostly includes lexicographic and morphological analysis, and the syntactic and semantic information is marked on basic level. The system allows the users when working at different places, to compare the data between one another, and to keep the results regardless of the number of specialists working at the same time. A product which completely solves the problems of the linguistic analysis of medieval records with the help of computers is offered."
"V tomto článku vyložíme podstatu  závislostní redukční analýzy
(DAR, dependency analysis by reduction) a její souvislost s pojmy
závislost a závislostní strom. Výklad budeme ilustrovat příklady z
češtiny, což je jazyk s (výrazně) volným slovosledem.
Tento výklad shrnuje základní rysy vývojových postupů závislostní syntaxe.
 Bude využit jako podklad pro ověřování (a vysvětlování) adekvátnosti
 formálních a počítačových modelů těchto postupů.","The syntactic structure of English sentences or sentences of other fixed word-order language is commonly described by phrase structure grammars. The description of syntactic structure of Latin, Italian, German, Arabic, Slavic languages and some other languages is more often based on approaches generally called dependency approaches. Both approaches are based
on stepwise simplification of individual sentences, on the so-called analysis by reduction (AR). The basic principles of the phrase-structure and dependency based analysis by reduction are substantially different. The phrase-structure based analysis (of fixed word-order languages) can be naturally modeled by the
bottom-up analysis using phrase structure (Chomskian) grammars. However, this type of grammars cannot model naturally the dependency analysis by reduction (of free word-order languages). In this paper we explain the basic principles of dependency analysis by reduction
(DAR) and its correspondence to notions used in the traditional dependency oriented linguistics."
Tato recenze se zabývá slovníkem švédských pomístních jmen editovaný Matsem Wahlbergem.,This review focuses the dictionary of Swedish location names edited by Mats Wahlberg.
Analýza obecných funkcí predikátu a jejich uplatnění v humanistické češtině,Analysis of general functions of predicate and their implementation in Czech in the period of humanism
"Článek popisuje valenční slovník PDT-Vallex, který je  propojený s reálnými texty v Pražském závislostním korpusu. Pojetí valence vychází z FGP jazyka.","The paper describes the PDT-Vallex valency dictionary, which is linked to real texts in the  Prague Dependency Treebank The concept of valency is based on the FGD."
"Abstrakt tohoto článku není k dispozici, protože autoři žádný nedodali.",No abstract of this paper is available because the authors have not provided any.
"Na moderní valenční slovník klademe řadu požadavků. Kromě strojové čitelnosti a dostatečné explicitnosti použitého popisu jde zejména
o kvalitu dat ve slovníku obsaľených. V článku přibližujeme nástroje navržené pro testování konzistence a úplnosti slovníku VALLEX. Rozebíráme metody využívané pro zvýšení jeho kvality od odstraňování technických chyb přes porovnání s existujícími lexikografickými zdroji po testování vnitřní konzistence
budovaného slovníku.",There are number of requirements put on vaůency dictionaries. We focus on testing the consistency and completeness of a valency lexicon of Czech verbs VALLEX.
"Short Czech abstract must be provided for all publications regardless their original language. Minimum is 64 characters, there is no upper bound but long abstracts will be truncated when reporting the publication.","Short English abstract must be provided for all publications regardless their original language. Minimum is 64 characters, there is no upper bound but long abstracts will be truncated when reporting the publication."
"K tomuto článku není abstrakt k dispozici, protože autoři žádný nedodali.",No abstract of this paper is available because the authors have not provided any.
V současné době existuje poměrně velká základna publikací o automatickém získávání lexikálně-syntaktických preferencí (valence) z korpusů.,"Today there is a relatively large body of work on automatic acquisition of lexico-syntactical preferences (subcategorization) from corpora. Various techniques have been developed that not only produce machine-readable subcategorization dictionaries but also they are capable of weighing the various subcategorization frames probabilistically. Clearly there should be a potential to use such weighted lexical information to improve statistical parsing, though published experiments proving (or disproving) such hypothesis are comparatively rare. One experiment is described in (Carroll et al., 1998) — they use subcategorization probabilities for ranking trees generated by unification-based phrasal grammar. The present paper, on the other hand, involves a statistical dependency parser. Although dependency and constituency parsing are of quite a different nature, we show that a subcategorization model is of much use here as well."
"Detris je šablona obsahující makro, s jehož pomocí můžete vytvářet jednotně vypadající závislostní stromečky do svých článků ve Wordu. Stromečky jsou reprezentované jako vektorová grafika, což znamená, že při změně jejich velikosti, popř. grafického rozlišení obrazovky nebo tiskárny bude minimalizován negativní dopad na vzhled stromu („schodovité čáry“ apod.) Vstupem makra je popis stromečku ve formátu CSTS, který je použit i v Pražském závislostním korpusu (PDT) verze 1. Stačí tedy do vašeho dokumentu okopírovat příslušnou část CSTS souboru, kde je popsána vaše věta. Pokud vytváříte umělý příklad, který není odkud zkopírovat, můžete použít značně zjednodušenou podmnožinu CSTS.","Detris is a template with a macro that helps you to create uniformly looking dependency trees for your documents in Word. The trees are represented as vector graphics which means that on changing their size, screen or printer resolution the deterioration will be minimal. Input is a tree description in the CSTS format, used in Prague Dependency Treebank (PDT) version 1. You can directly copy the corresponding part of the CSTS file to your document. If you are creating an artificial example that cannot be copied from anywhere, you can use a simplified subset of CSTS."
"Článek je studií vnějších faktorů, které mohou mít negativní vliv na úspěšnost parserů.","This paper is a study of outside factors that may have a negative impact on parsers’ accuracy. The discussed phenomena can be divided into two classes, those related to treebank design, and those related to morphological tagging. Although the scope of the paper is limited to the Prague Dependency Treebank, two particular taggers and one particular parser, we believe that our observations may be of interest to future treebank designers.

Anyway, since training parsers is usually not the only purpose of building treebanks, other good reasons may prevail and push aside the parser’s preferences. For that case, we suggest how the parser may work around the nasty input. More fine-grained elaboration of these workarounds and their evaluation is a matter of future work."
"K tomuto článku není k dispozici abstrakt, protože ho autoři nedodali.",No abstract is available for this paper because the authors have not provided any.
"De Cock M., Žabokrtský Z. and Kerre E. E. (2001): Representing
linguistic hedges by L-fuzzy modifiers. — Proc.
CIMCA’01 (Int. Conf. Computational Intelligence for
Modelling Control and Automation), Las Vegas (USA),
pp. 64–72 (CD-ROM).","L-fuzzy modifiers based on L-fuzzy relations prove to be
powerful tools for the representation of linguistic hedges.
They provide a general framework that is far more applicable
than the traditional approaches, and even in the
cases where traditional fuzzy hedges can be used, they
are still clearly outperformed by the fuzzy relation based
modifiers on the semantic level."
Článek popisuje pokusy s kombinováním statistického parseru a preprocesoru založeného na regulárních výrazech.,"The present paper describes experiments on combining a statistical parser with a preprocessor built of regular expres­sions. While the syntactic structure of a sentence may be very complex and will never be fully covered by such simple machine, there are phenomena such as noun phrases and simple coordinations that do quite well. Even these “chunks” may theoretically be unlimitedly complex but we show that in reality they rarely do. So a shallow parser based on regular expressions can be built to preprocess the input text and solve the simple chunks without introducing too many errors. We discuss one implementation of such preprocessor that is very easy to write and covers roughly 20% of input words with an accuracy of over 90%. Then we describe two ways of combining the preprocessor with a parser and show that the performance of the parser improves both in speed and accuracy."
"Článek podává zprávu o probíhajícím projektu, který se snaží kombinovat statistické modelování s ručně psanými regulárními výrazy pro syntaktickou analýzu češtiny.","This paper reports on a work in progress, which tries to combine statistical modeling and manually written regular rules for parsing Czech. While the syntactic structure of a sentence may be very complex and will never be fully covered by a finite-state machine, there are phenomena such as noun phrases and simple coordinations that do quite well. Even these “chunks” may theoretically be unlimitedly complex but I show that in real world they rarely do. So a shallow finite-state parser can be built to preprocess the input text and solve the simple chunks without introducing too many errors. With a minimum of programming effort, such preprocessor currently covers almost 20% of input words with an accuracy of more than 90%. Further increasing of the coverage without loss of accuracy would require much more effort, so the rest is left for the statistical parser."
"Vývoj počítačových technologií a počítačového zpracování jazykových dat spolu
s převratnými změnami v obou složkách jsou spolu zcela neodmyslitelně spjaty. Jejich
vzájemnou souvislost i podmíněnost nových možností automatického zpracování přirozeného
jazyka v kontextu nových informačních technologií se tu pokusíme ukázat
z hlediska dneška",The development of computer technology and computational processing of language data are related to each other.
Představujeme nové metody strojového učení pro identifikaci slovesných rámců v češtině.,"We present some novel machine learning techniques for the identification of subcategorization information for verbs in Czech. We compare three different statistical techniques applied to this problem. We show how the learning algorithm can be used to discover previously unknown subcategorization frames from the Czech Prague Dependency Treebank. The algorithm can then be used to label dependents of a verb in the Czech treebank as either arguments or adjuncts. Using our techniques, we are able to achieve 88 % accuracy on unseen parsed text."
"Recenze na knihu Stochastically-Based Semantic Analysis, vydanou nakladatelstvím Kluwer v roce 1999","A review of the book Stochastically-Based Semantic Analysis, published by the Kluwer publishing house in 1999"
Představujeme nové metody strojového učení pro identifikaci slovesných valenčních rámců v češtině.,"We present some novel machine learning techniques
for the identification of subcategorization information
for verbs in Czech. We compare three different
statistical techniques applied to this problem. We
show how the learning algorithm can be used to discover
previously unknown subcategorization frames
from the Czech Prague Dependency Treebank. The
algorithm can then be used to label dependents of
a verb in the Czech treebank as either arguments
or adjuncts. Using our techniques, we are able to
achieve 88% precision on unseen parsed text."
"Syntaktická analýza přirozených jazyků je úloha, kterou se pokoušela řešit řada lidí v minulosti, v současnosti a nepochybně také v budoucnosti. Všeobecně se předpokládá, že pokud dokážeme automaticky získat dobrý rozbor dané vstupní věty (např. funkce slov a vztahy mezi nimi), budou z něj mít užitek všechny úlohy související s ""porozuměním jazyku"".","Parsing natural languages is a task approached by many people in the past and present and undoubtedly also in the future. It is widely believed that if one can obtain automatically a good parse for a given input sentence (i.e. functions of the words and relations between them), then all the ""language understanding"" tasks can profit from it.

English has been studied most for this purpose and many good results have been obtained, especially using statistically-based techniques coupled with automatic learning from large annotated corpora. However, these techniques have not been applied to other languages than English very much, especially to languages which display substantially different behavior (both morphologically and syntactically) than English (such as Slavic languages, spoken mostly in Europe by approx. 350 million people)."
"Syntaktická analýza přirozených jazyků je úloha, kterou se pokoušela řešit řada lidí v minulosti, v současnosti a nepochybně také v budoucnosti. Všeobecně se předpokládá, že pokud dokážeme automaticky získat dobrý rozbor dané vstupní věty (např. funkce slov a vztahy mezi nimi), budou z něj mít užitek všechny úlohy související s ""porozuměním jazyku"".","Parsing natural languages is a task approached by many people in the past and present and undoubtedly also in the future. It is widely believed that if one can obtain automatically a good parse for a given input sentence (i.e. functions of the words and relations between them), then all the ""language understanding"" tasks can profit from it.
English has been studied most for this purpose and many good results have been obtained, especially using statistically-based techniques coupled with automatic learning from large annotated corpora. However, these techniques have not been applied to other languages than English very much, especially to languages which display substantially different behavior (both morphologically and syntactically) than English (such as Slavic languages, spoken mostly in Europe by approx. 350 million people)."
"Článek je založen na mé diplomové práci, která byla obhájena na Univerzitě Karlově v květnu 1997.","The present paper is based on my master thesis that was defended at Charles University in May 1997. I introduce here a simple probabilistic model of Czech syntax, based on training data extracted from a text corpus. Then I try to employ this model in building syntactic trees of Czech sentences. In this paper, a brief description of the model is given, as well as a summary of the test results. The work is one of the first attempts to use statistical learning methods for parsing of Czech. It is to be said here that the procedures used to parse English cannot be easily ported to Czech because some specific characteristics of Czech (free word order, and rich flexion implying a huge number of word forms) cause a different behaviour of a parser. The work presented is neither final, nor satisfying solution of the problem. It rather demonstrates the primary results and proposes some basic ideas of further research."
"Vypracovat matematický model významových zápisů vět
    Vypracovat program (C/C++) pro
        zjištění pravděpodobnosti daného zápisu na základě modelu
        generování zápisů na základě vedlejší informace
        zjištění hodnot entropie, křížové entropie a perplexity","Create a mathematical model of sentence meaning. Create a program (C/C++) to estimate probability of a given structure based on the model; to generate structures based on additional information; to compute entropy, cross entropy and perplexity."
